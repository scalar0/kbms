Mathématiques et Applications
For further volumes: http://www.springer.com/series/2966
Directeurs de la collection : J. Garnier et V. Perrier
71


Re ́ mi ABGRALL Inst. Math., Inst. Polytechnique de Bordeaux, FR remi.abgrall@inria.fr
Gre ́ goire ALLAIRE
CMAP, E ́ cole Polytechnique, Palaiseau, FR gregoire.allaire@polytechnique.fr
Michel BENAI ̈ M Inst. Math., Univ. de Neuchaˆ tel, CH michel.benaim@unine.ch
Maı ̈ tine BERGOUNIOUX MAPMO, Universite ́ d’Orle ́ ans, FR maitine.bergounioux@univ-orleans.fr
Thierry COLIN Inst. Math., Universite ́ Bordeaux 1, FR colin@math.u-bordeaux1.fr
Marie-Christine COSTA UMA, ENSTA, Paris, FR marie-christine.costa@ensta.fr
Arnaud DEBUSSCHE ENS Cachan, Bruz, FR
arnaud.debussche@bretagne.ens-cachan.fr Isabelle GALLAGHER Inst. Math. Jussieu, Univ. Paris 7, FR gallagher@math.jussieu.fr
Josselin GARNIER Lab. Proba. et Mod. Ale ́ atoires, Univ. Paris 7, FR garnier@math.univ-paris-diderot.fr
St  ́ephane GAUBERT
INRIA, Saclay - Iˆ le-de-France, Orsay, FR stephane.gaubert@inria.fr
Emmanuel GOBET
CMAP, E ́ cole Polytechnique, Palaiseau, FR emmanuel.gobet@polytechnique.edu
Raphaele HERBIN CMI LATP, Universite ́ d’Aix-Marseille, FR raphaele.herbin@latp.univ-mrs.fr
Marc HOFFMANN LAMA, Univ. Paris-Est, Champs-sur-Marne, FR marc.hoffmann@ensae.fr
Claude LE BRIS CERMICS, ENPC, Marne la Valle ́ e, FR lebris@cermics.enpc.fr
Sylvie M  ́ELE ́ ARD
CMAP, E ́ cole Polytechnique, Palaiseau, FR sylvie.meleard@polytechnique.edu
Felix OTTO Institute of Applied Math., Bonn, GE otto@iam.uni-bonn.de
Vale ́ rie PERRIER Lab. Jean-Kunztmann, ENSIMAG, Grenoble, FR valerie.perrier@imag.fr
Philippe ROBERT INRIA Rocquencourt, Le Chesnay, FR philippe.robert@inria.fr
Pierre ROUCHON
Automatique et Syste` mes, E ́ cole Mines, Paris, FR pierre.rouchon@ensmp.fr
Bruno SALVY INRIA Rocquencourt, Le Chesnay, FR bruno.salvy@inria.fr
Annick SARTENAER D  ́ept. Mathe ́ matiques, Univ. Namur, BE annick.sartenaer@fundp.ac.be
Eric SONNENDRU ̈ CKER IRMA, Strasbourg, FR sonnen@math.u-strasbg.fr
Alain TROUV  ́E CMLA, ENS Cachan, FR trouve@cmla.ens-cachan.fr
C  ́edric VILLANI IHP, Paris, FR villani@math.univ-lyon1.fr
Enrique ZUAZUA BCAM, Bilbao, ES enrique.zuazua@uam.es
MATHÉMATIQUES & APPLICATIONS
Comité de Lecture 2012–2015/Editorial Board 2012–2015
Directeurs de la collection J. GARNIER et V. PERRIER


Jean-François Le Gall
Mouvement brownien,
martingales et calcul
stochastique
123


Jean-François Le Gall Département de mathématiques Université Paris-Sud, Campus d’Orsay Orsay France
ISSN 1154-483X ISBN 978-3-642-31897-9 ISBN 978-3-642-31898-6 (eBook) DOI 10.1007/978-3-642-31898-6 Springer Heidelberg New York Dordrecht London
Library of Congress Control Number: 2012945744
Mathematics Subject Classification (2010), 60H05, 60G07, 60J65, 60G44, 60H10, 60J25
Ó Springer-Verlag Berlin Heidelberg 2013 Tous droits de traduction, de reproduction et d’adaptation réservés pour tous pays. La loi du 11 mars 1957 interdit les copies ou les reproductions destinées à une utilisation collective. Toute représentation, reproduction intégrale ou partielle faite par quelque procédé que ce soit, sans le consentement de l’auteur ou de ses ayants cause, est illicite et constitue une contrefaçon sanctionnée par les articles 425 et suivants du Code pénal.
Imprimé sur papier non acide
Springer est membre du groupe Springer Science+Business Media (www.springer.com)


Préface
Cet ouvrage est issu des notes d’un cours d’introduction au calcul stochastique enseigné en DEA puis en deuxième année de master, à l’Université Pierre et Marie Curie et à l’Université Paris-Sud. L’objectif de ce cours était de donner une présentation concise mais rigoureuse de la théorie de l’intégrale stochastique par rapport aux semimartingales continues, en portant une attention particulière au mouvement brownien. Le présent ouvrage s’adresse à des étudiants ayant bien assimilé un cours de probabilités avancées, incluant notamment les outils de la théorie de la mesure et la notion d’espérance conditionnelle, au niveau de la première année de master. Nous supposons aussi une certaine familiarité avec la notion d’uniforme intégrabilité (voir par exemple le chapitre II du livre de Neveu [7]). Pour la commodité du lecteur, nous avons rappelé en appendice les résultats de la théorie des martingales discrètes, souvent mais pas toujours enseignés en première année de master, que nous utilisons dans notre étude des martingales en temps continu. Le premier chapitre est une présentation rapide des vecteurs et processus gaussiens, dont l’objectif principal est d’arriver à la notion de mesure gaussienne, qui permet dans le second chapitre de donner une construction simple du mouvement brownien. Nous discutons les propriétés fondamentales du mouvement brownien, y compris la propriété de Markov forte et son application au principe de réflexion. Le Chapitre 2 permet en outre d’introduire dans le cadre relativement simple du mouvement brownien les notions importantes de filtration et de temps d’arrêt, qui sont étudiées de manière plus systématique et abstraite dans le Chapitre 3. Ce chapitre traite aussi les martingales et surmartingales à temps continu, en mettant l’accent sur les théorèmes de régularité des trajectoires et sur le théorème d’arrêt qui, utilisé conjointement avec le calcul stochastique, constitue un outil puissant pour des calculs explicites. Le Chapitre 4 présente les semimartingales continues, en commençant par une discussion détaillée des fonctions et processus à variation finie. On introduit ensuite les martingales locales, en se restreignant comme dans la suite de l’ouvrage au cas des trajectoires continues. Une attention particulière est portée au théorème clé d’existence de la variation quadratique d’une martingale locale. Le Chapitre 5 est le cœur du présent ouvrage, avec la construction de l’intégrale
v


stochastique par rapport à une semimartingale continue, la preuve dans ce cadre de la célèbre formule d’Itô, et de nombreuses applications importantes (théorème de caractérisation de Lévy, inégalités de Burkholder-Davis-Gundy, représentation des martingales dans la filtration brownienne, théorème de Girsanov, formule de Cameron-Martin, etc.). Les équations différentielles stochastiques, autre application très importante de la théorie du calcul stochastique, qui motiva l’invention par Itô de cette théorie, sont étudiées dans le Chapitre 7. Entre-temps, le Chapitre 6, qui présente les grandes idées de la théorie des processus de Markov avec l’accent sur le cas particulier des semigroupes de Feller, peut apparaître comme une digression à notre propos principal. Cependant, la théorie développée dans le Chapitre 6, outre qu’elle met en évidence des liens féconds avec la théorie des martingales, a le grand avantage de s’appliquer aux solutions d’équations différentielles stochastiques, dont les propriétés markoviennes jouent un rôle crucial dans nombre d’applications. A la fin de chaque chapitre sont proposés un certain nombre d’exercices, dont la résolution est vivement conseillée au lecteur. Ces exercices sont particulièrement nombreux à la fin du Chapitre 5, car le calcul stochastique est d’abord une technique, qu’on ne saurait assimiler sans traiter un nombre suffisant d’exemples explicites. La grande majorité des exercices du présent ouvrage est issue soit des textes d’examens de cours enseignés à l’Université Pierre et Marie Curie et à l’Université Paris-Sud, soit des travaux dirigés assurés parallèlement à ces cours. Le lecteur désireux d’aller plus loin dans la théorie et les applications du calcul stochastique pourra consulter les ouvrages classiques de Karatzas et Shreve [5], Revuz et Yor [9] et Rogers et Williams [10]. Pour une perspective historique sur le développement de la théorie, voir les articles originaux d’Itô [4], et le petit livre de McKean [6] qui contribua beaucoup à populariser ces travaux. Je remercie Mylène Maïda pour son aide dans la mise au point et la compilation des exercices. Merci aussi à Igor Kortchemski pour la simulation de mouvement brownien qui illustre le Chapitre 2. Pour conclure, je tiens à remercier tout particulièrement Marc Yor, qui m’a appris l’essentiel de ce que je connais de la théorie du calcul stochastique, et dont les nombreuses remarques m’ont aidé à améliorer ce texte.
Orsay, France, Mai 2012 Jean-François Le Gall
vi Préface


Table des matie`res
1 Vecteurs et processus gaussiens . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 1.1 Rappels sur les variables gaussiennes en dimension un . . . . . . . . . . . 1 1.2 Vecteurs gaussiens . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3 1.3 Espaces et processus gaussiens . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6 1.4 Mesures gaussiennes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10
2 Le mouvement brownien . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15 2.1 Le pre ́-mouvement brownien . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15 2.2 La continuite ́ des trajectoires . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18 2.3 Comportement des trajectoires du mouvement brownien . . . . . . . . . . 23 2.4 La proprie ́t ́e de Markov forte . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27
3 Filtrations et martingales . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33 3.1 Filtrations et processus . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33 3.2 Temps d’arrˆet et tribus associe ́es . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35 3.3 Martingales et surmartingales a` temps continu . . . . . . . . . . . . . . . . . . 40 3.4 The ́ore`mes d’arreˆt . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47
4 Semimartingales continues . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57 4.1 Processus a` variation finie . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57 4.1.1 Fonctions `a variation finie . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57 4.1.2 Processus a` variation finie . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60 4.2 Martingales locales . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61 4.3 Variation quadratique d’une martingale locale . . . . . . . . . . . . . . . . . . . 64 4.4 Semimartingales continues . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73
5 Inte ́grale stochastique . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 79 5.1 Construction de l’inte ́grale stochastique . . . . . . . . . . . . . . . . . . . . . . . . 79 5.2 La formule d’Itoˆ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 91 5.3 Quelques applications de la formule d’Itoˆ . . . . . . . . . . . . . . . . . . . . . . 96 5.4 Le the ́ore`me de Girsanov . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 105
vii
5.5 Quelques applications du the ́ore`me de Girsanov . . . . . . . . . . . . . . . . . 110


viii Table des matie`res
6 The ́orie ge ́n ́erale des processus de Markov . . . . . . . . . . . . . . . . . . . . . . . . 121 6.1 De ́finitions ge ́ne ́rales et probl`eme d’existence . . . . . . . . . . . . . . . . . . . 121 6.2 Semigroupes de Feller . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 126 6.3 La re ́gularite ́ des trajectoires . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 132 6.4 La proprie ́t ́e de Markov forte . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 135 6.5 Deux classes importantes de processus de Feller . . . . . . . . . . . . . . . . . 137 6.5.1 Processus de Le ́vy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 137 6.5.2 Processus de branchement continu . . . . . . . . . . . . . . . . . . . . . . 138
7 Equations diffe ́rentielles stochastiques . . . . . . . . . . . . . . . . . . . . . . . . . . . . 145 7.1 Motivation et de ́finitions ge ́ne ́rales . . . . . . . . . . . . . . . . . . . . . . . . . . . . 145 7.2 Le cas lipschitzien . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 148 7.3 Les solutions d’e ́quations diffe ́rentielles stochastiques comme processus de Markov . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 155 7.4 Quelques exemples d’e ́quations diffe ́rentielles stochastiques . . . . . . . 160 7.4.1 Le processus d’Ornstein-Uhlenbeck . . . . . . . . . . . . . . . . . . . . . 160 7.4.2 Le mouvement brownien ge ́ome ́trique . . . . . . . . . . . . . . . . . . . 161 7.4.3 Les processus de Bessel . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 161
Appendice A1. Lemme de classe monotone . . . . . . . . . . . . . . . . . . . . . . . . . . . . 167
Appendice A2. Martingales discre`tes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 169
Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 175
 ́
R ferences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 173
e ́


J.-F. Le Gall, Mouvement brownien, martingales et calcul stochastique, 71, DOI: 10.1007/978-3-642-31898-6_1, Ó Springer-Verlag Berlin Heidelberg 2013
Chapitre 1
Vecteurs et processus gaussiens
Re ́sume ́ Le principal objectif de ce chapitre est d’introduire les re ́sultats sur les processus gaussiens et les mesures gaussiennes qui seront utilise ́s dans le chapitre suivant pour construire le mouvement brownien.
1.1 Rappels sur les variables gaussiennes en dimension un
Dans toute la suite on se place sur un espace de probabilite ́ (Ω , F , P). Pour tout re ́el p ≥ 1, Lp(Ω , F , P), ou simplement Lp s’il n’y a pas d’ambigu ̈ıte ́, de ́signe l’espace des variables ale ́atoires re ́elles de puissance p-ie`me inte ́grable, muni de la norme usuelle. Une variable ale ́atoire re ́elle X est dite gaussienne (ou normale) centre ́e re ́duite si sa loi admet pour densite ́
pX (x) = √12π
exp(− x2
2 ).
La transforme ́e de Laplace complexe de X est alors donn ́ee par
E[ezX ] = ez2/2, ∀z ∈ C.
Pour obtenir cette formule (et aussi voir que la transforme ́e de Laplace complexe est bien de ́finie) on traite d’abord le cas ou` z = λ ∈ R :
E[eλX ] = √12π
∫
R
eλ x e−x2/2 dx = eλ 2/2 √12π
∫
R
e−(x−λ )2/2 dx = eλ 2/2.
Ce calcul assure que E[ezX ] est bien de ́fini pour tout z ∈ C et de ́finit une fonction
analytique sur C. L’e ́galite ́ E[ezX ] = ez2/2 e ́tant vraie pour tout z ∈ R doit donc l’ˆetre aussi pour tout z ∈ C. En prenant z = iξ , ξ ∈ R, on trouve la transforme ́e de Fourier de la loi de X :
1
Math ̄matiques et Applications


2 1 Vecteurs et processus gaussiens
E[eiξ X ] = e−ξ 2/2.
A partir du de ́veloppement limite ́ au voisinage de 0,
E[eiξX ] = 1 + iξ E[X] + · · · + (iξ )n
n! E[Xn] + O(|ξ |n+1),
valable quand X est dans tous les espaces Lp, 1 ≤ p < ∞, ce qui est le cas ici, on calcule
E[X] = 0, E[X2] = 1, E[X2n] = (2n)!
2nn! .
Pour σ > 0 et m ∈ R, on dit qu’une variable ale ́atoire re ́elle Y suit une loi gaussienne N (m, σ 2) si Y ve ́rifie l’une des trois proprie ́te ́s e ́quivalentes suivantes :
(i) Y = σ X + m ou` X suit une loi gaussienne centre ́e r ́eduite (i.e. N (0, 1)); (ii) la densit ́e de Y est
pY (y) = 1 σ
√2π
exp − (y − m)2
2σ 2 ;
(iii) la fonction caracte ́ristique de Y est
E[eiξY ] = exp(imξ − σ 2
2 ξ 2).
On a alors
E[Y ] = m, var(Y ) = σ 2.
Par extension, on dit que Y suit une loi N (m, 0) si Y = m p.s. (la proprie ́te ́ (iii) reste vraie).
Sommes de variables gaussiennes ind ́ependantes. Supposons que Y suit la loi N (m, σ 2), Y ′ suit la loi N (m′, σ ′2), et Y et Y ′ sont inde ́pendantes. Alors Y + Y ′ suit la loi N (m + m′, σ 2 + σ ′2). C’est une conse ́quence imme ́diate de (iii).
Proposition 1.1. Soit (Xn) une suite de variables al ́eatoires gaussiennes, telle que Xn soit de loi N (mn, σn). Supposons que Xn converge en loi vers X. Alors :
1) La variable X est gaussienne N (m, σ 2), o`u m = lim mn, σ = lim σn. 2) Si la suite (Xn) converge en probabilit ́e vers X, la convergence a lieu dans tous les espaces Lp, 1 ≤ p < ∞.
De ́monstration. 1) La convergence en loi e ́quivaut a` dire que, pour tout ξ ∈ R,
E[eiξ Xn ] = exp(imnξ − σn2
2 ξ 2) n−→→∞
E[eiξ X ].
En passant au module, on a aussi
exp(− σn2
2 ξ 2) n−→→∞
|E[eiξX ]|, ∀ξ ∈ R,


1.2 Vecteurs gaussiens 3
ce qui ne peut se produire que si σn2 converge vers σ 2 ≥ 0 (le cas σn2 → +∞ est a` e ́carter car la fonction limite 1{ξ=0} ne serait pas continue). On a ensuite, pour tout ξ ∈ R,
eimnξ n−→→∞
e1
2 σ2ξ 2 E[eiξ X ].
Montrons que cela entraˆıne la convergence de la suite (mn). Si on sait a priori que la suite (mn) est borne ́e, c’est facile : si m et m′ sont deux valeurs d’adhe ́rence on a
eimξ = eim′ξ pour tout ξ ∈ R, ce qui entraˆıne m = m′. Supposons la suite (mn) non borne ́e et montrons qu’on arrive a` une contradiction. On peut extraire une sous-suite (mnk ) qui converge vers +∞ (ou −∞ mais le raisonnement est le meˆme). Alors, pour tout A > 0,
P[X ≥ A] ≥ lim sup
k→∞
P[Xnk ≥ A] ≥ 1
2,
puisque P[Xnk ≥ A] ≥ P[Xnk ≥ mnk ] ≥ 1/2 pour k assez grand. En faisant tendre A vers +∞ on arrive a` une contradiction. On a donc mn → m, σn → σ , d’o`u
E[eiξX ] = exp(imξ − σ 2
2 ξ 2),
ce qui montre que X est gaussienne N (m, σ 2). 2) Puisque Xn a mˆeme loi que σnN + mn, o`u N de ́signe une variable de loi N (0, 1), et que les suites (mn) et (σn) sont borne ́es (d’apre`s 1)), on voit imme ́diatement que
sup
n
E[|Xn|q] < ∞, ∀q ≥ 1.
Il en de ́coule que
sup
n
E[|Xn − X|q] < ∞, ∀q ≥ 1.
Soit p ≥ 1. La suite Yn = |Xn − X|p converge en probabilite ́ vers 0 par hypothe`se et est uniforme ́ment inte ́grable, car borne ́e dans L2 d’apre`s ce qui pre ́ce`de (avec q = 2p). Elle converge donc dans L1 vers 0 d’ou` le re ́sultat recherche ́. tu
1.2 Vecteurs gaussiens
Soit E un espace euclidien de dimension d (E est isomorphe a` Rd et on peut si on le souhaite prendre E = Rd, mais il sera plus commode de travailler avec un espace abstrait). On note 〈u, v〉 le produit scalaire de E. Une variable al ́eatoire X a` valeurs dans E est un vecteur gaussien si, pour tout u ∈ E, 〈u, X〉 est une variable gaussienne. (Par exemple, si E = Rd et si X1, . . . , Xd sont des variables gaussiennes inde ́pendantes, la propri ́ete ́ des sommes de variables gaussiennes inde ́pendantes montre que le vecteur X = (X1, . . . , Xd) est un vecteur gaussien.)


4 1 Vecteurs et processus gaussiens
Si X est un vecteur gaussien a` valeurs dans E, il existe mX ∈ E et une forme quadratique positive qX sur E tels que, pour tout u ∈ E,
E[〈u, X〉] = 〈u, mX
〉,
var(〈u, X〉) = qX (u),
En effet, soit (e1, . . . , ed) une base orthonorme ́e de E et soit X = ∑d
i=1 X j e j la
de ́composition de X dans cette base. Remarquons que les variables ale ́atoires Xj = 〈e j, X〉 sont gaussiennes. On ve ́rifie alors imme ́diatement les formules pre ́ce ́dentes
avec mX = ∑d
i=1 E[Xj] e j
(no=t.) E[X ], et, si u = ∑d
i=1 u je j,
qX (u) =
n
∑
j,k=1
u juk cov(Xj, Xk).
Comme 〈u, X〉 est une variable gaussienne N (〈u, mX
〉, qX (u)), on en de ́duit la transforme ́e de Fourier
E[exp(i〈u, X〉)] = exp(i〈u, mX
〉− 1
2 qX (u)). (1.1)
Proposition 1.2. Sous les hypoth`eses pr ́ec ́edentes, les variables al ́eatoires X1, . . . , Xd sont ind ́ependantes si et seulement si la matrice de covariance (cov(Xj, Xk))1≤ j,k≤d est diagonale, soit si et seulement si la forme quadratique qX est diagonale dans la base (e1, . . . , ed).
De ́monstration. Il est e ́vident que si les variables ale ́atoires X1, . . . , Xd sont inde ́pendantes, la matrice de covariance (cov(Xj, Xk)) j,k=1,...d est diagonale. Inversement, si cette matrice est diagonale, on a, pour u = ∑d
j=1 u je j ∈ E,
qX (u) =
d
j= ∑1
λ j u2
j,
ou` λ j = var(Xj). En conse ́quence, en utilisant (1.1),
E
[
exp
(
i
d
j= ∑1
ujXj
)]
=
d
j= ∏1
exp(iu jE[Xj] − 1
2 λ ju2
j) =
d
j= ∏1
E[exp(iu jXj)],
ce qui entraˆıne l’inde ́pendance de X1, . . . , Xd. tu A la forme quadratique qX on associe l’endomorphisme syme ́trique positif γX de E tel que
qX (u) = 〈u, γX (u)〉
(γX a pour matrice (cov(Xj, Xk)) dans la base (e1, . . . , ed) mais comme le montre la formule ci-dessus la de ́finition de γX ne de ́pend pas de la base choisie).


1.2 Vecteurs gaussiens 5
A partir de maintenant, pour simplifier l’e ́criture, on se limite a` des vecteurs gaussiens centre ́s, i.e. tels que mX = 0, mais les re ́sultats qui suivent s’e ́tendent facilement au cas non centre ́.
The ́ore`me 1.1. (i) Si γ est un endomorphisme sym ́etrique positif de E, il existe un vecteur gaussien centr ́e X tel que γX = γ. (ii) Soit X un vecteur gaussien centr ́e. Soit (ε1, . . . , εd) une base de E qui diagonalise γX : γX ε j = λ jε j avec λ1 ≥ λ2 ≥ · · · ≥ λr > 0 = λr+1 = · · · = λd (r est le rang de γX ). Alors,
X=
r
j= ∑1
Yjεj,
o`u les variables Yj sont des variables gaussiennes (centr ́ees) ind ́ependantes, et Yj est de variance λ j. En cons ́equence, si PX d ́esigne la loi de X, le support topologique de PX est l’espace vectoriel engendr ́e par ε1, . . . , εr,
supp PX = e.v.(ε1, . . . , εr).
La loi PX est absolument continue par rapport `a la mesure de Lebesgue sur E si et seulement si r = d, et dans ce cas la densit ́e de X est
pX (x) = 1
(2π)d/2√det γX
exp − 1
2
〈x, γ−1
X (x)〉.
De ́monstration. (i) Soit (ε1, . . . , εd) une base orthonorme ́e de E dans laquelle γ est diagonale, γ(ε j) = λ jε j pour 1 ≤ j ≤ d, et soient Y1, . . . ,Yd des variables gaussiennes centre ́es inde ́pendantes avec var(Yj) = λ j, 1 ≤ j ≤ d. On pose
X=
d
j= ∑1
Yjεj,
et on ve ́rifie alors facilement que, si u = ∑d
j=1 u jε j,
qX (u) = E
[( d
j= ∑1
u jYj
)2]
=
d
j= ∑1
λ ju2
j = 〈u, γ(u)〉.
(ii) Si on e ́crit X dans la base (ε1, . . . , εd), la matrice de covariance des coordonne ́es Y1, . . . ,Yd est la matrice de γX dans cette base, donc une matrice diagonale avec λ1, . . . , λd sur la diagonale. Pour j ∈ {r + 1, . . . , d}, on a E[Yj2] = 0 donc Yj = 0 p.s. De plus, d’apre`s la Proposition 1.2 les variables Y1, . . . ,Yr sont inde ́pendantes. Ensuite, puisque X = ∑r
j=1 Yjε j p.s. il est clair que
supp PX ⊂ e.v.{ε1, . . . , εr},
et inversement, si O est un pave ́ de la forme


6 1 Vecteurs et processus gaussiens
O = {u =
r
j= ∑1
α jε j : a j < α j < b j, ∀1 ≤ j ≤ r},
on a P[X ∈ O] = ∏r
j=1 P[a j < Yj < b j] > 0. Cela suffit pour obtenir l’e ́galite ́ supp PX = e.v.{ε1, . . . , εr}. Si r < d, puisque e.v.{ε1, . . . , εr} est de mesure nulle, la loi de X est e ́trange`re par rapport `a la mesure de Lebesgue sur E. Si r = d, notons Y le vecteur ale ́atoire de Rd de ́fini par Y = (Y1, . . . ,Yd) et remarquons que X est l’image de Y par la bijection φ(y1, . . . , yd) = ∑ y jε j. Alors, en notant y = (y1, . . . , yd),
E[g(X)] = E[g(φ(Y ))]
=1
(2π )d/2
∫
Rd g(φ(y)) exp
(
−1
2
d
j= ∑1
y2j
λj
) dy1 . . . dyd
√
λ1 . . . λd
=1
(2π)d/2√det γX
∫
Rd g(φ(y)) exp(− 1
2
〈
φ(y), γ−1
X (φ(y))〉) dy1 . . . dyd
=1
(2π)d/2√det γX
∫
E
g(x) exp(− 1
2
〈x, γ−1
X (x)〉) dx,
puisque la mesure de Lebesgue sur E est par de ́finition l’image de la mesure de Lebesgue sur Rd par φ (ou par n’importe quelle autre isome ́trie de Rd sur E). Pour la deuxie`me e ́galit ́e, on a utilise ́ le fait que Y1, . . . ,Yd sont des variables gaussiennes N (0, λ j) inde ́pendantes, et pour la troisie`me l’e ́galite ́
〈
φ(y), γ−1
X (φ(y))〉 = 〈
∑yjεj,∑ yj
λj
εj
〉=∑
y2j
λj
.
1.3 Espaces et processus gaussiens
Dans ce paragraphe et le suivant, sauf indication du contraire, nous ne conside ́rons que des variables gaussiennes centr ́ees et nous omettrons le plus souvent le mot “centre ́”.
De ́finition 1.1. Un espace gaussien (centre ́) est un sous-espace vectoriel ferme ́ de L2(Ω , F , P) forme ́ de variables gaussiennes centre ́es.
Par exemple, si X = (X1, . . . , Xd) est un vecteur gaussien centre ́ dans Rd, l’espace vectoriel engendre ́ par {X1, . . . , Xd} est un espace gaussien.
De ́finition 1.2. Soit (E, E ) un espace mesurable, et soit T un ensemble d’indices quelconque. Un processus ale ́atoire (indexe ́ par T ) a` valeurs dans E est une famille (Xt )t∈T de variables ale ́atoires a` valeurs dans E. Si on ne pre ́cise pas (E, E ), on supposera implicitement que E = R et E = B(R) est la tribu bore ́lienne de R.


1.3 Espaces et processus gaussiens 7
De ́finition 1.3. Un processus ale ́atoire (Xt )t∈T a` valeurs re ́elles est un processus gaussien (centre ́) si toute combinaison line ́aire finie des variables Xt , t ∈ T est gaussienne centre ́e.
Proposition 1.3. Si (Xt )t∈T est un processus gaussien, le sous-espace vectoriel ferm ́e de L2 engendr ́e par les variables Xt , t ∈ T est un espace gaussien, appel ́e espace gaussien engendr ́e par le processus X.
De ́monstration. Il suffit de remarquer qu’une limite dans L2 de variables gaussiennes centre ́es est encore gaussienne centre ́e (cf. Proposition 1.1). tu
Si H est un ensemble de variables ale ́atoires de ́finies sur Ω , on note σ (H) la tribu engendre ́e par les variables ξ ∈ H (c’est la plus petite tribu sur Ω qui rend mesurables ces variables).
The ́ore`me 1.2. Soit H un espace gaussien et soit (Hi)i∈I une famille de sousespaces vectoriels de H. Alors les sous-espaces Hi, i ∈ I sont orthogonaux deux `a deux dans L2 si et seulement si les tribus σ (Hi), i ∈ I sont ind ́ependantes.
Remarque. Il est crucial que les espaces Hi soient contenus dans un meˆme espace gaussien. Conside ́rons par exemple une variable X de loi N (0, 1) et une seconde variable ε inde ́pendante de X et telle que P[ε = 1] = P[ε = −1] = 1/2. Alors X1 = X, X2 = εX sont deux variables N (0, 1). De plus, E[X1X2] = E[ε]E[X2] = 0. Cependant X1 et X2 ne sont  ́evidemment pas inde ́pendantes (parce que |X1| = |X2|). Dans cet exemple, le couple (X1, X2) n’est pas un vecteur gaussien dans R2 bien que ses coordonne ́es soient des variables gaussiennes.
De ́monstration. Si les tribus σ (Hi) sont inde ́pendantes, on a pour i 6= j, si X ∈ Hi et Y ∈ Hj,
E[XY ] = E[X]E[Y ] = 0,
et donc les espaces Hi sont deux a` deux orthogonaux. Inversement, supposons les espaces Hi deux a` deux orthogonaux. Par d ́efinition de l’inde ́pendance d’une famille infinie de tribus, il suffit de montrer que, si i1, . . . , ip ∈ I sont distincts, les tribus σ (Hi1 ), . . . , σ (Hip ) sont inde ́pendantes. Ensuite, il suffit de montrer que, si on fixe ξ 1
1 , . . . , ξn11 ∈ Hi1 , . . . , ξ p
1 , . . . , ξnpp ∈ Hip ,
les vecteurs (ξ 1
1 , . . . , ξn11 ), . . . , (ξ p
1 , . . . , ξnpp ) sont inde ́pendants (en effet, pour chaque
j ∈ {1, . . . , p}, les ensembles de la forme {ξ j
1 ∈ A1, . . . , ξnjj ∈ Anj } forment une classe stable par intersection finie qui engendre la tribu σ (Hij ), et on peut ensuite utiliser un argument classique de classe monotone, voir l’Appendice A1). Or,
pour chaque j ∈ {1, . . . , p} on peut trouver une base orthonorme ́e (η j
1 , . . . , ηmj j )
de e.v.{ξ j
1 , . . . , ξnjj } (vu comme sous-espace de L2). La matrice de covariance du vecteur
(η 1
1,...,η1
m1 , η 2
1,...,η2
m2 , . . . , η p
1 ,...,ηp
mp )
est donc la matrice identite ́ (pour i 6= j, E[ηi
l ηrj] = 0 a` cause de l’orthogonalite ́ de Hi et Hj). Ce vecteur est gaussien car ses composantes sont dans H. D’apre`s la


8 1 Vecteurs et processus gaussiens
Proposition 1.2, les composantes sont inde ́pendantes. Cela implique que les vecteurs (η 1
1 , . . . , ηm11 ), . . . , (η p
1 , . . . , ηmpp ) sont inde ́pendants. De mani`ere e ́quivalente les vecteurs (ξ 1
1 , . . . , ξn11 ), . . . , (ξ p
1 , . . . , ξnpp ) sont inde ́pendants, ce qui e ́tait le re ́sultat recherche ́. tu
Corollaire 1.1. Soient H un espace gaussien et K un sous-espace vectoriel ferm ́e de H. On note pK la projection orthogonale sur K. Soit X ∈ H.
(i) On a
E[X | σ (K)] = pK(X).
(ii) Soit σ 2 = E[(X − pK(X))2]. Alors, pour tout bor ́elien A de R,
P[X ∈ A | σ (K)] = Q(ω, A),
o`u Q(ω, ·) est la loi N (pK(X)(ω), σ 2) :
Q(ω, A) = 1 σ
√2π
∫
A
dy exp
(
− (y − pK(X))2
2σ 2
)
(et Q(ω, A) = 1A(pK(X)) si σ = 0).
Remarques. a) La partie (ii) de l’e ́nonce ́ s’interpre`te en disant que la loi conditionnelle de X sachant la tribu σ (K) est la loi N (pK(X), σ 2).
b) Pour une variable ale ́atoire X seulement suppose ́e dans L2, on a
E[X | σ (K)] = pL2(Ω,σ(K),P)(X ).
L’assertion (i) montre que dans notre cadre gaussien, cette projection orthogonale co ̈ıncide avec la projection orthogonale sur l’espace K, qui est bien plus petit que L2(Ω , σ (K), P).
c) L’assertion (i) donne aussi le principe de la re ́gression line ́aire. Par exemple, si (X1, X2, X3) est un vecteur gaussien (centre ́), la meilleure approximation (au sens L2) de X3 connaisssant X1 et X2 s’e ́crit λ1X1 + λ2X2 ou` λ1 et λ2 sont de ́termine ́s en disant que X3 − (λ1X1 + λ2X2) est orthogonal a` e.v.(X1, X2).
De ́monstration. (i) Soit Y = X − pK(X). Alors Y est orthogonal a` K et d’apre`s le The ́ore`me 1.2, Y est inde ́pendante de σ (K). Ensuite,
E[X | σ (K)] = E[pK(X) | σ (K)] + E[Y | σ (K)] = pK(X) + E[Y ] = pK(X).
(ii) On  ́ecrit, pour toute fonction f mesurable positive sur R+,
E[ f (X) | σ (K)] = E[ f (pK(X) +Y ) | σ (K)] =
∫
PY (dy) f (pK(X) + y),
ou` PY est la loi de Y qui est une loi N (0, σ 2) puisque Y est une variable gaussienne (centre ́e) de variance σ 2. Dans la deuxie`me  ́egalite ́, on a utilis ́e le fait ge ́n ́eral


1.3 Espaces et processus gaussiens 9
suivant : si Z est une variable G -mesurable et si Y est inde ́pendante de G alors, pour toute fonction g mesurable positive, E[g(Y, Z) | G ] = ∫ g(y, Z) PY (dy). Le re ́sultat annonce ́ en (ii) de ́coule aussitoˆt de la formule pr ́ece ́dente. tu
Soit (Xt )t∈T un processus gaussien (centre ́). La fonction de covariance de X est la fonction Γ : T × T −→ R de ́finie par Γ (s,t) = cov(Xs, Xt ) = E[XsXt ]. Cette fonction caracte ́rise ce qu’on appelle la famille des lois marginales de dimension finie de X, c’est-a`-dire la donne ́e pour toute famille finie {t1, . . . ,tp} de T , de la loi du vecteur (Xt1 , . . . , Xtp ) : en effet, ce vecteur est un vecteur gaussien centre ́ de matrice de covariance (Γ (ti,t j))1≤i, j≤p.
Remarque. On peut de ́finir de manie`re e ́vidente une notion de processus gaussien non centre ́. La famille des lois marginales de dimension finie est alors caracte ́ris ́ee par la donne ́e de la fonction de covariance et de la fonction moyenne m(t) = E[Xt ].
On peut se demander si inversement, e ́tant donne ́ une fonction Γ sur T × T , il existe un processus gaussien X dont Γ est la fonction de covariance. La fonction Γ doit eˆtre syme ́trique (Γ (s,t) = Γ (t, s)) et de type positif au sens suivant : si c est une fonction re ́elle a` support fini sur T , alors
T × ∑T
c(s)c(t)Γ (s,t) = E[( T∑
c(s)Xs)2] ≥ 0.
Remarquons que dans le cas ou` T est fini, le proble`me d’existence de X (qui est alors simplement un vecteur gaussien) est re ́solu sous les hypothe`ses pre ́ce ́dentes sur Γ par le The ́ore`me 1.1. Le the ́ore`me ci-dessous, que nous n’utiliserons pas dans la suite, re ́sout le proble`me d’existence dans le cas ge ́ne ́ral. Ce th ́eore`me est une conse ́quence directe du the ́ore`me d’extension de Kolmogorov, dont le cas particulier T = R+ est e ́nonce ́ ci-dessous dans le The ́ore`me 6.1 (voir [7, Chapitre III] pour le cas ge ́ne ́ral).
The ́ore`me 1.3. Soit Γ une fonction sym ́etrique de type positif sur T × T . Il existe alors un processus gaussien (centr ́e) dont la fonction de covariance est Γ .
Exemple. On conside`re le cas T = R et on se donne une mesure finie syme ́trique (i.e. μ(−A) = μ(A)) sur R. On pose alors
Γ (s,t) =
∫
eiξ (t−s) μ(dξ ).
On v ́erifie imm ́ediatement que Γ a les proprie ́te ́s requises : en particulier, si c est une fonction `a support fini sur R,
R× ∑R
c(s)c(t)Γ (s,t) =
∫
| R ∑
c(s)eiξs|2 μ(ds) ≥ 0.
La fonction Γ posse`de la proprie ́te ́ supple ́mentaire de de ́pendre seulement de la diffe ́rence t −s. On en de ́duit aussitoˆt que le processus X associe ́ a` Γ par le the ́ore`me pre ́c ́edent est stationnaire (au sens strict), au sens ou`


10 1 Vecteurs et processus gaussiens
(Xt1+t , . . . , Xtn+t ) (l=oi) (Xt1 , . . . , Xtn )
pour tout choix de t1, . . . ,tn,t ∈ R. La mesure μ est appele ́e la mesure spectrale du processus.
1.4 Mesures gaussiennes
De ́finition 1.4. Soit (E, E ) un espace mesurable, et soit μ une mesure σ -finie sur (E, E ). Une mesure gaussienne d’intensite ́ μ est une isome ́trie G de L2(E, E , μ) sur un espace gaussien.
Donc, si f ∈ L2(E, E , μ), G( f ) est une variable ale ́atoire gaussienne centre ́e de variance
E[G( f )2] = ‖G( f )‖2
L2(Ω ,F ,P) = ‖ f ‖2
L2(E,E ,μ).
En particulier, si f = 1A avec μ(A) < ∞, G(1A) suit la loi N (0, μ(A)). On notera pour simplifier G(A) = G(1A). Soient A1, . . . , An ∈ E disjoints et tels que μ(A j) < ∞ pour tout j. Alors le vecteur
(G(A1), . . . , G(An))
est un vecteur gaussien dans Rn de matrice de covariance diagonale, puisque pour i 6= j, la proprie ́te ́ d’isome ́trie donne
E[G(Ai)G(A j)] = 〈1Ai , 1Aj
〉
L2(E,E ,μ) = 0.
D’apre`s la Proposition 1.2 on en de ́duit que les variables G(A1), . . . , G(An) sont inde ́pendantes. Si A (tel que μ(A) < ∞) s’e ́crit comme re ́union disjointe d’une famille de ́nombrable A1, A2, . . . alors 1A = ∑ j∞=1 1Aj avec une se ́rie convergeant dans L2(E, E , μ), ce qui, a` nouveau par la proprie ́te ́ d’isome ́trie, entraˆıne que
G(A) =
∞
j= ∑1
G(A j)
avec convergence de la se ́rie dans L2(Ω , F , P) (graˆce a` l’inde ́pendance des G(A j) et au th ́eore`me de convergence des martingales discre`tes, on montre meˆme que la se ́rie converge p.s.). Les proprie ́te ́s de l’application A 7→ G(A) “ressemblent” donc a` celles d’une mesure (de ́pendant de ω). Cependant on peut montrer qu’en ge ́ne ́ral, pour ω fix ́e, l’application A 7→ G(A)(ω) ne de ́finit pas une mesure (nous reviendrons sur ce point plus loin).
Proposition 1.4. Soient (E, E ) un espace mesurable et μ une mesure σ -finie sur (E, E ). Il existe alors une mesure gaussienne d’intensit ́e μ.


1.4 Mesures gaussiennes 11
De ́monstration. Soit ( fi, i ∈ I) un syste`me orthonorme ́ total de L2(E, E , μ). Pour toute f ∈ L2(E, E , μ) on a
f = i∈∑I
αi fi
ou` les coefficients αi = 〈 f , fi
〉 sont tels que
i∈∑I
α2
i = ‖ f ‖2 < ∞.
Sur un espace de probabilite ́, on se donne alors une famille (Xi)i∈I de variables N (0, 1) inde ́pendantes (voir [7, Chapitre III] pour l’existence d’une telle famille dans la suite interviendra seulement le cas o`u I est de ́nombrable, dans lequel on peut donner une construction e ́le ́mentaire), et on pose
G( f ) = i∈∑I
αi Xi
(la se ́rie converge dans L2 puisque les Xi, i ∈ I, forment un syste`me orthonorme ́ dans L2). Il est alors clair que G prend ses valeurs dans l’espace gaussien engendre ́ par les Xi, i ∈ I. De plus il est imm ́ediat que G est une isome ́trie. tu
On aurait pu aussi de ́duire le re ́sultat pre ́ce ́dent du The ́ore`me 1.3 en prenant T = L2(E, E , μ) et Γ ( f , g) = 〈 f , g〉
L2(E,E ,μ). On construit ainsi un processus gaussien
(Xf , f ∈ L2(E, E , μ)) et il suffit de prendre G( f ) = Xf .
Remarque. Dans la suite, on conside ́rera uniquement le cas ou` L2(E, E , μ) est se ́parable. Par exemple, si (E, E ) = (R+, B(R+)) et μ est la mesure de Lebesgue, on peut pour construire G se donner une suite (ξn)n∈N de variables N (0, 1) inde ́pendantes, une base (φn)n∈N de L2(R+, B(R+), dt) et de ́finir G par
G( f ) = ∑
n∈N
〈 f , φn
〉
ξn.
Proposition 1.5. Soit G une mesure gaussienne sur (E, E ) d’intensit ́e μ. Soit A ∈ E tel que μ(A) < ∞. Supposons qu’il existe une suite de partitions de A,
A = An
1 ∪ . . . ∪ An
kn
de pas tendant vers 0, i.e.
nli→m∞
(
sup
1≤ j≤kn
μ (An
j)
)
= 0.
Alors,
nli→m∞
kn
j= ∑1
G(An
j )2 = μ(A)
dans L2.


12 1 Exercices
De ́monstration. Pour n fixe ́ les variables G(An
1), . . . , G(An
kn ) sont inde ́pendantes. De
plus, E[G(An
j )2] = μ(An
j ). On calcule alors facilement
E


( kn
j= ∑1
G(An
j )2 − μ(A)
)2
=
kn
j= ∑1
var(G(An
j )2) = 2
kn
j= ∑1
μ (An
j )2,
car si X est une variable N (0, σ 2), var(X2) = E(X4) − σ 4 = 3σ 4 − σ 4 = 2σ 4. Or,
kn
j= ∑1
μ (An
j )2 ≤
(
sup
1≤ j≤kn
μ (An
j)
)
μ (A)
qui tend vers 0 quand n → ∞ par hypothe`se. tu
Exercices
Exercice 1.1. Soit (Xt )t∈[0,1] un processus gaussien centre ́. On suppose que l’application (t, ω) 7→ Xt (ω) est mesurable de [0, 1] × Ω dans R. On note K la fonction de covariance de X. 1. Montrer que l’application t 7→ Xt est continue de [0, 1] dans L2(Ω ) si et seulement si K est continue sur [0, 1]2. On suppose dans la suite que cette condition est satisfaite.
2. Soit h : [0, 1] → R une fonction mesurable telle que ∫ 1
0 |h(t)|√K(t,t) dt < ∞.
Montrer que pour presque tout ω, l’inte ́grale ∫ 1
0 h(t)Xt (ω)dt est absolument conver
gente. On notera Z = ∫ 1
0 h(t)Xt dt.
3. On fait maintenant l’hypothe`se un peu plus forte ∫ 1
0 |h(t)|dt < ∞. Montrer que
Z est la limite dans L2, quand n → ∞, des variables Zn = ∑n
i=1 X i
n
∫i
n i−1 n
h(t)dt et en
de ́duire que Z est une variable gaussienne.
4. On suppose que K est de classe C2. Montrer que pour tout t ∈ [0, 1], la limite
X ̇t := lsi→mt
Xs − Xt s−t
existe dans L2(Ω ). Ve ́rifier que (X ̇t )t∈[0,1] est un processus gaussien centre ́. Calculer sa fonction de covariance.
Exercice 1.2. (Filtrage de Kalman) On se donne deux suites inde ́pendantes (εn)n∈N et (ηn)n∈N de variables ale ́atoires gaussiennes inde ́pendantes telles que pour tout n, εn est de loi N (0, σ 2) et ηn est de loi N (0, δ 2), ou` σ > 0 et δ > 0. On conside`re les deux autres suites (Xn)n∈N et (Yn)n∈N de ́finies par les relations X0 = 0, et pour tout n ∈ N, Xn+1 = anXn + εn+1 et Yn = cXn + ηn, ou` c et an sont des constantes strictement positives. On pose


1 Exercices 13
Xˆn/n = E[Xn | Y0,Y1, . . . ,Yn]
Xˆn+1/n = E[Xn+1 | Y0,Y1, . . . ,Yn].
Le but de l’exercice est de trouver une formule re ́cursive permettant de calculer ces deux suites de variables. 1. Ve ́rifier que Xˆn+1/n = anXˆn/n, pour tout n ≥ 0. 2. Montrer que pour tout n ≥ 1,
Xˆn/n = Xˆn/n−1 + E[XnZn]
E[Zn2] Zn,
avec Zn := Yn − cXˆn/n−1.
3. Calculer E[XnZn] et E[Zn2] en fonction de Pn := E[(Xn − Xˆn/n−1)2] et en de ́duire que pour tout n ≥ 1,
Xˆn+1/n = an
(
Xˆn/n−1 + cPn
c2Pn + δ 2 Zn
)
4. Ve ́rifier que P1 = σ 2 et que l’on a, pour tout n ≥ 1, la relation de re ́currence
Pn+1 := σ 2 + a2
n
δ 2Pn
c2Pn + δ 2 .
Exercice 1.3. Soient H un espace gaussien (centre ́) et H1 et H2 des sous-espaces vectoriels de H. Soit K un sous-espace vectoriel ferm ́e de H. On note pK la projection orthogonale sur K. Montrer que la condition
∀X1 ∈ H1, ∀X2 ∈ H2, E[X1X2] = E[pK(X1)pK(X2)]
entraˆıne que les tribus σ (H1) et σ (H2) sont inde ́pendantes conditionnellement a` σ (K). (L’inde ́pendance conditionnelle signifie que pour toute variable σ (H1)mesurable positive X1 et pour toute variable σ (H2)-mesurable positive X2 on a E[X1X2|σ (K)] = E[X1|σ (K)] E[X2|σ (K)]. Via des arguments de classe monotone explique ́s dans l’Appendice A1, on observera qu’on peut se limiter au cas ou` X1, resp. X2, est l’indicatrice d’un e ́ve ́nement de ́pendant d’un nombre fini de variables de H1, resp. de H2.)


J.-F. Le Gall, Mouvement brownien, martingales et calcul stochastique, 71, DOI: 10.1007/978-3-642-31898-6_2, Ó Springer-Verlag Berlin Heidelberg 2013
Chapitre 2
Le mouvement brownien
Re ́sume ́ Ce chapitre est consacre ́ a` la construction du mouvement brownien et a` l’e ́tude de certaines de ses proprie ́t ́es. Nous introduisons d’abord le pr ́e-mouvement brownien (terminologie non canonique!) qu’on de ́finit facilement a` partir d’une mesure gaussienne sur R+. Le passage du pre ́-mouvement brownien au mouvement brownien exige la proprie ́te ́ additionnelle de continuite ́ des trajectoires, ici obtenue via le lemme classique de Kolmogorov. La fin du chapitre discute quelques proprie ́te ́s importantes des trajectoires browniennes, et e ́tablit la proprie ́te ́ de Markov forte, avec son application classique au principe de re ́flexion.
2.1 Le pr ́e-mouvement brownien
Dans ce chapitre, on se place a` nouveau sur un espace de probabilite ́ (Ω , F , P).
De ́finition 2.1. Soit G une mesure gaussienne sur R+ d’intensite ́ la mesure de Lebesgue. Le processus (Bt )t∈R+ de ́fini par
Bt = G(1[0,t])
est appele ́ pr ́e-mouvement brownien.
Proposition 2.1. Le processus (Bt )t≥0 est un processus gaussien (centr ́e) de fonction de covariance
K(s,t) = min{s,t} (no=t.) s ∧ t.
De ́monstration. Par de ́finition d’une mesure gaussienne, les variables Bt appartiennent a` un meˆme espace gaussien, et (Bt )t≥0 est donc un processus gaussien. De plus, pour tous s,t ≥ 0,
E[BsBt ] = E[G([0, s])G([0,t])] =
∫∞
0
dr 1[0,s](r)1[0,t](r) = s ∧ t. tu
15
Math ̄matiques et Applications


16 2 Le mouvement brownien
Proposition 2.2. Soit (Xt )t≥0 un processus al ́eatoire `a valeurs r ́eelles. Il y a  ́equivalence entre les propri ́et ́es suivantes :
(i) (Xt )t≥0 est un pr ́e-mouvement brownien; (ii) (Xt )t≥0 est un processus gaussien centr ́e de covariance K(s,t) = s ∧ t; (iii) X0 = 0 p.s. et pour tous 0 ≤ s < t, la variable Xt − Xs est ind ́ependante de σ (Xr, r ≤ s) et suit la loi N (0,t − s); (iv) X0 = 0 p.s. et pour tout choix de 0 = t0 < t1 < · · · < tp, les variables Xti −Xti−1 , 1 ≤ i ≤ p sont ind ́ependantes, la variable Xti − Xti−1 suivant la loi N (0,ti −ti−1).
De ́monstration. L’implication (i)⇒(ii) est la Proposition 2.1. Montrons l’implication (ii)⇒(iii). On suppose que (Xt )t≥0 est un processus gaussien centre ́ de covariance K(s,t) = s ∧ t, et on note H l’espace gaussien engendre ́ par (Xt )t≥0. Alors X0 suit une loi N (0, 0) et donc X0 = 0 p.s. Ensuite, fixons s > 0 et notons Hs l’espace vectoriel engendre ́ par (Xr, 0 ≤ r ≤ s), H ̃s l’espace vectoriel engendre ́ par (Xs+u − Xs, u ≥ 0). Alors Hs et H ̃s sont orthogonaux puisque, pour r ∈ [0, s] et u ≥ 0,
E[Xr(Xs+u − Xs)] = r ∧ (s + u) − r ∧ s = r − r = 0.
Comme Hs et H ̃s sont aussi contenus dans le meˆme espace gaussien H, on de ́duit du The ́or`eme 1.2 que σ (Hs) et σ (H ̃s) sont ind ́ependantes. En particulier, si on fixe t > s, la variable Xt − Xs est inde ́pendante de σ (Hs) = σ (Xr, r ≤ s). Enfin, en utilisant la forme de la fonction de covariance, on voit aise ́ment que Xt − Xs suit la loi N (0,t − s).
L’implication (iii)⇒(iv) est facile : en prenant s = tp−1 et t = tp on obtient d’abord que Xtp − Xtp−1 est inde ́pendante de (Xt1 , . . . , Xtp−1 ) et on continue par re ́currence. Montrons l’implication (iv)⇒(i). Il de ́coule facilement de (iv) que X est un processus gaussien. Ensuite, si f est une fonction en escalier sur R+ de la forme f = ∑n
i=1 λi 1]ti−1,ti], on pose
G( f ) =
n
i=∑1
λi (Xti − Xti−1 )
(observer que cette de ́finition ne de ́pend pas de l’e ́criture choisie pour f ). On ve ́rifie imme ́diatement que si g est une autre fonction en escalier du meˆme type on a
E[G( f )G(g)] =
∫
R+
f (t)g(t) dt.
Graˆce a` la densite ́ des fonctions en escalier dans L2(R+, B(R+), dt), on en de ́duit que l’application f 7→ G( f ) s’e ́tend en une isome ́trie de L2(R+, B(R+), dt) dans l’espace gaussien engendre ́ par X. Enfin, par construction, G([0,t]) = Xt − X0 = Xt . tu Remarque. La proprie ́te ́ (iii) (avec seulement le fait que la loi de Xt − Xs ne de ́pend que de t − s) est souvent appele ́e proprie ́te ́ d’inde ́pendance et de stationnarite ́ des


2.1 Le pre ́-mouvement brownien 17
accroissements. Le pre ́-mouvement brownien est un cas particulier de la classe des processus `a accroissements inde ́pendants et stationnaires.
Corollaire 2.1. Soit (Bt )t≥0 un pr ́e-mouvement brownien. Alors, pour tout choix de 0 = t0 < t1 < · · · < tn, la loi du vecteur (Bt1 , Bt2 , . . . , Btn ) a pour densit ́e
p(x1, . . . , xn) = 1
(2π)n/2√t1(t2 − t1) . . . (tn − tn−1) exp
(
−
n
i=∑1
(xi − xi−1)2
2(ti − ti−1)
)
,
o`u par convention x0 = 0.
De ́monstration. Les variables Bt1 , Bt2 − Bt1 , . . . , Btn − Btn−1  ́etant inde ́pendantes et de lois respectives N (0,t1), N (0,t2 −t1), . . . , N (0,tn −tn−1), le vecteur (Bt1 , Bt2 − Bt1 , . . . , Btn − Btn−1 ) a pour densite ́
q(y1, . . . , yn) = 1
(2π)n/2√t1(t2 − t1) . . . (tn − tn−1) exp
(
−
n
i=∑1
yi2
2(ti − ti−1)
)
,
et il suffit de faire le changement de variables xi = y1 + · · · + yi pour i ∈ {1, . . . , n}. tu Remarque. Le Corollaire 2.1, avec la proprie ́te ́ B0 = 0, de ́termine les lois marginales de dimension finie du pre ́-mouvement brownien (rappelons qu’il s’agit de la donne ́e, pour tout choix de t1, . . . ,tp ∈ R+, de la loi de (Bt1 , . . . , Btp )). La proprie ́te ́ (iv) de la Proposition 2.2 montre qu’un processus ayant les meˆmes lois marginales qu’un pre ́-mouvement brownien doit aussi eˆtre un pre ́-mouvement brownien.
Proposition 2.3. Soit B un pr ́e-mouvement brownien. Alors,
(i) −B est aussi un pr ́e-mouvement brownien; (ii) pour tout λ > 0, le processus Btλ = 1
λ Bλ2t est aussi un pr ́e-mouvement brown
ien (invariance par changement d’ ́echelle);
(iii) pour tout s ≥ 0, le processus B(s)
t = Bs+t −Bs est un pr ́e-mouvement brownien ind ́ependant de σ (Br, r ≤ s) (propri ́et ́e de Markov simple).
De ́monstration. (i) et (ii) sont tre`s faciles. De ́montrons (iii). Avec les notations de la preuve de la Proposition 2.2, la tribu engendre ́e par B(s) est σ (H ̃s), qui est inde ́pendante de σ (Hs) = σ (Br, r ≤ s). Pour voir que B(s) est un pre ́-mouvement brownien, il suffit de ve ́rifier la proprie ́te ́ (iv) de la Proposition 2.2, ce qui est
imme ́diat puisque B(s)
ti − B(s)
ti−1 = Bs+ti − Bs+ti−1 . tu
f ∈ L2(R+, B(R+), dt),
G( f ) =
∫∞
0
f (s) dBs
et de meˆme
Si B est un pré-mouvement brownien et G est la mesure gaussienne associée, on note souvent pour


18 2 Le mouvement brownien
G( f 1[0,t]) =
∫t
0
f (s) dBs , G( f 1]s,t]) =
∫t
s
f (r) dBr .
Cette notation est justifie ́e par le fait que si u < v,
∫v
u
dBs = G(]u, v]) = Bv − Bu.
L’application f 7→ ∫ ∞
0 f (s) dBs (c’est-a`-dire la mesure gaussienne G) est alors appele ́e inte ́grale de Wiener par rapport au pre ́-mouvement brownien B. Rappelons que ∫ ∞
0 f (s)dBs suit une loi gaussienne N (0, ∫ ∞
0 f (s)2ds). Comme les mesures gaussiennes ne sont pas de “vraies” mesures, la notation
∫∞
0 f (s)dBs ne correspond pas a` une “vraie” inte ́grale de ́pendant de ω. Une partie
importante de la suite de ce cours est consacre ́e a` e ́tendre la de ́finition de ∫ ∞
0 f (s)dBs a` des fonctions f qui peuvent d ́ependre de ω.
2.2 La continuit ́e des trajectoires
De ́finition 2.2. Si (Xt )t∈T est un processus ale ́atoire a` valeurs dans un espace E, les trajectoires de X sont les applications T 3 t 7→ Xt (ω) obtenues en fixant ω. Les trajectoires constituent donc une famille, indexe ́e par ω ∈ Ω , d’applications de T dans E.
Soit B = (Bt )t≥0 un pre ́-mouvement brownien. Au stade ou` nous en sommes, on ne peut rien affirmer au sujet des trajectoires de B : il n’est meˆme pas e ́vident (ni vrai en ge ́ne ́ral) que ces applications soient mesurables. Le but de ce paragraphe est de montrer que, quitte a` modifier “un peu” B, on peut faire en sorte que ses trajectoires soient continues.
De ́finition 2.3. Soient (Xt )t∈T et (X ̃t )t∈T deux processus ale ́atoires index ́es par le meˆme ensemble T et a` valeurs dans le meˆme espace E. On dit que X ̃ est une modification de X si
∀t ∈ T, P[X ̃t = Xt ] = 1.
Remarquons que le processus X ̃ a alors mˆemes lois marginales de dimension finie que X. En particulier, si X est un pre ́–mouvement brownien, X ̃ est aussi un pre ́-mouvement brownien. En revanche, les trajectoires de X ̃ peuvent avoir un comportement tre`s diffe ́rent de celles de X. Il peut arriver par exemple que les trajectoires de X ̃ soient toutes continues alors que celles de X sont toutes discontinues.
De ́finition 2.4. Les deux processus X et X ̃ sont dits indistinguables s’il existe un sous-ensemble ne ́gligeable N de Ω tel que
∀ω ∈ Ω \N, ∀t ∈ T, Xt (ω) = X′
t (ω).
Dit de manie`re un peu diffe ́rente, les processus X et X ̃ sont indistinguables si


2.2 La continuite ́ des trajectoires 19
P(∀t ∈ T, Xt = X ̃t ) = 1.
(Cette formulation est le ́ge`rement abusive car l’e ́ve ́nement {∀t ∈ T, Xt = X ̃t } n’est pas force ́ment mesurable.) Si deux processus sont indistinguables, l’un est une modification de l’autre. La notion d’indistinguabilite ́ est cependant (beaucoup) plus forte : deux processus indistinguables ont p.s. les meˆmes trajectoires. Dans la suite on identifiera deux processus indistinguables. Une assertion de la forme “il existe un unique processus tel que ...” doit toujours eˆtre comprise “a` indistinguabilite ́ pre`s”, meˆme si cela n’est pas dit explicitement.
Si T = I est un intervalle de R, et si X et X ̃ sont deux processus dont les trajectoires sont p.s. continues, alors X ̃ est une modification de X si et seulement si X et X ̃ sont indistinguables. En effet, si X ̃ est une modification de X on a p.s. ∀t ∈ I ∩ Q, Xt = X ̃t (on e ́carte une re ́union d ́enombrable d’ensembles de probabilite ́ nulle) d’ou` p.s. ∀t ∈ I, Xt = X ̃t par continuite ́. Le meˆme argument marche si on suppose seulement les trajectoires continues a` droite, ou a` gauche.
The ́ore`me 2.1 (lemme de Kolmogorov). Soit X = (Xt )t∈I un processus al ́eatoire index ́e par un intervalle born ́e I de R, `a valeurs dans un espace m ́etrique complet (E, d). Supposons qu’il existe trois r ́eels q, ε,C > 0 tels que, pour tous s,t ∈ I,
E[d(Xs, Xt )q] ≤ C |t − s|1+ε .
d(X ̃s(ω), X ̃t (ω)) ≤ Cα (ω) |t − s|α .
En particulier, X ̃ est une modification continue de X (unique `a indistinguabilit ́e pr`es d’apr`es ci-dessus).
Remarques. (i) Si I est non borne ́, par exemple si I = R+, on peut appliquer le The ́ore`me 2.1 a` I = [0, 1], [1, 2], [2, 3], etc. et on trouve encore que X a une modification continue, qui est localement ho ̈lde ́rienne d’exposant α pour tout α ∈]0, ε/q[. (ii) Il suffit de montrer que pour α ∈]0, ε/q[ fixe ́, X a une modification dont les trajectoires sont ho ̈ld ́eriennes d’exposant α. En effet, on applique ce re ́sultat a` une suite αk ↑ ε/q en observant que les processus obtenus sont alors tous indistinguables, d’apre`s la remarque pre ́ce ́dant le the ́ore`me.
De ́monstration. Pour simplifier l’e ́criture, on prend I = [0, 1], mais la preuve est la meˆme pour un intervalle born ́e quelconque. On note D l’ensemble (de ́nombrable) des nombres dyadiques de l’intervalle [0, 1[, c’est-a`-dire des re ́els t ∈ [0, 1] qui s’e ́crivent
t=
p
∑
k=1
εk 2−k
ou` p ≥ 1 est un entier et εk = 0 ou 1, pour tout k ∈ {1, . . . , p}.
Alors, il existe une modification X ̃ de X dont les trajectoires sont höldériennes d’exposant α pour tout ω ∈ Ω et tout α ∈ ]0, ε
q [ : cela signifie que, pour tout
α ∈ ]0, ε
q [, il existe une constante Cα(ω) telle que, pour tous s, t ∈ I ,


20 2 Le mouvement brownien
L’hypothe`se du the ́ore`me entraˆıne que, pour a > 0 et s,t ∈ I,
P[d(Xs, Xt ) ≥ a] ≤ a−qE[d(Xs, Xt )q] ≤ C a−q |t − s|1+ε .
Fixons α ∈]0, ε
q [ et appliquons cette ine ́galite ́ a` s = (i − 1)2−n, t = i2−n (pour i ∈ {1, . . . , 2n}) et a = 2−nα :
P
[
d(X(i−1)2−n , Xi2−n ) ≥ 2−nα
]
≤ C 2nqα 2−(1+ε)n.
En sommant sur i on trouve
P
[ 2n
⋃
i=1
{d(X(i−1)2−n , Xi2−n ) ≥ 2−nα }
]
≤ 2n · C 2nqα−(1+ε)n = C 2−n(ε−qα).
Par hypothe`se, ε − qα > 0. En sommant maintenant sur n on a donc
∞
n= ∑1
P
[ 2n
⋃
i=1
{d(X(i−1)2−n , Xi2−n ) ≥ 2−nα }
]
< ∞,
et le lemme de Borel-Cantelli montre que
p.s. ∃n0(ω) : ∀n ≥ n0(ω), ∀i ∈ {1, . . . , 2n}, d(X(i−1)2−n , Xi2−n ) ≤ 2−nα .
En conse ́quence, la constante Kα (ω) de ́finie par
Kα (ω) = sup
n≥1
(
sup
1≤i≤2n
d(X(i−1)2−n , Xi2−n )
2−nα
)
est finie p.s. (Pour n ≥ n0(ω), le terme entre parenthe`ses est majore ́ par 1, et d’autre part, il n’y a qu’un nombre fini de termes avant n0(ω).) A ce point nous utilisons un lemme d’analyse e ́le ́mentaire, dont la preuve est reporte ́e apre`s la fin de la preuve du The ́ore`me 2.1.
Lemme 2.1. Soit f une fonction d ́efinie sur [0, 1] `a valeurs dans l’espace m ́etrique (E, d). Supposons qu’il existe un r ́eel α > 0 et une constante K < ∞ tels que, pour tout entier n ≥ 1 et tout i ∈ {1, 2, . . . , 2n},
d( f ((i − 1)2−n), f (i2−n)) ≤ K 2−nα .
Alors on a, pour tous s,t ∈ D,
d( f (s), f (t)) ≤ 2K
1 − 2−α |t − s|α
On de ́duit imme ́diatement du lemme et de la de ́finition de Kα (ω) que, sur l’ensemble {Kα (ω) < ∞} (qui est de probabilite ́ 1), on a, pour tous s,t ∈ D,


2.2 La continuite ́ des trajectoires 21
d(Xs, Xt ) ≤ Cα (ω) |t − s|α ,
ou` Cα (ω) = 2(1 − 2−α )−1Kα (ω). En conse ́quence, sur l’ensemble {Kα (ω) < ∞}, la fonction t 7→ Xt (ω) est ho ̈lde ́rienne sur D, donc uniforme ́ment continue sur D. Puisque (E, d) est complet, cette fonction a un unique prolongement continu a` I = [0, 1], et ce prolongement est lui aussi ho ̈lde ́rien d’exposant α. De manie`re plus pre ́cise, on pose pour tout t ∈ [0, 1]
X ̃t (ω) =
{ lim
s→t,s∈D Xs(ω) si Kα (ω) < ∞ ,
x0 si Kα (ω) = ∞ ,
ou` x0 est un point de E fixe ́ de manie`re arbitraire. D’apre`s les remarques pre ́ce ́dentes, le processus X ̃ a des trajectoires ho ̈lde ́riennes d’exposant α sur [0, 1]. Il reste a` voir que X ̃ est une modification de X. Pour cela, fixons t ∈ I. L’hypothe`se du th ́eore`me entraˆıne que
lsi→mt Xs = Xt
au sens de la convergence en probabilite ́. Comme par de ́finition X ̃t est aussi la limite p.s. de Xs quand s → t, s ∈ D, on conclut que Xt = X ̃t p.s. tu
De ́monstration du Lemme 2.1. Fixons s,t ∈ D avec s < t. Soit p ≥ 1 le plus petit entier tel que 2−p ≤ t − s. Alors il est facile de voir qu’on peut trouver un entier k ≥ 0 et deux entiers l, m ≥ 0 tels que
s = k2−p − εp+12−p−1 − . . . − εp+l 2−p−l
t = k2−p + ε′
p2−p + ε′
p+12−p−1 + . . . + ε′
p+m2−p−m,
ou` εi, ε′
j = 0 ou 1. Notons
si = k2−p − εp+12−p−1 − . . . − εp+i2−p−i (pour 0 ≤ i ≤ l)
t j = k2−p + ε′p2−p + ε′
p+12−p−1 + . . . + ε′
p+ j2−p− j (pour 0 ≤ j ≤ m).
Alors, en observant que s = sl,t = tm et qu’on peut appliquer l’hypothe`se du lemme aux couples (s0,t0), (si−1, si) (pour 1 ≤ i ≤ l) et (t j−1,t j) (pour 1 ≤ j ≤ m), on trouve
d( f (s), f (t)) = d( f (sl), f (tm))
≤ d( f (s0), f (t0)) +
l
i=∑1
d( f (si−1), f (si)) +
m
j= ∑1
d( f (t j−1), f (t j))
≤ K 2−pα +
l
i=∑1
K 2−(p+i)α +
m
j= ∑1
K 2−(p+ j)α
≤ 2K (1 − 2−α )−1 2−pα
≤ 2K (1 − 2−α )−1 (t − s)α


22 2 Le mouvement brownien
puisque 2−p ≤ t − s. Cela termine la preuve du Lemme 2.1. tu Nous appliquons maintenant le The ́ore`me 2.1 au pre ́-mouvement brownien.
Corollaire 2.2. Soit B = (Bt )t≥0 un pr ́e-mouvement brownien. Le processus B a une modification dont les trajectoires sont continues, et mˆeme localement h ̈old ́eriennes d’exposant 1
2 − δ pour tout δ ∈]0, 1
2 [.
De ́monstration. Pour s < t, la variable Bt − Bs suit une loi N (0,t − s), et donc
Bt − Bs a mˆeme loi que √t − s N, o`u N suit une loi N (0, 1). En conse ́quence, pour tout q > 0,
E[|Bt − Bs|q] = (t − s)q/2E[|N|q] = Cq (t − s)q/2
avec Cq = E[|N|q] < ∞. De`s que q > 2, on peut appliquer le the ́ore`me avec ε =
q
2 − 1. On trouve ainsi que B a une modification dont les trajectoires sont continues, et meˆme localement ho ̈lde ́riennes d’exposant α pour tout α < (q − 2)/(2q). En choisissant q grand on trouve le re ́sultat souhaite ́. tu
D ́efinition 2.5. Un processus (Bt )t≥0 est un mouvement brownien (re ́el, issu de 0) si :
(i) (Bt )t≥0 est un pre ́-mouvement brownien. (ii) Les trajectoires de B, c’est-a`-dire les applications t 7→ Bt (ω) pour ω ∈ Ω , sont toutes continues.
L’existence du mouvement brownien de ́coule du corollaire pre ́ce ́dent. En effet la modification obtenue dans ce corollaire est encore un pre ́-mouvement brownien, et ses trajectoires sont continues. Dans la suite on ne parlera plus de pre ́-mouvement brownien et on s’inte ́ressera uniquement au mouvement brownien. Il est important de remarquer que l’e ́nonce ́ de la Proposition 2.3 reste vrai mot pour mot si on remplace partout pre ́-mouvement brownien par mouvement brownien. En effet, avec les notations de cette proposition, on ve ́rifie imme ́diatement que les processus −B, Bλ , B(s) ont des trajectoires continues si c’est le cas pour B.
Mesure de Wiener. Notons C(R+, R) l’espace des fonctions continues de R+ dans R. La donne ́e d’un mouvement brownien B fournit donc une application
Ω −→ C(R+, R)
ω 7→ (t 7→ Bt (ω))
et il est facile de v ́erifier que cette application est mesurable lorsque C(R+, R) est muni de la plus petite tribu, not ́ee C , qui rende mesurables les applications coordonne ́es w 7→ w(t) (on montre aise ́ment que cette tribu co ̈ıncide avec la tribu bore ́lienne pour la topologie de la convergence uniforme sur tout compact). La mesure de Wiener, ou loi du mouvement brownien, est par de ́finition la mesureimage de P(dω) par cette application. C’est donc une mesure de probabilite ́ sur C(R+, R).
Si W (dw) de ́signe la mesure de Wiener, le Corollaire 2.1 montre que, pour 0 = t0 < t1 < · · · < tn, et A0, A1, . . . , An ∈ B(R),


2.3 Comportement des trajectoires du mouvement brownien 23
W ({w; w(t0) ∈ A0, w(t1) ∈ A1, . . . , w(tn) ∈ An})
= P(Bt0 ∈ A0, Bt1 ∈ A1, . . . , Btn ∈ An)
= 1A0 (0)
∫
A1 ×···×An
dx1 . . . dxn
(2π)n/2√t1(t2 − t1) . . . (tn − tn−1) exp
(
−
n
i=∑1
(xi − xi−1)2
2(ti − ti−1)
)
,
ou` x0 = 0 par convention. Les valeurs ainsi obtenues pour W ({w; w(t0) ∈ A0, w(t1) ∈ A1, . . . , w(tn) ∈ An}) caracte ́risent la probabilite ́ W : en effet, la classe des ensembles de la forme {w; w(t0) ∈ A0, w(t1) ∈ A1, . . . , w(tn) ∈ An} (les “cylindres”) est stable par intersection finie et engendre la tribu C , ce qui, par un argument standard de classe monotone (voir l’Appendice A1), suffit pour dire qu’une mesure de probabilite ́ sur C est caracte ́rise ́e par ses valeurs sur cette classe. Une conse ́quence des conside ́rations pr ́ece ́dentes est le fait que la construction de la mesure de Wiener ne de ́pend pas du choix du mouvement brownien B : la loi du mouvement brownien est unique (et bien de ́finie!). Si B′ est un autre mouvement brownien, on aura pour tout A ∈ C ,
P((B′
t )t≥0 ∈ A) = W (A) = P((Bt )t≥0 ∈ A).
Remarquons que dans l’ ́ecriture P((Bt )t≥0 ∈ A), il faut interpre ́ter (Bt )t≥0 comme la “fonction continue ale ́atoire” t 7→ Bt (ω) qui est une variable ale ́atoire a` valeurs dans C(R+, R). Nous utiliserons fre ́quemment la dernie`re proprie ́te ́ sans plus de commentaires. Voir par exemple la deuxie`me partie de la preuve du Corollaire 2.3 ci-dessous.
Si l’on prend maintenant comme espace de probabilite ́
Ω = C(R+, R), F = C , P(dw) = W (dw),
le processus, dit canonique,
Xt (w) = w(t)
est un mouvement brownien (d’apre`s le Corollaire 2.1 et les formules ci-dessus). C’est la construction canonique du mouvement brownien.
2.3 Comportement des trajectoires du mouvement brownien
Dans ce paragraphe, nous obtenons quelques informations sur l’allure des trajectoires du mouvement brownien. Nous fixons donc un mouvement brownien (Bt )t≥0 (issu de 0 comme c’est toujours le cas pour l’instant). Un ingre ́dient tre`s utile est le re ́sultat suivant, connu sous le nom de loi du tout ou rien de Blumenthal.
The ́ore`me 2.2. Pour tout t ≥ 0, soit Ft la tribu d ́efinie par
Ft = σ (Bs, s ≤ t),


24 2 Le mouvement brownien
et soit
F0+ = ⋂
s>0
Fs.
La tribu F0+ est grossi`ere, au sens o`u ∀A ∈ F0+, P(A) = 0 ou 1.
De ́monstration. Soient 0 < t1 < t2 < · · · < tk et soit g : Rk −→ R une fonction continue borne ́e. Soit aussi A ∈ F0+. Alors, par un argument de continuite ́,
E[1A g(Bt1 , . . . , Btk )] = lim
ε→0 E[1A g(Bt1 − Bε , . . . , Btk − Bε )].
Mais, de`s que ε < t1, les variables Bt1 − Bε , . . . , Btk − Bε sont inde ́pendantes de Fε (par la proprie ́te ́ de Markov simple) et donc aussi de la tribu F0+. Il en de ́coule que
E[1A g(Bt1 , . . . , Btk )] = lim
ε→0 P(A) E[g(Bt1 − Bε , . . . , Btk − Bε )]
= P(A) E[g(Bt1 , . . . , Btk )].
Ainsi on trouve que F0+ est inde ́pendante de σ (Bt1 , . . . , Btk ). Comme cela est vrai pour toute famille finie {t1, . . . ,tk} de re ́els strictement positifs, F0+ est inde ́pendante de σ (Bt ,t > 0). Finalement σ (Bt ,t > 0) = σ (Bt ,t ≥ 0) puisque B0 est la limite simple de Bt quand t → 0. Comme F0+ ⊂ σ (Bt ,t ≥ 0), on voit que F0+ est inde ́pendante d’elle-meˆme, ce qui entraˆıne que F0+ est grossie`re. tu
Corollaire 2.3. On a p.s., pour tout ε > 0,
sup
0≤s≤ε
Bs > 0, inf
0≤s≤ε
Bs < 0.
Pour tout a ∈ R, soit Ta = inf{t ≥ 0 : Bt = a} (avec la convention inf ∅ = ∞). Alors,
p.s., ∀a ∈ R, Ta < ∞.
En cons ́equence, p.s.,
lim sup
t→∞
Bt = +∞, lim inf
t→∞
Bt = −∞.
Remarque. Il n’est pas a priori e ́vident que la variable sup0≤s≤ε Bs soit mesurable : il s’agit d’un supremum non de ́nombrable de fonctions mesurables. Cependant, parce que nous savons que les trajectoires de B sont continues, on peut se restreindre aux valeurs rationnelles de s ∈ [0, ε] et on obtient alors un supremum de ́nombrable de variables ale ́atoires. Nous utiliserons ce type de remarque implicitement dans la suite.
De ́monstration. Soit (εp) une suite de re ́els strictement positifs de ́croissant vers 0, et soit
A=⋂
p
{
sup
0≤s≤εp
Bs > 0
}
.


2.3 Comportement des trajectoires du mouvement brownien 25
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
−0.4
−0.3
−0.2
−0.1
0
0.1
0.2
0.3
Fig. 2.1 Simulation d’une trajectoire de mouvement brownien sur l’intervalle de temps [0, 1]
Il s’agit d’une intersection de ́croissante, et il en de ́coule ais ́ement que l’e ́ve ́nement A est F0+-mesurable. D’autre part,
P(A) = pli→m∞
↓P
(
sup
0≤s≤εp
Bs > 0
)
,
et
P
(
sup
0≤s≤εp
Bs > 0
)
≥ P(Bεp > 0) = 1
2,
ce qui montre que P(A) ≥ 1/2. D’apre`s le The ́ore`me 2.2 on a P(A) = 1, d’ou`
p.s. ∀ε > 0, sup
0≤s≤ε
Bs > 0.
L’assertion concernant inf0≤s≤ε Bs est obtenue en rempla ̧cant B par −B. Ensuite, on e ́crit
1=P
(
sup
0≤s≤1
Bs > 0
)
= lim
δ ↓0
↑P
(
sup
0≤s≤1
Bs > δ
)
,


26 2 Le mouvement brownien
et on remarque en appliquant la proprie ́te ́ d’invariance d’e ́chelle (voir la Proposition 2.3(ii) et la notation de cette proposition) avec λ = 1/δ que
P
(
sup
0≤s≤1
Bs > δ
)
=P
(
sup
0≤s≤1/δ 2
B1/δ
s >1
)
=P
(
sup
0≤s≤1/δ 2
Bs > 1
)
.
Pour la deuxie`me  ́egalite ́, on utilise les remarques suivant la de ́finition de la mesure de Wiener, montrant que la probabilite ́ de l’e ́ve ́nement {sup0≤s≤1/δ2 Bs > 1} est la mˆeme pour n’importe quel mouvement brownien B. En faisant tendre δ vers 0, on trouve
P
(
sup
s≥0
Bs > 1
)
= lim
δ ↓0
↑P
(
sup
0≤s≤1/δ 2
Bs > 1
)
= 1.
Ensuite, un nouvel argument de changement d’e ́chelle montre que pour tout M > 0,
P
(
sup
s≥0
Bs > M
)
=1
et en utilisant le changement B → −B on a aussi
P
(
si≥nf0 Bs < −M
)
= 1.
Les dernie`res assertions du corollaire en de ́coulent facilement : pour la dernie`re, on observe qu’une fonction continue f : R+ −→ R ne peut visiter tous les re ́els que si lim supt→+∞ f (t) = +∞ et lim inft→+∞ f (t) = −∞. tu En utilisant la proprie ́te ́ de Markov simple, on de ́duit facilement du corollaire que p.s. la fonction t 7→ Bt n’est monotone sur aucun intervalle non-trivial.
Proposition 2.4. Soit 0 = tn
0 < tn
1 < · · · < tpnn = t une suite de subdivisions de [0,t]
de pas tendant vers 0 (i.e. sup1≤i≤pn (tn
i −tn
i−1) → 0). Alors,
nli→m∞
pn
i=∑1
(Btin − Btn
i−1 )2 = t,
dans L2.
De ́monstration. C’est une conse ́quence presque imme ́diate de la Proposition 1.5, en e ́crivant Btin − Btn
i−1 = G(]tn
i−1, tn
i ]), si G est la mesure gaussienne associe ́e a` B. tu
On de ́duit facilement de la Proposition 2.4 et de la continuite ́ des trajectoires que p.s. la fonction t 7→ Bt n’est a` variation finie sur aucun intervalle non trivial (voir le de ́but du Chapitre 4 pour des rappels sur les fonctions continues a` variation finie).
En particulier, il n’est pas possible de de ́finir “ω par ω” les int ́egrales de la forme
∫t
0 f (s)dBs comme des inte ́grales usuelles par rapport a` une fonction a` variation finie. Ceci justifie les commentaires de la fin du paragraphe 2.1.


2.4 La proprie ́te ́ de Markov forte 27
2.4 La proprie ́te ́ de Markov forte
Notre but est d’e ́tendre la proprie ́te ́ de Markov simple (Proposition 2.3 (iii)) au cas ou` l’instant de ́terministe s est remplace ́ par un temps ale ́atoire T . Nous devons d’abord pr ́eciser la classe des temps ale ́atoires admissibles. On garde la notation Ft introduite dans le The ́ore`me 2.2 et on note aussi F∞ = σ (Bs, s ≥ 0).
De ́finition 2.6. Une variable ale ́atoire T a` valeurs dans [0, ∞] est un temps d’arreˆt si, pour tout t ≥ 0, {T ≤ t} ∈ Ft .
On peut remarquer que si T est un temps d’arreˆt on a aussi pour tout t > 0,
{T < t} = ⋃
q∈[0,t[∩Q
{T ≤ q} ∈ Ft .
De ́finition 2.7. Soit T un temps d’arreˆt. La tribu du passe ́ avant T est
FT = {A ∈ F∞ : ∀t ≥ 0, A ∩ {T ≤ t} ∈ Ft }.
On ve ́rifie facilement que FT est bien une tribu et que la variable ale ́atoire T est FT -mesurable (exercice). De plus, si on de ́finit 1{T<∞}BT en posant
1{T <∞}BT (ω) =
{ BT(ω)(ω) si T (ω) < ∞ , 0 si T (ω) = ∞ ,
alors 1{T<∞}BT est aussi une variable ale ́atoire FT -mesurable. Pour le voir, on remarque que
1{T <∞}BT = nli→m∞
∞
i=∑0
1{i2−n≤T <(i+1)2−n}Bi2−n = nli→m∞
∞
i=∑0
1{T <(i+1)2−n}1{i2−n≤T }Bi2−n .
On observe ensuite que, pour tout s ≥ 0, Bs1{s≤T} est FT -mesurable, parce que si A est un bore ́lien de R ne contenant pas 0 (le cas 0 ∈ A est traite ́ par passage au comple ́mentaire) on a
{Bs1{s≤T } ∈ A} ∩ {T ≤ t} =
{ ∅ si t < s {Bs ∈ A} ∩ {s ≤ T ≤ t} si t ≥ s
qui est Ft -mesurable dans les deux cas (e ́crire {s ≤ T ≤ t} = {T ≤ t} ∩ {T < s}c).
The ́ore`me 2.3 (Proprie ́te ́ de Markov forte). Soit T un temps d’arrˆet. On suppose que P(T < ∞) > 0 et on pose, pour tout t ≥ 0,
Exemples. Les temps T = t (temps constant) ou T = Ta sont des temps d’arrêt (pour le deuxième cas remarquer que {Ta ≤ t} = { inf0 ≤ s ≤ t |Bs − a|=0}). En revanche, T = sup {s ≤ 1 : Bs = 0} n’est pas un temps d’arrêt (cela découlera par l’absurde de la propriété de Markov forte ci-dessous et de la Corollaire 2.3). Si T est un temps d’arrêt, pour tout t ≥ 0, T +t est aussi un temps d’arrêt (exercice).


28 2 Le mouvement brownien
B(T )
t = 1{T <∞}(BT +t − BT )
Alors, sous la probabilit ́e conditionnelle P(· | T < ∞), le processus (B(T)
t )t≥0 est un mouvement brownien ind ́ependant de FT .
De ́monstration. Nous e ́tablissons d’abord le the ́ore`me dans le cas ou` T < ∞ p.s. Pour cela, nous allons montrer que, si A ∈ FT , 0 ≤ t1 < · · · < tp et F est une fonction continue borne ́e de Rp dans R+, on a
E[1A F(B(T )
t1 , . . . , B(T )
tp )] = P[A] E[F(Bt1 , . . . , Btp )]. (2.1)
Cela suffit pour e ́tablir les diffe ́rentes assertions du the ́ore`me : le cas A = Ω montre que B(T) est un mouvement brownien (remarquer que les trajectoires de B(T) sont continues) et d’autre part (2.1) entraˆıne que pour tout choix de 0 ≤ t1 < · · · < tp, le
vecteur (B(T )
t1 , . . . , B(T )
tp ) est inde ́pendant de FT , d’o`u il de ́coule par un argument de
classe monotone (Appendice A1) que B(T) est inde ́pendant de FT . Pour tout entier n ≥ 1, notons [T ]n le plus petit re ́el de la forme k2−n supe ́rieur ou e ́gal a` T , avec [T ]n = ∞ si T = ∞ (il est facile de voir que [T ]n est un temps d’arreˆt, mais nous n’aurons pas besoin de cela). Pour montrer (2.1), on observe d’abord que p.s.
F(B(T )
t1 , . . . , B(T )
tp ) = nli→m∞
F (B([T ]n)
t1 , . . . , B([T ]n)
tp ),
d’ou` par convergence domine ́e,
E[1A F(B(T )
t1 , . . . , B(T )
tp )]
= nli→m∞
E[1A F(B([T ]n)
t1 , . . . , B([T ]n)
tp )]
= nli→m∞
∞
∑
k=0
E[1A1{(k−1)2−n<T ≤k2−n}F (Bk2−n+t1 − Bk2−n , . . . , Bk2−n+tp − Bk2−n )],
ou` pour la dernie`re e ́galite ́ on a distingue ́ les valeurs possibles de [T ]n. Pour A ∈ FT , l’e ́ve ́nement A ∩ {(k − 1)2−n < T ≤ k2−n} = (A ∩ {T ≤ k2−n}) ∩ {T ≤ (k − 1)2−n}c est Fk2−n -mesurable. D’apre`s la proprie ́te ́ de Markov simple (Proposition 2.3 (iii)), on a donc
E[1A∩{(k−1)2−n<T ≤k2−n}F (Bk2−n+t1 − Bk2−n , . . . , Bk2−n+tp − Bk2−n )]
= P[A ∩ {(k − 1)2−n < T ≤ k2−n}] E[F(Bt1 , . . . , Btp )],
et il ne reste plus qu’a` sommer sur k pour arriver au re ́sultat souhaite ́. Finalement, lorsque P[T = ∞] > 0, les meˆmes arguments conduisent a`
E[1A∩{T <∞} F (B(T )
t1 , . . . , B(T )
tp )] = P[A ∩ {T < ∞}] E[F(Bt1 , . . . , Btp )]
et le re ́sultat recherch ́e en de ́coule a` nouveau. tu


2.4 La proprie ́te ́ de Markov forte 29
Une application importante de la proprie ́te ́ de Markov forte est le principe de re ́flexion illustre ́ dans la preuve du the ́ore`me suivant.
The ́ore`me 2.4. Pour tout t > 0, notons St = sups≤t Bs. Alors, si a ≥ 0 et b ≤ a, on a
P[St ≥ a, Bt ≤ b] = P[Bt ≥ 2a − b].
En particulier, St a mˆeme loi que |Bt |.

6
Ta t
a
b
2a − b
Fig. 2.2 Illustration du principe de r ́eflexion : la probabilite ́, conditionnellement a` {Ta ≤ t}, que la courbe soit sous b a` l’instant t co ̈ıncide avec la probabilite ́ que la courbe re ́fle ́chie au niveau a apre`s Ta (en pointille ́s) soit au-dessus de 2a − b a` l’instant t
De ́monstration. On applique la proprie ́te ́ de Markov forte au temps d’arreˆt
Ta = inf{t ≥ 0 : Bt = a}.
On a de ́ja` vu (Corollaire 2.3) que Ta < ∞ p.s. Ensuite, avec la notation du The ́ore`me 2.3, on a
P[St ≥ a, Bt ≤ b] = P[Ta ≤ t, Bt ≤ b] = P[Ta ≤ t, B(Ta)
t−Ta ≤ b − a],
puisque B(Ta)
t−Ta = Bt − BTa = Bt − a. Notons B′ = B(Ta), de sorte que d’apr`es le
The ́ore`me 2.3, le processus B′ est un mouvement brownien inde ́pendant de FTa
donc en particulier de Ta. Comme B′ a meˆme loi que −B′, le couple (Ta, B′) a aussi meˆme loi que (Ta, −B′). Soit H = {(s, w) ∈ R+ ×C(R+, R) : s ≤ t, w(t −s) ≤ b−a}. La probabilite ́ pre ́ce ́dente vaut
P[(Ta, B′) ∈ H] = P[(Ta, −B′) ∈ H]


30 2 Le mouvement brownien
= P[Ta ≤ t, −B(Ta)
t−Ta ≤ b − a]
= P[Ta ≤ t, Bt ≥ 2a − b]
= P[Bt ≥ 2a − b]
parce que l’e ́ve ́nement {Bt ≥ 2a − b} est p.s. contenu dans {Ta ≤ t}. Pour la deuxie`me assertion on observe que
P[St ≥ a] = P[St ≥ a, Bt ≥ a] + P[St ≥ a, Bt ≤ a] = 2P[Bt ≥ a] = P[|Bt ] ≥ a],
d’ou` le re ́sultat voulu. tu On de ́duit imme ́diatement du the ́ore`me pre ́c ́edent que la loi du couple (St , Bt ) a pour densite ́
g(a, b) = 2(2a − b)
√
2πt3 exp
(
− (2a − b)2
2t
)
1{a>0,b<a}.
Corollaire 2.4. Pour tout a > 0, Ta a mˆeme loi que a2
B2
1
et a donc pour densit ́e
f (t) = a
√
2πt3 exp
(
− a2
2t
)
1{t>0}.
De ́monstration. On e ́crit, en utilisant le The ́ore`me 2.4 dans la deuxie`me e ́galite ́,
P[Ta ≤ t] = P[St ≥ a] = P[|Bt | ≥ a] = P[B2
t ≥ a2] = P[tB2
1 ≥ a2] = P[ a2
B2
1
≤ t].
Ensuite, puisque B1 suit une loi N (0, 1) on calcule facilement la densit ́e de a2/B2
1. tu
G ́en ́eralisations. Soit Z une variable ale ́atoire re ́elle. Un processus (Xt )t≥0 est appele ́ mouvement brownien (re ́el) issu de Z si on peut e ́crire Xt = Z + Bt ou` B est un mouvement brownien issu de 0 et ind ́ependant de Z. Un processus Bt = (Bt1, . . . , Btd) a` valeurs dans Rd est un mouvement brownien
en dimension d issu de 0 si ses composantes B1, . . . , Bd sont des mouvements browniens re ́els issus de 0 ind ́ependants. On ve ́rifie facilement que si Φ est une isome ́trie vectorielle de Rd, le processus (Φ(Bt ))t≥0 est encore un mouvement brownien en dimension d. Enfin, si Z est une variable ale ́atoire a` valeurs dans Rd et Xt = (Xt1, . . . , Xtd) un
processus a` valeurs dans Rd, on dit que X est un mouvement brownien en dimension d issu de Z si on peut e ́crire Xt = Z + Bt ou` B est un mouvement brownien en dimension d issu de 0 et ind ́ependant de Z. La plupart des re ́sultats qui pre ́ce`dent peuvent eˆtre e ́tendus au mouvement brownien en dimension d. En particulier, la proprie ́te ́ de Markov forte reste vraie, avec exactement la meˆme de ́monstration.


2 Exercices 31
Exercices
Dans tous les exercices ci-dessous, (Bt )t≥0 de ́signe un mouvement brownien re ́el issu de 0. On note St = sup0≤s≤t Bs.
Exercice 2.1. (Inversion du temps) 1. Montrer que le processus (Wt )t≥0 de ́fini par W0 = 0 et Wt = tB1/t pour t > 0 est indistinguable d’un mouvement brownien re ́el issu de 0 (ve ́rifier d’abord que W est un pre ́-mouvement brownien).
2. En de ́duire que tli→m∞
Bt
t = 0 p.s.
Exercice 2.2. Pour tout re ́el a ≥ 0, on pose Ta = inf{t ≥ 0 : Bt = a}. Montrer que le processus (Ta)a≥0 est a` accroissements ind ́ependants et stationnaires, au sens ou`, pour tous 0 ≤ a ≤ b, la variable Tb − Ta est inde ́pendante de la tribu σ (Tc, 0 ≤ c ≤ a) et a meˆme loi que Tb−a.
Exercice 2.3. (Pont brownien) On pose Wt = Bt − tB1 pour tout t ∈ [0, 1]. 1. Montrer que (Wt )t∈[0,1] est un processus gaussien centre ́ et donner sa fonction de covariance. 2. Soient 0 < t1 < t2 < · · · < tp < 1. Montrer que la loi de (Wt1 ,Wt2 , . . . ,Wtp ) a pour densite ́
g(x1, . . . , xp) =
√
2π pt1 (x1)pt2−t1 (x2 − x1) · · · ptp−tp−1 (xp − xp−1)p1−tp (−xp),
ou` pt (x) = √21πt exp(−x2/2t). Justifier le fait que la loi de (Wt1 ,Wt2 , . . . ,Wtp ) peut
eˆtre interpre ́te ́e comme la loi de (Bt1 , Bt2 , . . . , Btp ) conditionnellement a` B1 = 0. 3. Ve ́rifier que les deux processus (Wt )t∈[0,1] et (W1−t )t∈[0,1] ont meˆme loi (comme dans la de ́finition de la mesure de Wiener cette loi est une mesure de probabilite ́ sur l’espace des fonctions continues de [0, 1] dans R).
Exercice 2.4. (Maxima locaux) Montrer que p.s. les maxima locaux du mouvement brownien sont distincts : p.s. pour tout choix des rationnels p, q, r, s tels que p < q < r < s on a
sup
p≤t≤q
Bt 6= sup
r≤t≤s
Bt .
Exercice 2.5. (Non-diffe ́rentiabilite ́) A l’aide de la loi du tout ou rien, montrer que, p.s.,
lim sup
t↓0
√Btt = +∞ , lim inf
t↓0
√Btt = −∞ .
En d ́eduire que pour tout s ≥ 0, la fonction t 7→ Bt n’est p.s. pas de ́rivable a` droite en s.
Exercice 2.6. (Ze ́ros du mouvement brownien) Soit H := {t ∈ [0, 1] : Bt = 0}. En utilisant le Corollaire 2.3 et la proprie ́te ́ de Markov forte, montrer que H est p.s. un sous-ensemble compact sans point isole ́ et de mesure de Lebesgue nulle de l’intervalle [0, 1].


32 2 Exercices
Exercice 2.7. (Retournement du temps) On pose Bt′ = B1 − B1−t pour tout t ∈ [0, 1].
Montrer que les deux processus (Bt )t∈[0,1] et (Bt′)t∈[0,1] ont meˆme loi (comme dans la de ́finition de la mesure de Wiener ces lois sont des mesures de probabilite ́ sur l’espace des fonctions continues de [0, 1] dans R).
Exercice 2.8. (Loi de l’arcsinus) On pose T := inf{t ≥ 0 : Bt = S1}. 1. Montrer que T < 1 p.s. (on pourra utiliser l’exercice pre ́ce ́dent) puis que T n’est pas un temps d’arreˆt. 2. Ve ́rifier que les trois variables ale ́atoires St , St − Bt et |Bt | ont meˆme loi. 3. Montrer que T suit la loi dite de l’arcsinus qui a pour densite ́
g(t) = 1 π
√t(1 − t) 1]0,1[(t).
4. Montrer que les re ́sultats des questions 1. et 3. restent vrais si on remplace T par L := sup{t ≤ 1 : Bt = 0}.
Exercice 2.9. (Loi du logarithme ite ́re ́) Le but de l’exercice est de montrer la proprie ́te ́ suivante:
lim sup
t→∞
Bt
√2t log logt = 1 p.s.
On pose h(t) = √2t log logt.
1. Montrer que, pour tout t > 0, P(St > u√t) ∼ e−u2/2
u√2π
, quand u tend vers +∞.
2. On se donne deux re ́els r et c tels que 1 < r < c2. Etudier le comportement des probabilite ́s P(Srn > c h(rn−1)) quand n → ∞ et en de ́duire que p.s.
lim sup
t→∞
Bt
√2t log logt ≤ 1.
3. Montrer qu’il existe p.s. une infinite ́ de valeurs de n telles que
Brn − Brn−1 ≥
√r−1
r h(rn).
En de ́duire le re ́sultat annonce ́.
4. Que vaut la limite lim inf
t→∞
Bt
√2t log logt ?


J.-F. Le Gall, Mouvement brownien, martingales et calcul stochastique, 71, DOI: 10.1007/978-3-642-31898-6_3, Ó Springer-Verlag Berlin Heidelberg 2013
Chapitre 3
Filtrations et martingales
Re ́sume ́ Dans ce chapitre, nous introduisons les rudiments de la the ́orie ge ́ne ́rale des processus sur un espace de probabilite ́ muni d’une filtration. Cela nous ame`ne a` ge ́ne ́raliser plusieurs notions introduites dans le chapitre pre ́ce ́dent dans le cadre du mouvement brownien. Dans un second temps, nous de ́veloppons la the ́orie des martingales a` temps continu et nous e ́tablissons en particulier les r ́esultats de re ́gularite ́ des trajectoires, ainsi que plusieurs formes des the ́ore`mes d’arreˆt pour les martingales et les surmartingales.
3.1 Filtrations et processus
De ́finition 3.1. Soit (Ω , F , P) un espace de probabilite ́. Une filtration sur cet espace est une famille croissante (Ft )0≤t≤∞, index ́ee par [0, ∞], de sous-tribus de F .
On a alors, pour tous 0 ≤ s < t,
F0 ⊂ Fs ⊂ Ft ⊂ F∞ ⊂ F .
On dira parfois que (Ω , F , (Ft ), P) est un espace de probabilite ́ filtre ́.
Exemple. Si B est un mouvement brownien, on peut prendre
Ft = σ (Bs, 0 ≤ s ≤ t), F∞ = σ (Bs, s ≥ 0).
Plus g ́ene ́ralement, si X = (Xt ,t ≥ 0) est un processus indexe ́ par R+, la filtration canonique de X est de ́finie par Ft = σ (Xs, s ≤ t) et F∞ = σ (Xs, s ≥ 0). Cette filtration canonique sera souvent comple ́te ́e, comme nous le de ́finirons plus loin.
Soit (Ft )0≤t≤∞ une filtration sur (Ω , F , P). On pose pour tout t ≥ 0
Ft+ = ⋂
s>t
Fs.
33
Dans ce chapitre, les processus sont indexés par R+.
Math ̄matiques et Applications


34 3 Filtrations et martingales
La famille (Ft+)0≤t≤∞ (avec F∞+ = F∞) est aussi une filtration. On dit que la filtration (Ft ) est continue `a droite si
Ft+ = Ft , ∀t ≥ 0.
Soit (Ft ) une filtration et soit N la classe des ensembles P-ne ́gligeables de F∞ (i.e. A ∈ N s’il existe A′ ∈ F∞ tel que A ⊂ A′ et P(A′) = 0). La filtration est dite compl`ete si N ⊂ F0 (et donc N ⊂ Ft pour tout t). Si (Ft ) n’est pas comple`te, on peut la comple ́ter en posant Ft′ = Ft ∨ N , pour tout t ∈ [0, ∞], de sorte que (Ft′) est une filtration comple`te.
On dira qu’une filtration (Ft ) satisfait les conditions habituelles si elle est a` la fois continue a` droite et comple`te. Partant d’une filtration quelconque (Ft ) on peut construire une filtration qui satisfait les conditions habituelles, simplement en comple ́tant la filtration (Ft+). C’est ce qu’on appelle aussi l’augmentation habituelle de la filtration (Ft ).
De ́finition 3.2. Un processus X = (Xt )t≥0 a` valeurs dans un espace mesurable E est dit mesurable si l’application
(ω,t) 7→ Xt (ω)
de ́finie sur Ω × R+ muni de la tribu produit F ⊗ B(R+) est mesurable.
Cette proprie ́te ́ est plus forte que de dire que, pour tout t ≥ 0, Xt est F -mesurable. Cependant, si l’on suppose que E est un espace me ́trique muni de sa tribu bore ́lienne et que les trajectoires de X sont continues, ou seulement continues a` droite, il est facile de voir que les deux proprie ́te ́s sont e ́quivalentes (approcher X par des processus “en escalier” qui sont mesurables).
Dans toute la suite de ce chapitre on suppose qu’on s’est fixe ́ une filtration (Ft ) sur un espace de probabilite ́ (Ω , F , P), et de nombreuses notions parmi celles que nous allons introduire d ́ependent du choix de cette filtration.
De ́finition 3.3. Un processus (Xt )t≥0 est dit adapte ́ si, pour tout t ≥ 0, Xt est Ft mesurable. Ce processus est dit progressif si, pour tout t ≥ 0, l’application
(ω, s) 7→ Xs(ω)
de ́finie sur Ω × [0,t] est mesurable pour la tribu Ft ⊗ B([0,t]).
Remarquons qu’un processus progressif est adapte ́ et mesurable (dire qu’un processus est mesurable est e ́quivalent a` dire que, pour tout t ≥ 0, l’application (ω, s) 7→ Xs(ω) de ́finie sur Ω × [0,t] est mesurable pour la tribu F ⊗ B([0,t])).
Proposition 3.1. Soit (Xt )t≥0 un processus `a valeurs dans un espace m ́etrique (E, d). Supposons que X est adapt ́e et `a trajectoires continues `a droite (i.e. pour tout ω ∈ Ω , t 7→ Xt (ω) est continue `a droite). Alors X est progressif.


3.2 Temps d’arreˆt et tribus associe ́es 35
De ́monstration. Fixons t > 0. Pour tout entier n ≥ 1 et pour tout s ∈ [0,t], de ́finissons une variable ale ́atoire Xsn en posant
Xn
s = Xkt/n si s ∈ [(k − 1)t/n, kt/n[, k ∈ {1, . . . , n},
et Xtn = Xt . La continuite ́ a` droite des trajectoires assure que, pour tous s ∈ [0,t] et ω ∈ Ω,
Xs(ω) = nli→m∞
Xn
s (ω).
Par ailleurs, pour tout bore ́lien A de E,
{(ω, s) ∈ Ω × [0,t] : Xn
s (ω) ∈ A} = ({Xt ∈ A} × {t})
⋃( n
⋃
k=1
(
{Xkt/n ∈ A} × [ (k − 1)t
n , kt
n[
))
qui est clairement dans la tribu Ft ⊗ B([0,t]). Donc, pour tout n ≥ 1, l’application (ω, s) 7→ Xsn(ω), de ́finie sur Ω × [0,t], est mesurable pour Ft ⊗ B([0,t]). Une limite simple de fonctions mesurables e ́tant mesurable, la meˆme proprie ́te ́ de mesurabilite ́ reste vraie pour l’application (ω, s) 7→ Xs(ω) de ́finie sur Ω × [0,t]. On conclut que le processus X est progressif. tu Remarque. On peut remplacer continu a` droite par continu a` gauche dans l’e ́nonce ́ de la proposition. La preuve est exactement analogue.
Tribu progressive. La famille des parties A ∈ F ⊗ B(R+) telles que le processus Xt (ω) = 1A(ω,t) soit progressif forme une tribu sur Ω × R+, appele ́e la tribu progressive. Il est alors facile de ve ́rifier (exercice!) qu’un processus X est progressif si et seulement si l’application (ω,t) 7→ Xt (ω) est mesurable sur Ω × R+ muni de la tribu progressive.
3.2 Temps d’arrˆet et tribus associ ́ees
Dans ce paragraphe, nous ge ́ne ́ralisons les notions de temps d’arreˆt et de tribu du passe ́ avant un temps d’arreˆt, qui ont de ́ja` e ́te ́ vues dans un cadre particulier dans le chapitre pr ́ece ́dent.
De ́finition 3.4. Une variable ale ́atoire T : Ω −→ [0, ∞] est un temps d’arreˆt de la filtration (Ft ) si, pour tout t ≥ 0, {T ≤ t} ∈ Ft .
Dans la suite, sauf pre ́cision contraire, “temps d’arreˆt” voudra dire “temps d’arreˆt de la filtration (Ft )” (nous rencontrerons d’autres filtrations). Remarquons que, si T est un temps d’arreˆt, {T = ∞} = (∪n∈N{T ≤ n})c est dans F∞. On associe a` un temps d’arreˆt T la tribu du passe ́ avant T de ́finie par
FT = {A ∈ F∞ : ∀t ≥ 0, A ∩ {T ≤ t} ∈ Ft }.


36 3 Filtrations et martingales
Proposition 3.2. Notons Gt = Ft+ la filtration des limites `a droite de Ft . Alors, pour tout temps d’arrˆet T , on a
GT = {A ∈ F∞ : ∀t > 0, A ∩ {T < t} ∈ Ft }.
On notera
FT + := GT .
De ́monstration. D’abord, si A ∈ GT , on a pour tout t ≥ 0, A ∩ {T ≤ t} ∈ Gt . Donc
A ∩ {T < t} = ⋃
n≥1
(
A ∩ {T ≤ t − 1
n}
)
∈ Ft
puisque A ∩ {T ≤ t − 1
n } ∈ Gt−1/n ⊂ Ft , pour tout n ≥ 1. Inversement, supposons A ∩ {T < t} ∈ Ft pour tout t > 0. Alors, pour tout t ≥ 0, et tout s > t,
A ∩ {T ≤ t} = ⋂
n≥1
(
A ∩ {T < t + 1
n}
)
∈ Fs
puisqu’on peut limiter l’intersection aux valeurs n ≥ n0, avec n0 tel que t + 1
n0 < s. On obtient ainsi que A ∩ {T ≤ t} ∈ Ft+ = Gt et donc A ∈ GT . tu
Proprie ́te ́s des temps d’arrˆet et des tribus associe ́es.
(a) Pour tout temps d’arreˆt T , on a FT ⊂ FT+. Si la filtration (Ft ) est continue a` droite, on a FT+ = FT . (b) Une fonction T : Ω → R ̄ + est un temps d’arreˆt de la filtration (Ft+) si et seulement si, pour tout t ≥ 0, {T < t} ∈ Ft . Cela e ́quivaut encore a` dire que T ∧ t est Ft -mesurable, pour tout t. (c) Si T = t est un temps d’arreˆt constant, FT = Ft , FT+ = Ft+. (d) Soit T un temps d’arrˆet. Pour A ∈ F∞, posons
T A(ω) =
{ T (ω) si ω ∈ A +∞ si ω ∈/ A
Alors A ∈ FT si et seulement si T A est un temps d’arreˆt. (e) Soit T un temps d’arrˆet. Alors T est FT -mesurable.
(g) Si (Sn) est une suite croissante de temps d’arreˆt, alors S = lim ↑ Sn est aussi un temps d’arreˆt. (h) Si (Sn) est une suite de ́croissante de temps d’arreˆt, alors S = lim ↓ Sn est un temps d’arreˆt de la filtration (Ft+), et
FS+ = ⋂
n
FSn+.
(f) Soient S, T deux temps d’arrêt. Si S ≤ T , alors FS ⊂ FT et FS+ ⊂ FT +. En général, S ∨ T et S ∧ T sont deux temps d’arrêt et FS ∧ T =FS∩FT . De plus, {S ≤ T } ∈ FS ∧ T , {S=T } ∈ FS ∧ T .


3.2 Temps d’arreˆt et tribus associe ́es 37
(i) Si (Sn) est une suite de ́croissante stationnaire de temps d’arreˆt (i.e. ∀ω, ∃N(ω): ∀n ≥ N(ω), Sn(ω) = S(ω)) alors S = lim ↓ Sn est aussi un temps d’arreˆt, et
FS = ⋂
n
FSn .
(j) Soit T un temps d’arreˆt. Une fonction ω 7→ Y (ω) de ́finie sur l’ensemble {T < ∞} et a` valeurs dans un espace mesurable (E, E ) est FT -mesurable si et seulement si, pour tout t ≥ 0, la restriction de Y a` l’ensemble {T ≤ t} est Ft -mesurable.
Remarque. Dans la proprie ́te ́ (j) nous utilisons la notion e ́vidente de G -mesurabilite ́ pour une variable ω 7→ Y (ω) de ́finie seulement sur une partie G -mesurable de l’espace Ω (G e ́tant une tribu sur Ω ). Cette notion interviendra de nouveau dans le The ́ore`me 3.1 ci-dessous.
La preuve des proprie ́te ́s pre ́ce ́dentes est facile. Nous laissons en exercice la preuve des cinq premie`res et de ́montrons les cinq dernie`res. (f) Si S ≤ T et A ∈ FS alors
A ∩ {T ≤ t} = (A ∩ {S ≤ t}) ∩ {T ≤ t} ∈ Ft ,
d’ou` A ∈ FT . Le meˆme argument (utilisant cette fois la Proposition 3.2) donne
FS+ ⊂ FT +. En g ́ene ́ral,
{S ∧ T ≤ t} = {S ≤ t} ∪ {T ≤ t} ∈ Ft ,
{S ∨ T ≤ t} = {S ≤ t} ∩ {T ≤ t} ∈ Ft .
Il est imme ́diat d’apre`s la premie`re assertion de (f) que FS∧T ⊂ (FS ∩ FT ). De plus, si A ∈ FS ∩ FT ,
A ∩ {S ∧ T ≤ t} = (A ∩ {S ≤ t}) ∪ (A ∩ {T ≤ t}) ∈ Ft ,
d’ou` A ∈ FS∧T . Ensuite, pour t ≥ 0,
{S ≤ T } ∩ {T ≤ t} = {S ≤ t} ∩ {T ≤ t} ∩ {S ∧ t ≤ T ∧ t} ∈ Ft
{S ≤ T } ∩ {S ≤ t} = {S ∧ t ≤ T ∧ t} ∩ {S ≤ t} ∈ Ft ,
car S ∧t et T ∧t sont Ft -mesurables d’apre`s (b). Cela donne {S ≤ T } ∈ FS ∩ FT = FS∧T . Ensuite, on e ́crit {S = T } = {S ≤ T } ∩ {T ≤ S}.
(g) Il suffit d’e ́crire
{S ≤ t} = ⋂
n
{Sn ≤ t} ∈ Ft .
(h) On e ́crit
{S < t} = ⋃
n
{Sn < t} ∈ Ft .


38 3 Filtrations et martingales
De plus, d’apre`s (f) on a FS+ ⊂ FSn+ pour tout n, et inversement si A ∈ ⋂
n FSn+,
A ∩ {S < t} = ⋃
n
(A ∩ {Sn < t}) ∈ Ft ,
d’ou` A ∈ FS+.
(i) Dans ce cas on a aussi
{S ≤ t} = ⋃
n
{Sn ≤ t} ∈ Ft ,
et pour A ∈ ⋂
n FSn ,
A ∩ {S ≤ t} = ⋃
n
(A ∩ {Sn ≤ t}) ∈ Ft ,
d’ou` A ∈ FS.
(j) Supposons d’abord que, pour tout t ≥ 0, la restriction de Y a` {T ≤ t} est Ft -mesurable. On a alors, pour toute partie mesurable A de E,
{Y ∈ A} ∩ {T ≤ t} ∈ Ft .
En faisant tendre t vers ∞, on obtient d’abord que {Y ∈ A} ∈ F∞, puis on de ́duit de l’e ́galite ́ pre ́ce ́dente que {Y ∈ A} est dans FT . On conclut que Y est FT -mesurable. Inversement, si Y est FT -mesurable, {Y ∈ A} ∈ FT et donc {Y ∈ A}∩{T ≤ t} ∈ Ft , d’ou` le re ́sultat voulu. tu
The ́ore`me 3.1. Soit (Xt )t≥0 un processus progressif `a valeurs dans un espace mesurable (E, E ), et soit T un temps d’arrˆet. Alors la fonction ω 7→ XT (ω) = XT(ω)(ω), d ́efinie sur l’ensemble {T < ∞}, est FT -mesurable.
De ́monstration. On applique la propri ́ete ́ (j) ci-dessus : la restriction a` {T ≤ t} de l’application ω 7→ XT (ω) est la composition des deux applications
{T ≤ t} 3 ω 7→ (ω, T (ω))
Ft Ft ⊗ B([0,t])
et
(ω, s) 7→ Xs(ω)
Ft ⊗ B([0,t]) E
qui sont toutes les deux mesurables (la deuxie`me par de ́finition d’un processus progressif). On obtient que la restriction a` {T ≤ t} de l’application ω 7→ XT (ω) est Ft -mesurable, ce qui suffit pour conclure d’apre`s la proprie ́te ́ (j). tu
Proposition 3.3. Soient T un temps d’arrˆet et S une variable al ́eatoire FT -mesurable telle que S ≥ T . Alors S est aussi un temps d’arrˆet.


3.2 Temps d’arreˆt et tribus associe ́es 39
En particulier, si T est un temps d’arrˆet,
Tn =
∞
∑
k=0
k+1
2n 1{k2−n<T ≤(k+1)2−n} + ∞ · 1{T =∞} , n = 0, 1, 2, . . .
d ́efinit une suite de temps d’arrˆet qui d ́ecroˆıt vers T .
De ́monstration. On e ́crit
{S ≤ t} = {S ≤ t} ∩ {T ≤ t} ∈ Ft
puisque {S ≤ t} est FT -mesurable. La deuxie`me assertion en de ́coule puisque Tn est clairement FT -mesurable et Tn ≥ T . tu Nous terminons ce paragraphe avec un the ́ore`me ge ́ne ́ral qui permet la construction de nombreux temps d’arreˆt.
The ́ore`me 3.2. On suppose que la filtration (Ft ) v ́erifie les conditions habituelles (elle est compl`ete et continue `a droite). Soit A ⊂ Ω × R+ un ensemble progressif (i.e. tel que le processus Xt (ω) = 1A(ω,t) soit progressif) et soit DA le d ́ebut de A d ́efini par
DA(ω) = inf{t ≥ 0 : (ω,t) ∈ A} (avec inf ∅ = ∞).
Alors DA est un temps d’arrˆet.
La preuve de ce th ́eore`me repose sur le re ́sultat difficile de the ́orie de la mesure qui suit.
The ́ore`me. Soit (Λ , G , Π ) un espace de probabilit ́e complet, au sens o`u la tribu G contient tous les ensembles Π -n ́egligeables. Soit H ⊂ Λ × R+ un ensemble mesurable pour la tribu produit G ⊗ B(R+). Alors la projection de H,
p(H) = {ω ∈ Λ : ∃t ≥ 0, (ω,t) ∈ H}
appartient `a la tribu G .
(Pour une preuve voir par exemple le Chapitre III de [1].)
De ́monstration du The ́ore`me 3.2. On applique le the ́or`eme ci-dessus en fixant t ≥ 0, en prenant (Λ , G , Π ) = (Ω , Ft , P) et H = (Ω × [0,t[) ∩ A. La de ́finition d’un processus progressif montre que H est mesurable pour Ft ⊗ B(R+). En conse ́quence,
p(H) = {ω ∈ Ω : ∃s < t, (ω, s) ∈ A} ∈ Ft .
Or {DA < t} = p(H). On a donc obtenu {DA < t} ∈ Ft et puisque la filtration est continue a` droite, la proprie ́te ́ (b) montre que DA est un temps d’arreˆt. tu
Dans la suite, nous n’utiliserons pas le re ́sultat du The ́ore`me 3.2 mais seulement des re ́sultats plus faibles que l’on peut obtenir sans hypothe`se sur la filtration (Ft ).


40 3 Filtrations et martingales
Proposition 3.4. Soit (Xt )t≥0 un processus adapt ́e, `a valeurs dans un espace m ́etrique (E, d).
(i) Supposons que les trajectoires de X sont continues `a droite, et soit O un ouvert de E. Alors TO = inf{t ≥ 0 : Xt ∈ O}
est un temps d’arrˆet de la filtration (Ft+). (ii) Supposons que les trajectoires de X sont continues, et soit F un ferm ́e de E. Alors TF = inf{t ≥ 0 : Xt ∈ F}
est un temps d’arrˆet.
De ́monstration. (i) On a pour tout t ≥ 0,
{TO < t} = ⋃
s∈[0,t[∩Q
{Xs ∈ O} ∈ Ft .
(ii) De meˆme,
{TF ≤ t} =
{
inf
0≤s≤t d(Xs, F) = 0
}
=
{
inf
s∈[0,t]∩Q
d(Xs, F) = 0
}
∈ Ft . tu
3.3 Martingales et surmartingales `a temps continu
Rappelons qu’on a fixe ́ un espace de probabilite ́ filtre ́ (Ω , F , (Ft ), P). Dans la suite de ce chapitre, tous les processus sont a` valeurs re ́elles.
De ́finition 3.5. Un processus (Xt )t≥0 adapte ́ et tel que Xt ∈ L1 pour tout t ≥ 0, est appel ́e
· martingale si, pour tous 0 ≤ s < t, E[Xt | Fs] = Xs; · surmartingale si, pour tous 0 ≤ s < t, E[Xt | Fs] ≤ Xs; · sous-martingale si, pour tous 0 ≤ s < t, E[Xt | Fs] ≥ Xs.
Cette de ́finition ge ́ne ́ralise de manie`re e ́vidente les notions analogues a` temps discret, ou` on conside`re un processus (Yn)n∈N indexe ́ par les entiers positifs, ainsi qu’une filtration discre`te (Gn)n∈N (voir l’Appendice A2 ci-dessous). Si (Xt )t≥0 est une surmartingale, (−Xt )t≥0 est une sous-martingale. Pour cette raison, une partie des re ́sultats qui suivent sont e ́nonce ́s seulement pour des surmartingales, les analogues pour des sous-martingales en de ́coulant imme ́diatement.
Exemple important. On dit qu’un processus (Zt )t≥0 (a` valeurs re ́elles) est un processus a` accroissements inde ́pendants (PAI) par rapport a` la filtration (Ft ) si Z est adapt ́e et si, pour tous 0 ≤ s < t, Zt − Zs est inde ́pendant de la tribu Fs (par exemple un mouvement brownien est un PAI par rapport a` sa filtration canonique, comple ́t ́ee ou non). Si Z est un PAI par rapport a` (Ft ), alors


3.3 Martingales et surmartingales a` temps continu 41
(i) si Zt ∈ L1 pour tout t ≥ 0, Z ̃t = Zt − E[Zt ] est une martingale; (ii) si Zt ∈ L2 pour tout t ≥ 0, Xt = Z ̃t2 − E[Z ̃t2] est une martingale;
(iii) s’il existe θ ∈ R tel que E[eθZt ] < ∞ pour tout t ≥ 0,
Xt = eθ Zt
E[eθZt ]
est une martingale.
Les de ́monstrations sont tre`s faciles. Dans le deuxie`me cas, on a pour 0 ≤ s < t,
E[(Z ̃t )2 | Fs] = E[(Z ̃s + Z ̃t − Z ̃s)2 | Fs]
=
Z ̃2
s + 2Z ̃sE[Z ̃t − Z ̃s | Fs] + E[(Z ̃t − Z ̃s)2 | Fs]
=
Z ̃2
s + E[(Z ̃t − Z ̃s)2]
=
Z ̃2
s + E[Z ̃2
t ] − 2E[Z ̃sZ ̃t ] + E[Z ̃2
s]
=
Z ̃2
s + E[Z ̃2
t ] − E[Z ̃2
s ],
parce que E[Z ̃sZ ̃t ] = E[Z ̃sE[Z ̃t | Fs]] = E[Z ̃s2]. Le re ́sultat voulu en de ́coule. Dans le troisi`eme cas,
E[Xt | Fs] = eθZs E[eθ(Zt −Zs) | Fs]
E[eθ Zs ] E[eθ (Zt −Zs)] = eθ Zs
E[eθZs ] = Xs.
Conside ́rons le cas particulier du mouvement brownien : on dit que B est un (Ft )-mouvement brownien si B est un mouvement brownien, et si B est (adapte ́ et) a` accroissements inde ́pendants par rapport a` (Ft ) au sens donn ́e ci-dessus. Cette dernie`re proprie ́te ́ est toujous vraie si (Ft ) est la filtration canonique (e ́ventuellement comple ́te ́e) de B. Si B est un (Ft )-mouvement brownien, on voit que les processus
Bt , B2
t − t , eθ Bt − θ2
2t
sont des martingales. Les processus eθBt− θ2
2 t sont appele ́s des martingales exponentielles du mouvement brownien : ces processus et leurs g ́ene ́ralisations joueront un roˆle important dans la suite. On peut aussi prendre pour f ∈ L2(R+, B(R+), dt),
Zt =
∫t
0
f (s) dBs .
Les proprie ́te ́s des mesures gaussiennes montrent que Z est un PAI par rapport a` la filtration canonique de B, et donc
∫t
0
f (s)dBs ,
(∫ t
0
f (s)dBs
)2
−
∫t
0
f (s)2ds , exp
(
θ
∫t
0
f (s)dBs − θ 2
2
∫t
0
f (s)2ds
)
sont des martingales.


42 3 Filtrations et martingales
On peut enfin prendre Z = N, processus de Poisson standard (et pour (Ft ) la filtration canonique de N), et on trouve alors en particulier que
Nt − t , (Nt − t)2 − t
sont des martingales.
Proposition 3.5. Soit (Xt )t≥0 une martingale (respectivement une sous-martingale) et soit f : R −→ R+ une fonction convexe (resp. une fonction convexe croissante). Supposons aussi que E[ f (Xt )] < ∞ pour tout t ≥ 0. Alors, ( f (Xt ))t≥0 est une sousmartingale.
De ́monstration. D’apr`es l’ine ́galit ́e de Jensen, on a pour s < t
E[ f (Xt ) | Fs] ≥ f (E[Xt | Fs]) ≥ f (Xs),
la dernie`re ine ́galite ́ utilisant le caracte`re croissant de f lorsque (Xt ) est une sousmartingale. tu Conse ́quences. Si (Xt )t≥0 est une martingale, |Xt | est une sous-martingale, et plus ge ́ne ́ralement, pour tout re ́el p ≥ 1, |Xt |p est une sous-martingale, a` condition qu’on ait E[|Xt |p] < ∞ pour tout t ≥ 0. Si (Xt )t≥0 est une sous-martingale, (Xt )+ est aussi une sous-martingale.
Remarque. Si (Xt )t≥0 est une martingale quelconque, l’ine ́galite ́ de Jensen montre que, pour tout p ≥ 1, E[|Xt |p] est fonction croissante de t a` valeurs dans [0, ∞].
Proposition 3.6. Soit (Xt )t≥0 une sous-martingale ou une surmartingale. Alors pour tout t > 0,
sup
0≤s≤t
E[|Xs|] < ∞.
De ́monstration. Il suffit bien suˆr de traiter le cas ou` (Xt )t≥0 est une sous-martingale. Puisque (Xt )+ est aussi une sous-martingale, on a pour tout s ∈ [0,t],
E[(Xs)+] ≤ E[(Xt )+].
D’autre part, puisque X est une sous-martingale on a aussi pour s ∈ [0,t],
E[Xs] ≥ E[X0].
En combinant ces deux ine ́galite ́s, et en remarquant que |x| = 2x+ − x, on trouve
sup
s∈[0,t]
E[|Xs|] ≤ 2 E[(Xt )+] − E[X0] < ∞,
d’ou` le re ́sultat voulu. tu
La proposition suivante sera tre`s utile dans l’e ́tude des martingales de carre ́ inte ́grable.


3.3 Martingales et surmartingales a` temps continu 43
Proposition 3.7. Soit (Mt )t≥0 une martingale de carr ́e int ́egrable (Mt ∈ L2 pour tout t ≥ 0). Soient 0 ≤ s < t et soit s = t0 < t1 < · · · < tp = t une subdivision de l’intervalle [s,t]. Alors,
E
[p
i=∑1
(Mti − Mti−1 )2
∣
∣
∣ Fs
]
= E[M2
t − M2
s | Fs] = E[(Mt − Ms)2 | Fs].
En particulier,
E
[p
i=∑1
(Mti − Mti−1 )2]
= E[M2
t − M2
s ] = E[(Mt − Ms)2].
De ́monstration. Pour tout i = 1, . . . , p,
E[(Mti − Mti−1 )2 | Fs] = E[E[(Mti − Mti−1 )2 | Fti−1 ] | Fs]
=E
[
E [M 2
ti | Fti−1 ] − 2Mti−1 E[Mti | Fti−1 ] + M2
ti−1
∣
∣
∣ Fs
]
=E
[
E [M 2
ti | Fti−1 ] − M2
ti−1
∣
∣
∣ Fs
]
= E[M2
ti − M2
ti−1 | Fs]
d’ou` aise ́ment le re ́sultat voulu. tu
Notre objectif est maintenant d’e ́tablir des re ́sultats de re ́gularite ́ des trajectoires pour les martingales et les surmartingales a` temps continu. Nous commenc ̧ons par e ́tablir des analogues d’ine ́galit ́es classiques a` temps discret.
Proposition 3.8. (i) (Ine ́galite ́ maximale) Soit (Xt )t≥0 une surmartingale `a trajectoires continues `a droite. Alors, pour tout t > 0 et tout λ > 0,
λP
[
sup
0≤s≤t
|Xs| > λ
]
≤ E[|X0|] + 2E[|Xt |].
(ii) (In ́egalite ́ de Doob dans Lp) Soit (Xt )t≥0 une martingale `a trajectoires continues `a droite. Alors pour tout t > 0 et tout p > 1,
E
[
sup
0≤s≤t
|Xs|p]
≤
(p
p−1
)p
E[|Xt |p].
λP
[
sup
s∈Dm
|Xs| > λ
]
≤ E[|X0|] + 2E[|Xt |].
Démonstration. (i) Fixons t>0 et considérons un sous-ensemble dénombrable dense D de R+ tel que 0 ∈ D et t ∈ D. On peut écrire D∩[0, t] comme la réunion croissante
d’une suite (Dm)m ≥ 1 de parties finies de [0, t] de la forme Dm = {tm
0 ,tm
1 , . . . , tmm}
avec 0 = tm
0 <tm
1 < · · · < tmm = t. Pour chaque valeur de m fixée on peut appliquer
l’inégalité maximale (voir l’Appendice A2 ci-dessous) à la suite Yn = Xtnm∧m qui est
une surmartingale discrète relativement à la filtration Gn = Ftnm∧m . On trouve ainsi


44 3 Filtrations et martingales
Mais il est imme ́diat que
P
[
sup
s∈Dm
|Xs| > λ
]
↑P
[
sup
s∈D∩[0,t]
|Xs| > λ
]
quand m ↑ ∞. On a donc aussi
λP
[
sup
s∈D∩[0,t]
|Xs| > λ
]
≤ E[|X0|] + 2E[|Xt |].
Enfin, la continuite ́ a` droite des trajectoires, et le fait que t ∈ D, assurent que
sup
s∈D∩[0,t]
|Xs| = sup
s∈[0,t]
|Xs|. (3.1)
La majoration de (i) de ́coule de ces observations. (ii) En suivant la meˆme de ́marche que dans la preuve de (i), et en utilisant l’ine ́galite ́ de Doob dans Lp pour les martingales discre`tes (voir l’Appendice A2), on trouve, pour tout entier m ≥ 1,
E
[
sup
s∈Dm
|Xs|p]
≤
(p
p−1
)p
E[|Xt |p].
Il suffit maintenant de faire tendre m vers l’infini, en utilisant le the ́ore`me de convergence monotone, et ensuite d’appliquer (3.1). tu
Remarque. Si on ne suppose pas que les trajectoires sont continues a` droite, la preuve ci-dessus montre que, pour tout sous-ensemble de ́nombrable dense D de R+ et tout t > 0,
P
[
sup
s∈D∩[0,t]
|Xs| > λ
]
≤1
λ (E[|X0|] + 2E[|Xt |]).
En faisant tendre λ vers ∞, on a en particulier
sup
s∈D∩[0,t]
|Xs| < ∞ , p.s.
Nombres de monte ́es. Si f : I −→ R est une fonction de ́finie sur une partie I de R+, et si a < b, le nombre de monte ́es de f le long de [a, b], note ́ M f
ab(I) est le supremum des entiers k ≥ 1 tels que l’on puisse trouver une suite finie croissante s1 < t1 < · · · < sk < tk d’e ́le ́ments de I tels que f (si) < a et f (ti) > b pour tout i ∈ {1, . . . , k} (s’il n’existe de telle suite pour aucun entier k ≥ 1, on prend M f
ab(I) = 0). Il est commode d’utiliser les nombres de monte ́es pour e ́tudier la re ́gularite ́ des fonctions. Dans le lemme suivant, la notation
lsi↓↓mt f (s) (resp. lsi↑↑mt f (s) )
signifie


3.3 Martingales et surmartingales a` temps continu 45
s↓lti,sm>t f (s) (resp. s↑lti,sm<t f (s) ).
On dit qu’une fonction g : R+ → R est ca`dla`g si elle est continue a` droite et si elle admet une limite a` gauche en tout t > 0.
Lemme 3.1. Soit D un sous-ensemble d ́enombrable dense de R+ et soit f une fonction d ́efinie sur D et `a valeurs r ́eelles. Supposons que, pour tout r ́eel T ∈ D, la fonction f est born ́ee sur D ∩ [0, T ], et que, pour tout choix des rationnels a et b tels que a < b on a Mf
ab(D ∩ [0, T ]) < ∞.
Alors, la limite `a droite
f (t+) := lim
s↓↓t,s∈D f (s)
existe pour tout r ́eel t ≥ 0, et de mˆeme la limite `a gauche
f (t−) := lim
s↑↑t,s∈D f (s)
existe pour tout r ́eel t > 0. De plus, la fonction g : R+ −→ R d ́efinie par g(t) = f (t+) est c`adl`ag.
La preuve de ce lemme d’analyse est laisse ́e au lecteur. Il est important de noter que les limites a` droite et a` gauche f (t+) et f (t−) sont de ́finies pour tout re ́el t (t > 0 dans le cas de f (t−)) et pas seulement pour t ∈ D.
The ́ore`me 3.3. Soit (Xt )t≥0 une surmartingale et soit D un sous-ensemble d ́enombrable dense de R+. (i) Pour presque tout ω ∈ Ω , la restriction `a D de l’application s 7→ Xs(ω) admet en tout point t de R+ une limite `a droite finie not ́ee Xt+(ω) et en tout point t de R+\{0} une limite `a gauche finie not ́ee Xt−(ω). (ii) Pour tout t ∈ R+, Xt+ ∈ L1 et
Xt ≥ E[Xt+ | Ft ]
avec  ́egalit ́e si la fonction t −→ E[Xt ] est continue `a droite (en particulier si X est une martingale). Le processus (Xt+)t≥0 est une surmartingale par rapport `a la filtration (Ft+), une martingale si X en est une.
Remarque. Pour les assertions de (ii), particulie`rement la dernie`re, il faut que Xt+(ω) soit de ́fini pour tout ω ∈ Ω et pas seulement en dehors d’un ensemble ne ́gligeable comme dans (i) : ce point sera pre ́cise ́ dans la preuve qui suit.
De ́monstration. (i) Fixons T ∈ D. D’apre`s la remarque suivant la Proposition 3.8, on a sup
s∈D∩[0,T ]
|Xs| < ∞ , p.s.
Comme dans la preuve de la Proposition 3.8, on peut choisir une suite (Dm)m≥1 de sous-ensembles finis de D croissant vers D ∩ [0, T ] (et tels que 0, T ∈ Dm) et


46 3 Filtrations et martingales
l’ine ́galite ́ des nombres de mont ́ees de Doob (voir l’Appendice A2) donne, pour tous a < b et tout m ≥ 1,
E [M X
ab(Dm)] ≤ 1
b − a E[(XT − a)−].
On peut faire tendre m vers ∞ et obtenir par convergence monotone
E [M X
ab(D ∩ [0, T ])] ≤ 1
b − a E[(XT − a)−] < ∞.
On a donc
MX
ab([0, T ] ∩ D) < ∞ , p.s.
Posons
N= ⋃
T ∈D
({
sup
t∈D∩[0,T ]
|Xt | = ∞
}
∪
⋃
a,b∈Q,a<b
{MX
ab(D ∩ [0, T ]) = ∞}
)
. (3.2)
Alors P(N) = 0, et d’autre part si ω ∈/ N, la fonction D 3 t 7→ Xt (ω) satisfait les hypothe`ses du Lemme 3.1, ce qui donne le r ́esultat de (i).
(ii) Pour que Xt+(ω) soit de ́fini pour tout ω et pas seulement sur l’ensemble Ω \N, on pose
Xt+(ω) =
{ lim
s↓↓t,s∈D Xs(ω) si la limite existe
0 sinon.
Fixons t ≥ 0 et choisissons une suite (tn)n∈N dans D telle que tn de ́croˆıt strictement vers t quand n → ∞. Alors, par construction on a p.s.,
Xt+ = nli→m∞
Xtn .
Graˆce a` la convergence dans L1, on peut passer a` la limite dans l’ine ́galite ́ Xt ≥ E[Xtn | Ft ], et on trouve
Xt ≥ E[Xt+ | Ft ].
De plus, toujours graˆce a` la convergence dans L1, on a E[Xt+] = lim E[Xtn ] et donc, si la fonction s −→ E[Xs] est continue a` droite, on doit avoir E[Xt+] = E[Xt ]. Clairement, l’ine ́galite ́ Xt ≥ E[Xt+ | Ft ] n’est alors possible que si Xt = E[Xt+ | Ft ]. Nous avons de ́ja` remarque ́ que Xt+ est Ft+-mesurable. Soient ensuite s < t et soit aussi une suite (sn)n∈N dans D qui de ́croˆıt strictement vers s. On peut bien suˆr supposer sn ≤ tn pour tout n. Alors Xsn converge vers Xs+ dans L1, et donc, si A ∈ Fs+ ⊂ Fsn pour tout n,
Avec cette convention, Xt+ est Ft+-mesurable.
De plus, posons, pour tout entier k ≤ 0, Yk=Xt− k . Alors Y est une surmartingale rétrograde par rapport à la filtration Hk=Ft− k (voir l’Appendice A2). D’après la Proposition 3.6, on a supk ≤ 0 E[|Yk|]<∞. Le théorème de convergence pour les surmartingales discrètes rétrogrades (voir l’Appendice A2) entraîne alors que la suite Xtn converge dans L1 vers Xt+. En particulier Xt+ ∈ L1.


3.4 The ́ore`mes d’arreˆt 47
E[Xs+1A] = nli→m∞
E[Xsn 1A] ≥ nli→m∞
E[Xtn 1A] = E[Xt+1A] = E[E[Xt+ | Fs+]1A],
ce qui entraˆıne Xs+ ≥ E[Xt+ | Fs+] puisque Xs+ et E[Xt+ | Fs+] sont toutes deux Fs+-mesurables. Enfin, si X est une martingale, on peut remplacer dans le calcul pr ́ece ́dent l’ine ́galite ́ ≥ par une e ́galite ́. tu
The ́ore`me 3.4. Supposons que la filtration (Ft ) satisfait les conditions habituelles. Si X = (Xt )t≥0 est une surmartingale et si la fonction t −→ E[Xt ] est continue `a droite, alors X a une modification, qui est aussi une (Ft )-surmartingale, dont les trajectoires sont c`adl`ag.
De ́monstration. Fixons un ensemble D comme dans le The ́ore`me 3.3. Soit N l’ensemble ne ́gligeable de ́fini par (3.2). Posons alors, pour tout t ≥ 0,
Yt (ω) =
{ Xt+(ω) si ω ∈/ N 0 si ω ∈ N.
Le Lemme 3.1 montre alors que les trajectoires de Y sont ca`dla`g. Rappelons que la variable Xt+ est Ft+-mesurable, et donc ici Ft -mesurable puisque la filtration est continue a` droite. Puisque l’ensemble ne ́gligeable N est dans F∞, le fait que la filtration soit comple`te assure aussi que Yt est Ft -mesurable. Enfin, on a d’apre`s le The ́or`eme 3.3 (ii),
Xt = E[Xt+ | Ft ] = Xt+ = Yt , p.s.
puisque Xt+ est Ft -mesurable. On voit ainsi que Y est une modification de X. Le processus Y est adapte ́ a` la filtration (Ft ) et il est aussi imme ́diat que Y est une (Ft )-surmartingale. tu
Remarque. Si la filtration est quelconque, on peut toujours appliquer le the ́ore`me pre ́ce ́dent a` l’augmentation habituelle de (Ft ) et au processus (Xt+) du The ́ore`me 3.3 (remarquer que l’application t 7→ E[Xt+] est toujours continue a` droite). On trouve ainsi que (Xt+) a une modification ca`dl`ag. En particulier, si on sait a` l’avance que les trajectoires de X sont continues a` droite, on en de ́duit que p.s. elles ont aussi des limites a` gauche (une modification continue a` droite est unique `a indistinguabilite ́ pre`s).
3.4 The ́or`emes d’arreˆt
Nous commen ̧cons par un the ́ore`me de convergence pour les surmartingales.
The ́ore`me 3.5. Soit X une surmartingale `a trajectoires continues `a droite et born ́ee dans L1. Alors, il existe une variable X∞ ∈ L1 telle que
tli→m∞
Xt = X∞, p.s.


48 3 Filtrations et martingales
De ́monstration. Soit D un sous-ensemble de ́nombrable dense de R+. D’apre`s la preuve du The ́ore`me 3.3, on a pour tout T ∈ D et a < b,
E [M X
ab(D ∩ [0, T ])] ≤ 1
b − a E[(XT − a)−].
Par convergence monotone, on a pour tous a < b,
E [M X
ab(D)] ≤ 1
b − a sup
t≥0
E[(Xt − a)−] < ∞,
X∞ := lim
D3t→∞
Xt (3.3)
existe p.s. dans [−∞, ∞]. Le lemme de Fatou montre alors que
E[|X∞|] ≤ lim inf
D3t→∞
E[|Xt |] < ∞.
Donc X∞ ∈ L1 (en particulier |X∞| < ∞ p.s.). La continuite ́ a` droite des trajectoires permet de supprimer la restriction t ∈ D dans la limite (3.3). tu
De ́finition 3.6. Une martingale (Xt )t≥0 est dite ferme ́e s’il existe une variable Z ∈ L1 telle que, pour tout t ≥ 0,
Xt = E[Z | Ft ].
La proposition suivante est l’analogue continu d’un re ́sultat pour les martingales discre`tes rappele ́ dans l’Appendice A2.
Proposition 3.9. Soit (Xt )t≥0 une martingale `a trajectoires continues `a droite. Alors il y a  ́equivalence entre
(i) (Xt )t≥0 est ferm ́ee; (ii) Xt converge p.s. et dans L1 quand t → ∞, vers une variable not ́ee X∞; (iii) la famille (Xt )t≥0 est uniform ́ement int ́egrable.
De plus si ces propri ́et ́es sont satisfaites on a Xt = E[X∞ | Ft ] pour tout t ≥ 0.
Nous utilisons maintenant les th ́eore`mes d’arreˆt du cas discret pour e ́tablir des re ́sultats analogues a` temps continu. Si (Xt )t≥0 est une martingale ou une surmartingale a` trajectoires continues `a droite et qui converge p.s. quand t → ∞ vers une limite note ́e X∞, pour tout temps d’arreˆt T , on notera XT la variable
puisque la famille (Xt )t ≥ 0 est bornée dans L1. Donc, p.s. pour tous rationnels a<b
on a M X
ab(D)<∞. Cela suffit pour obtenir que la limite
Démonstration. L’implication (i)⇒(iii) est facile : si Z ∈ L1, la famille des variables E[Z | G ], lorsque G décrit l’ensemble des sous-tribus de F , est uniformément intégrable. Si (iii) est vrai, la Théorème 3.5 entraîne que Xt converge p.s. vers X∞, donc aussi dans L1 par uniforme intégrabilité. Enfin, si (ii) est vérifié, on
peut passer à la limite t → ∞ dans L1 dans l’égalité Xs = E[Xt | Fs ] et on trouve Xs = E[X∞ | Fs ]. t


3.4 The ́ore`mes d’arreˆt 49
XT (ω) = 1{T (ω)<∞}XT (ω)(ω) + 1{T (ω)=∞}X∞(ω).
Comparer avec le The ́ore`me 3.1 ou` la variable XT e ́tait seulement de ́finie sur l’ensemble {T < ∞}. Avec cette nouvelle de ́finition, la variable XT reste FT mesurable : utiliser le The ́ore`me 3.1 et le fait, facile a` ve ́rifier, que 1{T=∞}X∞ est FT -mesurable.
The ́ore`me 3.6 (The ́ore`me d’arreˆt pour les martingales). Soit (Xt )t≥0 une martingale `a trajectoires continues `a droite et uniform ́ement int ́egrable. Soient S et T deux temps d’arrˆet avec S ≤ T . Alors XS et XT sont dans L1 et
XS = E[XT | FS].
En particulier, pour tout temps d’arrˆet S, on a
XS = E[X∞ | FS],
et
E[XS] = E[X∞] = E[X0].
De ́monstration. Posons pour tout entier n ≥ 0,
Tn =
∞
∑
k=0
k+1
2n 1{k2−n<T ≤(k+1)2−n} + ∞ · 1{T =∞}
et de meˆme
Sn =
∞
∑
k=0
k+1
2n 1{k2−n<S≤(k+1)2−n} + ∞ · 1{S=∞}.
La Proposition 3.3 montre que (Tn) et (Sn) sont deux suites de temps d’arreˆt qui de ́croissent respectivement vers T et vers S. De plus on a Sn ≤ Tn pour tout n ≥ 0. Observons maintenant que pour chaque n fixe ́, Sn et Tn sont des temps d’arreˆt de la filtration discre`te (Fk/2n )k≥0. En appliquant le the ́ore`me d’arreˆt pour les martingales discr`etes ferme ́es (voir l’Appendice A2) on a
XSn = E[XTn | FSn ]
(il y a ici une petite subtilite ́ : il faut ve ́rifier que la tribu du passe ́ avant Sn lorsque Sn est vu comme temps d’arreˆt de la filtration discre`te (Fk/2n )k≥0 co ̈ıncide bien avec la tribu FSn – cela ne pose cependant aucune difficulte ́). Soit maintenant A ∈ FS. Puisque FS ⊂ FSn , on a A ∈ FSn et donc
E[1AXSn ] = E[1AXTn ].
Par continuite ́ a` droite des trajectoires on a p.s.
XS = nli→m∞
XSn , XT = nli→m∞
XTn .


50 3 Filtrations et martingales
Ces limites ont aussi lieu dans L1. En effet, toujours d’apre`s le the ́ore`me d’arreˆt pour les martingales discr`etes ferme ́es, on a XSn = E[X∞ | FSn ] pour tout n, et donc la suite (XSn ) est uniforme ́ment inte ́grable (et de meˆme pour la suite (XTn )).
La convergence L1 montre que XS et XT sont dans L1, et permet aussi de passer a` la limite dans l’e ́galite ́ E[1AXSn ] = E[1AXTn ] pour obtenir
E[1A XS] = E[1A XT ].
Comme ceci est vrai pour tout A ∈ FS, et comme la variable XS est FS-mesurable (d’apre`s les remarques pre ́ce ́dant le the ́ore`me), on conclut que
XS = E[XT | FS]
ce qui ache`ve la preuve. tu
Nous donnons maintenant deux corollaires du The ́ore`me 3.6.
Corollaire 3.1. Soit (Xt )t≥0 une martingale `a trajectoires continues `a droite et soient S ≤ T deux temps d’arrˆet born ́es. Alors XS et XT sont dans L1 et
XS = E[XT | FS] .
De ́monstration. Soit a ≥ 0 tel que T ≤ a. On applique le the ́ore`me pre ́ce ́dent a` (Xt∧a)t≥0 qui est bien suˆr ferme ́e par Xa. tu
Le second corollaire montre qu’une martingale (resp. une martingale uniforme ́ment inte ́grable) arreˆte ́e a` un temps d’arreˆt reste une martingale (resp. une martingale uniforme ́ment inte ́grable). Ce re ́sultat jouera un rˆole particulie`rement important dans les chapitres qui suivent.
Corollaire 3.2. Soit (Xt )t≥0 une martingale `a trajectoires continues `a droite, et soit T un temps d’arrˆet. (i) Le processus (Xt∧T )t≥0 est encore une martingale. (ii) Supposons de plus la martingale (Xt )t≥0 uniform ́ement int ́egrable. Alors le processus (Xt∧T )t≥0 est aussi une martingale uniform ́ement int ́egrable, et on a pour tout t ≥ 0, Xt∧T = E[XT | Ft ]. (3.4)
De ́monstration. On commence par montrer (ii). Rappelons que XT ∈ L1 d’apre`s le Th ́eore`me 3.6. Il suffit donc d’ ́etablir (3.4). D’apre`s le The ́ore`me 3.6, on a aussi
Xt∧T = E[XT | Ft∧T ].
Puisque XT 1{T<∞} est FT -mesurable, on sait que XT 1{T≤t} est Ft -mesurable (d’apr`es la proprie ́te ́ (j) ci-dessus), et aussi FT -mesurable, donc Ft∧T -mesurable. Il en de ́coule que
E[XT 1{T ≤t} | Ft∧T ] = XT 1{T ≤t} = E[XT 1{T ≤t} | Ft ].
Pour comple ́ter la preuve, il reste a` voir que


3.4 The ́ore`mes d’arreˆt 51
E[XT 1{T >t} | Ft∧T ] = E[XT 1{T >t} | Ft ]. (3.5)
Or si A ∈ Ft , on ve ́rifie tre`s facilement que A ∩ {T > t} ∈ FT . On a e ́galement A ∩ {T > t} ∈ Ft , et donc A ∩ {T > t} ∈ Ft ∩ FT = Ft∧T , ce qui entraˆıne
E[1A1{T >t}XT ] = E[1A1{T >t}E[XT | Ft∧T ]] = E[1AE[XT 1{T >t} | Ft∧T ]].
On voit ainsi que la variable E[XT 1{T>t} | Ft∧T ], qui est Ft -mesurable, ve ́rifie la proprie ́te ́ caracte ́ristique de E[XT 1{T>t} | Ft ]. L’e ́galit ́e (3.5) en de ́coule, ce qui comple`te la preuve de (3.4) et de (ii). Pour obtenir (i), il suffit maintenant d’appliquer (ii) a` la martingale (uniforme ́ment inte ́grable) (Xt∧a)a≥0, pour tout choix de a ≥ 0. tu
Exemples d’application. Avant tout, le the ́ore`me d’arreˆt est un outil de calcul explicite de probabilite ́s et de lois. Donnons deux exemples typiques et importants de telles applications (plusieurs autres exemples se trouvent dans les exercices de ce chapitre et des chapitres suivants). Soit B un mouvement brownien re ́el issu de 0. Pour tout re ́el a, posons Ta = inf{t ≥ 0 : Bt = a}. Rappelons que Ta < ∞ p.s.
(a) Loi du point de sortie d’un intervalle. Pour tout choix de a < 0 < b, on a
P(Ta < Tb) = b
b − a , P(Tb < Ta) = −a
b−a.
Pour obtenir ce re ́sultat on conside`re le temps d’arreˆt T = Ta ∧ Tb et la martingale arreˆte ́e Mt = Bt∧T (c’est une martingale d’apre`s le Corollaire 3.2). Manifestement M est borne ́e par b ∨ |a|, donc uniforme ́ment inte ́grable, et on peut donc appliquer le the ́ore`me d’arreˆt pour obtenir
0 = E[M0] = E[MT ] = b P(Tb < Ta) + a P(Ta < Tb).
Comme on a aussi P(Tb < Ta)+ P(Ta < Tb) = 1, la formule annonce ́e en de ́coule. En fait la preuve montre que ce re ́sultat est valable plus ge ́ne ́ralement si on remplace le mouvement brownien par une martingale a` trajectoires continues issue de 0, a` condition de savoir que le processus sort p.s. de ]a, b[.
(b) Transform ́ee de Laplace des temps d’atteinte. Nous fixons maintenant a > 0 et notre but est de calculer la transforme ́e de Laplace de Ta. Pour tout λ ∈ R, conside ́rons la martingale exponentielle
Ntλ = exp(λ Bt − λ 2
2 t).
Supposons d’abord λ > 0. D’apre`s le Corollaire 3.2, le processus Ntλ∧Ta est encore
une martingale, et on voit imme ́diatement que cette martingale est borne ́e par eλa, donc uniforme ́ment inte ́grable. En appliquant la derni`ere assertion du The ́ore`me 3.6 a` cette martingale et au temps d’arreˆt S = Ta (ou S = ∞) on trouve


52 3 Filtrations et martingales
eλ aE[e− λ2
2 Ta ] = E[NTλa ] = 1 .
En rempla ̧cant λ par
√
2λ , on conclut que, pour tout λ > 0,
E[e−λ Ta ] = e−a
√
2λ . (3.6)
(Cette formule pourrait aussi eˆtre de ́duite de la connaissance de la densit ́e de Ta, voir le Corollaire 2.4.) Il est instructif d’essayer de reproduire le raisonnement pre ́ce ́dent en utilisant la martingale Ntλ pour λ < 0 : on aboutit alors a` un re ́sultat absurde, ce qui s’explique par le fait que la martingale arrˆete ́e Ntλ∧Ta n’est pas uniforme ́ment
inte ́grable lorsque λ < 0. Il est crucial de toujours ve ́rifier l’uniforme inte ́grabilite ́ lorsqu’on applique le The ́ore`me 3.6 : dans l’immense majorite ́ des cas, cela se fait en montrant que la martingale locale arrˆete ́e au temps d’arreˆt conside ́re ́ est borne ́e.
Exercice. Pour a > 0, posons Ua = inf{t ≥ 0 : |Bt | = a}. Montrer que, pour tout λ > 0,
E[exp(−λUa)] = 1
ch(a
√
2λ ) .
Nous terminons avec une forme du the ́ore`me d’arreˆt pour les surmartingales, qui nous sera utile dans des applications ulte ́rieures aux processus de Markov.
Proposition 3.10. Soit (Zt )t≥0 est une surmartingale positive `a trajectoires continues `a droite. Soient U et V deux temps d’arrˆet avec U ≤ V . Alors, ZU et ZV sont dans L1, et E[ZV 1{V <∞}] ≤ E[ZU 1{U<∞}].
De ́monstration. Nous supposons d’abord que U et V sont borne ́s. Soit p ≥ 1 un entier tel que U ≤ p et V ≤ p. Posons, pour tout entier n ≥ 0,
Un =
p2n −1
∑
k=0
k+1
2n 1{k2−n<U≤(k+1)2−n} , Vn =
p2n −1
∑
k=0
k+1
2n 1{k2−n<V ≤(k+1)2−n}
de sorte que (d’apre`s la Proposition 3.3) (Un) et (Vn) sont deux suites de temps d’arreˆt born ́es qui de ́croissent respectivement vers U et V , et Un ≤ Vn pour tout n ≥ 0. La continuite ́ a` droite des trajectoires montre en particulier que ZUn −→ ZU et ZVn −→ ZV quand n → ∞, p.s. Ensuite, une application du the ́ore`me d’arreˆt pour les surmartingales discre`tes dans le cas borne ́ (voir l’Appendice A2), dans la filtration (Fk/2n+1 )k≥0, montre que, pour tout entier n ≥ 0,
ZUn+1 ≥ E[ZUn | FUn+1 ].
En posant Yn = ZU−n et Hn = FU−n , pour tout n ∈ −N, on voit alors que la suite (Yn)n∈−N forme une surmartingale re ́trograde dans la filtration (Hn)n∈−N. Comme, pour tout n ∈ N, E[ZUn ] ≤ E[Z0] (par application a` nouveau du the ́ore`me d’arreˆt
discret), la suite (Yn)n∈−N est born ́ee dans L1, et, d’apre`s les re ́sultats sur les surmartingales re ́trogrades (voir l’Appendice A2), elle converge dans L1. Donc la convergence de ZUn vers ZU a aussi lieu dans L1 et de meˆme la convergence de ZVn vers


3 Exercices 53
ZV a lieu dans L1. Mais, en appliquant a` nouveau le the ́or`eme d’arreˆt pour les surmartingales discre`tes, on a E[ZUn ] ≥ E[ZVn ] pour tout entier n ≥ 0, et il suffit de faire
tendre n vers ∞, en utilisant la convergence L1, pour obtenir que E[ZU ] ≥ E[ZV ]. Conside ́rons maintenant le cas ge ́ne ́ral. La premie`re partie de la preuve assure que, pour tout entier p ≥ 1,
E[ZU∧p] ≥ E[ZV ∧p].
Mais puisque Z est a` valeurs positives, il est aussi imm ́ediat que
E[ZU∧p 1{U>p}] = E[Zp 1{U>p}] ≤ E[Zp 1{V >p}] = E[ZV ∧p 1{V >p}].
En retranchant cette ine ́galite ́ de la pre ́ce ́dente, on trouve
E[ZU∧p 1{U≤p}] ≥ E[ZV ∧p 1{V ≤p}] = E[ZV 1{V ≤p}].
Mais E[ZU 1{U<∞}] ≥ E[ZU∧p 1{U≤p}], et d’autre part E[ZV 1{V ≤p}] ↑ E[ZV 1{V <∞}] quand p ↑ ∞, par convergence monotone. L’in ́egalite ́ annonce ́e en de ́coule. tu
Exercices
Dans les exercices qui suivent, on se place sur un espace de probabilite ́ (Ω , F , P) muni d’une filtration comple`te (Ft )t∈[0,∞].
Exercice 3.1. 1. Soit M une martingale a` trajectoires continues telle que M0 = x ∈ R+. On suppose que Mt ≥ 0 pour tout t ≥ 0 et que Mt → 0 quand t → ∞, p.s. Montrer que, pour tout y > x,
P
(
sup
t≥0
Mt ≥ y
)
=x
y.
2. En de ́duire la loi de sup
t ≤T0
Bt
lorsque B est un mouvement brownien issu de x > 0 et T0 = inf{t ≥ 0 : Bt = 0}. 3. Supposons maintenant que B est un mouvement brownien issu de 0, et soit μ > 0. En introduisant une martingale exponentielle bien choisie, montrer que
sup
t≥0
(Bt − μt)
suit la loi exponentielle de parame`tre 2μ.
Exercice 3.2. Soit B un (Ft )-mouvement brownien re ́el issu de 0. Pour tout x ∈ R, on note
Tx = inf{t ≥ 0 : Bt = x}.
On fixe deux re ́els a et b avec a < 0 < b, et on note


54 3 Exercices
T = Ta ∧ Tb .
1. Montrer que, pour tout λ > 0,
E[exp(−λ T )] = ch( b+a
2
√
2λ )
ch( b−a
2
√
2λ ) .
(Il pourra ˆetre utile de consid ́erer une martingale de la forme
Mt = exp
(√
2λ (Bt − α) − λ t
)
+ exp
(
−
√
2λ (Bt − α) − λ t
)
avec un choix convenable de α.)
2. Montrer de meˆme que, pour tout λ > 0,
E[exp(−λ T ) 1{T =Ta}] = sh(b
√
2λ )
sh((b − a) √
2λ ) .
3. A l’aide de la question 2., retrouver l’expression de P(Ta < Tb).
Exercice 3.3. Soit (Bt )t≥0 un (Ft )-mouvement brownien issu de 0. Soit a > 0 et
σa = inf{t ≥ 0 : Bt ≤ t − a}.
1. Montrer que σa est un temps d’arrˆet et que σa < ∞ p.s. 2. En introduisant une martingale exponentielle arreˆte ́e bien choisie, montrer que, pour tout λ ≥ 0,
E[exp(−λ σa)] = exp(−a(
√
1 + 2λ − 1)).
On admettra que cette formule reste vraie pour λ ∈ [− 1
2 , 0[.
3. Soit μ ∈ R et Mt = exp(μBt − μ2
2 t). Montrer que la martingale arreˆte ́e Mtσa = Mσa∧t est ferme ́e si et seulement si μ ≤ 1 (on remarquera d’abord que cette martingale est ferme ́e si et seulement si E[Mσa ] = 1).
Exercice 3.4. Soit (Yt )t≥0 une martingale a` trajectoires continues uniforme ́ment inte ́grable, telle que Y0 = 0. On note Y∞ = limt→∞ Yt . Soit aussi p ≥ 1 un re ́el fixe ́. On dit que la martingale Y ve ́rifie la proprie ́te ́ (P) s’il existe une constante C telle que, pour tout temps d’arreˆt T , on ait
E[|Y∞ −YT |p | FT ] ≤ C.
1. Montrer que si Y∞ est borne ́e, la martingale Y ve ́rifie la proprie ́te ́ (P). 2. Soit B un (Ft )-mouvement brownien re ́el issu de 0. Montrer que la martingale Yt = Bt∧1 ve ́rifie la proprie ́te ́ (P). (On pourra observer que la variable al ́eatoire supt≤1 |Bt | est dans Lp.)
3. Montrer que Y ve ́rifie la proprie ́t ́e (P) avec la constante C, si et seulement si pour tout temps d’arreˆt T ,


3 Exercices 55
E[|YT −Y∞|p] ≤ C P[T < ∞].
(On pourra utiliser les temps d’arrˆet T A d ́efinis pour A ∈ FT dans la propri ́et ́e (d) des temps d’arrˆet.)
4. On suppose que Y ve ́rifie la proprie ́te ́ (P) avec la constante C. Soit S un temps d’arreˆt et soit Y S la “martingale arreˆte ́e” de ́finie par YtS = Yt∧S (cf. Corollaire 3.2).
Montrer que Y S ve ́rifie la proprie ́t ́e (P) avec la meˆme constante C. On pourra commencer par observer que, si S et T sont des temps d’arreˆt, on a Y S
T = YS∧T = Y T
S= E[YT | FS].
5. On suppose dans cette question et la suivante que Y ve ́rifie la proprie ́te ́ (P) avec la constante C = 1. Soit a > 0, et soit (Rn)n∈N la suite de temps d’arreˆt de ́finis par re ́currence par
R0 = 0 , Rn+1 = inf{t ≥ Rn : |Yt −YRn | ≥ a} (inf ∅ = ∞).
Montrer que, pour tout entier n ≥ 0,
ap P(Rn+1 < ∞) ≤ P(Rn < ∞).
6. En de ́duire que, pour tout x > 0,
P
(
sup
t≥0
Yt > x
)
≤ 2p 2−px/2.


J.-F. Le Gall, Mouvement brownien, martingales et calcul stochastique, 71, DOI: 10.1007/978-3-642-31898-6_4, Ó Springer-Verlag Berlin Heidelberg 2013
Chapitre 4
Semimartingales continues
Re ́sume ́ Les semimartingales continues constituent la classe ge ́ne ́rale de processus a` trajectoires continues pour laquelle on peut de ́velopper une the ́orie de l’inte ́grale stochastique, qui sera traite ́e dans le chapitre suivant. Par de ́finition, une semimartingale est la somme d’une martingale (locale) et d’un processus a` variation finie. Dans ce chapitre nous e ́tudions se ́pare ́ment ces deux classes de processus. En particulier, nous introduisons la notion de variation quadratique d’une martingale, qui jouera plus tard un roˆle fondamental. Tous les processus conside ́re ́s dans ce chapitre sont indexe ́s par R+ et a` valeurs re ́elles.
4.1 Processus a` variation finie
4.1.1 Fonctions `a variation finie
Dans ce paragraphe, nous discutons brie`vement les fonctions `a variation finie sur R+. Nous nous limitons au cas des fonctions continues, qui est le seul qui interviendra dans la suite.
De ́finition 4.1. Soit T > 0. Une fonction continue a : [0, T ] −→ R telle que a(0) = 0 est dite a` variation finie s’il existe une mesure signe ́e (i.e. diffe ́rence de deux mesures positives finies) μ sur [0, T ] telle que a(t) = μ([0,t]) pour tout t ∈ [0, T ].
La mesure μ est alors de ́termine ́e de fa ̧con unique. La de ́composition de μ comme diffe ́rence de deux mesures positives finies n’est bien suˆr pas unique, mais il existe une seule de ́composition μ = μ+ − μ− telle que μ+ et μ− soient deux mesures positives finies porte ́es par des bore ́liens disjoints. Pour obtenir l’existence d’une telle de ́composition, on peut partir d’une de ́composition quelconque μ = μ1 − μ2, poser ν = μ1 + μ2 puis utiliser le the ́ore`me de Radon-Nikodym pour trouver deux fonctions bore ́liennes positives h1 et h2 sur [0, T ] telles que
μ1(dt) = h1(t)ν(dt), μ2(dt) = h2(t)ν(dt).
57
Math ̄matiques et Applications


58 4 Semimartingales continues
Ensuite, si h(t) = h1(t) − h2(t) on a
μ(dt) = h(t)ν(dt) = h(t)+ν(dt) − h(t)−ν(dt)
ce qui donne la de ́composition μ = μ+ − μ− avec μ+(dt) = h(t)+ν(dt), μ−(dt) = h(t)−ν(dt), les mesures μ+ et μ−  ́etant porte ́es respectivement par les bore ́liens disjoints D+ = {t : h(t) > 0} et D− = {t : h(t) < 0}. L’unicite ́ de la de ́composition μ = μ+ − μ− d ́ecoule du fait que l’on a ne ́cessairement, pour tout A ∈ B([0, T ]),
μ+(A) = sup{μ(C) : C ∈ B([0, T ]), C ⊂ A}.
On note |μ| la mesure positive |μ| = μ+ + μ−. La mesure |μ| est appele ́e la variation totale de a. On a |μ(A)| ≤ |μ|(A) pour tout A ∈ B([0, T ]). De plus, la de ́rive ́e de Radon-Nikodym de μ par rapport a` |μ| est
dμ
d|μ| = 1D+ − 1D− .
On a a(t) = μ+([0,t]) − μ−([0,t]), ce qui montre que la fonction a est diffe ́rence de deux fonctions croissantes continues et nulles en 0 (la continuite ́ de a entraˆıne que μ n’a pas d’atomes, et il en va alors de meˆme pour μ+ et μ−). Inversement une diffe ́rence de fonctions croissantes (continues et nulles en 0) est aussi a` variation finie au sens pre ́ce ́dent. En effet, cela de ́coule du fait bien connu que la formule g(t) = ν([0,t]) e ́tablit une bijection entre les fonctions croissantes continues a` droite g : [0, T ] −→ R+ et les mesures positives finies sur [0, T ].
Soit f : [0, T ] −→ R une fonction mesurable telle que ∫
[0,T ] | f (s)| |μ|(ds) < ∞. On note
∫T
0
f (s) da(s) =
∫
[0,T ]
f (s) μ(ds),
∫T
0
f (s) |da(s)| =
∫
[0,T ]
f (s) |μ|(ds).
On ve ́rifie facilement l’ine ́galite ́
∣ ∣ ∣ ∣
∫T
0
f (s) da(s)
∣ ∣ ∣ ∣
≤
∫T
0
| f (s)| |da(s)|.
Remarquons de plus que la fonction t 7→ ∫ t
0 f (s) da(s) est aussi a` variation finie (la
mesure associe ́e est simplement μ′(ds) = f (s)μ(ds)).
Proposition 4.1. Pour tout t ∈]0, T ],
|μ|([0,t]) = sup
{p
i=∑1
|a(ti) − a(ti−1)|
}
,


4.1 Processus a` variation finie 59
o`u le supremum porte sur toutes les subdivisions 0 = t0 < t1 < · · · < tp = t de [0,t]. Plus pr ́ecis ́ement, pour toute suite 0 = tn
0 < tn
1 < · · · < tpnn = t de subdivisions emboˆıt ́ees de [0,t] de pas tendant vers 0 on a
nli→m∞
pn
i=∑1
|a(t n
i ) − a(tn
i−1)| = |μ|([0,t]).
Remarque. Dans la pre ́sentation habituelle des fonctions a` variation finie, on part de la proprie ́te ́ que le supremum ci-dessus est fini. De ́monstration. Il suffit clairement de traiter le cas t = T . L’ine ́galite ́ ≥ dans la premie`re assertion est tre`s facile puisque
|a(ti) − a(ti−1)| = |μ(]ti−1,ti])| ≤ |μ|(]ti−1,ti]).
Pour l’autre ine ́galite ́, il suffit d’e ́tablir la seconde assertion. Conside ́rons pour simplifier les subdivisions dyadiques tn
i = i2−nT , 0 ≤ i ≤ 2n (l’argument est facilement adapte ́ au cas ge ́ne ́ral). Bien qu’il s’agisse d’un r ́esultat “de ́terministe”, nous allons utiliser un argument de martingales en introduisant l’espace de probabilite ́ Ω = [0, T ] muni de la tribu bore ́lienne B = B([0, T ]) et de la probabilite ́ P(ds) = (|μ|([0, T ]))−1|μ|(ds). Introduisons sur cet espace la filtration discre`te (Bn)n∈N
telle que, pour tout n ∈ N, Bn est engendre ́e par les intervalles ](i − 1)2−nT, i2−nT ], 1 ≤ i ≤ 2n. Posons enfin
X (s) = 1D+ (s) − 1D− (s) = dμ
d|μ| (s),
et, pour chaque n ∈ N,
Xn = E[X | Bn].
Les propri ́ete ́s de l’espe ́rance conditionnelle montrent que Xn est constante sur chaque intervalle ](i − 1)2−nT, i2−nT ] et vaut sur cet intervalle
μ(](i − 1)2−nT, i2−nT ])
|μ|(](i − 1)2−nT, i2−nT ]) = a(i2−nT ) − a((i − 1)2−nT )
|μ|(](i − 1)2−nT, i2−nT ]) .
D’autre part, il est clair que la suite (Xn) est une martingale ferme ́e, relativement a` la filtration (Bn). Puisque X est mesurable par rapport a` B = ∨
n Bn, cette martin
gale converge p.s. et dans L1 vers X, d’apre`s le th ́eore`me de convergence pour les martingales discre`tes ferme ́es (voir l’Appendice A2). En particulier,
nli→m∞
E[|Xn|] = E[|X|] = 1,
cette dernie`re e ́galite ́ e ́tant claire puisque |X(s)| = 1, |μ|(ds) p.p. Le re ́sultat annonce ́ en de ́coule puisque, d’apre`s ci-dessus,
E[|Xn|] = (|μ|([0, T ]))−1
2n
i=∑1
|a(i2−nT ) − a((i − 1)2−nT )|. tu


60 4 Semimartingales continues
Lemme 4.1. Si f : [0, T ] −→ R est une fonction continue et si 0 = tn
0 < tn
1 < ··· <
tpnn = T est une suite de subdivisions de [0, T ] de pas tendant vers 0 on a
∫T
0
f (s) da(s) = nli→m∞
pn
i=∑1
f (tn
i−1) (a(tn
i ) − a(tn
i−1)).
De ́monstration. Soit fn la fonction de ́finie par fn(s) = f (tn
i−1) si s ∈]tn
i−1, tn
i ]. Alors,
pn
i=∑1
f (tn
i−1) (a(tn
i ) − a(tn
i−1)) =
∫
[0,T ]
fn(s) μ(ds),
et le r ́esultat voulu en de ́coule par convergence domin ́ee. tu
On dira qu’une fonction continue a : R+ −→ R est a` variation finie sur R+ si la restriction de a a` [0, T ] est a` variation finie, pour tout T > 0. Il est alors facile d’e ́tendre les de ́finitions pre ́ce ́dentes. En particulier, on peut de ́finir ∫ ∞
0 f (s)da(s) pour toute fonction f telle que ∫ ∞
0 | f (s)||da(s)| = supT>0
∫T
0 | f (s)||da(s)| < ∞.
4.1.2 Processus `a variation finie
On se place maintenant sur un espace de probabilite ́ filtre ́ (Ω , F , (Ft ), P).
De ́finition 4.2. Un processus a` variation finie A = (At )t≥0 est un processus adapte ́ dont toutes les trajectoires sont a` variation finie au sens de la de ́finition pre ́ce ́dente. Le processus A est appele ́ processus croissant si de plus les trajectoires de A sont croissantes.
Remarque. En particulier on a A0 = 0 et les trajectoires de A sont continues.
Si A est un processus a` variation finie, le processus
Vt =
∫t
0
|dAs|
est un processus croissant. En effet il est clair que les trajectoires de V sont croissantes (et aussi continues et nulles en t = 0). Le fait que la variable Vt soit Ft mesurable de ́coule de la deuxie`me partie de la Proposition 4.1.
Proposition 4.2. Soit A un processus `a variation finie et soit H un processus progressif tel que
∀t ≥ 0, ∀ω ∈ Ω ,
∫t
0
|Hs(ω)| |dAs(ω)| < ∞.
Alors le processus H · A d ́efini par
(H · A)t =
∫t
0
Hs dAs


4.2 Martingales locales 61
est aussi un processus `a variation finie.
De ́monstration. D’apre`s des remarques pre ́ce ́dentes, il est clair que les trajectoires de H · A sont a` variation finie. Il reste donc a` montrer que H · A est adapte ́. Pour cela, il suffit de voir que, si h : Ω × [0,t] −→ R est mesurable pour la tribu pro
duit Ft ⊗ B([0,t]) et si ∫ t
0 |h(ω, s)||dAs(ω)| est fini pour tout ω, alors la variable
∫t
0 h(ω, s)dAs(ω) est Ft -mesurable. Si h(ω, s) = 1]u,v](s)1Γ (ω) avec ]u, v] ⊂ [0,t] et Γ ∈ Ft , le re ́sultat est e ́vident. On passe ensuite au cas h = 1G, G ∈ Ft ⊗B([0,t]) par un argument de classe monotone. Enfin, dans le cas g ́ene ́ral, on observe qu’on peut toujours  ́ecrire h comme limite ponctuelle d’une suite de fonctions e ́tag ́ees hn telles que |hn| ≤ |h| pour tout n, ce
qui assure que ∫ t
0 hn(ω, s)dAs(ω) −→ ∫ t
0 h(ω, s)dAs(ω) par convergence domine ́e. tu Remarques. (i) Il arrive souvent qu’on ait l’hypothe`se plus faible
p.s. ∀t ≥ 0,
∫t
0
|Hs(ω)| |dAs(ω)| < ∞.
Si la filtration est compl`ete, on peut encore de ́finir H ·A comme processus a` variation finie : on remplace H par H′ de ́fini par
H′
t (ω) =
{ Ht (ω) si ∫ n
0 |Hs(ω)| |dAs(ω)| < ∞, ∀n , 0 sinon.
Graˆce au fait que la filtration est comple`te, le processus H′ reste adapte ́ ce qui permet de de ́finir H · A = H′ · A. Nous ferons syste ́matiquement cette extension dans la suite.
(ii) Sous des hypothe`ses convenables (si ∫ t
0 |Hs| |dAs| < ∞ et ∫ t
0 |HsKs| |dAs| < ∞ pour tout t ≥ 0), on a la proprie ́te ́ d’associativit ́e K · (H · A) = (KH) · A.
Un cas particulier important est celui ou` At = t. Si H est un processus progressif tel que
∀t ≥ 0, ∀ω ∈ Ω ,
∫t
0
|Hs(ω)| ds < ∞,
le processus ∫ t
0 Hs ds est un processus a` variation finie.
4.2 Martingales locales
Nous nous plac ̧ons a` nouveau sur un espace de probabilite ́ filtre ́ (Ω , F , (Ft ), P). Si T est un temps d’arreˆt et X = (Xt )t≥0 est un processus a` trajectoires continues, on note XT le processus arreˆte ́ XtT = Xt∧T pour tout t ≥ 0.
De ́finition 4.3. Un processus adapt ́e `a trajectoires continues M = (Mt )t≥0 tel que M0 = 0 p.s. est une martingale locale (continue) s’il existe une suite croissante (Tn)n∈N de temps d’arreˆt telle que Tn ↑ ∞ et, pour tout n, le processus arreˆte ́ MTn est une martingale uniforme ́ment inte ́grable.


62 4 Semimartingales continues
Plus ge ́ne ́ralement, lorsque M0 6= 0, on dit que M est une martingale locale si Mt = M0 + Nt , ou` le processus N est une martingale locale issue de 0. Dans tous les cas, on dit que la suite de temps d’arreˆt Tn ↑ ∞ re ́duit M si, pour tout n, le processus arreˆte ́ MTn est une martingale uniforme ́ment inte ́grable.
Remarques. (i) On n’impose pas dans la de ́finition d’une martingale locale que les variables Mt soient dans L1 (comparer avec la de ́finition des martingales). En particulier, on voit sur la de ́finition pre ́ce ́dente que M0 peut eˆtre n’importe quelle variable F0-mesurable. (ii) Donnons des exemples de martingales locales M qui ne sont pas de vraies martingales. Partant d’un (Ft )-mouvement brownien B issu de 0, et d’une variable Z F0-mesurable, on peut poser Mt = Z + Bt , qui ne sera pas une vraie martingale si E[|Z|] = ∞. Si on veut avoir la proprie ́te ́ M0 = 0, on peut aussi prendre Mt = ZBt qui est toujours une martingale locale (voir l’Exercice 4.1) mais pas une vraie martingale si E[|Z|] = ∞. Pour un exemple moins artificiel, voir la question 8. de l’Exercice 5.9. (iii) On peut de ́finir une notion de martingale locale `a trajectoires seulement continues a` droite. Cependant dans ce cours, nous ne conside ́rons que des martingales locales a` trajectoires continues (et donc une martingale locale sera toujours pour nous un processus a` trajectoires continues).
Les proprie ́te ́s qui suivent sont tre`s faciles a` e ́tablir.
Proprie ́te ́s des martingales locales.
(a) Une martingale a` trajectoires continues est une martingale locale (et la suite Tn = n re ́duit M). (b) Dans la de ́finition d’une martingale locale issue de 0 on peut remplacer “martingale uniforme ́ment inte ́grable” par “martingale” (en effet on peut ensuite remplacer Tn par Tn ∧ n). (c) Si M est une martingale locale, pour tout temps d’arrˆet T , MT est une martingale locale (cf. Corollaire 3.2). (d) Si (Tn) re ́duit M et si Sn est une suite de temps d’arreˆt telle que Sn ↑ ∞, alors la suite (Tn ∧ Sn) re ́duit aussi M. (e) L’espace des martingales locales est un espace vectoriel (utiliser la proprie ́te ́ pre ́ce ́dente).
Proposition 4.3. (i) Une martingale locale positive M telle que M0 ∈ L1 est une surmartingale. (ii) Une martingale locale M born ́ee, ou plus g ́en ́eralement telle qu’il existe une variable Z ∈ L1 telle que, pour tout t ≥ 0, |Mt | ≤ Z, est une martingale (automatiquement uniform ́ement int ́egrable). (iii) Si M est une martingale locale avec M0 = 0, la suite de temps d’arrˆet
Tn = inf{t ≥ 0 : |Mt | ≥ n}
r ́eduit M.


4.2 Martingales locales 63
De ́monstration. (i) Ecrivons Mt = M0 + Nt . Par de ́finition, il existe une suite (Tn) de temps d’arreˆt qui re ́duit N. Alors, si s ≤ t, on a pour tout n,
Ns∧Tn = E[Nt∧Tn | Fs].
Ms∧Tn = E[Mt∧Tn | Fs]. (4.1)
Puisque M est a` valeurs positives, on peut faire tendre n vers ∞ et appliquer le lemme de Fatou (pour les esp ́erances conditionnelles) qui donne
Ms ≥ E[Mt | Fs].
En prenant s = 0, on voit que E[Mt ] ≤ E[M0] < ∞, donc Mt ∈ L1 pour tout t ≥ 0. L’ine ́galite ́ pre ́ce ́dente montre alors que M est une surmartingale. (ii) Si M est borne ́e (ou plus ge ́ne ́ralement domine ́e par une variable inte ́grable), le meˆme raisonnement que ci-dessus donne pour s ≤ t
Ms∧Tn = E[Mt∧Tn | Fs].
Or par convergence domine ́e la suite Mt∧Tn converge dans L1 vers Mt , et donc on peut passer a` la limite n → ∞ pour trouver Ms = E[Mt | Fs]. (iii) C’est une conse ́quence imme ́diate de (ii) puisque MTn est une martingale locale borne ́e. tu
Remarque. Au vu de la proprie ́te ́ (ii) de la proposition, on pourrait croire qu’une martingale locale M telle que la famille (Mt )t≥0 est uniforme ́ment inte ́grable (ou meˆme satisfait la proprie ́te ́ plus forte d’eˆtre borne ́e dans un espace Lp avec p > 1) est automatiquement une vraie martingale. Cela est faux!! Par exemple, si B est un mouvement brownien en dimension trois issu de x 6= 0, le processus Mt = 1/|Bt | est une martingale locale borne ́e dans L2 mais n’est pas une vraie martingale : voir l’Exercice 5.9.
The ́ore`me 4.1. Soit M une martingale locale. Alors si M est un processus `a variation finie, M est indistinguable de 0.
De ́monstration. Supposons que M est un processus a` variation finie (donc en particulier M0 = 0) et posons pour tout n ∈ N,
τn = inf{t ≥ 0 :
∫t
0
|dMs| ≥ n}.
Les temps τn sont des temps d’arreˆt d’apre`s la Proposition 3.4 (remarquer que le
processus ∫ t
0 |dMs| a des trajectoires continues et est adapte ́). Fixons n ≥ 1 et posons
N = Mτn . Alors N est une martingale locale issue de 0 telle que ∫ ∞
0 |dNs| ≤ n, et donc en particulier |Nt | ≤ n. D’apre`s la Proposition 4.3, N est une (vraie) martingale borne ́e. Ensuite, fixons t > 0 et soit 0 = t0 < t1 < · · · < tp = t une subdivision de [0,t]. Alors, en utilisant la Proposition 3.7,
En ajoutant des deux côtés la variable M0 (qui est F0-mesurable et dans L1), on trouve


64 4 Semimartingales continues
E [N 2
t]=
p
i=∑1
E[(Nti − Nti−1 )2]
≤E
[(
sup
1≤i≤ p
|Nti − Nti−1 |
)p
i=∑1
|Nti − Nti−1 |
]
≤ nE
[
sup
1≤i≤ p
|Nti − Nti−1 |
]
en utilisant la Proposition 4.1. On applique l’ine ́galite ́ pre ́ce ́dente a` une suite 0 = tk
0 < tk
1 < · · · < tkpk = t de subdivisions de [0,t] de pas tendant vers 0. En utilisant la continuit ́e des trajectoires, et le fait que N est borne ́e (pour justifier la convergence domine ́e), on a
kli→m∞
E
[
sup
1≤i≤ pk
|Ntik − Ntk
i−1
|
]
= 0.
On conclut alors que E[Nt2] = 0, soit E[Mt2∧τn ] = 0. En faisant tendre n vers ∞ on obtient E[Mt2] = 0. tu
4.3 Variation quadratique d’une martingale locale
Jusqu’a` la fin de ce chapitre (et dans le chapitre suivant), nous supposons que la filtration (Ft ) est comple`te. Le the ́ore`me ci-dessous joue un roˆle tre`s important dans la suite.
The ́ore`me 4.2. Soit M = (Mt )t≥0 une martingale locale. Il existe un processus croissant not ́e (〈M, M〉
t )t≥0, unique `a indistinguabilit ́e pr`es, tel que Mt2 − 〈M, M〉
t
soit une martingale locale. De plus, pour tout T > 0, si 0 = tn
0 < tn
1 < · · · < tpnn = T est une suite de subdivisions emboˆıt ́ees de [0, T ] de pas tendant vers 0, on a
〈M, M〉
T = nli→m∞
pn
i=∑1
(Mtin − Mtn
i−1 )2
au sens de la convergence en probabilit ́e. Le processus 〈M, M〉 est appel ́e la variation quadratique de M.
Observons imme ́diatement que le processus 〈M, M〉 ne de ́pend pas de la valeur initiale M0, mais seulement des accroissements de M : si on e ́crit Mt = M0 + Nt , on a 〈M, M〉 = 〈N, N〉. Cela est e ́vident a` partir de l’approximation donne ́e dans le the ́ore`me, et cela sera aussi clair dans la preuve qui va suivre.
Remarques. (i) Si M = B est un mouvement brownien, la Proposition 2.4 montre que 〈B, B〉
t = t.
(ii) Dans la derni`ere assertion du the ́ore`me, il n’est en fait pas ne ́cessaire de supposer que les subdivisions soient emboˆıte ́es.
De ́monstration. L’unicite ́ est une conse ́quence facile du Th ́eore`me 4.1. En effet, soient A et A′ deux processus croissants satisfaisant la condition de l’e ́nonce ́. Alors,


4.3 Variation quadratique d’une martingale locale 65
le processus At − At′ = (Mt2 − At′) − (Mt2 − At ) doit ˆetre a` la fois une martingale locale
et un processus a` variation finie, et donc A − A′ = 0. Pour l’existence conside ́rons d’abord le cas ou` M0 = 0 et M est borne ́e (donc en particulier est une vraie martingale, d’apre`s la Proposition 4.3 (ii)). Fixons T > 0 et 0 = tn
0 < tn
1 < · · · < tpnn = T une suite de subdivisions emboˆıte ́es de [0, T ] de pas tendant vers 0. Une ve ́rification tre`s simple montre que, pour tout n et tout i = 1, . . . , pn, le pro
cessus
X n,i
t = Mtn
i−1 (Mtin∧t − Mtn
i−1∧t )
est une martingale (borne ́e). En conse ́quence, si on pose
Xn
t=
pn
i=∑1
Mtn
i−1 (Mtin∧t − Mtn
i−1∧t ),
le processus Xn est aussi une martingale. La raison de conside ́rer ces martingales vient de l’identite ́ suivante, qui de ́coule d’un calcul simple : pour tout n, pour tout j ∈ {1, . . . , pn},
M2
t jn − 2X n
t jn =
j
i=∑1
(Mtin − Mtn
i−1 )2, (4.2)
Lemme 4.2. On a
lim
n,m→∞
E [(X n
T −Xm
T )2] = 0.
De ́monstration du lemme. Fixons d’abord n ≤ m et e ́valuons le produit E[Xn
TXm
T ]. Ce produit vaut
pn
i=∑1
pm
j= ∑1
E [Mt n
i−1 (Mtin − Mtn
i−1 ) Mtm
j−1 (Mt jm − Mtm
j−1 )]
Dans cette somme double, les seuls termes susceptibles d’eˆtre non nuls sont ceux qui corrrespondent a` des indices i et j tels que l’intervalle ]tm
j−1, tm
j ] est contenu dans ]t n
i−1, tn
i ]. En effet, supposons tn
i ≤ tm
j−1 (le cas syme ́trique tm
j ≤ tn
i−1 est traite ́ de
manie`re analogue). Alors, en conditionnant par la tribu Ftm
j−1 ,
E [Mt n
i−1 (Mtin − Mtn
i−1 ) Mtm
j−1 (Mt jm − Mtm
j−1 )]
= E[Mtn
i−1 (Mtin − Mtn
i−1 ) Mtm
j−1 E[Mt jm − Mtm
j−1 | Ftm
j−1 ]] = 0.
Pour tout j = 1, . . . , pm, notons in,m( j) l’unique indice i tel que ]tm
j−1, tm
j ] ⊂]tn
i−1, tn
i ]. On a donc obtenu
E[X n
TXm
T]= ∑
1≤ j≤pm, i=in,m( j)
E [Mt n
i−1 (Mtin − Mtn
i−1 ) Mtm
j−1 (Mt jm − Mtm
j−1 )].
Dans chaque terme E[Mtn
i−1 (Mtin − Mtn
i−1 ) Mtm
j−1 (Mt jm − Mtm
j−1 )] on peut maintenant de ́composer


66 4 Semimartingales continues
Mtin − Mtn
i−1 = ∑ k:in,m (k)=i
(Mtm
k − Mtm
k−1 )
et observer qu’on a si k 6= j,
E [Mt n
i−1 (Mtm
k − Mtm
k−1 ) Mtm
j−1 (Mt jm − Mtm
j−1 )] = 0
(conditionner par rapport a` Ftm
k−1 si k > j et par rapport a` Ftm
j−1 si k < j). Il ne reste donc que le cas k = j a` consid ́erer, et on a obtenu
E[X n
TXm
T]= ∑
1≤ j≤pm, i=in,m( j)
E [Mt n
i−1 Mtm
j−1 (Mt jm − Mtm
j−1 )2].
En rempla ̧cant n par m on a
E [(X m
T )2] = ∑
1≤ j≤pm
E [M 2
tm
j−1 (Mt jm − Mtm
j−1 )2].
On a donc aussi, en utilisant la Proposition 3.7 a` la troisie`me e ́galite ́,
E [(X n
T )2] = ∑
1≤i≤ pn
E [M 2
tn
i−1 (Mtin − Mtn
i−1 )2]
=∑
1≤i≤ pn
E [M 2
tn
i−1 E[(Mtin − Mtn
i−1 )2 | Ftn
i−1 ]]
=∑
1≤i≤ pn
E
[
M2
tn
i−1 ∑
j:in,m( j)=i
E[(Mt jm − Mtm
j−1 )2 | Ftn
i−1 ]
]
=∑
1≤ j≤pm, i=in,m( j)
E [M 2
tn
i−1 (Mt jm − Mtm
j−1 )2]
En combinant les trois identite ́s obtenues, on trouve
E [(X n
T −Xm
T )2] = E
[
∑
1≤ j≤pm, i=in,m( j)
(Mtn
i−1 − Mtm
j−1 )2 (Mt jm − Mtm
j−1 )2]
.
En utilisant l’ine ́galite ́ de Cauchy-Schwarz, il vient
E [(X n
T −Xm
T )2] ≤ E
[
sup
1≤ j≤pm, i=in,m( j)
(Mtn
i−1 − Mtm
j−1 )4]1/2
×E
[(
∑
1≤ j≤pm
(Mt jm − Mtm
j−1 )2)2]1/2
.
La continuite ́ des trajectoires assure, par convergence domine ́e, que
lim
n,m→∞, n≤m E
[
sup
1≤ j≤pm, i=in,m( j)
(Mtn
i−1 − Mtm
j−1 )4]
= 0.


4.3 Variation quadratique d’une martingale locale 67
Pour terminer la preuve du lemme, il suffit donc de montrer l’existence d’une constante C telle que, pour tout m,
E
[(
∑
1≤ j≤pm
(Mt jm − Mtm
j−1 )2)2]
≤ C. (4.3)
Notons K une constante telle que |Mt | ≤ K pour tout t ≥ 0. En de ́veloppant le carre ́ et en utilisant (deux fois) la Proposition 3.7,
E
[(
∑
1≤ j≤pm
(Mt jm − Mtm
j−1 )2)2]
=E
[
∑
1≤ j≤pm
(Mt jm − Mtm
j−1 )4]
+ 2E
[
∑
1≤ j<k≤pm
(Mt jm − Mtm
j−1 )2(Mtm
k − Mtm
k−1 )2]
≤ 4K2E
[
∑
1≤ j≤pm
(Mt jm − Mtm
j−1 )2]
+2
pm −1
j= ∑1
E
[
(Mt jm − Mtm
j−1 )2E
[ pm
∑
k= j+1
(Mtm
k − Mtm
k−1 )2
∣
∣
∣ Ft jm
]]
= 4K2E
[
∑
1≤ j≤pm
(Mt jm − Mtm
j−1 )2]
+2
pm −1
j= ∑1
E
[
(Mt jm − Mtm
j−1 )2 E[(MT − Mt jm )2 | Ft jm ]
]
≤ 12K2 E
[
∑
1≤ j≤pm
(Mt jm − Mtm
j−1 )2]
= 12K2 E[(MT − M0)2]
≤ 48K4
ce qui donne bien la majoration (4.3) avec C = 48K4. Cela termine la preuve. tu Nous revenons maintenant a` la preuve du th ́eore`me. Via l’ine ́galite ́ de Doob dans L2 (Proposition 3.8 (ii)), le Lemme 4.2 entraˆıne que
lim
n,m→∞
E
[
sup
t≤T
(X n
t −Xm
t )2]
= 0.
On peut donc trouver une suite strictement croissante (nk)k≥1 telle que, pour tout k ≥ 1,
E
[
sup
t≤T
(X nk+1
t − Xtnk )2]
≤ 2−k.
Il en de ́coule que
E
[∞
∑
k=1
sup
t≤T
|X nk+1
t − Xtnk |
]
<∞
et donc


68 4 Semimartingales continues
∞
∑
k=1
sup
t≤T
|X nk+1
t − Xtnk | < ∞ , p.s.
En conse ́quence, sauf sur un ensemble ne ́gligeable N , la suite de fonctions ale ́atoi
res (Xtnk , 0 ≤ t ≤ T ) converge uniform ́ement sur [0, T ] vers une fonction ale ́atoire limite (Yt , 0 ≤ t ≤ T ). On prend Yt (ω) = 0 pour tout t ∈ [0, T ] si ω ∈ N . Le processus (Yt )0≤t≤T a des trajectoires continues et est adapte ́ a` la filtration (Ft )0≤t≤T (on utilise ici le caracte`re complet de la filtration). De plus, pour chaque t ∈ [0, T ], Yt est
aussi la limite dans L2 de Xtnk , et en passant a` la limite dans l’e ́galite ́ de martingale
pour Xn, on voit que Y est une martingale a` trajectoires continues (de ́finie seulement sur l’intervalle de temps [0, T ]). Par ailleurs, l’identite ́ (4.2) montre que le processus Mt2 − 2Xtn est croissant le
long de la subdivision (tn
i , 0 ≤ i ≤ pn). En passant a` la limite n → ∞, on voit que
la fonction t 7→ Mt2 − 2Yt doit eˆtre croissante sur [0, T ], sauf e ́ventuellement sur le
ne ́gligeable N . Sur Ω \N , on pose, pour t ∈ [0, T ], 〈M, M〉
t = Mt2 − 2Yt et sur N
on prend 〈M, M〉
t = 0. Alors, 〈M, M〉 est un processus croissant et Mt2 − 〈M, M〉
t=
2Yt est une martingale, sur l’intervalle de temps [0, T ]. Il est facile d’e ́tendre la de ́finition de 〈M, M〉
t a` tout t ∈ R+ : on applique ce qui
pre ́ce`de avec T = k pour tout entier k ≥ 1, en remarquant que le processus croissant obtenu avec T = k doit eˆtre indistinguable de la restriction a` [0, k] de celui obtenu avec T = k + 1, a` cause de l’argument d’unicite ́. Le processus 〈M, M〉
t ainsi e ́tendu satisfait manifestement la premie`re proprie ́te ́ de l’e ́nonce ́. La partie unicite ́ montre aussi que le processus 〈M, M〉
t ne de ́pend pas de la suite
de subdivisions choisie pour le construire. On de ́duit alors de (4.2) (avec j = pn) que pour tout T > 0, pour n’importe quelle suite de subdivisions emboˆıte ́es de [0, T ] de pas tendant vers 0, on a
nli→m∞
pn
j= ∑1
(Mt jn − Mtn
j−1 )2 = 〈M, M〉
T
dans L2. Cela ache`ve la preuve du the ́ore`me dans le cas borne ́.
Conside ́rons maintenant le cas ge ́ne ́ral. En e ́crivant Mt = M0 + Nt , donc Mt2 =
M2
0 + 2 M0Nt + Nt2, et en remarquant que M0Nt est une martingale locale (exercice!), on se rame`ne facilement au cas ou` M0 = 0. On pose alors
Tn = inf{t ≥ 0 : |Mt | ≥ n}
et on peut appliquer ce qui pre ́ce`de aux martingales borne ́es MTn . Notons An = 〈MTn , MTn 〉. Graˆce a` la partie unicite ́, on voit facilement que les processus An+1
t∧Tn et
Atn sont indistinguables. On en de ́duit qu’il existe un processus croissant A tel que,
pour tout n, At∧Tn et Atn soient indistinguables. Par construction, Mt2∧Tn − At∧Tn est une martingale, ce qui entraˆıne pre ́cise ́ment que Mt2 − At est une martingale locale.
On prend 〈M, M〉
t = At et cela termine la preuve de la partie existence.
Enfin, la deuxie`me assertion du the ́ore`me est vraie si on remplace M et 〈M, M〉
T
par MTn et 〈M, M〉
T∧Tn (mˆeme avec convergence L2). Il suffit alors de faire tendre n


4.3 Variation quadratique d’une martingale locale 69
vers ∞ en observant que, pour tout T > 0, P[T ≤ Tn] converge vers 1 quand n → ∞. tu
Proprie ́te ́. Si T est un temps d’arrˆet on a p.s. pour tout t ≥ 0,
〈MT , MT 〉
t = 〈M, M〉
t∧T.
Cela de ́coule du fait que Mt2∧T − 〈M, M〉
t∧T est une martingale locale comme martingale locale arreˆt ́ee (cf. proprie ́te ́ (c) des martingales locales).
Nous e ́non ̧cons maintenant un the ́ore`me qui montre comment les proprie ́te ́s d’une martingale locale sont lie ́es `a celles de sa variation quadratique. Si A est un processus croissant, A∞ de ́signe de manie`re e ́vidente la limite croissante de At quand t → ∞ (cette limite existe toujours dans [0, ∞]).
The ́ore`me 4.3. Soit M une martingale locale avec M0 = 0.
(i) Il y a  ́equivalence entre : (a) M est une (vraie) martingale born ́ee dans L2. (b) E[〈M, M〉
∞] < ∞.
De plus si ces conditions sont satisfaites, le processus Mt2 − 〈M, M〉
t est une (vraie)
martingale uniform ́ement int ́egrable, et en particulier E[M2
∞] = E[〈M, M〉∞].
(ii) Il y a  ́equivalence entre : (a) M est une (vraie) martingale de carr ́e int ́egrable (E[Mt2] < ∞ pour tout t ≥ 0).
(b) E[〈M, M〉
t ] < ∞ pour tout t ≥ 0.
De plus si ces conditions sont satisfaites, Mt2 − 〈M, M〉
t est une martingale.
Remarque. Dans la proprie ́te ́ (a) de (i) (ou de (ii)), il est essentiel de supposer que M est une martingale, et pas seulement une martingale locale. L’ine ́galite ́ de Doob utilise ́e dans la preuve suivante n’est pas valable pour une martingale locale!
De ́monstration. (i) Supposons d’abord que M est une martingale borne ́e dans L2. L’ine ́galite ́ de Doob dans L2 (Proposition 3.8 (ii)) montre que, pour tout T > 0,
E
[
sup
0≤t≤T
M2
t
]
≤ 4 E[M2
T ].
En faisant tendre T vers ∞, on a
E
[
sup
t≥0
M2
t
]
≤ 4 sup
t≥0
E [M 2
t ] < ∞.
Soit (Tn) une suite de temps d’arreˆt qui re ́duit la martingale locale M2 − 〈M, M〉. Alors, pour tout t ≥ 0, la variable Mt2∧Tn − 〈M, M〉t∧Tn est inte ́grable et ve ́rifie
E [M 2
t∧Tn − 〈M, M〉t∧Tn ] = 0.
Puisque Mt2∧Tn , qui est domine ́e par sups≥0 Ms2, est aussi int ́egrable, on a


70 4 Semimartingales continues
E[〈M, M〉t∧Tn ] = E[M2
t∧Tn ] ≤ E
[
sup
s≥0
M2
s
]
.
En faisait tendre d’abord n, puis t vers ∞, on obtient par convergence monotone que
E[〈M, M〉∞] ≤ E
[
sup
s≥0
M2
s
]
< ∞.
Inversement supposons que E[〈M, M〉∞] < ∞. Conside ́rons comme ci-dessus une suite de temps d’arreˆt (Tn) qui re ́duit la martingale locale M2 − 〈M, M〉, et posons pour tout n,
Sn = Tn ∧ inf{t ≥ 0 : |Mt | ≥ n}.
de sorte que (Sn) re ́duit aussi M2 − 〈M, M〉, et les martingales locales areˆte ́es MSn sont borne ́es. Comme dans la premie`re partie de la preuve, on obtient l’e ́galite ́
E [M 2
t∧Sn ] = E[〈M, M〉t∧Sn ] ≤ E[〈M, M〉∞] < ∞.
D’apre`s le lemme de Fatou, cela entraˆıne aussi E[Mt2] ≤ E[〈M, M〉∞] pour tout t ≥ 0,
et donc la famille (Mt )t≥0 est borne ́e dans L2. Par ailleurs, pour t fixe ́, l’ine ́galite ́ pr ́ece ́dente montre aussi que la suite (Mt∧Sn ) est borne ́e dans L2, donc uniforme ́ment
inte ́grable. Il en de ́coule que cette suite converge dans L1 vers Mt quand n → ∞. Cela permet de passer `a la limite dans l’e ́galite ́
E[Mt∧Sn | Fs] = Ms∧Sn (pour s < t)
et d’obtenir
E[Mt | Fs] = Ms
ce qui montre que M est une vraie martingale, borne ́e dans L2 d’apre`s ce qui pre ́ce`de. Enfin, si les proprie ́te ́s (a) et/ou (b) sont satisfaites, la martingale locale M2 − 〈M, M〉 est domine ́e par la variable inte ́grable
sup
t≥0
M2
t + 〈M, M〉∞
et est donc (Proposition 4.3 (ii)) une vraie martingale uniforme ́ment inte ́grable. (ii) Il suffit d’appliquer (i) a` (Mt∧a)t≥0 pour tout choix de a ≥ 0. tu
Corollaire 4.1. Soit M une martingale locale telle que M0 = 0. Alors on a 〈M, M〉
t=
0 p.s. pour tout t ≥ 0 si et seulement si M est indistinguable de 0.
De ́monstration. Supposons 〈M, M〉
t = 0 p.s. pour tout t ≥ 0. D’apre`s la partie (i) du
the ́ore`me ci-dessus, Mt2 est une martingale uniforme ́ment inte ́grable, d’ou` E[Mt2] =
E [M 2
0 ] = 0. tu
Crochet de deux martingales locales. Si M et N sont deux martingales locales, on pose
〈M, N〉
t=1
2 (〈M + N, M + N〉
t − 〈M, M〉
t − 〈N, N〉
t ).


4.3 Variation quadratique d’une martingale locale 71
Proposition 4.4. (i) 〈M, N〉 est l’unique (`a indistinguabilit ́e pr`es) processus `a variation finie tel que Mt Nt − 〈M, N〉
t soit une martingale locale.
(ii) L’application (M, N) 7→ 〈M, N〉 est bilin ́eaire sym ́etrique. (iii) Si 0 = tn
0 < tn
1 < · · · < tpnn = t est une suite de subdivisions emboˆıt ́ees de [0,t] de pas tendant vers 0, on a
nli→m∞
pn
i=∑1
(Mtin − Mtn
i−1 )(Ntin − Ntn
i−1 ) = 〈M, N〉
t
en probabilit ́e. (iv) Pour tout temps d’arrˆet T , 〈MT , NT 〉
t = 〈MT , N〉
t = 〈M, N〉
t∧T .
(v) Si M et N sont deux martingales born ́ees dans L2, Mt Nt − 〈M, N〉t est une martingale uniform ́ement int ́egrable. En particulier, 〈M, N〉∞ est bien d ́efini (comme la limite p.s. de 〈M, N〉t quand t → ∞), est int ́egrable et v ́erifie
E[M∞N∞] = E[M0N0] + E[〈M, N〉∞].
De ́monstration. (i) de ́coule de la caracte ́risation analogue dans le The ́ore`me 4.2 (et l’unicit ́e de ́coule du The ́ore`me 4.1). (iii) est de meˆme une conse ́quence de l’assertion analogue dans le The ́ore`me 4.2. (ii) de ́coule de (iii). Ensuite, on peut voir (iv) comme une conse ́quence de la proprie ́te ́ (iii), en remarquant que cette proprie ́te ́ entraˆıne, pour tous 0 ≤ s ≤ t, p.s.
〈MT , NT 〉
t = 〈MT , N〉
t = 〈M, N〉
t sur {T ≥ t},
〈MT , NT 〉
t − 〈MT , NT 〉
s = 〈MT , N〉
t − 〈MT , N〉
s = 0 sur {T ≤ s < t}.
Enfin, (v) est une conse ́quence facile du The ́ore`me 4.3 (i). tu
Remarque. Une conse ́quence de (iv) est que MT (N −NT ) est une martingale locale, ce qui n’est pas si facile a` voir directement.
De ́finition 4.4. Deux martingales locales M et N sont dites orthogonales si 〈M, N〉 = 0, ce qui e ́quivaut a` dire que le produit MN est une martingale locale.
Exemple important. Nous avons de ́ja` observe ́ qu’un (Ft )-mouvement brownien B est une (vraie) martingale de variation quadratique 〈B, B〉
t = t. Deux (Ft )
mouvements browniens ind ́ependants B et B′ sont des martingales orthogonales. Le plus simple pour le voir est d’observer que le processus √12 (Bt + Bt′) est encore une
(Ft )-martingale locale, et d’autre part il est tre`s facile de v ́erifier que c’est aussi un mouvement brownien. Donc la Proposition 2.4 montre que sa variation quadratique est t, et par biline ́arite ́ du crochet cela entraˆıne 〈B, B′〉
t = 0.
Si M et N sont deux (vraies) martingales borne ́es dans L2 et orthogonales, on a E[Mt Nt ] = E[M0N0], et meˆme E[MSNS] = E[M0N0] pour tout temps d’arreˆt S. Cela de ́coule en effet du The ́ore`me 3.6, en utilisant la proprie ́te ́ (v) de la Proposition 4.4.
Proposition 4.5 (Ine ́galite ́ de Kunita-Watanabe). Soient M et N deux martingales locales et H et K deux processus mesurables. Alors, p.s.,


72 4 Semimartingales continues
∫∞
0
|Hs| |Ks| |d〈M, N〉
s| ≤
(∫ ∞
0
H2
s d〈M, M〉
s
)1/2( ∫ ∞
0
K2
s d〈N, N〉
s
)1/2
.
De ́monstration. Notons 〈M, N〉t
s = 〈M, N〉
t − 〈M, N〉
s pour s ≤ t. On commence
par remarquer que p.s. pour tous s < t rationnels (donc aussi par continuite ́ pour tous s < t) on a
|
〈M, N〉t
s| ≤
√
〈M, M〉t
s
√
〈N, N〉t
s.
En effet, cela de ́coule imme ́diatement des approximations de 〈M, M〉 et 〈M, N〉 donne ́es dans le The ́ore`me 4.2 et la Proposition 4.4 respectivement, ainsi que de l’in ́egalite ́ de Cauchy-Schwarz. A partir de maintenant, on fixe ω tel que l’ine ́galite ́ pre ́ce ́dente soit vraie pour tous s < t, et on raisonne sur cette valeur de ω. On remarque d’abord qu’on a aussi
∫t
s
|d〈M, N〉
u| ≤
√
〈M, M〉t
s
√
〈N, N〉t
s. (4.4)
En effet, il suffit d’utiliser la Proposition 4.1 et de majorer, pour toute subdivision s = t0 < t1 < · · · < tp = t,
p
i=∑1
|
〈M, N〉ti
ti−1 | ≤
p
i=∑1
√
〈M, M〉ti
ti−1
√
〈N, N〉ti
ti−1
≤
(p
i=∑1
〈M, M〉ti
ti−1
)1/2( p
i=∑1
〈N, N〉ti
ti−1
)1/2
=
√
〈M, M〉t
s
√
〈N, N〉t
s
On peut ge ́ne ́raliser et obtenir, pour toute partie bore ́lienne borne ́e A de R+,
∫
A
|d〈M, N〉
u| ≤
√∫
A
d
〈M, M〉
u
√∫
A
d
〈N, N〉
u.
Soient h = ∑ λi1Ai et k = ∑ μi1Ai deux fonctions e ́tage ́es positives. Alors,
∫
h(s)k(s)|d〈M, N〉
s| = ∑ λiμi
∫
Ai
|d〈M, N〉
s|
≤
(
∑λ2
i
∫
Ai
d
〈M, M〉
s
)1/2(
∑μ2
i
∫
Ai
d
〈N, N〉
s
)1/2
Lorsque A=[s, t], c’est l’inégalité (4.4). Si A est une réunion finie d’intervalles, cela découle de (4.4) et d’une nouvelle application de l’inégalité de Cauchy-Schwarz. Un argument de classe monotone montre alors que cette inégalité est vraie pour toute partie borélienne bornée (on utilise ici une version du lemme de classe monotone différente de celle de l’Appendice A1 : précisément, la plus petite classe stable par réunion croissante et intersection décroissante dénombrables, et contenant une algèbre de parties, contient aussi la tribu engendrée par cette algèbre – voir le premier chapitre de [7]).


4.4 Semimartingales continues 73
=
(∫
h(s)2d〈M, M〉
s
)1/2( ∫
k(s)2d〈N, N〉
s
)1/2
,
ce qui donne l’ine ́galite ́ voulue pour des fonctions e ́tage ́es. Il ne reste qu’a`  ́ecrire une fonction mesurable positive quelconque comme limite croissante de fonctions e ́tage ́es. tu
4.4 Semimartingales continues
De ́finition 4.5. Un processus X = (Xt )t≥0 est une semimartingale continue s’il s’ ́ecrit sous la forme
Xt = Mt + At ,
ou` M est une martingale locale et A est un processus a` variation finie.
La de ́composition ci-dessus est unique a` indistinguabilite ́ pre`s, toujours a` cause du The ́ore`me 4.1. Si Yt = Mt′ + At′ est une autre semimartingale continue on pose par de ́finition
〈X,Y 〉
t = 〈M, M′〉
t.
En particulier, 〈X, X〉
t = 〈M, M〉
t.
Proposition 4.6. Soit 0 = tn
0 < tn
1 < · · · < tpnn = t une suite de subdivisions emboˆıt ́ees de [0,t] de pas tendant vers 0. Alors,
nli→m∞
pn
i=∑1
(Xtin − Xtn
i−1 )(Ytin − Ytn
i−1 ) = 〈X ,Y 〉
t
en probabilit ́e.
De ́monstration. Pour simplifier, traitons seulement le cas ou` X = Y . Alors,
pn
i=∑1
(Xtin − Xtn
i−1 )2 =
pn
i=∑1
(Mtin − Mtn
i−1 )2 +
pn
i=∑1
(Atin − Atn
i−1 )2
+2
pn
i=∑1
(Mtin − Mtn
i−1 )(Atin − Atn
i−1 ).
On sait de ́ja` (The ́or`eme 4.2) que
nli→m∞
pn
i=∑1
(Mtin − Mtn
i−1 )2 = 〈M, M〉
t = 〈X, X〉
t,
en probabilite ́. D’autre part,


74 4 Exercices
pn
i=∑1
(Atin − Atn
i−1 )2 ≤
(
sup
1≤i≤ pn
|Atin − Atn
i−1 |
) pn
i=∑1
|Atin − Atn
i−1 |
≤
(∫ t
0
|dAs|
)
sup
1≤i≤ pn
|Atin − Atn
i−1 |,
qui tend vers 0 p.s. quand n → ∞ par continuite ́ de la fonction s 7→ As. Le meˆme raisonnement montre que
∣ ∣ ∣
pn
i=∑1
(Atin − Atn
i−1 )(Mtin − Mtn
i−1 )
∣
∣
∣≤
(∫ t
0
|dAs|
)
sup
1≤i≤ pn
|Mtin − Mtn
i−1 |
tend vers 0 p.s. tu
Exercices
Dans les exercices qui suivent, on se place sur un espace de probabilite ́ (Ω , F , P) muni d’une filtration comple`te (Ft )t∈[0,∞].
Exercice 4.1. Soit U une variable ale ́atoire re ́elle F0-mesurable, et soit M une martingale locale. Montrer que le processus Nt = UMt est encore une martingale locale. (Ce r ́esultat a  ́et ́e utilis ́e dans la construction de la variation quadratique d’une martingale locale.)
Exercice 4.2. 1. Soit M une (vraie) martingale a` trajectoires continues issue de M0 = 0. On suppose que (Mt )t≥0 est aussi un processus gaussien. Montrer alors que pour tout t ≥ 0 et tout s > 0, la variable ale ́atoire Mt+s −Mt est inde ́pendante de σ (Mr, 0 ≤ r ≤ t).
2. Sous les hypoth`eses de la question 1., montrer qu’il existe une fonction croissante continue f : R+ → R+ telle que 〈M, M〉t = f (t) pour tout t ≥ 0.
Exercice 4.3. Soit M une martingale locale issue de 0. 1. Pour tout entier n ≥ 1, on pose Tn = inf{t ≥ 0 : |Mt | = n}. Montrer que p.s.
{
tli→m∞
Mt existe et est finie
}
=
∞
⋃
n=1
{Tn = ∞} ⊂ {〈M, M〉∞ < ∞}.
2. On pose Sn = inf{t ≥ 0 : 〈M, M〉t = n} pour tout entier n ≥ 1. Montrer qu’on a aussi p.s.
{〈M, M〉∞ < ∞} =
∞
⋃
n=1
{Sn = ∞} ⊂
{
tli→m∞
Mt existe et est finie
}
,
et conclure que


4 Exercices 75
{
tli→m∞
Mt existe et est finie
}
= {〈M, M〉∞ < ∞} , p.s.
Exercice 4.4. Pour tout entier n ≥ 1, soit Mn = (Mtn)t≥0 une martingale locale issue de 0. On suppose dans tout l’exercice que
nli→m∞
〈Mn, Mn〉∞ = 0
en probabilite ́.
1. Soit ε > 0, et, pour tout n ≥ 1, soit
Tn
ε = inf{t ≥ 0 : 〈Mn, Mn〉t ≥ ε}.
Justifier le fait que T n
ε est un temps d’arreˆt, puis montrer que la martingale locale
arreˆte ́e
Mn,ε
t = Mn
t∧T n
ε , ∀t ≥ 0 ,
est une vraie martingale borne ́e dans L2.
2. Montrer que
E
[
sup
t≥0
|Mn,ε
t| ≤
2
]
4 ε.
3. En e ́crivant, pour tout a > 0,
P
[
sup
t≥0
|Mn
t |≥a
]
≤P
[
sup
t≥0
|Mn,ε
t |≥a
]
+ P[T n
ε < ∞]
montrer que
nli→m∞
(
sup
t≥0
|Mn
t|
)
=0
en probabilite ́.
Exercice 4.5. 1. Soit A un processus croissant (a` trajectoires continues, adapte ́, tel que A0 = 0) tel que A∞ < ∞ p.s., et soit Z une variable positive inte ́grable. On suppose que, pour tout temps d’arreˆt T , on a
E[A∞ − AT ] ≤ E[Z 1{T <∞}].
Montrer en utilisant un temps d’arreˆt bien choisi que pour tout λ > 0,
E[(A∞ − λ ) 1{A∞>λ }] ≤ E[Z 1{A∞>λ }].
2. Soit f : R+ −→ R une fonction croissante de classe C1, telle que f (0) = 0 et soit
F(x) = ∫ x
0 f (t)dt pour tout x ≥ 0. Montrer que, sous les hypothe`ses de la question 1., on a
E[F(A∞)] ≤ E[Z f (A∞)].
(On pourra remarquer que F(x) = x f (x) − ∫ x
0 λ f ′(λ ) dλ pour tout x ≥ 0.)


76 4 Exercices
3. Soit M une (vraie) martingale a` trajectoires continues, borne ́e dans L2, telle que M0 = 0, et soit M∞ la limite presque sˆure de Mt quand t → ∞. Montrer que les hypothe`ses de la question 1. sont satisfaites lorsque At = 〈M, M〉t et Z = M2
∞. En de ́duire que, pour tout re ́el q ≥ 1,
E[(〈M, M〉∞)q+1] ≤ (q + 1) E[(〈M, M〉∞)q M2
∞].
4. Soit p ≥ 2 un re ́el tel que E[(〈M, M〉∞)p] < ∞. Montrer que
E[(〈M, M〉∞)p] ≤ pp E[|M∞|2p].
5. Soit N une martingale locale telle que N0 = 0, et soit T un temps d’arreˆt tel que la martingale arreˆte ́e NT soit uniforme ́ment inte ́grable. Montrer que, pour tout re ́el p ≥ 2, E[(〈N, N〉T )p] ≤ pp E[|NT |2p].
Donner un exemple montrant que ce re ́sultat peut eˆtre faux si NT n’est pas uniforme ́ment inte ́grable.
Exercice 4.6. Soit (Xt )t≥0 un processus adapt ́e, a` trajectoires continues et a` valeurs positives ou nulles. Soit (At )t≥0 un processus croissant (a` trajectoires continues, adapte ́, tel que A0 = 0). On conside`re la condition suivante :
(D) Pour tout temps d’arreˆt borne ́ T , on a E[XT ] ≤ E[AT ].
1. Montrer que si M est une (vraie) martingale a` trajectoires continues et de carre ́ inte ́grable, et M0 = 0, alors la condition (D) est satisfaite par Xt = Mt2 et At = 〈M, M〉t .
2. Montrer que la conclusion de la question pre ́ce ́dente reste vraie si on suppose seulement que M est une martingale locale issue de 0. 3. On note Xt∗ = sups≤t Xs. Montrer que sous la condition (D) on a pour tout temps d’arreˆt borne ́ S et tout c > 0 :
P[X ∗
S ≥ c] ≤ 1
c E[AS].
(on pourra appliquer l’ine ́galite ́ (D) a` T = S ∧ R, avec R = inf{t ≥ 0 : Xt ≥ c}). 4. En de ́duire, toujours sous la condition (D), que, pour tout temps d’arreˆt S (fini ou pas),
P[X ∗
S > c] ≤ 1
c E[AS]
(lorsque S prend la valeur ∞, on prend bien entendu X∗
∞ = sups≥0 Xs). 5. Soient c > 0 et d > 0, et S = inf{t ≥ 0 : At ≥ d}. Soit aussi T un temps d’arreˆt. En remarquant que
{X ∗
T > c} ⊂
(
{X ∗
T ∧S > c} ∪ {AT ≥ d}
)
montrer que, sous la condition (D), on a


4 Exercices 77
P[X ∗
T > c] ≤ 1
c E[AT ∧ d] + P[AT ≥ d].
6. De ́duire des questions 2. et 5. que si M(n) est une suite de martingales locales et T un temps d’arreˆt tel que 〈M(n), M(n)〉T converge en probabilite ́ vers 0 quand n → ∞, alors on a aussi :
nli→m∞
(
sup
s≤T
|M(n)
s|
)
= 0 , en probabilite ́.


J.-F. Le Gall, Mouvement brownien, martingales et calcul stochastique, 71, DOI: 10.1007/978-3-642-31898-6_ , Ó Springer-Verlag Berlin Heidelberg 2013
Chapitre 5
Inte ́grale stochastique
Re ́sume ́ Ce chapitre est au cœur du pre ́sent ouvrage. Dans un premier temps, nous de ́finissons l’inte ́grale stochastique par rapport a` une (semi)martingale continue, en conside ́rant d’abord l’inte ́grale des processus e ́le ́mentaires (qui jouent ici un roˆle analogue aux fonctions en escalier dans la the ́orie de l’inte ́grale de Riemann) puis en utilisant un argument d’isome ́trie entre espaces de Hilbert pour passer au cas ge ́ne ́ral. Nous e ́tablissons ensuite la ce ́l`ebre formule d’Itoˆ, qui est l’outil principal du calcul stochastique. Nous discutons plusieurs applications importantes de la formule d’Itoˆ : the ́ore`me de Le ́vy caracte ́risant le mouvement brownien comme martingale locale de variation quadratique t, ine ́galite ́s de Burkholder-Davis-Gundy, repr ́esentation des martingales dans la filtration d’un mouvement brownien. La fin du chapitre est consacre ́e au the ́ore`me de Girsanov, qui de ́crit la stabilite ́ des notions de martingales et de semimartingales par changement absolument continu de probabilite ́. En application du the ́or`eme de Girsanov, nous  ́etablissons la ce ́le`bre formule de Cameron-Martin donnant l’image de la mesure de Wiener par une translation par une fonction de ́terministe. Sauf indication du contraire, les processus conside ́re ́s dans ce chapitre sont indexe ́s par R+ et a` valeurs re ́elles.
5.1 Construction de l’inte ́grale stochastique
Dans tout ce chapitre on se place sur un espace de probabilite ́ (Ω , F , (Ft ), P) muni d’une filtration comple`te. On dira parfois “martingale continue” au lieu de “martingale a` trajectoires continues”. Rappelons que par de ́finition les martingales locales ont des trajectoires continues.
De ́finition 5.1. On note H2 l’espace des martingales continues M borne ́es dans L2 et telles que M0 = 0, avec la convention que deux processus indistinguables sont identifi ́es.
La Proposition 4.4 (v) montre que, si M, N ∈ H2 la variable ale ́atoire 〈M, N〉
∞ est
bien de ́finie et on a E[|〈M, N〉
∞|] < ∞. Cela permet de de ́finir une forme biline ́aire
79
5
Math ̄matiques et Applications


80 5 Inte ́grale stochastique
syme ́trique sur H2 par la formule
(M, N)H2 = E[〈M, N〉
∞] = E[M∞N∞].
Le Corollaire 4.1 montre aussi que (M, M)H2 = 0 si et seulement si M = 0. La norme
sur H2 associe ́e au produit scalaire (M, N)H2 est
‖M‖H2 = (M, M)1/2
H2 = E[〈M, M〉
∞]1/2.
Proposition 5.1. L’espace H2 muni du produit scalaire (M, N)H2 est un espace de Hilbert.
De ́monstration. Il faut voir que H2 est complet pour la norme ‖ ‖H2 . Soit donc
(Mn) une suite de Cauchy pour cette norme : d’apre`s le The ́ore`me 4.3, on a
lim
m,n→∞
E [(M n
∞ − Mm
∞ )2] = lim
m,n→∞
E[〈Mn − Mm, Mn − Mm〉
∞] = 0.
En particulier, la suite (Mn
∞) converge dans L2 vers une limite note ́e M∞. L’ine ́galite ́
de Doob dans L2 (Proposition 3.8 (ii)), et un passage a` la limite facile montrent que, pour tous m, n,
E
[
sup
t≥0
(Mn
t − Mm
t )2]
≤ 4 E[(Mn
∞ − Mm
∞ )2].
On obtient donc que
lim
m,n→∞
E
[
sup
t≥0
(Mn
t − Mm
t )2]
= 0. (5.1)
Il est ensuite facile d’extraire une sous-suite (nk) telle que
E
[∞
∑
k=1
sup
t≥0
|Mtnk − Mnk+1
t|
]
≤
∞
∑
k=1
E
[
sup
t≥0
(Mtnk − Mnk+1
t )2]1/2
< ∞.
On en de ́duit que p.s.
∞
∑
k=1
sup
t≥0
|Mtnk − Mnk+1
t | < ∞,
et donc p.s. la suite (Mnk )t≥0 converge uniforme ́ment sur R+ vers une limite note ́e (Mt )t≥0. Clairement le processus limite M a des trajectoires continues (on se de ́barrasse facilement de l’ensemble de probabilite ́ nulle en prenant M ≡ 0 sur
cet ensemble). Puisque Mtnk converge aussi dans L2 vers Mt , pour tout t ≥ 0 (car la
suite (Mtn) est de Cauchy dans L2 d’apre`s (5.1)) on voit imme ́diatement en passant
a` la limite dans l’e ́galite ́ Mtnk = E[Mn∞k | Ft ] que Mt = E[M∞ | Ft ], et donc (Mt )t≥0
est une martingale borne ́e dans L2. Enfin,
kli→m∞
E[〈Mnk − M, Mnk − M〉
∞] = kli→m∞
E [(M nk
∞ − M∞)2] = 0,
ce qui montre que la sous-suite (Mnk ), donc aussi la suite (Mn) converge vers M dans H2. tu


5.1 Construction de l’inte ́grale stochastique 81
On note Prog la tribu progressive sur Ω × R+ (voir la fin du paragraphe 3.1).
De ́finition 5.2. Pour M ∈ H2, on note
L2(M) = L2(Ω × R+, Prog, dP d〈M, M〉
s)
l’espace des processus progressifs H tels que
E
[∫ ∞
0
H2
s d〈M, M〉
s
]
< ∞.
Comme n’importe quel espace L2, l’espace L2(M) est un espace de Hilbert pour le produit scalaire
(H, K)L2(M) = E
[∫ ∞
0
HsKs d〈M, M〉
s
]
.
De ́finition 5.3. On note E le sous-espace vectoriel de L2(M) forme ́ des processus e ́le ́mentaires, c’est-a`-dire des processus H de la forme
Hs(ω) =
p−1
i=∑0
H(i)(ω ) 1]ti,ti+1](s),
ou` 0 = t0 < t1 < t2 < · · · < tp et pour chaque i ∈ {0, 1, . . . , p−1}, H(i) est une variable Fti -mesurable et borne ́e.
Proposition 5.2. Pour tout M ∈ H2, E est dense dans L2(M).
De ́monstration. Il suffit de montrer que si K ∈ L2(M) est orthogonal a` E alors K = 0. Supposons donc K orthogonal a` E , et posons, pour tout t ≥ 0,
Xt =
∫t
0
Ku d〈M, M〉
u.
Le fait que cette inte ́grale soit (p.s.) absolument convergente de ́coule facilement de l’ine ́galite ́ de Cauchy-Schwarz et des proprie ́te ́s M ∈ H2, K ∈ L2(M). Cet argument montre meˆme que Xt ∈ L1. Soient ensuite 0 ≤ s < t, soit F une variable Fs-mesurable borne ́e et soit H ∈ E de ́fini par Hr(ω) = F(ω) 1]s,t](r). En e ́crivant (H, K)L2(M) = 0, on trouve
E
[
F
∫t
s
Ku d〈M, M〉
u
]
= 0.
On a ainsi obtenu E[F(Xt − Xs)] = 0 pour tous s < t et toute variable Fs-mesurable F. Cela montre que X est une martingale. D’autre part, puisque X est aussi un processus a` variation finie (d’apre`s la Proposition 4.2, et la remarque (i) suivant cette proposition), cela n’est possible (The ́ore`me 4.1) que si X = 0. On a donc
∫t
0
Ku d〈M, M〉
u = 0 ∀t ≥ 0, p.s.


82 5 Inte ́grale stochastique
ce qui entraˆıne
Ku = 0, d〈M, M〉
u p.p., p.s.
c’est-a`-dire K = 0 dans L2(M). tu
Rappelons la notation XT pour le processus X arreˆte ́ au temps d’arreˆt T , XtT =
Xt∧T .
The ́ore`me 5.1. Soit M ∈ H2. Pour tout H ∈ E , de la forme
Hs(ω) =
p−1
i=∑0
H(i)(ω ) 1]ti,ti+1](s),
on d ́efinit H · M ∈ H2 par la formule
(H · M)t =
p−1
i=∑0
H(i) (Mti+1∧t − Mti∧t ).
L’application H 7→ H ·M s’ ́etend en une isom ́etrie de L2(M) dans H2. De plus, H ·M est caract ́eris ́e par la relation
〈H · M, N〉 = H · 〈M, N〉, ∀N ∈ H2. (5.2)
Si T est un temps d’arrˆet, on a
(1[0,T ]H) · M = (H · M)T = H · MT . (5.3)
On note souvent
(H · M)t =
∫t
0
Hs dMs
et on appelle H · M l’int ́egrale stochastique de H par rapport `a M.
Remarque. L’inte ́grale H · 〈M, N〉 qui figure dans le terme de droite de (5.2) est une inte ́grale par rapport a` un processus a` variation finie, comme cela a e ́te ́ de ́fini dans le paragraphe 4.1.
De ́monstration. On va d’abord ve ́rifier que l’application M 7→ H · M est une isome ́trie de E dans H2. On montre tre`s facilement que, si H ∈ E , H · M est une martingale continue borne ́e dans L2, donc appartient a` H2. De plus l’application H 7→ H · M est clairement line ́aire. Ensuite, on observe que, si H est de la forme donne ́e dans le the ́ore`me, H · M est la somme des martingales
Mi
t = H(i) (Mti+1∧t − Mti∧t )
qui sont orthogonales et de processus croissants respectifs
〈Mi, Mi〉
t = H2
(i)
(〈M, M〉
ti+1∧t − 〈M, M〉
ti ∧t
)


5.1 Construction de l’inte ́grale stochastique 83
(ces proprie ́t ́es sont faciles a` ve ́rifier, par exemple en utilisant les approximations de 〈M, N〉). On conclut que
〈H · M, H · M〉
t=
p−1
i=∑0
H2
(i)
(〈M, M〉
ti+1∧t − 〈M, M〉
ti ∧t
).
En conse ́quence,
‖H · M‖2
H2 = E
[ p−1
i=∑0
H2
(i)
(〈M, M〉
ti+1 − 〈M, M〉
ti
)
]
=E
[∫ ∞
0
H2
s d〈M, M〉
s
]
= ‖H‖2
L2(M).
L’application M 7→ H · M est donc une isome ́trie de E dans H2. Puisque E est dense dans L2(M) (Proposition 5.2) et H2 est un espace de Hilbert (Proposition 5.1), on peut prolonger, de manie`re unique, cette application en une isome ́trie de L2(M) dans H2.
Ve ́rifions maintenant la propri ́ete ́ (5.2). On fixe N ∈ H2. On remarque d’abord que, si H ∈ L2(M), l’ine ́galite ́ de Kunita-Watanabe (Proposition 4.5) montre que
E
[∫ ∞
0
|Hs| |d〈M, N〉s|
]
≤ ‖H‖L2(M) ‖N‖H2 < ∞
et donc la variable ∫ ∞
0 Hsd〈M, N〉s = (H · 〈M, N〉)∞ est bien de ́finie et dans L1. Conside ́rons d’abord le cas ou` H est e ́le ́mentaire de la forme ci-dessus. Alors, pour tout i ∈ {0, 1, . . . , p − 1},
〈H · M, N〉 =
p−1
i=∑0
〈Mi, N〉
et on ve ́rifie aise ́ment que
〈Mi, N〉
t = H(i)
(〈M, N〉
ti+1∧t − 〈M, N〉
ti ∧t
).
On en de ́duit que
〈H · M, N〉
t=
p−1
i=∑0
H(i)
(〈M, N〉
ti+1∧t − 〈M, N〉
ti ∧t
)=
∫t
0
Hs d〈M, N〉
s
ce qui donne la relation (5.2) lorsque H ∈ E . Ensuite, on remarque que l’application X 7→ 〈X, N〉
∞ est continue de H2 dans L1 : en effet, d’apre`s l’ine ́galite ́ de Kunita
Watanabe,
E[|〈X, N〉
∞|] ≤ E[〈X, X〉
∞]1/2E[〈N, N〉
∞]1/2 = ‖N‖H2 ‖X ‖H2 .


84 5 Inte ́grale stochastique
Si on se donne une suite (Hn) dans E , telle que Hn → H dans L2(M), on a donc
〈H · M, N〉
∞ = nli→m∞
〈Hn · M, N〉
∞ = nli→m∞
(Hn · 〈M, N〉)∞ = (H · 〈M, N〉)∞,
ou` les convergences ont lieu dans L1 et la dernie`re e ́galite ́ de ́coule `a nouveau de l’ine ́galite ́ de Kunita-Watanabe, en e ́crivant
E
[∣ ∣ ∣
∫∞
0
(H n
s − Hs) d〈M, N〉
s
∣ ∣ ∣
]
≤ E[〈N, N〉
∞]1/2 ‖Hn − H‖L2(M).
En rempla ̧cant N par Nt dans l’ ́egalite ́ 〈H · M, N〉
∞ = (H · 〈M, N〉)∞ on trouve
〈H · M, N〉
t = (H · 〈M, N〉)t , ce qui termine la preuve de (5.2).
Il est facile de voir que la relation (5.2) caracte ́rise H · M. En effet, si X est une autre martingale de H2 qui satisfait la meˆme proprie ́te ́, on a pour tout N ∈ H2,
〈H · M − X, N〉 = 0
et en prenant N = H · M − X on trouve que X = H · M. Il reste a` ve ́rifier la dernie`re proprie ́te ́. En utilisant les proprie ́te ́s du crochet de deux martingales, on remarque que, si N ∈ H2,
〈(H · M)T , N〉
t = 〈H · M, N〉
t∧T = (H · 〈M, N〉)t∧T = (1[0,T ] H · 〈M, N〉)t
ce qui montre que la martingale arreˆte ́e (H · M)T ve ́rifie la proprie ́t ́e caracte ́ristique de l’inte ́grale (1[0,T]H) · M. On obtient ainsi la premie`re e ́galite ́ de (5.3). La preuve de la seconde est analogue, en e ́crivant
〈H · MT , N〉 = H · 〈MT , N〉 = H · 〈M, N〉T = 1[0,T] H · 〈M, N〉.
Cela termine la preuve du the ́ore`me. tu Remarque. On aurait pu utiliser la relation (5.2) pour d ́efinir l’inte ́grale stochastique H · M, en observant que l’application N 7→ E[(H · 〈M, N〉)∞] de ́finit une forme line ́aire continue sur H2, et donc qu’il existe un e ́le ́ment unique H · M de H2 tel que
E[(H · 〈M, N〉)∞] = (H · M, N)H2 = E[〈H · M, N〉
∞].
La proprie ́te ́ suivante d’associativite ́ de l’inte ́grale stochastique est tre`s utile.
Proposition 5.3. Si K ∈ L2(M) et H ∈ L2(K · M) alors HK ∈ L2(M) et
(HK) · M = H · (K · M).
De ́monstration. D’apre`s le The ́ore`me 5.1, on a
〈K · M, K · M〉 = K · 〈M, K · M〉 = K2 · 〈M, M〉,
et donc


5.1 Construction de l’inte ́grale stochastique 85
∫∞
0
H2
s K2
s d〈M, M〉
s=
∫∞
0
H2
s d〈K · M, K · M〉
s
ce qui donne la premie`re assertion. Pour la seconde il suffit de remarquer que si N ∈ H2,
〈(HK) · M, N〉 = HK · 〈M, N〉 = H · (K · 〈M, N〉)
= H · 〈K · M, N〉
=
〈H · (K · M), N〉
d’ou` le re ́sultat voulu. tu Remarque. De manie`re informelle, l’e ́galite ́ de la proposition pre ́c ́edente s’e ́crit
∫t
0
Hs (Ks dMs) =
∫t
0
HsKs dMs.
De meˆme la proprie ́te ́ (5.2) s’e ́crit
〈
∫·
0
HsdMs, N〉
t=
∫t
0
Hs d〈M, N〉
s.
En appliquant deux fois cette relation on a aussi
〈
∫·
0
HsdMs,
∫·
0
KsdNs
〉
t=
∫t
0
HsKs d〈M, N〉
s.
En particulier,
〈
∫·
0
HsdMs,
∫·
0
HsdMs
〉
t=
∫t
0
H2
s d〈M, M〉
s.
Formules de moments. Soient M ∈ H2, N ∈ H2, H ∈ L2(M) et K ∈ L2(N). Puisque H · M et K · N sont des martingales de H2, on a, pour tout t ∈ [0, ∞],
E
[∫ t
0
Hs dMs
]
= 0 (5.4)
E
[( ∫ t
0
HsdMs
)( ∫ t
0
KsdNs
)]
=E
[∫ t
0
HsKs d〈M, N〉
s
]
. (5.5)
En particulier,
E
[( ∫ t
0
Hs dMs
)2]
=E
[∫ t
0
H2
s d〈M, M〉
s
]
. (5.6)
Par ailleurs, H · M e ́tant une vraie martingale, on a aussi, pour tous 0 ≤ s < t ≤ ∞,
E
[∫ t
0
Hr dMr
∣
∣
∣ Fs
]
=
∫s
0
Hr dMr (5.7)
Il est important de remarquer que ces relations (et notamment (5.4) et (5.6)) ne seront plus forc ́ement vraies pour les extensions de l’inte ́grale stochastique qui vont eˆtre de ́crites ci-dessous.


86 5 Inte ́grale stochastique
A l’aide des identite ́s (5.3) il est facile d’e ́tendre la de ́finition de l’inte ́grale stochastique H · M a` une martingale locale quelconque. Soit M une martingale locale issue de 0. On note L2
loc(M) (resp. L2(M)) l’espace des processus progressifs H tels que, pour tout t ≥ 0,
∫t
0
H2
s d〈M, M〉
s < ∞, p.s. (resp. E
[∫ ∞
0
H2
s d〈M, M〉
s
]
< ∞).
The ́ore`me 5.2. Soit M une martingale locale issue de 0. Pour tout H ∈ L2
loc(M), il existe une unique martingale locale issue de 0, not ́ee H · M, telle que pour toute martingale locale N, 〈H · M, N〉 = H · 〈M, N〉. (5.8)
Si T est un temps d’arrˆet, on a
(1[0,T ]H) · M = (H · M)T = H · MT . (5.9)
Si K ∈ L2
loc(M) et H ∈ L2
loc(K · M), on a HK ∈ L2
loc(M), et
H · (K · M) = HK · M. (5.10)
Enfin, si M ∈ H2, et H ∈ L2(M), la d ́efinition de H · M  ́etend celle du Th ́eor`eme 5.1.
De ́monstration. On note
Tn = inf{t ≥ 0 :
∫t
0
(1 + H2
s ) d〈M, M〉
s ≥ n},
de sorte que (Tn) est une suite de temps d’arreˆt croissant vers +∞ (en toute rigueur, il faudrait ici tenir compte de l’ensemble de probabilit ́e nulle sur lequel il existe une valeur t < ∞ pour laquelle ∫ t
0 Hs2 d〈M, M〉
s = ∞ : sur cet ensemble ne ́gligeable, on remplace H par 0 dans la construction qui suit). Puisque
〈MTn , MTn 〉
t = 〈M, M〉
t∧Tn ≤ n,
la martingale arreˆte ́e MTn est dans H2 (The ́ore`me 4.3). De plus, il est aussi clair que
∫∞
0
H2
s d〈MTn , MTn 〉
s ≤ n.
Donc, H ∈ L2(MTn ), et on peut de ́finir l’inte ́grale stochastique H · MTn pour chaque n. En utilisant la proprie ́te ́ (5.3), on voit que si m > n on a
H · MTn = (H · MTm )Tn .
Cela montre qu’il existe un (unique) processus, note ́ H · M, tel que, pour tout n,
(H · M)Tn = H · MTn .


5.1 Construction de l’inte ́grale stochastique 87
Puisque les processus (H · M)Tn sont des martingales de H2, donc en particulier uniforme ́ment inte ́grables, H · M est une martingale locale. Soit N une martingale locale, qu’on peut supposer issue de 0 et soient Tn′ =
inf{t ≥ 0 : |Nt | ≥ n}, Sn = Tn ∧ Tn′. Alors,
〈H · M, N〉Sn = 〈(H · M)Tn , NTn′ 〉
=
〈H · MTn , NTn′ 〉
= H · 〈MTn , NTn′ 〉
= H · 〈M, N〉Sn
= (H · 〈M, N〉)Sn
d’ou` l’e ́galite ́ 〈H ·M, N〉 = H ·〈M, N〉. Le fait que cette  ́egalite ́  ́ecrite pour toute martingale locale N caracte ́rise H · M se de ́montre exactement comme dans le Th ́eore`me 5.1. La proprie ́te ́ (5.9) est obtenue dans ce cadre par les meˆmes arguments que la proprie ́te ́ (5.3) dans la preuve du The ́ore`me 5.1 (ces arguments utilisaient seulement la proprie ́te ́ caracte ́ristique (5.2) qu’on vient d’e ́tendre sous la forme (5.8)). De meˆme la preuve de (5.10) est exactement analogue a` celle de la Proposition 5.3. Enfin, si M ∈ H2 et H ∈ L2(M), l’e ́galite ́ 〈H · M, H · M〉 = H2 · 〈M, M〉 entraˆıne d’abord que H · M ∈ H2, et ensuite la proprie ́te ́ caracte ́ristique (5.2) montre que les de ́finitions des The ́ore`mes 5.1 et 5.2 co ̈ıncident. tu
Remarque. Lien avec l’inte ́grale de Wiener. Conside ́rons le cas particulier ou` B est un mouvement brownien (en dimension un, issu de 0) et h ∈ L2(R+, B(R+), dt) est une fonction d ́eterministe de carre ́ inte ́grable. On peut alors d ́efinir l’inte ́grale de Wiener ∫ t
0 h(s)dBs = G( f 1[0,t]), ou` G est la mesure gaussienne associe ́e a` B (voir la fin du paragraphe 2.1 ci-dessus). On voit aise ́ment que cette inte ́grale co ̈ıncide avec l’inte ́grale stochastique (h · B)t que nous venons de d ́efinir. En effet, c’est imme ́diat dans le cas ou` h est une fonction en escalier, et on peut ensuite utiliser un argument de densit ́e.
Discutons maintenant l’extension des formules de moments e ́nonce ́es avant le The ́ore`me 5.2. Soient M une martingale locale, H ∈ L2
loc(M) et t ∈ [0, ∞]. Alors, sous la condition
E
[∫ t
0
H2
s d〈M, M〉
s
]
< ∞, (5.11)
on peut appliquer a` (H · M)t le The ́ore`me 4.3, et on a
E
[∫ t
0
Hs dMs
]
= 0, E
[( ∫ t
0
Hs dMs
)2]
=E
[∫ t
0
H2
s d〈M, M〉
s
]
,
et de meˆme (5.7) reste vrai sur l’intervalle de temps [0,t]. En particulier (cas t = ∞), si H ∈ L2(M), la martingale locale H.M est dans H2 (vraie martingale borne ́e dans L2) et sa valeur terminale ve ́rifie


88 5 Inte ́grale stochastique
E
[( ∫ ∞
0
Hs dMs
)2]
=E
[∫ ∞
0
H2
s d〈M, M〉
s
]
.
Si la condition (5.11) n’est pas satisfaite, les formules pre ́ce ́dentes ne sont pas toujours vraies. Cependant, on a toujours la majoration suivante.
Proposition 5.4. Soit M une martingale locale, et soit H ∈ L2
loc(M). Alors, pour tout t ≥ 0,
E
[( ∫ t
0
Hs dMs
)2]
≤E
[∫ t
0
H2
s d〈M, M〉
s
]
. (5.12)
De ́monstration. En introduisant la meˆme suite (Tn) que dans la preuve du The ́ore`me 5.2, et en utilisant le fait que H ∈ L2(MTn ), on de ́duit de (5.6) que, pour tout t ≥ 0,
E[(H · M)2
t∧Tn ] = E
[ ∫ t∧Tn
0
H2
s d〈M, M〉
s
]
.
On aboutit ensuite au re ́sultat recherche ́ en utilisant le lemme de Fatou (pour le terme de droite) et le the ́ore`me de convergence monotone (pour celui de gauche). tu
Nous allons maintenant e ́tendre l’inte ́grale stochastique aux semimartingales continues. On dit qu’un processus progressif H est localement borne ́ si
∀t ≥ 0, sup
s≤t
|Hs| < ∞, p.s.
En particulier, tout processus adapte ́ a` trajectoires continues est localement borne ́. De plus, si H est localement borne ́, alors, pour tout processus a` variation finie V , on a
∀t ≥ 0,
∫t
0
|Hs| |dVs| < ∞, p.s.
et de meˆme, pour toute martingale locale M, on a H ∈ L2
loc(M).
De ́finition 5.4. Soit X = M +V une semimartingale continue, et soit H un processus (progressif) localement borne ́. L’inte ́grale stochastique H · X est alors de ́finie par
H · X = H · M + H ·V,
et on note
(H · X)t =
∫t
0
Hs dXs.
Proprie ́te ́s.
(i) L’application (H, X) 7→ H · X est biline ́aire. (ii) H · (K · X) = (HK) · X, si H et K sont localement borne ́s. (iii) Pour tout temps d’arreˆt T , (H · X)T = H1[0,T] · X = H · XT . (iv) Si X est une martingale locale, resp. si X est un processus a` variation finie, alors il en va de meˆme pour H · X.


5.1 Construction de l’inte ́grale stochastique 89
(v) Si H est un processus progressif de la forme Hs(ω) = ∑p−1
i=0 H(i)(ω ) 1]ti,ti+1](s),
ou`, pour chaque i, H(i) est Fti -mesurable, alors
(H · X)t =
p−1
i=∑0
H(i) (Xti+1∧t − Xti∧t ).
Les proprie ́te ́s (i)-(iv) d ́ecoulent facilement des re ́sultats obtenus quand X est une martingale, resp. un processus a` variation finie. Dans la proprie ́te ́ (v), la (petite) difficult ́e vient de ce qu’on ne suppose pas que les variables H(i) soient borne ́es (si c’est le cas H est un processus e ́le ́mentaire, et l’e ́galite ́ de (v) est vraie par de ́finition). Pour la preuve de (v), on remarque d’abord qu’il suffit de traiter le cas ou` X = M est une martingale locale, et on peut meˆme supposer que M est dans H2 (quitte a` arreˆter M a` des temps d’arreˆt convenables). Ensuite, on observe que si on pose pour tout entier n ≥ 1,
Tn = inf{t ≥ 0 : |Ht | ≥ n} = inf{ti : |H(i)| ≥ n} (avec inf ∅ = ∞)
les Tn forment une suite de temps d’arreˆt qui croˆıt vers l’infini (meˆme de manie`re stationnaire) et on peut e ́crire
Hs 1[0,Tn](s) =
p−1
i=∑0
Hn
(i) 1]ti,ti+1](s)
ou` les Hn
(i) = H(i) 1{Tn>ti} ve ́rifient les meˆmes proprie ́te ́s que les H(i) et sont de plus borne ́s par n. Donc H 1[0,Tn] est un processus e ́le ́mentaire, et par la construction meˆme de l’inte ́grale stochastique dans ce cas on a
(H · M)t∧Tn = (H 1[0,Tn] · M)t =
p−1
i=∑0
Hn
(i) (Xti+1∧t − Xti∧t ).
Il suffit maintenant de faire tendre n vers l’infini dans l’e ́galite ́ entre les deux termes extreˆmes. Nous terminons ce paragraphe par un r ́esultat technique d’approximation qui sera utile dans la suite.
Proposition 5.5. Soit X une semimartingale continue et soit H un processus adapt ́e `a trajectoires continues. Alors, pour tout t > 0, pour toute suite 0 = tn
0 < · · · < tpnn = t de subdivisions de [0,t] de pas tendant vers 0, on a
nli→m∞
pn −1
i=∑0
Htin (Xtn
i+1 − Xtin ) =
∫t
0
Hs dXs,
au sens de la convergence en probabilit ́e.
De ́monstration. On peut traiter se ́pare ́ment les parties martingale et a` variation finie de X. La partie `a variation finie est traite ́e par le Lemme 4.1. On peut donc supposer


90 5 Inte ́grale stochastique
que X = M est une martingale locale issue de 0. Pour chaque n, de ́finissons un processus H(n) par
H (n)
s=



Htin si tn
i < s ≤ tn
i+1
0 si s > t ou s = 0.
Posons enfin, pour tout p ≥ 1,
Tp = inf{s ≥ 0 : |Hs| + 〈M, M〉
s ≥ p},
et remarquons que H, H(n) et 〈M, M〉 sont borne ́s par p sur l’intervalle ]0, Tp]. D’apre`s (5.12), pour tout p fixe ́,
E
[ (
(H(n) · MTp )t − (H · MTp )t
)2]
≤E
[ ∫ t∧Tp
0
(H (n)
s − Hs)2d〈M, M〉
s
]
converge vers 0 quand n → ∞ par convergence domine ́e. En utilisant (5.3), on en de ́duit que
nli→m∞
(H(n) · M)t∧Tp = (H · M)t∧Tp ,
dans L2. Puisque que P[Tp > t] ↑ 1 quand p ↑ ∞, on obtient que
nli→m∞
(H(n) · M)t = (H · M)t ,
en probabilite ́. Cela termine la preuve puisque d’apre`s la proprie ́te ́ (v) ci-dessus on a
(H(n) · M)t =
pn −1
i=∑0
Htin (Xtn
i+1 − Xtin ). tu
Remarque. Il est essentiel que dans l’approximation donne ́e dans la proposition pre ́ce ́dente on conside`re la valeur de H a` l’extr ́emite ́ gauche de l’intervalle ]tn
i ,tn
i+1]:
si on remplace Htin par Htn
i+1 le re ́sultat n’est plus vrai. Montrons-le par un contre
exemple tre`s simple, en prenant Ht = Xt et en supposant les subdivisions (tn
i )0≤i≤pn
emboˆıte ́es. On a d’apre`s la proposition,
nli→m∞
pn −1
i=∑0
Xtin (Xtn
i+1 − Xtin ) =
∫t
0
Xs dXs,
en probabilite ́. D’autre part, en e ́crivant
pn −1
i=∑0
Xtn
i+1 (Xtn
i+1 − Xtin ) =
pn −1
i=∑0
Xtin (Xtn
i+1 − Xtin ) +
pn −1
i=∑0
(Xtn
i+1 − Xtin )2,
et en utilisant la Proposition 4.6, on a


5.2 La formule d’Itoˆ 91
nli→m∞
pn −1
i=∑0
Xtn
i+1 (Xtn
i+1 − Xtin ) =
∫t
0
Xs dXs + 〈X , X 〉t ,
en probabilite ́. La limite obtenue est diff ́erente de ∫ t
0 XsdXs sauf si la partie martingale de X est de ́ge ́ne ́re ́e. Si on fait la somme des deux convergences pre ́ce ́dentes, on aboutit a` la formule
(Xt )2 − (X0)2 = 2
∫t
0
XsdXs + 〈X , X 〉t
qui est un cas particulier de la formule d’Itoˆ du paragraphe suivant.
5.2 La formule d’Itˆo
La formule d’Itoˆ est l’outil de base du calcul stochastique. Elle montre qu’une fonction de classe C2 de p semimartingales continues est encore une semimartingale continue, et exprime explicitement la de ́composition de cette semimartingale.
The ́ore`me 5.3 (Formule d’Itoˆ). Soient X1, . . . , X p p semimartingales continues, et soit F une fonction de classe C2 de Rp dans R. Alors,
F(X 1
t ,...,Xp
t ) = F(X 1
0,...,Xp
0 )+
p
i=∑1
∫t
0
∂F
∂ xi (X 1
s ,...,Xp
s ) dX i
s
+1
2
p
i, j∑=1
∫t
0
∂ 2F
∂ xi∂ x j (X 1
s ,...,Xp
s ) d〈X i, X j〉
s.
De ́monstration. On traite d’abord le cas p = 1 et on note X = X1. Conside ́rons une suite 0 = tn
0 < · · · < tpnn = t de subdivisions emboˆıte ́es de [0,t] de pas tendant vers 0. Alors, pour tout n,
F(Xt ) = F(X0) +
pn −1
i=∑0
(F (Xt n
i+1 ) − F (Xtin )),
et d’apre`s la formule de Taylor, on a, pour tout i ∈ {0, 1, . . . , pn − 1},
F (Xt n
i+1 ) − F (Xtin ) = F ′(Xtin )(Xtn
i+1 − Xtin ) + fn,i(ω )
2 (Xtn
i+1 − Xtin )2,
ou`
inf
θ ∈[0,1]
F′′(Xtin + θ (Xtn
i+1 − Xtin )) ≤ fn,i ≤ sup
θ ∈[0,1]
F ′′(Xtin + θ (Xtn
i+1 − Xtin )).
D’apre`s la Proposition 5.5 avec Hs = F′(Xs), on a


92 5 Inte ́grale stochastique
nli→m∞
pn −1
i=∑0
F ′(Xtin )(Xtn
i+1 − Xtin ) =
∫t
0
F′(Xs) dXs,
en probabilite ́. Pour comple ́ter la preuve, il suffit donc de montrer que
nli→m∞
pn −1
i=∑0
fn,i(Xtn
i+1 − Xtin )2 =
∫t
0
F′′(Xs) d〈X, X〉
s, (5.13)
en probabilite ́. Commen ̧cons par observer que pour m < n,
∣ ∣ ∣ ∣ ∣ ∣
pn −1
i=∑0
fn,i(Xtn
i+1 − Xtin )2 −
pm −1
j= ∑0
fm, j ∑
{i:t jm≤tin<tm
j+1 }
(Xtn
i+1 − Xtin )2
∣ ∣ ∣ ∣ ∣ ∣
≤ Zm,n
( pn −1
i=∑0
(Xtn
i+1 − Xtin )2
)
,
avec
Zm,n = sup
0≤ j≤pm−1

 sup
{i:t jm≤tin<tm
j+1 }
| fn,i − fm, j|

.
Graˆce `a la continuite ́ de F′′, on ve ́rifie facilement que Zm,n −→ 0 p.s. quand m, n → ∞ avec m < n. Il de ́coule alors de la Proposition 4.6 que, pour ε > 0 donne ́, on peut choisir m1 assez grand de fa ̧con que, pour tout m ≥ m1 et tout n > m,
P
[
Zm,n
( pn −1
i=∑0
(Xtn
i+1 − Xtin )2
)
≥ε
]
≤ ε,
et donc
P
[∣ ∣ ∣
pn −1
i=∑0
fn,i(Xtn
i+1 − Xtin )2 −
pm −1
j= ∑0
fm, j ∑
{i:t jm≤tin<tm
j+1 }
(Xtn
i+1 − Xtin )2
∣ ∣
∣≥ε
]
≤ ε. (5.14)
Par ailleurs, pour tout m fixe ́, la Proposition 4.6 montre aussi que
nli→m∞
pm −1
j= ∑0
fm, j ∑
{i:t jm≤tin<tm
j+1 }
(Xtn
i+1 − Xtin )2 =
pm −1
j= ∑0
fm, j
(
〈X, X〉
tm
j+1
−
〈X, X〉
t jm
)
=
∫t
0
hm(s) d〈X, X〉
s, (5.15)
ou` hm(s) = fm, j si tm
j ≤ s < tm
j+1, et la convergence a lieu en probabilite ́. Il est clair
que hm(s) −→ F′′(Xs) uniforme ́ment sur [0,t] quand m → ∞, p.s.. Donc, on peut aussi choisir un entier m2 tel que, pour tout m ≥ m2,


5.2 La formule d’Itoˆ 93
P
[∣ ∣ ∣
∫t
0
hm(s) d〈X, X〉
s−
∫t
0
F′′(Xs) d〈X , X 〉
s
∣ ∣
∣≥ε
]
≤ ε. (5.16)
Prenons maintenant m0 = m1 ∨ m2 et observons que, graˆce a` (5.15) on a pour tout entier n ≥ m0 assez grand,
P
[∣ ∣ ∣
pm0 −1
j= ∑0
fm0, j ∑
{i:t jm0 ≤tin<t jm+01}
(Xtn
i+1 − Xtin )2 −
∫t
0
hm0 (s) d〈X, X〉
s
∣ ∣
∣≥ε
]
≤ ε.
En combinant cette derni`ere estimation avec (5.14) et (5.16) on trouve, pour tout n assez grand,
P
[∣ ∣ ∣
pn −1
i=∑0
fn,i(Xtn
i+1 − Xtin )2 −
∫t
0
F′′(Xs) d〈X , X 〉
s
∣ ∣
∣ ≥ 3ε
]
≤ 3ε,
ce qui termine la preuve de (5.13), et de la formule d’Itoˆ dans le cas p = 1. Dans le cas ou` p est quelconque, la formule de Taylor, applique ́e pour tout i ∈ {0, 1, . . . , pn − 1} a` la fonction
[0, 1] 3 θ 7→ F(X1
tin + θ (X 1
tn
i+1 − X 1
tin ), . . . , X p
tin + θ (X p
tn
i+1
−Xp
tin )) ,
donne
F(X 1
tn
i+1 , . . . , X p
tn
i+1
) − F(X1
tin , . . . , X p
tin ) =
p
∑
k=1
∂F
∂ xk (X 1
tin , . . . , X p
tin ) (X k
tn
i+1 − X k
tin )
+
p
∑
k,l=1
f k,l
n,i
2 (X k
tn
i+1 − X k
tin )(X l
tn
i+1 − X l
tin )
avec, pour tous k, l ∈ {1, . . . , p}, en notant Xt = (Xt1, . . . , X p
t ),
inf
θ ∈[0,1]
∂ 2F
∂ xk∂ xl
(Xtin + θ (Xtn
i+1 − Xtin )) ≤ f k,l
n,i ≤ sup
θ ∈[0,1]
∂ 2F
∂ xk∂ xl
(Xtin + θ (Xtn
i+1 − Xtin ))
La Proposition 5.5 donne a` nouveau le re ́sultat recherche ́ pour les termes faisant intervenir les de ́rive ́es premie`res. De plus une le ́ge`re modification des arguments ci-dessus montre que, pour tous k, l ∈ {1, . . . , p},
nli→m∞
pn −1
i=∑0
f k,l
n,i (X k
tn
i+1 − X k
tin )(X l
tn
i+1 − X l
tin ) =
∫t
0
∂ 2F
∂ xk∂ xl
(X 1
s ,...,Xp
s )d〈X k, X l〉
s,
ce qui termine la preuve du the ́ore`me. tu Un cas particulier important de la formule d’Itoˆ est la formule d’int ́egration par parties, obtenue en prenant p = 2 et F(x, y) = xy : si X et Y sont deux semimartingales continues, on a


94 5 Inte ́grale stochastique
XtYt = X0Y0 +
∫t
0
Xs dYs +
∫t
0
Ys dXs + 〈X,Y 〉
t.
En particulier, si Y = X,
X2
t = X2
0 +2
∫t
0
Xs dXs + 〈X, X〉
t.
Lorsque X = M est une martingale locale, on sait que M2 − 〈M, M〉 est une martingale locale. La formule pre ́ce ́dente montre que cette martingale locale est
M2
0 +2
∫t
0
Ms dMs,
ce qu’on aurait pu voir directement sur la de ́monstration faite dans le Chapitre 4 (notre construction de 〈M, M〉 faisait intervenir des approximations de l’inte ́grale stochastique ∫ t
0 MsdMs).
Soit B un (Ft )-mouvement brownien re ́el (rappelons que cela signifie que B est un mouvement brownien adapte ́ a` (Ft ) et que, pour tous 0 ≤ s < t, la variable Bt −Bs est inde ́pendante de la tribu Fs). Un (Ft )-mouvement brownien est une martingale, et on a de ́ja` remarque ́ que sa variation quadratique est 〈B, B〉
t = t.
Pour un (Ft )-mouvement brownien B, la formule d’Itoˆ s’e ́crit
F(Bt ) = F(B0) +
∫t
0
F′(Bs) dBs + 1
2
∫t
0
F ′′ (Bs )ds.
En prenant Xt1 = t, Xt2 = Bt , on a aussi pour toute fonction F de classe C2 sur R+ × R,
F(t, Bt ) = F(0, B0) +
∫t
0
∂F
∂ x (s, Bs) dBs +
∫t
0
(∂F
∂t + 1
2
∂ 2F
∂ x2 )(s, Bs) ds.
On peut aussi de ́finir la notion de (Ft )-mouvement brownien en dimension d : un processus Bt = (Bt1, . . . , Btd) est un (Ft )-mouvement brownien en dimension d si B est un mouvement brownien en dimension d (voir la fin du chapitre 2), qui est adapt ́e a` (Ft ) et tel que, pour tous 0 ≤ s < t, la variable Bt − Bs est inde ́pendante de la tribu Fs. Cela entraˆıne en particulier que les composantes B1, . . . , Bd sont des (Ft )-mouvements browniens re ́els (pas force ́ment inde ́pendants car il peut exister une de ́pendance a` cause de la valeur initiale). Il est facile d’adapter la preuve du The ́ore`me 2.3 pour montrer que si T est un temps d’arreˆt de la filtration (Ft )t≥0 qui
est fini p.s., alors le processus (B(T)
t = BT+t − BT ,t ≥ 0) est aussi un mouvement brownien en dimension d et est inde ́pendant de FT . Si Bt = (Bt1, . . . , Btd) est un (Ft )-mouvement brownien en dimension d, il de ́coule
d’une remarque suivant le De ́finition 4.4 que 〈Bi, B j〉 = 0 lorsque i 6= j (remarquer qu’on se rame`ne au cas ou` B1, . . . , Bd sont inde ́pendants en retranchant la valeur initiale, ce qui ne change pas la valeur de 〈Bi, B j〉). La formule d’Itoˆ montre alors que, pour toute fonction F de classe C2 sur Rd,


5.2 La formule d’Itoˆ 95
F (B1
t , . . . , Bd
t)
= F(B1
0, . . . , Bd
0)+
p
i=∑1
∫t
0
∂F
∂ xi
(B1
s , . . . , Bd
s ) dBi
s+ 1
2
∫t
0
∆ F(B1
s , . . . , Bd
s ) ds,
et on a une formule analogue pour F(t, Bt1, . . . , Btd).
Remarque importante. Il arrive fre ́quemment que l’on ait besoin d’appliquer la formule d’Itˆo du The ́ore`me 5.3 a` une fonction F qui est de ́finie et de classe C2 seulement sur un ouvert U de Rp. Dans ce cas on peut raisonner de la manie`re suivante. Supposons donne ́ un autre ouvert V , tel que V ̄ ⊂ U (typiquement V sera l’ensemble des points a` distance strictement supe ́rieure a` ε de Uc) et (X1
0,...,Xp
0 ) ∈ V p.s.
Notons TV := inf{t ≥ 0 : (Xt1, . . . , X p
t ) ∈/ V }. Des arguments simples d’analyse per
mettent de trouver une fonction G de classe C2 sur Rp tout entier et qui co ̈ıncide avec F sur V ̄ . On peut maintenant appliquer la formule d’Itoˆ pour exprimer la
de ́composition de la semimartingale G(Xt1∧TV , . . . , X p
t∧TV ) = F(Xt1∧TV , . . . , X p
t∧TV ), qui
ne fait intervenir que les de ́rive ́es de F sur V . Si l’on sait de plus que p.s. le processus
(Xt1, . . . , X p
t ) ne quitte pas U, on peut faire croˆıtre l’ouvert V vers U, et obtenir que
la formule d’Itoˆ pour F(Xt1, . . . , X p
t ) s’e ́crit exactement comme dans le The ́ore`me 5.3. Ces conside ́rations s’appliquent par exemple a` la fonction F(x) = log x et a` une semimartingale X a` valeurs strictement positives : voir la preuve de la Proposition 5.8 ci-dessous.
Nous utilisons maintenant la formule d’Itoˆ pour de ́gager une classe importante de martingales, qui ge ́ne ́ralise les martingales exponentielles rencontr ́ees pour les processus a` accroissements inde ́pendants. On dit qu’un processus a` valeurs dans C est une martingale locale si sa partie re ́elle et sa partie imaginaire sont des martingales locales.
Proposition 5.6. Soit M une martingale locale et pour tout λ ∈ C, soit
E (λ M)t = exp
(
λ Mt − λ 2
2
〈M, M〉
t
)
.
Le processus E (λ M) est une martingale locale, qui s’exprime sous la forme
E (λ M)t = eλ M0 + λ
∫t
0
E (λ M)s dMs.
Remarque. L’inte ́grale stochastique dans la derni`ere formule est (e ́videmment) de ́finie en se ́parant partie re ́elle et partie imaginaire.
De ́monstration. Si F(x, r) est une fonction de classe C2 sur R × R+, la formule d’Itˆo entraˆıne que
F(Mt , 〈M, M〉
t ) = F(M0, 0) +
∫t
0
∂F
∂ x (Ms, 〈M, M〉
s) dMs
+
∫t
0
(∂F
∂r + 1
2
∂ 2F ∂ x2
)
(Ms, 〈M, M〉
s) d〈M, M〉
s.