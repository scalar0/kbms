National Aeronautics and Space Administration
NASA
SYSTEMS ENGINEERING
HANDBOOK
design
test
integrate
fly
www.nasa.gov


NASA SP-2016-6105 Rev2 supersedes SP-2007-6105 Rev 1 dated December, 2007.
Cover photos: Top left: In this photo, engineers led by researcher Greg Gatlin have sprayed fluorescent oil on a 5.8 percent scale
model of a futuristic hybrid wing body during tests in the 14- by 22-Foot Subsonic Wind Tunnel at NASA’s Langley Research Center
in Hampton, VA. The oil helps researchers “see” the flow patterns when air passes over and around the model. (NASA Langley/
Preston Martin) Top right: Water impact test of a test version of the Orion spacecraft took place on August 24, 2016, at NASA
Langley Research Center (NASA) Bottom left: two test mirror segments are placed onto the support structure that will hold them.
(NASA/Chris Gunn) Bottom right: This self-portrait of NASA’s Curiosity Mars rover shows the vehicle at the “Mojave” site, where its
drill collected the mission’s second taste of Mount Sharp. (NASA/JPL-Caltech/MSSS)
Comments, questions, and suggestions regarding this document can be sent to:
Steven R. Hirshorn
Chief Engineer, Aeronautics Research Mission Directorate (ARMD)
Office of the Chief Engineer
NASA Headquarters, Room 6D37
300 E St SW
Washington, DC 20546-0001
202-358-0775
steven.r.hirshorn@nasa.gov


NASA SYSTEMS ENGINEERING HANDBOOK iii
Table of Contents
Preface viii
Acknowledgments ix
1.0 Introduction 1
1.1 Purpose 1
1.2 Scope and Depth 1
2.0 Fundamentals of Systems Engineering 3
2.1 The Common Technical Processes and the SE Engine 5
2.2 An Overview of the SE Engine by Project Phase 8
2.3 Example of Using the SE Engine 10
2.4 Distinctions between Product Verification and Product Validation 11
2.5 Cost Effectiveness Considerations 11
2.6 Human Systems Integration (HSI) in the SE Process 12
2.7 Competency Model for Systems Engineers 13
3.0 NASA Program/Project Life Cycle 17
3.1 Program Formulation 20
3.2 Program Implementation 20
3.3 Project Pre-Phase A: Concept Studies 21
3.4 Project Phase A: Concept and Technology Development 23
3.5 Project Phase B: Preliminary Design and Technology Completion 25
3.6 Project Phase C: Final Design and Fabrication 27
3.7 Project Phase D: System Assembly, Integration and Test, Launch 29
3.8 Project Phase E: Operations and Sustainment 31
3.9 Project Phase F: Closeout 31
3.10 Funding: The Budget Cycle 33
3.11 Tailoring and Customization of NPR 7123 1 Requirements 34
3.11.1 Introduction 34
3.11.2 Criteria for Tailoring 34
3.11.3 Tailoring SE NPR Requirements Using the Compliance Matrix 35
3.11.4 Ways to Tailor a SE Requirement 36
3.11.5 Examples of Tailoring and Customization 37
3.11.6 Approvals for Tailoring 40
4.0 System Design Processes 43
4.1 Stakeholder Expectations Definition 45
4.1.1 Process Description 45
4.1.2 Stakeholder Expectations Definition Guidance 53
4.2 Technical Requirements Definition 54
4.2.1 Process Description 54
4.2.2 Technical Requirements Definition Guidance 62
4.3 Logical Decomposition 62
4.3.1 Process Description 62
4.3.2 Logical Decomposition Guidance 65
4.4 Design Solution Definition 65
4.4.1 Process Description 66
4.4.2 Design Solution Definition Guidance 76
5.0 Product Realization 77
5.1 Product Implementation 78
5.1.1 Process Description 79
5.1.2 Product Implementation Guidance 83
5.2 Product Integration 83
5.2.1 Process Description 85
5.2.2 Product Integration Guidance 88
5.3 Product Verification 88


NASA SYSTEMS ENGINEERING HANDBOOK iv
Table of Contents
5.3.1 Process Description 89
5.3.2 Product Verification Guidance 99
5.4 Product Validation 99
5.4.1 Process Description 99
5.4.2 Product Validation Guidance 106
5.5 Product Transition 106
5.5.1 Process Description 106
5.5.2 Product Transition Guidance 112
6.0 Crosscutting Technical Management 113
6.1 Technical Planning 113
6.1.1 Process Description 114
6.1.2 Technical Planning Guidance 130
6.2 Requirements Management 130
6.2.1 Process Description 131
6.2.2 Requirements Management Guidance 135
6.3 Interface Management 135
6.3.1 Process Description 136
6.3.2 Interface Management Guidance 138
6.4 Technical Risk Management 138
6.4.1 Risk Management Process Description 141
6.4.2 Risk Management Process Guidance 143
6.5 Configuration Management 143
6.5.1 Process Description 144
6.5.2 CM Guidance 150
6.6 Technical Data Management 151
6.6.1 Process Description 151
6.6.2 Technical Data Management Guidance 155
6.7 Technical Assessment 155
6.7.1 Process Description 157
6.7.2 Technical Assessment Guidance 160
6.8 Decision Analysis 160
6.8.1 Process Description 164
6.8.2 Decision Analysis Guidance 170
Appendix A Acronyms 173
Appendix B Glossary 176
Appendix C How to Write a Good RequirementChecklist 197
Appendix D Requirements Verification Matrix 201
Appendix E Creating the Validation Plan with a Validation Requirements Matrix 203
Appendix F Functional, Timing, and State Analysis 205
Appendix G Technology Assessment/Insertion 206
Appendix H Integration Plan Outline 214
Appendix I Verification and Validation Plan Outline 216
Appendix J SEMP Content Outline 223
Appendix K Technical Plans 235
Appendix L Interface Requirements Document Outline 236
Appendix M CM Plan Outline 239
Appendix N Guidance on Technical Peer Reviews/Inspections 240
Appendix O Reserved 241
Appendix P SOW Review Checklist 242
Appendix Q Reserved 243
Appendix R HSI Plan Content Outline 244
Appendix S Concept of Operations Annotated Outline 251
Appendix T Systems Engineering in Phase E 254
References Cited 260
Bibliography 270


NASA SYSTEMS ENGINEERING HANDBOOK v
Table of Figures
Figure 2.0-1 SE in Context of Overall Project Management 5
Figure 2.1-1 The Systems Engineering Engine (NPR 7123 1) 6
Figure 2.2-1 Miniature Version of the Poster-Size NASA Project Life Cycle Process Flow for Flight and Ground Systems Accompanying this Handbook 8
Figure 2.5-1 Life-Cycle Cost Impacts from Early Phase Decision-Making 13
Figure 3.0-1 NASA Space Flight Project Life Cycle from NPR 7120 5E 18
Figure 3.11-1 Notional Space Flight Products Tailoring Process 36
Figure 4.0-1 Interrelationships among the System Design Processes 44
Figure 4.1-1 Stakeholder Expectations Definition Process 46
Figure 4.1-2 Information Flow for Stakeholder Expectations 48
Figure 4.1-3 Example of a Lunar Sortie DRM Early in the Life Cycle 51
Figure 4.2-1 Technical Requirements Definition Process 55
Figure 4.2-2 Flow, Type and Ownership of Requirements 57
Figure 4.2-3 The Flowdown of Requirements 58
Figure 4.3-1 Logical Decomposition Process 63
Figure 4.4-1 Design Solution Definition Process 66
Figure 4.4-2 The Doctrine of Successive Refinement 67
Figure 4.4-3 A Quantitative Objective Function, Dependent on Life Cycle Cost and All Aspects of Effectiveness 71
Figure 5.0-1 Product Realization 78
Figure 5.1-1 Product Implementation Process 79
Figure 5.2-1 Product Integration Process 86
Figure 5.3-1 Product Verification Process 91
Figure 5.3-2 Example of End-to-End Data Flow for a Scientific Satellite Mission 96
Figure 5.4-1 Product Validation Process 100
Figure 5.5-1 Product Transition Process 107
Figure 6.1-1 Technical Planning Process 115
Figure 6.2-1 Requirements Management Process 131
Figure 6.3-1 Interface Management Process 136
Figure 6.4-1 Risk Scenario Development 139
Figure 6.4-2 Risk as an Aggregate Set of Risk Triplets 139
Figure 6.4-3 Risk Management Process 141
Figure 6.4-4 Risk Management as the Interaction of Risk-Informed Decision Making and Continuous Risk Management 142
Figure 6.5-1 Configuration Management Process 145
Figure 6.5-2 Five Elements of Configuration Management 145
Figure 6.5-3 Evolution of Technical Baseline 147
Figure 6.5-4 Typical Change Control Process 148
Figure 6.6-1 Technical Data Management Process 151
Figure 6.7-1 Technical Assessment Process 158
Figure 6.7-2 Planning and Status Reporting Feedback Loop 159
Figure 6.8-1 Decision Analysis Process 165
Figure 6.8-2 Risk Analysis of Decision Alternatives 166
Figure G.1-1 PBS Example 208
Figure G.3-1 Technology Assessment Process 209
Figure G.3-2 Architectural Studies and Technology Development 210
Figure G.4-1 Technology Readiness Levels 211
Figure G.4-2 TMA Thought Process 212
Figure G.4-3 TRL Assessment Matrix 213


NASA SYSTEMS ENGINEERING HANDBOOK vi
Table of Tables
Table 2.1-1 Alignment of the 17 SE Processes to AS9100 7
Table 2.2-1 Project Life Cycle Phases 9
Table 2.7-1 NASA System Engineering Competency Model 14
Table 3.0-1 SE Product Maturity from NPR 7123 1 19
Table 3.11-1 Example of Program/Project Types 38
Table 3.11-2 Example of Tailoring NPR 7120 5 Required Project Products 39
Table 3.11-3 Example Use of a Compliance Matrix 41
Table 4.1-1 Stakeholder Identification throughout the Life Cycle 47
Table 4.2-1 Benefits of Well-Written Requirements 59
Table 4.2-2 Requirements Metadata 59
Table 5.3-1 Example information in Verification Procedures and Reports 94
Table 6.1-1 Example Engineering Team Disciplines in Pre-Phase A for Robotic Infrared Observatory 118
Table 6.1-2 Examples of Types of Facilities to Consider during Planning 120
Table 6.6-1 Technical Data Tasks 156
Table 6.7-1 Purpose and Results for Life-Cycle Reviews for Spaceflight Projects 161
Table 6.8-1 Typical Information to Capture in a Decision Report 171
Table D-1 Requirements Verification Matrix 202
Table E-1 Validation Requirements Matrix 204
Table G.1-1 Products Provided by the TA as a Function of Program/Project Phase 207
Table J-1 Guidance on SEMP Content per Life-Cycle Phase 233
Table K-1 Example of Expected Maturity of Key Technical Plans 235
Table R.2-1 HSI Activity, Product, or Risk Mitigation by Program/Project Phase 250


NASA SYSTEMS ENGINEERING HANDBOOK vii
Table of Boxes
The Systems Engineer’s Dilemma 12
Space Flight Program Formulation 20
Space Flight Program Implementation 21
Space Flight Pre-Phase A: Concept Studies 22
Space Flight Phase A: Concept and Technology Development 24
Space Flight Phase B: Preliminary Design and Technology Completion 26
Space Flight Phase C: Final Design and Fabrication 28
Space Flight Phase D: System Assembly, Integration and Test, Launch 30
Space Flight Phase E: Operations and Sustainment 32
Phase F: Closeout 33
System Design Keys 44
Concept of Operations vs Operations Concept 51
Example of Functional and Performance Requirements 56
Rationale 60
Product Realization Keys 78
Differences between Verification and Validation Testing 89
Differences between Verification, Qualification, Acceptance and Certification 90
Methods of Verification 93
Methods of Validation 101
Crosscutting Technical Management Keys 114
Types of Hardware 124
Environments 127
Definitions 130
Types of Configuration Management Changes 149
Data Collection Checklist 155
HSI Relevance 246
HSI Strategy 246
HSI Domains 247
HSI Requirements 247
HSI Implementation 249
HSI Plan Updates 250


NASA SYSTEMS ENGINEERING HANDBOOK viii
Preface
S
ince the initial writing of NASA/SP-6105 in 1995 and the following revision (Rev 1) in 2007, systems engineering as a discipline at the National Aeronautics and Space Administration (NASA) has undergone rapid and continued evolution. Changes include using Model-Based Systems Engineering to improve development and delivery of products, and accommodating updates to NASA Procedural Requirements (NPR) 7123.1. Lessons learned on systems engineering were documented in reports such as those by the NASA Integrated Action Team (NIAT), the Columbia Accident Investigation Board (CAIB), and the follow-on Diaz Report. Other lessons learned were garnered from the robotic missions such as Genesis and the Mars Reconnaissance Orbiter as well as from mishaps from ground operations and the commercial space flight industry. Out of these reports came the NASA Office of the Chief Engineer (OCE) initiative to improve the overall Agency systems engineering infrastructure and capability for the efficient and effective engineering of NASA systems, to produce quality products, and to achieve mission success. This handbook update is a part of that OCE-sponsored Agency-wide systems engineering initiative.
In 1995, SP-6105 was initially published to bring the fundamental concepts and techniques of systems engineering to NASA personnel in a way that recognized the nature of NASA systems and the NASA environment. This revision (Rev 2) of SP-6105 maintains that original philosophy while updating the Agency’s systems engineering body of knowledge, providing guidance for insight into current best Agency practices, and maintaining the alignment of the handbook with the Agency’s systems engineering policy.
The update of this handbook continues the methodology of the previous revision: a top-down compatibility with higher level Agency policy and a bottom-up infusion of guidance from the NASA practitioners in the field. This approach provides the opportunity to obtain best practices from across NASA and bridge the information to the established NASA systems engineering processes and to communicate principles of good practice as well as alternative approaches rather than specify a particular way to accomplish a task. The result embodied in this handbook is a top-level implementation approach on the practice of systems engineering unique to NASA. Material used for updating this handbook has been drawn from many sources, including NPRs, Center systems engineering handbooks and processes, other Agency best practices, and external systems engineering textbooks and guides.
This handbook consists of six chapters: (1) an introduction, (2) a systems engineering fundamentals discussion, (3) the NASA program/project life cycles, (4) systems engineering processes to get from a concept to a design, (5) systems engineering processes to get from a design to a final product, and (6) crosscutting management processes in systems engineering. The chapters are supplemented by appendices that provide outlines, examples, and further information to illustrate topics in the chapters. The handbook makes extensive use of boxes and figures to define, refine, illustrate, and extend concepts in the chapters.
Finally, it should be noted that this handbook provides top-level guidance for good systems engineering practices; it is not intended in any way to be a directive.
NASA/SP-2016-6105 Rev2 supersedes SP-2007-6105 Rev 1
dated December, 2007.


NASA SYSTEMS ENGINEERING HANDBOOK ix
Acknowledgments
The following individuals are recognized as contributing practitioners to the content of this expanded guidance:
Alexander, Michael, NASA/Langley Research Center
Allen, Martha, NASA/Marshall Space Flight Center
Baumann, Ethan, NASA/Armstrong Flight Research Center
Bixby, CJ, NASA/Armstrong Flight Research Center
Boland, Brian, NASA/Langley Research Center
Brady, Timothy, NASA/NASA Engineering and Safety Center
Bromley, Linda, NASA/Headquarters/Bromley SE Consulting
Brown, Mark, NASA/Jet Propulsion Laboratory
Brumfield, Mark, NASA/Goddard Space Flight Center
Campbell, Paul, NASA/Johnson Space Center
Carek, David, NASA/Glenn Research Center
Cox, Renee, NASA/Marshall Space Flight Center
Crable, Vicki, NASA/Glenn Research Center
Crocker, Alan, NASA/Ames Research Center
DeLoof, Richard, NASA/Glenn Research Center
Demo, Andrew/Ames Research Center
Dezfuli, Homayoon, NASA/HQ
Diehl, Roger, NASA/Jet Propulsion Laboratory
DiPietro, David, NASA/Goddard Space Flight Center
Doehne, Thomas, NASA/Glenn Research Center
Duarte, Alberto, NASA/Marshall Space Flight Center
Durham, David, NASA/Jet Propulsion Laboratory
Epps, Amy, NASA/Marshall Space Flight Center
Fashimpaur, Karen, Vantage Partners
Feikema, Douglas, NASA/Glenn Research Center
Fitts, David, NASA/Johnson Space Flight Center
Foster, Michele, NASA/Marshall Space Flight Center
Fuller, David, NASA/Glenn Research Center
Gati, Frank, NASA/Glenn Research Center
Gefert, Leon, NASA/Glenn Research Center
Ghassemieh, Shakib, NASA/Ames Research Center
Grantier, Julie, NASA/Glenn Research Center
Hack, Kurt, NASA/Glenn Research Center
Hall, Kelly, NASA/Glenn Research Center
Hamaker, Franci, NASA/Kennedy Space Center
Hange, Craig, NASA/Ames Research Center
Henry, Thad, NASA/Marshall Space Flight Center
Hill, Nancy, NASA/Marshall Space Flight Center
Hirshorn, Steven, NASA/Headquarters
Holladay, Jon, NASA/NASA Engineering and Safety Center
Hyatt, Mark, NASA/Glenn Research Center
Killebrew, Jana, NASA/Ames Research Center
Jannette, Tony, NASA/Glenn Research Center
Jenks, Kenneth, NASA/Johnson Space Center
Jones, Melissa, NASA/Jet Propulsion Laboratory
Jones, Ross, NASA/Jet Propulsion Laboratory
Killebrew, Jana, NASA/Ames Research Center
Leitner, Jesse, NASA/Goddard Space Flight Center
Lin, Chi, NASA/Jet Propulsion Laboratory
Mascia, Anne Marie, Graphic Artist
McKay, Terri, NASA/Marshall Space Flight Center
McNelis, Nancy, NASA/Glenn Research Center
Mendoza, Donald, NASA/Ames Research Center
Miller, Scott, NASA/Ames Research Center
Montgomery, Patty, NASA/Marshall Space Flight Center
Mosier, Gary, NASA/Goddard Space Flight Center
Noble, Lee, NASA/Langley Research Center
Oleson, Steven, NASA/Glenn Research Center
Parrott, Edith, NASA/Glenn Research Center
Powell, Christine, NASA/Stennis Space Center
Powell, Joseph, NASA/Glenn Research Center
Price, James, NASA/Langley Research Center
Rawlin, Adam, NASA/Johnson Space Center
Rochlis-Zumbado, Jennifer, NASA/Johnson Space Center
Rohn, Dennis, NASA/Glenn Research Center
Rosenbaum, Nancy, NASA/Goddard Space Flight Center


NASA SYSTEMS ENGINEERING HANDBOOK x
Acknowledgments
Ryan, Victoria, NASA/Jet Propulsion Laboratory
Sadler, Gerald, NASA/Glenn Research Center
Salazar, George, NASA/Johnson Space Center
Sanchez, Hugo, NASA/Ames Research Center
Schuyler, Joseph, NASA/Stennis Space Center
Sheehe, Charles, NASA/Glenn Research Center
Shepherd, Christena, NASA/Marshall Space Flight Center
Shull, Thomas, NASA/Langley Research Center
Singer, Bart, NASA/Langley Research Center
Slywczak, Richard, NASA/Glenn Research Center
Smith, Scott, NASA/Goddard Space Flight Center
Smith, Joseph, NASA/Headquarters
Sprague, George, NASA/Jet Propulsion Laboratory
Trase, Kathryn, NASA/Glenn Research Center
Trenkle, Timothy, NASA/Goddard Space Flight Center
Vipavetz, Kevin, NASA/Langley Research Center
Voss, Linda, Dell Services
Walters, James Britton, NASA/Johnson Space Center
Watson, Michael, NASA/Marshall Space Flight Center
Weiland, Karen, NASA/Glenn Research Center
Wiedeman, Grace, Dell Services
Wiedenmannott, Ulrich, NASA/Glenn Research Center
Witt, Elton, NASA/Johnson Space Center
Woytach, Jeffrey, NASA/Glenn Research Center
Wright, Michael, NASA/Marshall Space Flight Center
Yu, Henry, NASA/Kennedy Space Center


NASA SYSTEMS ENGINEERING HANDBOOK 1
1.0 Introduction
1.1 Purpose
T
his handbook is intended to provide general guidance and information on systems engineering that will be useful to the NASA community. It provides a generic description of Systems Engineering (SE) as it should be applied throughout NASA. A goal of the handbook is to increase awareness and consistency across the Agency and advance the practice of SE. This handbook provides perspectives relevant to NASA and data particular to NASA.
This handbook should be used as a companion for implementing NPR 7123.1, Systems Engineering Processes and Requirements, as well as the Centerspecific handbooks and directives developed for implementing systems engineering at NASA. It provides a companion reference book for the various systems engineering-related training being offered under NASA’s auspices.
1.2 Scope and Depth
This handbook describes systems engineering best practices that should be incorporated in the development and implementation of large and small NASA programs and projects. The engineering of NASA
systems requires a systematic and disciplined set of processes that are applied recursively and iteratively for the design, development, operation, maintenance, and closeout of systems throughout the life cycle of the programs and projects. The scope of this handbook includes systems engineering functions regardless of whether they are performed by a manager or an engineer, in-house or by a contractor.
There are many Center-specific handbooks and directives as well as textbooks that can be consulted for in-depth tutorials. For guidance on systems engineering for information technology projects, refer to Office of Chief Information Officer Information Technology Systems Engineering Handbook Version 2.0. For guidance on entrance and exit criteria for milestone reviews of software projects, refer to NASAHDBK-2203, NASA Software Engineering Handbook. A NASA systems engineer can also participate in the NASA Engineering Network (NEN) Systems Engineering Community of Practice, located at
https://nen.nasa.gov/web/se. This Web site includes
many resources useful to systems engineers, including document templates for many of the work products and milestone review presentations required by the NASA SE process.


2
1.0 Introduction
NASA SYSTEMS ENGINEERING HANDBOOK
This handbook is applicable to NASA space flight projects of all sizes and to research and development programs and projects. While all 17 processes are applicable to all projects, the amount of formality, depth of documentation, and timescales are varied as appropriate for the type, size, and complexity of the project. References to “documents” are intended to include not only paper or digital files but also models,
graphics, drawings, or other appropriate forms that capture the intended information.
For a more in-depth discussion of the principles provided in this handbook, refer to the NASA Expanded Guidance for SE document which can be found at
https://nen.nasa.gov/web/se/doc-repository. This hand
book is an abridged version of that reference.


NASA SYSTEMS ENGINEERING HANDBOOK 3
2.0 Fundamentals of
Systems Engineering
A
t NASA, “systems engineering” is defined as a methodical, multi-disciplinary approach for the design, realization, technical management, operations, and retirement of a system. A “system” is the combination of elements that function together to produce the capability required to meet a need. The elements include all hardware, software, equipment, facilities, personnel, processes, and procedures needed for this purpose; that is, all things required to produce system-level results. The results include system-level qualities, properties, characteristics, functions, behavior, and performance. The value added by the system as a whole, beyond that contributed independently by the parts, is primarily created by the relationship among the parts; that is, how they are interconnected.1 It is a way of looking at the “big picture” when making technical decisions. It is a way of achieving stakeholder functional, physical, and operational performance requirements in the intended use environment over the planned life of the system within cost, schedule, and other constraints. It is a methodology that supports the containment of the life cycle cost of a system. In other words, systems engineering is a logical way of thinking.
1 Eberhardt Rechtin, Systems Architecting of Organizations: Why Eagles Can’t Swim.
Systems engineering is the art and science of developing an operable system capable of meeting requirements within often opposed constraints. Systems engineering is a holistic, integrative discipline, wherein the contributions of structural engineers, electrical engineers, mechanism designers, power engineers, human factors engineers, and many more disciplines are evaluated and balanced, one against another, to produce a coherent whole that is not dominated by the perspective of a single discipline.2
Systems engineering seeks a safe and balanced design in the face of opposing interests and multiple, sometimes conflicting constraints. The systems engineer should develop the skill for identifying and focusing efforts on assessments to optimize the overall design and not favor one system/subsystem at the expense of another while constantly validating that the goals of the operational system will be met. The art is in knowing when and where to probe. Personnel with these skills are usually tagged as “systems engineers.” They may have other titles—lead systems engineer,
2 Comments on systems engineering throughout Chapter 2 0 are extracted from the speech “System Engineering and the Two Cultures of Engineering” by Michael D Griffin, NASA Administrator


4
2.0 Fundamentals of Systems Engineering
NASA SYSTEMS ENGINEERING HANDBOOK
technical manager, chief engineer—but for this document, the term “systems engineer” is used.
The exact role and responsibility of the systems engineer may change from project to project depending on the size and complexity of the project and from phase to phase of the life cycle. For large projects, there may be one or more systems engineers. For small projects, the project manager may sometimes perform these practices. But whoever assumes those responsibilities, the systems engineering functions should be performed. The actual assignment of the roles and responsibilities of the named systems engineer may also therefore vary. The lead systems engineer ensures that the system technically fulfills the defined needs and requirements and that a proper systems engineering approach is being followed. The systems engineer oversees the project’s systems engineering activities as performed by the technical team and directs, communicates, monitors, and coordinates tasks. The systems engineer reviews and evaluates the technical aspects of the project to ensure that the systems/subsystems engineering processes are functioning properly and evolves the system from concept to product. The entire technical team is involved in the systems engineering process.
The systems engineer usually plays the key role in leading the development of the concept of operations (ConOps) and resulting system architecture, defining boundaries, defining and allocating requirements, evaluating design tradeoffs, balancing technical risk between systems, defining and assessing interfaces, and providing oversight of verification and validation activities, as well as many other tasks. The systems engineer typically leads the technical planning effort and has the prime responsibility in documenting many of the technical plans, requirements and specification documents, verification and validation documents, certification packages, and other technical documentation.
In summary, the systems engineer is skilled in the art and science of balancing organizational, cost, and technical interactions in complex systems. The systems engineer and supporting organization are vital to supporting program and Project Planning and Control (PP&C) with accurate and timely cost and schedule information for the technical activities. Systems engineering is about tradeoffs and compromises; it uses a broad crosscutting view of the system rather than a single discipline view. Systems engineering is about looking at the “big picture” and not only ensuring that they get the design right (meet requirements) but that they also get the right design (enable operational goals and meet stakeholder expectations).
Systems engineering plays a key role in the project organization. Managing a project consists of three main objectives: managing the technical aspects of the project, managing the project team, and managing the cost and schedule. As shown in FIGURE 2.0-1, these three functions are interrelated. Systems engineering is focused on the technical characteristics of decisions including technical, cost, and schedule and on providing these to the project manager. The Project Planning and Control (PP&C) function is responsible for identifying and controlling the cost and schedules of the project. The project manager has overall responsibility for managing the project team and ensuring that the project delivers a technically correct system within cost and schedule. Note that there are areas where the two cornerstones of project management, SE and PP&C, overlap. In these areas, SE provides the technical aspects or inputs whereas PP&C provides the programmatic, cost, and schedule inputs.
This document focuses on the SE side of the diagram. The practices/processes are taken from NPR 7123.1, NASA Systems Engineering Processes and Requirements. Each process is described in much greater detail in subsequent chapters of this


5
2.0 Fundamentals of Systems Engineering
NASA SYSTEMS ENGINEERING HANDBOOK
document, but an overview is given in the following subsections of this chapter.
2.1 The Common Technical Processes and the SE Engine
There are three sets of common technical processes in NPR 7123.1, NASA Systems Engineering Processes and Requirements: system design, product realization, and technical management. The processes in each set and their interactions and flows are illustrated
by the NPR systems engineering “engine” shown in FIGURE 2.1-1. The processes of the SE engine are used to develop and realize the end products. This chapter provides the application context of the 17 common technical processes required in NPR7123.1. The system design processes, the product realization processes, and the technical management processes are discussed in more detail in Chapters 4.0, 5.0, and 6.0, respectively. Processes 1 through 9 indicated in FIGURE 2.1-1 represent the tasks in the execution of a project. Processes 10 through17 are crosscutting tools for carrying out the processes.
PROJECT MANAGEMENT
PROJECT MANAGEMENT ACTIVITIES
• Setting up Project Team • Programmatic Stakeholders (non-technical, non-business) • Programmatic Planning (non-technical, non-business) • Identifying Programmatic (non-technical) requirements
• Identifying Programmatic Risks • Technology Transfer and Commercialization • Integration of technical and non-technical activities • Overall Approver/Decider
Systems Engineering
System Design Processes
• Stakeholder Expectations Definition • Technical Requirement’s Definition • Logical Decomposition • Design Solution Definition Product Realization Processes • Product Implementation • Product Integration • Product Verification • Product Validation • Product Transition
Technical Management Processes • Technical Planning • Requirements Management • Interface Management • Technical Risk Management • Configuration Management • Technical Data Management • Technical Assessment • Decision Analyses
PP&C
• PP&C Integration • Resource Management • Scheduling • Cost Estimation & Assessment • Acquisition & Contract Management • Risk Management • CM/DM
Common Areas
• Stakeholders • Risks • Configuration Management • Data Management • Reviews • Schedule
FIGURE 2.0-1 SE in Context of Overall Project Management


6
2.0 Fundamentals of Systems Engineering
NASA SYSTEMS ENGINEERING HANDBOOK
Requirements Definition Processes
1. Stakeholders Expectations Definition 2. Technical Requirements Definition
3. Logical Decomposition 4. Design Solution Definition
System Design Processes
Requirements Flow Down from Level above
Technical Management Processes
10. Technical Planning
11. Requirement Management 12. Interface Management 13. Technical Risk Management 14. Configuration Management 15. Technical Data Management
16. Technical Assessment
Technical Decision Analysis Process
17. Decision Analysis
9. Product Transition
8. Product Validation 7. Product Verification
6. Product Integration 5. Product Implementation
Product Realization Processes
System Design Processes applied to each product layer down through system structure
Product Realization Processes applied to each product layer up through system structure
Requirements Flow Down To Level below
Realized Products to Level above
Realized Products From Level below
Cross cutting
Cross cutting
Technical Solution Definition Processes
Technical Planning Processes
Technical Control Processes
Product Transition Processes
Evaluation Processes
Design Realization Processes
Technical Assessment Processes
FIGURE 2.1-1 The Systems Engineering Engine (NPR 7123 1)
• System Design Processes: The four system
design processes shown in FIGURE 2.1-1 are used to define and baseline stakeholder expectations, generate and baseline technical requirements, decompose the requirements into logical and behavioral models, and convert the technical requirements into a design solution that will satisfy the baselined stakeholder expectations. These processes are applied to each product of the system structure from the top of the structure to the bottom until the lowest products in any system structure branch are defined to the point where they can be built, bought, or reused. All other products in the
system structure are realized by implementation or integration.
• Product Realization Processes: The product real
ization processes are applied to each operational/ mission product in the system structure starting from the lowest level product and working up to higher level integrated products. These processes are used to create the design solution for each product (through buying, coding, building, or reusing) and to verify, validate, and transition up to the next hierarchical level those products that satisfy their design solutions and meet stakeholder


7
2.0 Fundamentals of Systems Engineering
NASA SYSTEMS ENGINEERING HANDBOOK
expectations as a function of the applicable life cycle phase.
• Technical Management Processes: The techni
cal management processes are used to establish and evolve technical plans for the project, to manage communication across interfaces, to assess progress against the plans and requirements for the system products or services, to control technical execution of the project through to completion, and to aid in the decision-making process.
TABLE 2.1-1 Alignment of the 17 SE Processes to AS9100
SE Process AS9100 Requirement
Stakeholder Expectations Customer Requirements
Technical Requirements Definition
Planning of Product Realization
Logical Decomposition Design and Development Input
Design Solution Definition Design and Development Output
Product Implementation Control of Production
Product Integration Control of Production
Product Verification Verification
Product Validation Validation
Product Transition Control of Work Transfers; Post Delivery Support, Preservation of Product
Technical Planning Planning of Product Realization; Review of Requirements; Measurement, Analysis and Improvement
Requirements Management Design and Development Planning; Purchasing
Interface Management Configuration Management
Technical Risk Management Risk Management
Configuration Management Configuration Management; Identification and Traceability; Control of Nonconforming Product
Technical Data Management Control of Documents; Control of Records; Control of Design and Development Changes
Technical Assessment Design and Development Review
Decision Analysis Measurement, Analysis and Improvement; Analysis of Data
The processes within the SE engine are used both iteratively and recursively. As defined in NPR 7123.1, “iterative” is the “application of a process to the same
product or set of products to correct a discovered discrepancy or other variation from requirements,” whereas “recursive” is defined as adding value to the system “by the repeated application of processes to design next lower layer system products or to realize next upper layer end products within the system structure. This also applies to repeating application of the same processes to the system structure in the next life cycle phase to mature the system definition and satisfy phase success criteria.” The technical processes are applied recursively and iteratively to break down the initializing concepts of the system to a level of detail concrete enough that the technical team can implement a product from the information. Then the processes are applied recursively and iteratively to


8
2.0 Fundamentals of Systems Engineering
NASA SYSTEMS ENGINEERING HANDBOOK
integrate the smallest product into greater and larger systems until the whole of the system or product has been assembled, verified, validated, and transitioned.
For a detailed example of how the SE Engine could be used, refer to the NASA Expanded Guidance
for SE document at https://nen.nasa.gov/web/se/
doc-repository.
AS9100 is a widely adopted and standardized quality management system developed for the commercial aerospace industry. Some NASA Centers have chosen to certify to the AS9100 quality system and may require their contractors to follow NPR 7123.1. TABLE 2.1-1 shows how the 17 NASA SE processes align with AS9100.
2.2 An Overview of the SE Engine by Project Phase
FIGURE 2.2-1 conceptually illustrates how the SE engine is used during each phase of a project (PrePhase A through Phase F). The life cycle phases are described in TABLE 2.2-1. FIGURE 2.2-1 is a conceptual diagram. For full details, refer to the poster version of this figure, which is located at https://nen.nasa.gov/
web/se/doc-repository.
Pre-Phase A: Concept Studies
Implementation
Approval
Technical Management Technical Development
5.2
Key Decision Points:
Major Reviews:
Feasible Concept Top-Level Architecture Functional Baseline Allocated
Baseline As-Deployed Baseline
6.1
6.8
6.1
6.8
6.1
6.8
6.1
6.8
6.1
6.8
6.1
6.8
6.1
6.8
?
?
?
5.3
5.4
5.5
5.1
4.2
4.1
4.3
4.4
?
?
?
?
?
?
?
4.2
4.1
4.3
4.4
5.1
5.3
5.4
5.5
5.2
Product Baseline
Phase F: Closeout
Phase E: Operations & Sustainment
Phase D: System Assembly, Integration & Test, Launch
Phase B: Preliminary Design & Technology Completion
Phase A: Concept & Technology Development
Phase C: Final Design & Fabrication
6.2
6.7
6.6
6.5
6.4
6.3
Formulation
FIGURE 2.2-1 Miniature Version of the Poster-Size NASA Project Life Cycle Process Flow for Flight and Ground Systems Accompanying this Handbook
The uppermost horizontal portion of this chart is used as a reference to project system maturity, as the project progresses from a feasible concept to an as-deployed system; phase activities; Key Decision Points (KDPs); and major project reviews. The next major horizontal band shows the technical development


9
2.0 Fundamentals of Systems Engineering
NASA SYSTEMS ENGINEERING HANDBOOK
processes (steps 1 through 9) in each project phase. The SE engine cycles five times from Pre-Phase A through Phase D. Note that NASA’s management has structured Phases C and D to “split” the technical development processes in half in Phases C and D to ensure closer management control. The engine is bound by a dashed line in Phases C and D. Once a project enters into its operational state (Phase E)
and closes out (Phase F), the technical work shifts to activities commensurate with these last two project phases. The next major horizontal band shows the eight technical management processes (steps 10 through 17) in each project phase. The SE engine cycles the technical management processes seven times from Pre-Phase A through Phase F.
TABLE 2.2-1 Project Life Cycle Phases
Phase Purpose Typical Outcomes
Pre-Formulation
Pre-Phase A Concept Studies
To produce a broad spectrum of ideas and alternatives for missions from which new programs/projects can be selected. Determine feasibility of desired system, develop mission concepts, draft system-level requirements, assess performance, cost, and schedule feasibility; identify potential technology needs, and scope.
Feasible system concepts in the form of simulations, analysis, study reports, models, and mock-ups
Formulation
Phase A
Concept and Technology Development
To determine the feasibility and desirability of a suggested new system and establish an initial baseline compatibility with NASA’s strategic plans. Develop final mission concept, system-level requirements, needed system technology developments, and program/project technical management plans.
System concept definition in the form of simulations, analysis, engineering models and mock-ups, and trade study definition
Phase B Preliminary Design and Technology Completion
To define the project in enough detail to establish an initial baseline capable of meeting mission needs. Develop system structure end product (and enabling product) requirements and generate a preliminary design for each system structure end product.
End products in the form of mock-ups, trade study results, specification and interface documents, and prototypes
Implementation
Phase C
Final Design and Fabrication
To complete the detailed design of the system (and its associated subsystems, including its operations systems), fabricate hardware, and code software. Generate final designs for each system structure end product.
End product detailed designs, end product component fabrication, and software development
Phase D System Assembly, Integration and Test, Launch
To assemble and integrate the system (hardware, software, and humans), meanwhile developing confidence that it is able to meet the system requirements. Launch and prepare for operations. Perform system end product implementation, assembly, integration and test, and transition to use.
Operations-ready system end product with supporting related enabling products
Phase E
Operations and Sustainment
To conduct the mission and meet the initially identified need and maintain support for that need. Implement the mission operations plan.
Desired system
Phase F Closeout
To implement the systems decommissioning/disposal plan developed in Phase E and perform analyses of the returned data and any returned samples.
Product closeout


10
2.0 Fundamentals of Systems Engineering
NASA SYSTEMS ENGINEERING HANDBOOK
2.3 Example of Using the SE Engine
In Pre-Phase A, the SE engine is used to develop the initial concepts; clearly define the unique roles of humans, hardware, and software in performing the missions objectives; establish the system functional and performance boundaries; develop/identify a preliminary/draft set of key high-level requirements, define one or more initial Concept of Operations (ConOps) scenarios; realize these concepts through iterative modeling, mock-ups, simulation, or other means; and verify and validate that these concepts and products would be able to meet the key high-level requirements and ConOps. The operational concept must include scenarios for all significant operational situations, including known off-nominal situations. To develop a useful and complete set of scenarios, important malfunctions and degraded-mode operational situations must be considered. The importance of early ConOps development cannot be underestimated. As system requirements become more detailed and contain more complex technical information, it becomes harder for the stakeholders and users to understand what the requirements are conveying; i.e., it may become more difficult to visualize the end product. The ConOps can serve as a check in identifying missing or conflicting requirements.
Note that this Pre-Phase A initial concepts development work is not the formal verification and validation program that is performed on the final product, but rather it is a methodical run through ensuring that the concepts that are being developed in this Pre-Phase A are able to meet the likely requirements and expectations of the stakeholders. Concepts are developed to the lowest level necessary to ensure that they are feasible and to a level that reduces the risk low enough to satisfy the project. Academically, this process could proceed down to the circuit board level for every system; however, that would involve a great deal of time and money. There may be a higher level or tier of product than circuit board level that would
enable designers to accurately determine the feasibility of accomplishing the project, which is the purpose of Pre-Phase A.
During Phase A, the recursive use of the SE engine is continued, this time taking the concepts and draft key requirements that were developed and validated during Pre-Phase A and fleshing them out to become the set of baseline system requirements and ConOps. During this phase, key areas of high risk might be simulated to ensure that the concepts and requirements being developed are good ones and to identify verification and validation tools and techniques that will be needed in later phases.
During Phase B, the SE engine is applied recursively to further mature requirements and designs for all products in the developing product tree and perform verification and validation of concepts to ensure that the designs are able to meet their requirements. Operational designs and mission scenarios are evaluated and feasibility of execution within design capabilities and cost estimates are assessed.
Phase C again uses the left side of the SE engine to finalize all requirement updates, finalize the ConOps validation, develop the final designs to the lowest level of the product tree, and begin fabrication.
Phase D uses the right side of the SE engine to recursively perform the final implementation, integration, verification, and validation of the end product, and at the final pass, transition the end product to the user.
The technical management processes of the SE engine are used in Phases E and F to monitor performance; control configuration; and make decisions associated with the operations, sustaining engineering, and closeout of the system. Any new capabilities or upgrades of the existing system reenter the SE engine as new developments.


11
2.0 Fundamentals of Systems Engineering
NASA SYSTEMS ENGINEERING HANDBOOK
2.4 Distinctions between Product Verification and Product Validation
From a process perspective, the Product Verification and Product Validation processes may be similar in nature, but the objectives are fundamentally different:
• Verification of a product shows proof of compliance with requirements—that the product can meet each “shall” statement as proven though performance of a test, analysis, inspection, or demonstration (or combination of these).
• Validation of a product shows that the product accomplishes the intended purpose in the intended environment—that it meets the expectations of the customer and other stakeholders as shown through performance of a test, analysis, inspection, or demonstration.
Verification testing relates back to the approved requirements set and can be performed at different stages in the product life cycle. The approved specifications, drawings, parts lists, and other configuration documentation establish the configuration baseline of that product, which may have to be modified at a later time. Without a verified baseline and appropriate configuration controls, later modifications could be costly or cause major performance problems.
Validation relates back to the ConOps document. Validation testing is conducted under realistic conditions (or simulated conditions) on end products for the purpose of determining the effectiveness and suitability of the product for use in mission operations by typical users. Validation can be performed in each development phase using phase products (e.g., models) and not only at delivery using end products.
It is appropriate for verification and validation methods to differ between phases as designs advance. The ultimate success of a program or project may relate to the frequency and diligence of validation efforts during the design process, especially in Pre-Phase A and Phase A during which corrections in the direction of product design might still be made cost-effectively. The question should be continually asked, “Are we building the right product for our users and other stakeholders?” The selection of the verification or validation method is based on engineering judgment as to which is the most effective way to reliably show the product’s conformance to requirements or that it will operate as intended and described in the ConOps.
2.5 Cost Effectiveness Considerations
The objective of systems engineering is to see that the system is designed, built, and can be operated so that it accomplishes its purpose safely in the most cost-effective way possible considering performance, cost, schedule, and risk. A cost-effective and safe system should provide a particular kind of balance between effectiveness and cost. This causality is an indefinite one because there are usually many designs that meet the cost-effective condition.
Design trade studies, an important part of the systems engineering process, often attempt to find designs that provide the best combination of cost and effectiveness. At times there are alternatives that either reduce costs without reducing effectiveness or increase effectiveness without increasing cost. In such “win-win” cases, the systems engineer’s decision is easy. When the alternatives in a design trade study require trading cost for effectiveness, the decisions become harder.


12
2.0 Fundamentals of Systems Engineering
NASA SYSTEMS ENGINEERING HANDBOOK
FIGURE 2.5-1 shows that the life cycle costs of a program or project tend to get “locked in” early in design and development. The cost curves clearly show that late identification of and fixes to problems cost considerably more later in the life cycle. Conversely, descopes taken later versus earlier in the project life cycle result in reduced cost savings. This figure, obtained from the Defense Acquisition University, is an example of how these costs are determined by the early concepts and designs. The numbers will vary from project to project, but the general shape of the curves and the message they send will be similar. For example, the figure shows that during design, only about 15% of the costs might be expended, but the design itself will commit about 75% of the life cycle costs. This is because the way the system is designed will determine how expensive it will be to test, manufacture, integrate, operate, and sustain. If these factors have not been considered during design, they pose significant cost risks later in the life cycle. Also note that the cost to change the design increases as you get later in the life cycle. If the project waits until verification to do any type of test or analysis, any problems found will have a significant cost impact to redesign and reverify.
THE SYSTEMS ENGINEER’S DILEMMA
At each cost-effective solution:
• To reduce cost at constant risk, performance must be reduced.
• To reduce risk at constant cost, performance must be reduced.
• To reduce cost at constant performance, higher risks must be accepted.
• To reduce risk at constant performance, higher costs must be accepted.
In this context, time in the schedule is often a critical resource, so that schedule behaves like a kind of cost.
The technical team may have to choose among designs that differ in terms of numerous attributes. A variety of methods have been developed that can be used to help uncover preferences between attributes and to quantify subjective assessments of relative value. When this can be done, trades between attributes can be assessed quantitatively. Often, however, the attributes are incompatible. In the end, decisions need to be made in spite of the given variety of attributes. There are several decision analysis techniques (Section 6.8) that can aid in complex decision analysis. The systems engineer should always keep in mind the information that needs to be available to help the decision-makers choose the most cost-effective option.
2.6 Human Systems Integration (HSI) in the SE Process
As noted at the beginning of NPR 7123.1, the “systems approach is applied to all elements of a system (i.e., hardware, software, human systems integration. In short, the systems engineering approach must equally address and integrate these three key elements: hardware, software, and human systems


13
2.0 Fundamentals of Systems Engineering
NASA SYSTEMS ENGINEERING HANDBOOK
integration. Therefore, the human element is something that integration and systems engineering processes must address. The definition of “system” in NPR 7123.1 is inclusive; i.e., a system is “the combination of elements that function together to produce the capability required to meet a need. The elements include all hardware, software, equipment, facilities, personnel, processes, and procedures needed for this purpose. For additional information and guidance on his, refer to Section 2.6 of the NASA Expanded Guidance for Systems Engineering at https://nen.
nasa.gov/web/se/doc-repository.
0%
10%
20%
MCR SRR SDR PDR CDR SIR ORR DR/DRR
30%
40% 3–6×
45%
Concept Design Develop
Prod/Test
Operations through Disposal
75%
90%
100%
50%
20%
15%
8%
2 0 –10 0×
5 0 0 –10 0 0×
50%
60%
70%
80%
90%
100%
Cumulative Percentage Life Cycle Cost against Time
Time
CommittedLife
CycleCosts
%Completed
(CostsExpended)
CosttoChangeDesignDirection
MCR Mission Concept Review CDR Critical Design Review
SRR System Requirements Review SIR System Integration Review
SDR System Definition Review ORR Operational Readiness Review
PDR Preliminary Design Review DR/DRR Decommissioning/Disposal Readiness Review
Adapted from INCOSE-TP-2003-002-04, 2015
FIGURE 2.5-1 Life-Cycle Cost Impacts from Early Phase Decision-Making
2.7 Competency Model for Systems Engineers
TABLE 2.7-1 provides a summary of the Competency Model for Systems Engineering. For more information on the NASA SE Competency model refer to:
http://appel.nasa.gov/competency-model/.
There are four levels of proficiencies associated with each of these competencies:
• Team Practitioner/Technical Engineer • Team Lead/Subsystem Lead • Project Systems Engineer • Chief Engineer


14
2.0 Fundamentals of Systems Engineering
NASA SYSTEMS ENGINEERING HANDBOOK
TABLE 2.7-1 NASA System Engineering Competency Model
Competency Area
Competency Description
SE 1.0 System Design
SE 1.1
Stakeholder Expectation Definition & Management
Eliciting and defining use cases, scenarios, concept of operations and stakeholder expectations. This includes identifying stakeholders, establishing support strategies, establishing a set of Measures of Effectiveness (MOEs), validating stakeholder expectation statements, and obtaining commitments from the customer and other stakeholders, as well as using the baselined stakeholder expectations for product validation during product realization
SE 1.2
Technical Requirements Definition
Transforming the baseline stakeholder expectations into unique, quantitative, and measurable technical requirements expressed as “shall” statements that can be used for defining the design solution. This includes analyzing the scope of the technical problems to be solved, defining constraints affecting the designs, defining the performance requirements, validating the resulting technical requirement statements, defining the Measures of Performance (MOPs) for each MOE, and defining appropriate Technical Performance Measures (TPMs) by which technical progress will be assessed.
SE 1.3 Logical Decomposition
Transforming the defined set of technical requirements into a set of logical decomposition models and their associated set of derived technical requirements for lower levels of the system, and for input to the design solution efforts. This includes decomposing and analyzing by function, time, behavior, data flow, object, and other models. It also includes allocating requirements to these decomposition models, resolving conflicts between derived requirements as revealed by the models, defining a system architecture for establishing the levels of allocation, and validating the derived technical requirements.
SE 1.4 Design Solution Definition
Translating the decomposition models and derived requirements into one or more design solutions, and using the Decision Analysis process to analyze each alternative and for selecting a preferred alternative that will satisfy the technical requirements. A full technical data package is developed describing the selected solution. This includes generating a full design description for the selected solution; developing a set of ‘make-to,’ ‘buy-to,’ ‘reuse-to,’ specifications; and initiating the development or acquisition of system products and enabling products.
SE 2.0 Product Realization
SE 2.1 Product Implementation
Generating a specific product through buying, making, or reusing so as to satisfy the design requirements. This includes preparing the implementation strategy; building or coding the produce; reviewing vendor technical information; inspecting delivered, built, or reused products; and preparing product support documentation for integration.
SE 2.2 Product Integration
Assembling and integrating lower-level validated end products into the desired end product of the higher-level product. This includes preparing the product integration strategy, performing detailed planning, obtaining products to integrate, confirming that the products are ready for integration, preparing the integration environment, and preparing product support documentation.
SE 2.3 Product Verification
Proving the end product conforms to its requirements. This includes preparing for the verification efforts, analyzing the outcomes of verification (including identifying anomalies and establishing recommended corrective actions), and preparing a product verification report providing the evidence of product conformance with the applicable requirements.
(continued)


15
2.0 Fundamentals of Systems Engineering
NASA SYSTEMS ENGINEERING HANDBOOK
Competency Area
Competency Description
SE 2.0 Product Realization
SE 2.4 Product Validation
Confirming that a verified end product satisfies the stakeholder expectations for its intended use when placed in its intended environment and ensuring that any anomalies discovered during validation are appropriately resolved prior to product transition. This includes preparing to conduct product validation, performing the product validation, analyzing the results of validation (including identifying anomalies and establishing recommended corrective actions), and preparing a product validation report providing the evidence of product conformance with the stakeholder expectations baseline.
SE 2.5 Product Transition
Transitioning the verified and validated product to the customer at the next level in the system structure. This includes preparing to conduct product transition, evaluating the product and enabling product readiness for product transition, preparing the product for transition (including handling, storing, and shipping preparation), preparing sites, and generating required documentation to accompany the product
SE 3.0
Technical Management
SE 3.1
Technical Planning
Planning for the application and management of each common technical process, as well as identifying, defining, and planning the technical effort necessary to meet project objectives. This includes preparing or updating a planning strategy for each of the technical processes, and determining deliverable work products from technical efforts; identifying technical reporting requirements; identifying entry and success criteria for technical reviews; identifying product and process measures to be used; identifying critical technical events; defining cross domain interoperability and collaboration needs; defining the data management approach; identifying the technical risks to be addressed in the planning effort; identifying tools and engineering methods to be employed; and defining the approach to acquire and maintain technical expertise needed. This also includes preparing the Systems Engineering Management Plan (SEMP) and other technical plans; obtaining stakeholder commitments to the technical plans; and issuing authorized technical work directives to implement the technical work
SE 3.2
Requirements Management
Managing the product requirements, including providing bidirectional traceability, and managing changes to establish requirement baselines over the life cycle of the system products. This includes preparing or updating a strategy for requirements management; selecting an appropriate requirements management tool; training technical team members in established requirement management procedures; conducting expectation and requirements traceability audits; managing expectation and requirement changes; and communicating expectation and requirement change information
SE 3.3 Interface Management
Establishing and using formal interface management to maintain internal and external interface definition and compliance among the end products and enabling products. This includes preparing interface management procedures, identifying interfaces, generating and maintaining interface documentation, managing changes to interfaces, disseminating interface information, and conducting interface control
SE 3.4
Technical Risk Management
Examining on a continual basis the risks of technical deviations from the plans, and identifying potential technical problems before they occur. Planning, invoking, and performing risk-handling activities as needed across the life of the product or project to mitigate impacts on meeting technical objectives. This includes developing the strategy for technical risk management, identifying technical risks, and conducting technical risk assessment; preparing for technical risk mitigation, monitoring the status of each technical risk, and implementing technical risk mitigation and contingency action plans when applicable thresholds have been triggered.
(continued)


16
2.0 Fundamentals of Systems Engineering
NASA SYSTEMS ENGINEERING HANDBOOK
Competency Area
Competency Description
SE 3.0
Technical Management
SE 3.5
Configuration Management
Identifying the configuration of the product at various points in time, systematically controlling changes to the configuration of the product, maintaining the integrity and traceability of product configuration, and preserving the records of the product configuration throughout its life cycle. This includes establishing configuration management strategies and policies, identifying baselines to be under configuration control, maintaining the status of configuration documentation, and conducting configuration audits
SE 3.6
Technical Data Management
Identifying and controlling product-related data throughout its life cycle; acquiring, accessing, and distributing data needed to develop, manage, operate, support, and retire system products; managing and disposing data as records; analyzing data use; obtaining technical data feedback for managing the contracted technical efforts; assessing the collection of appropriate technical data and information; maintaining the integrity and security of the technical data, effectively managing authoritative data that defines, describes, analyzes, and characterizes a product life cycle; and ensuring consistent, repeatable use of effective Product Data and Life-cycle Management processes, best practices, interoperability approaches, methodologies, and traceability. This includes establishing technical data management strategies and policies; maintaining revision, status, and history of stored technical data and associated metadata; providing approved, published technical data; providing technical data to authorized parties; and collecting and storing required technical data.
SE 3.7
Technical Assessment
Monitoring progress of the technical effort and providing status information for support of the system design, product realization, and technical management efforts. This includes developing technical assessment strategies and policies, assessing technical work productivity, assessing product quality, tracking and trending technical metrics, and conducting technical, peer, and life cycle reviews.
SE 3.8
Technical Decision Analysis
Evaluating technical decision issues, identifying decision criteria, identifying alternatives, analyzing alternatives, and selecting alternatives. Performed throughout the system life cycle to formulate candidate decision alternatives, and evaluate their impacts on health and safety, technical, cost, and schedule performance. This includes establishing guidelines for determining which technical issues are subject to formal analysis processes; defining the criteria for evaluating alternative solutions; identifying alternative solutions to address decision issues; selecting evaluation methods; selecting recommended solutions; and reporting the results and findings with recommendations, impacts, and corrective actions.


NASA SYSTEMS ENGINEERING HANDBOOK 17
3.0 NASA Program/Project Life Cycle
O
ne of the fundamental concepts used within NASA for the management of major systems is the program/project life cycle, which categorizes everything that should be done to accomplish a program or project into distinct phases that are separated by Key Decision Points (KDPs). KDPs are the events at which the decision authority determines the readiness of a program/project to progress to the next phase of the life cycle (or to the next KDP). Phase boundaries are defined so that they provide natural points for “go” or “no-go” decisions. Decisions to proceed may be qualified by liens that should be removed within an agreed-to time period. A program or project that fails to pass a KDP may be allowed to try again later after addressing deficiencies that precluded passing the KDP, or it may be terminated.
All systems start with the recognition of a need or the discovery of an opportunity and proceed through various stages of development to the end of the project. While the most dramatic impacts of the analysis and optimization activities associated with systems engineering are obtained in the early stages, decisions that affect cost continue to be amenable to the systems approach even as the end of the system lifetime approaches.
Decomposing the program/project life cycle into phases organizes the entire process into more manageable pieces. The program/project life cycle should provide managers with incremental visibility into the progress being made at points in time that fit with the management and budgetary environments.
For NASA projects, the life cycle is defined in the applicable governing document:
• For space flight projects: NPR 7120.5, NASA
Space Flight Program and Project Management Requirements
• For information technology: NPR 7120.7,
NASA Information Technology and Institutional Infrastructure Program and Project Management Requirements
• For NASA research and technology: NPR 7120.8,
NASA Research and Technology Program and Project Management Requirements
• For software: NPR 7150.2 NASA Software Engineering Requirements


18
3.0 NASA Program/Project Life Cycle
NASA SYSTEMS ENGINEERING HANDBOOK
For example, NPR 7120.5 defines the major NASA life cycle phases as Formulation and Implementation. For space flight systems projects, the NASA life cycle phases of Formulation and Implementation divide into the following seven incremental pieces. The phases of the project life cycle are:
Program Pre-Formulation:
• Pre-Phase A: Concept Studies
Program Formulation
• Phase A: Concept and Technology Development • Phase B: Preliminary Design and Technology Completion
Program Implementation:
• Phase C: Final Design and Fabrication
• Phase D: System Assembly, Integration and Test, Launch • Phase E: Operations and Sustainment • Phase F: Closeout
FIGURE 3.0-1 is taken from NPR 7120.5 and provides the life cycle for NASA space flight projects and identifies the KDPs and reviews that characterize the phases. More information concerning life cycles can be found in the NASA Expanded Guidance for SE document at
https://nen.nasa.gov/web/se/doc-repository and in the
SP-2014-3705, NASA Space Flight Program and Project Management Handbook.
TABLE 3.0-1 is taken from NPR 7123.1 and represents the product maturity for the major SE products developed and matured during the product life cycle.
NASA Life-Cycle
Phases FORMULATION IMPLEMENTATION
Project Life-Cycle Phases
Pre-Phase A: Concept Studies
Phase A: Concept and Technology Development
Phase B: Preliminary Design and Technology Completion
Phase C: Final Design and Fabrication
Phase D: System Assembly, Integration & Test, Launch & Checkout
Phase E: Operations and Sustainment
Phase F: Closeout
Project LifeCycle Gates, Documents, and Major Events
Agency Reviews
Human Space Flight Project Life-Cycle Reviews1,2
Re-flights
Robotic Mission Project Life Cycle Reviews1,2
Other Reviews
Supporting Reviews
FOOTNOTES
1. Flexibility is allowed as to the timing, number, and content of reviews as long as the equivalent information is provided at each KDP and the approach is fully documented in the Project Plan. 2. Life-cycle review objectives and expected maturity states for these reviews and the attendant KDPs are contained in Table 2-5 and Appendix D Table D-3 of this handbook 3. PRR is needed only when there are multiple copies of systems. It does not require an SRB. Timing is notional. 4. CERRs are established at the discretion of program . 5. For robotic missions, the SRR and the MDR may be combined. 6. SAR generally applies to human space flight. 7. Timing of the ASM is determined by the MDAA. It may take place at any time during Phase A. Red triangles represent life-cycle reviews that require SRBs. The Decision Authority, Administrator, MDAA, or Center Director may request the SRB to conduct other reviews.
ACRONYMS
ASM – Acquisition Strategy Meeting CDR – Critical Design Review CERR – Critical Events Readiness Review DR – Decommissioning Review DRR – Disposal Readiness Review FA – Formulation Agreement FAD – Formulation Authorization Document FRR – Flight Readiness Review KDP – Key Decision Point LRR – Launch Readiness Review LV – Launch Vehicle MCR – Mission Concept Review
MDR – Mission Definition Review MRR – Mission Readiness Review ORR – Operational Readiness Review PDR – Preliminary Design Review PFAR – Post-Flight Assessment Review PLAR – Post-Launch Assessment Review PRR – Production Readiness Review SAR – System Acceptance Review SDR – System Definition Review SIR – System Integration Review SMSR – Safety and Mission Success Review SRB – Standing Review Board SRR – System Requirements Review
FIGURE 3.0-1 NASA Space Flight Project Life Cycle from NPR 7120 5E
Approval for Formulation
Approval for Implementation
KDP A
Preliminary Project Requirements
Preliminary Project Plan
Baseline Project Plan
Launch End of Mission Final Archival of Data
Inspections and Refurbishment
Re-enters appropriate life-cycle phase if modifications are needed between flights
End of Flight
FAD
MCR
MCR
ASM7
SRR
SRR
SDR
MDR5
PDR
PDR
SIR
SIR
ORR
ORR
FRR
MRR
PLAR
PLAR
SAR6 SMSR,LRR (LV), FRR (LV)
CERR4
CERR4
PFAR
DR
DR
DRR
DRR
CDR/ PRR3
CDR/ PRR3
FA
KDP B KDP C KDP D KDP E KDP F
Peer Reviews, Subsystem PDFs, Subsystem CDRs, and System Reviews


19
3.0 NASA Program/Project Life Cycle
NASA SYSTEMS ENGINEERING HANDBOOK
TABLE 3.0-1 SE Product Maturity from NPR 7123 1
Formulation Implementation
Products
Uncoupled/
Loosely Coupled KDP 0 KDP I Periodic KDPs
Tightly Coupled
Programs KDP 0 KDP I KDP II KDP III Periodic KDPs
Projects and Single Project Programs
Pre
Phase A Phase A Phase B Phase C Phase D Phase E Phase F
KDP A KDP B KDP C KDP D KDP E KDP F
MCR SRR MDR/SDR PDR CDR SIR ORR FRR DR DRR
Stakeholder identification and **Baseline Update Update Update
Concept definition **Baseline Update Update Update Update
Measure of effectiveness definition
**Approve
Cost and schedule for technical Initial Update Update Update Update Update Update Update Update
SEMP1 Preliminary **Baseline **Baseline Update Update Update
Requirements Preliminary **Baseline Update Update Update
Technical Performance Measures definition
**Approve
Architecture definition **Baseline
Allocation of requirements to next lower level
**Baseline
Required leading indicator trends
**Initial Update Update Update
Design solution definition Preliminary **Preliminary **Baseline Update Update
Interface definition(s) Preliminary Baseline Update Update
Implementation plans (Make/ code, buy, reuse)
Preliminary Baseline Update
Integration plans Preliminary Baseline Update **Update
Verification and validation plans
Approach Preliminary Baseline Update Update
Verification and validation results
**Initial **Preliminary **Baseline
Transportation criteria and instructions
Initial Final Update
Operations plans Baseline Update Update **Update
Operational procedures Preliminary Baseline **Update Update
Certification (flight/use) Preliminary **Final
Decommissioning plans Preliminary Preliminary Preliminary **Baseline Update **Update
Disposal plans Preliminary Preliminary Preliminary **Baseline Update Update **Update
** Item is a required product for that review
1 SEMP is baselined at SRR for projects, tightly coupled programs and single-project programs, and at MDR/SDR for uncoupled, and loosely coupled programs


20
3.0 NASA Program/Project Life Cycle
NASA SYSTEMS ENGINEERING HANDBOOK
3.1 Program Formulation
The program Formulation Phase establishes a cost-effective program that is demonstrably capable of meeting Agency and mission directorate goals and objectives. The program Formulation Authorization Document (FAD) authorizes a Program Manager (PM) to initiate the planning of a new program and to perform the analyses required to formulate a sound program plan. The lead systems engineer provides the technical planning and concept development or this phase of the program life cycle. Planning includes identifying the major technical reviews that are needed and associated entrance and exit criteria. Major reviews leading to approval at KDP I are the SRR, SDR, PDR, and governing Program Management
Council (PMC) review. A summary of the required gate products for the program Formulation Phase can be found in the governing NASA directive (e.g., NPR 7120.5 for space flight programs, NPR 7120.7 for IT projects, NPR 7120.8 for research and technology projects). Formulation for all program types is the same, involving one or more program reviews followed by KDP I where a decision is made approving a program to begin implementation.
3.2 Program Implementation
During the program Implementation phase, the PM works with the Mission Directorate Associate Administrator (MDAA) and the constituent project
SPACE FLIGHT PROGRAM FORMULATION
Purpose
To establish a cost-effective program that is demonstrably capable of meeting Agency and mission
directorate goals and objectives
Typical Activities and Their Products for Space Flight Programs
• Identify program stakeholders and users
• Develop program requirements based on user expectations and allocate them to initial projects
• Identify NASA risk classification
• Define and approve program acquisition strategies
• Develop interfaces to other programs
• Start developing technologies that cut across multiple projects within the program
• Derive initial cost estimates and approve a program budget based on the project’s life cycle costs
• Perform required program Formulation technical activities defined in NPR 7120.5
• Satisfy program Formulation reviews’ entrance/success criteria detailed in NPR 7123.1
• Develop a clear vision of the program’s benefits and usage in the operational era and document it in a ConOps
Reviews
• MCR (pre-Formulation)
• SRR
• SDR


21
3.0 NASA Program/Project Life Cycle
NASA SYSTEMS ENGINEERING HANDBOOK
managers to execute the program plan cost-effectively. Program reviews ensure that the program continues to contribute to Agency and mission directorate goals and objectives within funding constraints. A summary of the required gate products for the program Implementation Phase can be found in the governing NASA directive; e.g., NPR 7120.5 for space flight programs. The program life cycle has two different implementation paths, depending on program type. Each implementation path has different types of major reviews. It is important for the systems engineer to know what type of program a project falls under so that the appropriate scope of the technical work, documentation requirements, and set of reviews can be determined.
SPACE FLIGHT PROGRAM IMPLEMENTATION
Purpose
To execute the program and constituent projects and ensure that the program continues to contribute to
Agency goals and objectives within funding constraints
Typical Activities and Their Products
• Initiate projects through direct assignment or competitive process (e.g., Request for Proposal (RFP),
Announcement of Opportunity (AO)
• Monitor project’s formulation, approval, implementation, integration, operation, and ultimate
decommissioning
• Adjust program as resources and requirements change
• Perform required program Implementation technical activities from NPR 7120.5
• Satisfy program Implementation reviews’ entrance/success criteria from NPR 7123.1
Reviews
• PSR/PIR (uncoupled and loosely coupled programs only)
• Reviews synonymous (not duplicative) with the project reviews in the project life cycle (see FIGURE 3.0-4)
through Phase D (single-project and tightly coupled programs only)
3.3 Project Pre-Phase A: Concept Studies
The purpose of Pre-Phase A is to produce a broad spectrum of ideas and alternatives for missions from which new programs/projects can be selected. During Pre-Phase A, a study or proposal team analyses a broad range of mission concepts that can fall within technical, cost, and schedule constraints and that contribute to program and Mission Directorate goals and objectives. Pre-Phase A effort could include focused examinations on high-risk or high technology development areas. These advanced studies, along with interactions with customers and other potential stakeholders, help the team to identify promising mission concept(s). The key stakeholders (including the customer) are determined and


22
3.0 NASA Program/Project Life Cycle
NASA SYSTEMS ENGINEERING HANDBOOK
SPACE FLIGHT PRE‐PHASE A: CONCEPT STUDIES
Purpose
To produce a broad spectrum of ideas and alternatives for missions from which new programs and projects can
be selected. Determine feasibility of desired system; develop mission concepts; draft system-level requirements;
assess performance, cost, and schedule feasibility; identify potential technology needs and scope.
Typical Activities and Products
• Review/identify any initial customer requirements or scope of work, which may include:
> Mission
> Science
> Top-level system
• Identify and involve users and other stakeholders
> Identify key stakeholders for each phase of the life cycle
> Capture and baseline expectations as Needs, Goals, and Objectives (NGOs)
> Define measures of effectiveness
• Develop and baseline the Concept of Operations
> Identify and perform trade-offs and analyses of alternatives (AoA)
> Perform preliminary evaluations of possible missions
• Identify risk classification
• Identify initial technical risks
• Identify the roles and responsibilities in performing mission objectives (i.e., technical team, flight, and
ground crew) including training
• Develop plans
> Develop preliminary SEMP
> Develop and baseline Technology Development Plan
> Define preliminary verification and validation approach
• Prepare program/project proposals, which may include:
> Mission justification and objectives;
> A ConOps that exhibits clear understanding of how the program’s outcomes will cost-effectively
satisfy mission objectives;
> High-level Work Breakdown Structures (WBSs);
> Life cycle rough order of magnitude (ROM) cost, schedule, and risk estimates; and
> Technology assessment and maturation strategies.
• Satisfy MCR entrance/success criteria from NPR 7123.1
Reviews
• MCR
• Informal proposal review


23
3.0 NASA Program/Project Life Cycle
NASA SYSTEMS ENGINEERING HANDBOOK
expectations for the project are gathered from them. If feasible concepts can be found, one or more may be selected to go into Phase A for further development. Typically, the system engineers are heavily involved in the development and assessment of the concept options. In projects governed by NPR 7120.5, the descope options define what the system can accomplish if the resources are not available to accomplish the entire mission. This could be in the form of fewer instruments, a less ambitious mission profile, accomplishing only a few goals, or using cheaper, less capable technology. Descope options can also reflect what the mission can accomplish in case a hardware failure results in the loss of a portion of the spacecraft architecture; for example, what an orbiter can accomplish after the loss of a lander. The success criteria are reduced to correspond with a descoped mission.
Descope options are developed when the NGOs or other stakeholder expectation documentation is developed. The project team develops a preliminary set of mission descope options as a gate product for the MCR, but these preliminary descope options are not baselined or maintained. They are kept in the documentation archive in case they are needed later in the life cycle.
It is important in Pre-Phase A to define an accurate group of stakeholders and users to help ensure that mission goals and operations concepts meet the needs and expectations of the end users. In addition, it is important to estimate the composition of the technical team and identify any unique facility or personnel requirements.
Advanced studies may extend for several years and are typically focused on establishing mission goals and formulating top-level system requirements and ConOps. Conceptual designs may be developed to demonstrate feasibility and support programmatic estimates. The emphasis is on establishing feasibility
and desirability rather than optimality. Analyses and designs are accordingly limited in both depth and number of options, but each option should be evaluated for its implications through the full life cycle, i.e., through Operations and Disposal. It is important in Pre-Phase A to develop and mature a clear vision of what problems the proposed program will address, how it will address them, and how the solution will be feasible and cost-effective.
3.4 Project Phase A: Concept and Technology Development
The purpose of Phase A is to develop a proposed mission/system architecture that is credible and responsive to program expectations, requirements, and constraints on the project, including resources. During Phase A, activities are performed to fully develop a baseline mission concept, begin or assume responsibility for the development of needed technologies, and clarify expected reliance on human elements to achieve full system functionality or autonomous system development. This work, along with interactions with stakeholders, helps mature the mission concept and the program requirements on the project. Systems engineers are heavily involved during this phase in the development and assessment of the architecture and the allocation of requirements to the architecture elements.
In Phase A, a team—often associated with a program or informal project office—readdresses the mission concept first developed in Pre-Phase A to ensure that the project justification and practicality are sufficient to warrant a place in NASA’s budget. The team’s effort focuses on analyzing mission requirements and establishing a mission architecture. Activities become formal, and the emphasis shifts toward optimizing the concept design. The effort addresses more depth and considers many alternatives. Goals and objectives are


24
3.0 NASA Program/Project Life Cycle
NASA SYSTEMS ENGINEERING HANDBOOK
SPACE FLIGHT PHASE A: CONCEPT AND TECHNOLOGY DEVELOPMENT
Purpose
To determine the feasibility and desirability of a suggested new system and establish an initial baseline
compatibility with NASA’s strategic plans. Develop final mission concept, system-level requirements,
needed system technology developments, and program/project technical management plans.
Typical Activities and Their Products
• Review and update documents baselined in Pre-Phase A if needed
• Monitor progress against plans
• Develop and baseline top-level requirements and constraints including internal and external interfaces,
integrated logistics and maintenance support, and system software functionality
• Allocate system requirements to functions and to next lower level
• Validate requirements
• Baseline plans
> Systems Engineering Management Plan
> Human Systems Integration Plan
> Control plans such as the Risk Management Plan, Configuration Management Plan, Data
Management Plan, Safety and Mission Assurance Plan, and Software Development or Management
Plan (See NPR 7150.2)
> Other crosscutting and specialty plans such as environmental compliance documentation,
acquisition surveillance plan, contamination control plan, electromagnetic interference/
electromagnetic compatibility control plan, reliability plan, quality control plan, parts management
plan, logistics plan
• Develop preliminary Verification and Validation Plan
• Establish human rating plan and perform initial evaluations
• Develop and baseline mission architecture
> Develop breadboards, engineering units or models identify and reduce high risk concepts
> Demonstrate that credible, feasible design(s) exist
> Perform and archive trade studies
> Initiate studies on human systems interactions
• Initiate environmental evaluation/National Environmental Policy Act process
• Develop initial orbital debris assessment (NASA-STD-8719.14)
• Perform technical management
> Provide technical cost estimate and range and develop system-level cost-effectiveness model
> Define the WBS
> Develop SOWs
> Acquire systems engineering tools and models
(continued)


25
3.0 NASA Program/Project Life Cycle
NASA SYSTEMS ENGINEERING HANDBOOK
solidified, and the project develops more definition in the system requirements, top-level system architecture, and ConOps. Conceptual designs and analyses (including engineering units and physical models, as appropriate) are developed and exhibit more engineering detail than in Pre-Phase A. Technical risks are identified in more detail, and technology development needs become focused. A Systems Engineering Management Plan (SEMP) is baselined in Phase A to document how NASA systems engineering requirements and practices of NPR 7123.1 will be addressed throughout the program life cycle.
In Phase A, the effort focuses on allocating functions to particular items of hardware, software, and to humans. System functional and performance requirements, along with architectures and designs, become firm as system tradeoffs and subsystem tradeoffs iterate back and forth, while collaborating with subject matter experts in the effort to seek out more cost-effective designs. A method of determining life cycle cost (i.e., system-level cost-effectiveness model) is refined in order to compare cost impacts for each of the different alternatives. (Trade studies should precede—rather than follow—system design decisions.) Major products to this point include an accepted functional baseline for the system and its major end items. The project team conducts the security categorization of IT systems required by NPR 2810.1 and Federal Information Processing Standard
Publication (FIPS PUB) 199. The effort also produces various engineering and management plans to prepare for managing the project’s downstream processes such as verification and operations.
3.5 Project Phase B: Preliminary Design and Technology Completion
The purpose of Phase B is for the project team to complete the technology development, engineering prototyping, heritage hardware and software assessments, and other risk-mitigation activities identified in the project Formulation Agreement (FA) and the preliminary design. The project demonstrates that its planning, technical, cost, and schedule baselines developed during Formulation are complete and consistent; that the preliminary design complies with its requirements; that the project is sufficiently mature to begin Phase C; and that the cost and schedule are adequate to enable mission success with acceptable risk. It is at the conclusion of this phase that the project and the Agency commit to accomplishing the project’s objectives for a given cost and schedule. For projects with a Life Cycle Cost (LCC) greater than $250 million, this commitment is made with the Congress and the U.S. Office of Management and Budget (OMB). This external commitment is the Agency Baseline Commitment (ABC). Systems
> Establish technical resource estimates
• Identify, analyze and update risks
• Perform required Phase A technical activities from NPR 7120.5 as applicable
• Satisfy Phase A reviews’ entrance/success criteria from NPR 7123.1
Reviews
• SRR
• MDR/SDR


26
3.0 NASA Program/Project Life Cycle
NASA SYSTEMS ENGINEERING HANDBOOK
SPACE FLIGHT PHASE B: PRELIMINARY DESIGN AND TECHNOLOGY COMPLETION
Purpose
To define the project in enough detail to establish an initial baseline capable of meeting mission needs.
Develop system structure end product (and enabling product) requirements and generate a preliminary
design for each system structure end product.
Typical Activities and Their Products
• Review and update documents baselined in previous phases
• Monitor progress against plans
• Develop the preliminary design
> Identify one or more feasible preliminary designs including internal and external interfaces
> Perform analyses of candidate designs and report results
> Conduct engineering development tests as needed and report results
> Perform human systems integration assessments
> Select a preliminary design solution
• Develop operations plans based on matured ConOps
> Define system operations as well as Principal Investigator (PI)/contract proposal management,
review, and access and contingency planning
• Report technology development results
• Update cost range estimate and schedule data (Note that after PDR changes are incorporated and
costed, at KDP C this will turn into the Agency Baseline Commitment)
• Improve fidelity of models and prototypes used in evaluations
• Identify and update risks
• Develop appropriate level safety data package and security plan
• Develop preliminary plans
> Orbital Debris Assessment
> Decommissioning Plan
> Disposal Plan
• Perform required Phase B technical activities from NPR 7120.5 as applicable
• Satisfy Phase B reviews’ entrance/success criteria from NPR 7123.1
Reviews
• PDR
• Safety review


27
3.0 NASA Program/Project Life Cycle
NASA SYSTEMS ENGINEERING HANDBOOK
engineers are involved in this phase to ensure the preliminary designs of the various systems will work together, are compatible, and are likely to meet the customer expectations and applicable requirements.
During Phase B, activities are performed to establish an initial project baseline, which (according to NPR 7120.5 and NPR 7123.1) includes “a formal flow down of the project-level performance requirements to a complete set of system and subsystem design specifications for both flight and ground elements” and “corresponding preliminary designs.” The technical requirements should be sufficiently detailed to establish firm schedule and cost estimates for the project. It also should be noted, especially for AO-driven projects, that Phase B is where the toplevel requirements and the requirements flowed down to the next level are finalized and placed under configuration control. While the requirements should be baselined in Phase A, changes resulting from the trade studies and analyses in late Phase A and early Phase B may result in changes or refinement to system requirements.
It is important in Phase B to validate design decisions against the original goals and objectives and ConOps. All aspects of the life cycle should be considered, including design decisions that affect training, operations resource management, human factors, safety, habitability and environment, and maintainability and supportability.
The Phase B baseline consists of a collection of evolving baselines covering technical and business aspects of the project: system (and subsystem) requirements and specifications, designs, verification and operations plans, and so on in the technical portion of the baseline, and schedules, cost projections, and management plans in the business portion. Establishment of baselines implies the implementation of configuration management procedures. (See Section 6.5.)
Phase B culminates in a series of PDRs, containing the system-level PDR and PDRs for lower level end items as appropriate. The PDRs reflect the successive refinement of requirements into designs. Design issues uncovered in the PDRs should be resolved so that final design can begin with unambiguous design-to specifications. From this point on, almost all changes to the baseline are expected to represent successive refinements, not fundamental changes. As noted in FIGURE 2.5-1, significant design changes at and beyond Phase B become increasingly expensive.
3.6 Project Phase C: Final Design and Fabrication
The purpose of Phase C is to complete and document the detailed design of the system that meets the detailed requirements and to fabricate, code, or otherwise realize the products. During Phase C, activities are performed to establish a complete design (product baseline), fabricate or produce hardware, and code software in preparation for integration. Trade studies continue and results are used to validate the design against project goals, objectives, and ConOps. Engineering test units more closely resembling actual hardware are built and tested to establish confidence that the design will function in the expected environments. Human subjects representing the user population participate in operations evaluations of the design, use, maintenance, training procedures, and interfaces. Engineering specialty and crosscutting analysis results are integrated into the design, and the manufacturing process and controls are defined and valid. Systems engineers are involved in this phase to ensure the final detailed designs of the various systems will work together, are compatible, and are likely to meet the customer expectations and applicable requirements. During fabrication, the systems engineer is available to answer questions and work any interfacing issues that might arise.


28
3.0 NASA Program/Project Life Cycle
NASA SYSTEMS ENGINEERING HANDBOOK
SPACE FLIGHT PHASE C: FINAL DESIGN AND FABRICATION
Purpose
To complete the detailed design of the system (and its associated subsystems, including its operations
systems), fabricate hardware, and code software. Generate final designs for each system structure end
product.
Typical Activities and Their Products
• Review and update documents baselined in previous phases
• Monitor progress against plans
• Develop and document hardware and software detailed designs
> Fully mature and define selected preliminary designs
> Add remaining lower level design specifications to the system architecture
> Perform and archive trade studies
> Perform development testing at the component or subsystem level
> Fully document final design and develop data package
• Develop/refine and baseline plans
> Interface definitions
> Implementation plans
> Integration plans
> Verification and validation plans
> Operations plans
• Develop/refine preliminary plans
> Decommissioning and disposal plans, including human capital transition
> Spares
> Communications (including command and telemetry lists)
• Develop/refine procedures for
> Refine integration
> Manufacturing and assembly
> Verification and validation
• Fabricate (or code) the product
• Identify and update risks
• Monitor project progress against project plans
• Prepare launch site checkout and post launch activation and checkout
• Finalize appropriate level safety data package and updated security plan
• Identify opportunities for preplanned product improvement
• Refine orbital debris assessment
• Perform required Phase C technical activities from NPR 7120.5 as applicable
• Satisfy Phase C review entrance/success criteria from NPR 7123.1
(continued)


29
3.0 NASA Program/Project Life Cycle
NASA SYSTEMS ENGINEERING HANDBOOK
Reviews
• CDR
• PRR
• SIR
• Safety review
All the planning initiated back in Phase A for the testing and operational equipment, processes and analysis, integration of the crosscutting and engineering specialty analysis, and manufacturing processes and controls is implemented. Configuration management continues to track and control design changes as detailed interfaces are defined. At each step in the successive refinement of the final design, corresponding integration and verification activities are planned in greater detail. During this phase, technical parameters, schedules, and budgets are closely tracked to ensure that undesirable trends (such as an unexpected growth in spacecraft mass or increase in its cost) are recognized early enough to take corrective action. These activities focus on preparing for the CDR, Production Readiness Review (PRR) (if required), and the SIR.
Phase C contains a series of CDRs containing the system-level CDR and CDRs corresponding to the different levels of the system hierarchy. A CDR for each end item should be held prior to the start of fabrication/production for hardware and prior to the start of coding of deliverable software products. Typically, the sequence of CDRs reflects the integration process that will occur in the next phase; that is, from lower level CDRs to the system-level CDR. Projects, however, should tailor the sequencing of the reviews to meet the needs of the project. If there is a production run of products, a PRR will be performed to ensure the production plans, facilities, and personnel are ready to begin production. Phase C culminates with an SIR. Training requirements and preliminary
mission operations procedures are created and baselined. The final product of this phase is a product ready for integration.
3.7 Project Phase D: System Assembly, Integration and Test, Launch
The purpose of Phase D is to assemble, integrate, verify, validate, and launch the system. These activities focus on preparing for the Flight Readiness Review (FRR)/Mission Readiness Review (MRR). Activities include assembly, integration, verification, and validation of the system, including testing the flight system to expected environments within margin. Other activities include updating operational procedures, rehearsals and training of operating personnel and crew members, and implementation of the logistics and spares planning. For flight projects, the focus of activities then shifts to prelaunch integration and launch. System engineering is involved in all aspects of this phase including answering questions, providing advice, resolving issues, assessing results of the verification and validation tests, ensuring that the V&V results meet the customer expectations and applicable requirements, and providing information to decision makers for go/no-go decisions.
The planning for Phase D activities was initiated in Phase A. For IT projects, refer to the IT Systems Engineering Handbook. The planning for the activities should be performed as early as possible since


30
3.0 NASA Program/Project Life Cycle
NASA SYSTEMS ENGINEERING HANDBOOK
SPACE FLIGHT PHASE D: SYSTEM ASSEMBLY, INTEGRATION AND TEST, LAUNCH
Purpose
To assemble and integrate the system (hardware, software, and humans), meanwhile developing confidence
that it will be able to meet the system requirements. Launch and prepare for operations. Perform system
end product implementation, assembly, integration and test, and transition to use.
Typical Activities and Their Products
• Update documents developed and baselined in previous phases
• Monitor project progress against plans
• Identify and update risks
• Integrate/assemble components according to the integration plans
• Perform verification and validation on assemblies according to the V&V Plan and procedures
> Perform system qualification verifications, including environmental verifications
> Perform system acceptance verifications and validation(s) (e.g., end-to-end tests encompassing all
elements; i.e., space element, ground system, data processing system)
> Assess and approve verification and validation results
> Resolve verification and validation discrepancies
> Archive documentation for verifications and validations performed
> Baseline verification and validation report
• Prepare and baseline
> Operator’s manuals
> Maintenance manuals
> Operations handbook
• Prepare launch, operations, and ground support sites including training as needed
> Train initial system operators and maintainers
> Train on contingency planning
> Confirm telemetry validation and ground data processing
> Confirm system and support elements are ready for flight
> Provide support to the launch and checkout of the system
> Perform planned on-orbit operational verification(s) and validation(s)
• Document lessons learned. Perform required Phase D technical activities from NPR 7120.5
• Satisfy Phase D reviews’ entrance/success criteria from NPR 7123.1
Reviews
• Test Readiness Reviews (TRRs)
• System Acceptance Review (SAR) or pre-Ship Review
• ORR
(continued)


31
3.0 NASA Program/Project Life Cycle
NASA SYSTEMS ENGINEERING HANDBOOK
• FRR
• System functional and physical configuration audits
• Safety review
changes at this point can become costly. Phase D concludes with a system that has been shown to be capable of accomplishing the purpose for which it was created.
3.8 Project Phase E: Operations and Sustainment
The purpose of Phase E is to conduct the prime mission to meet the initially identified need and to maintain support for that need. The products of the phase are the results of the mission and performance of the system.
Systems engineering personnel continue to play a role during this phase since integration often overlaps with operations for complex systems. Some programs have repeated operations/flights which require configuration changes and new mission objectives with each occurrence. And systems with complex sustainment needs or human involvement will likely require evaluation and adjustments that may be beyond the scope of operators to perform. Specialty engineering disciplines, like maintainability and logistics servicing, will be performing tasks during this phase as well. Such tasks may require reiteration and/or recursion of the common systems engineering processes.
Systems engineering personnel also may be involved in in-flight anomaly resolution. Additionally, software development may continue well into Phase E. For example, software for a planetary probe may be developed and uplinked while in-flight. Another example would be new hardware developed for space station increments.
This phase encompasses the evolution of the system only insofar as that evolution does not involve major changes to the system architecture. Changes of that scope constitute new “needs,” and the project life cycle starts over. For large flight projects, there may be an extended period of cruise, orbit insertion, on-orbit assembly, and initial shakedown operations. Near the end of the prime mission, the project may apply for a mission extension to continue mission activities or attempt to perform additional mission objectives.
For additional information on systems engineering in Phase E, see Appendix T.
3.9 Project Phase F: Closeout
The purpose of Phase F is to implement the systems decommissioning and disposal planning and analyze any returned data and samples. The products of the phase are the results of the mission. The system engineer is involved in this phase to ensure all technical information is properly identified and archived, to answer questions, and to resolve issues as they arise.
Phase F deals with the final closeout of the system when it has completed its mission; the time at which this occurs depends on many factors. For a flight system that returns to Earth after a short mission duration, closeout may require little more than de-integrating the hardware and returning it to its owner. On flight projects of long duration, closeout may proceed according to established plans or may begin as a result of unplanned events, such as failures. Refer to NASA Policy Directive (NPD) 8010.3, Notification of Intent to Decommission or Terminate Operating Space Systems and Terminate Missions,


32
3.0 NASA Program/Project Life Cycle
NASA SYSTEMS ENGINEERING HANDBOOK
SPACE FLIGHT PHASE E: OPERATIONS AND SUSTAINMENT
Purpose
To conduct the mission and meet the initially identified need and maintain support for that need. Implement
the mission operations plan.
Typical Activities and Their Products
• Conduct launch vehicle performance assessment. Commission and activate science instruments
• Conduct the intended prime mission(s)
• Provide sustaining support as planned
> Implement spares plan
> Collect engineering and science data
> Train replacement operators and maintainers
> Train the flight team for future mission phases (e.g., planetary landed operations)
> Maintain and approve operations and maintenance logs
> Maintain and upgrade the system
> Identify and update risks
> Address problem/failure reports
> Process and analyze mission data
> Apply for mission extensions, if warranted
• Prepare for deactivation, disassembly, decommissioning as planned (subject to mission extension)
• Capture lessons learned
• Complete post-flight evaluation reports
• Develop final mission report
• Perform required Phase E technical activities from NPR 7120.5
• Satisfy Phase E reviews’ entrance/success criteria from NPR 7123.1
Reviews
• Post-Launch Assessment Review (PLAR)
• Critical Event Readiness Review (CERR)
• Post-Flight Assessment Review (PFAR) (human space flight only)
• DR
• System upgrade review
• Safety review


33
3.0 NASA Program/Project Life Cycle
NASA SYSTEMS ENGINEERING HANDBOOK
for terminating an operating mission. Alternatively, technological advances may make it uneconomical to continue operating the system either in its current configuration or an improved one.
To limit space debris, NPR 8715.6, NASA Procedural Requirements for Limiting Orbital Debris, provides requirements for removing Earth-orbiting robotic satellites from their operational orbits at the end of their useful life. For Low Earth Orbit (LEO) missions, the satellite is usually deorbited. For small satellites, this is accomplished by allowing the orbit to slowly decay until the satellite eventually burns up in Earth’s atmosphere. Larger, more massive satellites and observatories should be designed to demise or deorbit in a controlled manner so that they can be safely targeted for impact in a remote area of the ocean. The Geostationary (GEO) satellites at 35,790 km above the Earth cannot be practically deorbited,
so they are boosted to a higher orbit well beyond the crowded operational GEO orbit.
In addition to uncertainty about when this part of the phase begins, the activities associated with safe closeout of a system may be long and complex and may affect the system design. Consequently, different options and strategies should be considered during the project’s earlier phases along with the costs and risks associated with the different options.
3.10 Funding: The Budget Cycle
For a description of the NASA Budget Cycle, refer to the NASA Expanded Guidance for Systems Engineering document found at https://nen.nasa.gov/ web/se/doc-repository. See also Section 5.8 of NASA/ SP-2014-3705, NASA Space Flight Program and Project Management Handbook.
PHASE F: CLOSEOUT
Purpose
To implement the systems decommissioning/disposal plan developed in Phase E and perform analyses of
the returned data and any returned samples.
Typical Activities and Their Products
• Dispose of the system and supporting processes
• Document lessons learned
• Baseline mission final report
• Archive data
• Capture lessons learned
• Perform required Phase F technical activities from NPR 7120.5
• Satisfy Phase F reviews’ entrance/success criteria from NPR 7123.1
Reviews
• DRR


34
3.0 NASA Program/Project Life Cycle
NASA SYSTEMS ENGINEERING HANDBOOK
3.11Tailoring and Customization of NPR 7123.1 Requirements
In this section, the term requirements refers to the “shall” statements imposed from Agency directives. This discussion focuses on the tailoring of the requirements contained in NPR 7123.1.
3.11.1 Introduction
NASA policy recognizes the need to accommodate the unique aspects of each program or project to achieve mission success in an efficient and economical manner. Tailoring is a process used to accomplish this.
NPR 7123.1 defines tailoring as “the process used to seek relief from SE NPR requirements consistent with program or project objectives, allowable risk, and constraints.” Tailoring results in deviations or waivers (see NPR 7120.5, Section 3.5) to SE requirements and is documented in the next revision of the SEMP (e.g., via the Compliance Matrix).
Since NPR 7123.1 was written to accommodate programs and projects regardless of size or complexity, the NPR requirements leave considerable latitude for interpretation. Therefore, the term “customization” is introduced and is defined as “the modification of recommended SE practices that are used to accomplish the SE requirements.” Customization does not require waivers or deviations, but significant customization should be documented in the SEMP.
Tailoring and customization are essential systems engineering tools that are an accepted and expected part of establishing the proper SE NPR requirements for a program or project. Although tailoring is expected for all sizes of projects and programs, small projects present opportunities and challenges that are different from those of large, traditional projects such as the Shuttle, International Space Station, Hubble Space Telescope, and Mars Science Laboratory.
While the technical aspects of small projects are generally narrower and more focused, they can also be challenging when their objectives are to demonstrate advanced technologies or provide “one of a kind” capabilities. At the same time, their comparatively small budgets and restricted schedules dictate lean and innovative implementation approaches to project management and systems engineering. Tailoring and customization allow programs and projects to be successful in achieving technical objectives within cost and schedule constraints. The key is effective tailoring that reflects lessons learned and best practices. Tailoring the SE requirements and customizing the SE best practices to the specific needs of the project helps to obtain the desired benefits while eliminating unnecessary overhead. To accomplish this, an acceptable risk posture must be understood and agreed upon by the project, customer/stakeholder, Center management, and independent reviewers. Even with this foundation, however, the actual process of appropriately tailoring SE requirements and customizing NPR 7123.1 practices to a specific project can be complicated and arduous. Effective approaches and experienced mentors make the tailoring process for any project more systematic and efficient.
Chapter 6 of the NASA Software Engineering Handbook provides guidance on tailoring SE requirements for software projects.
3.11.2 Criteria for Tailoring
NPR 8705.4, Risk Classification for NASA Payloads, is intended for assigning a risk classification to projects and programs. It establishes baseline criteria that enable users to define the risk classification level for NASA payloads on human or non-human-rated launch systems or carrier vehicles. It is also a starting point for understanding and defining criteria for tailoring.
The extent of acceptable tailoring depends on several characteristics of the program/project such as the following:


35
3.0 NASA Program/Project Life Cycle
NASA SYSTEMS ENGINEERING HANDBOOK
1. Type of mission. For example, the requirements for a human space flight mission are much more rigorous than those for a small robotic mission.
2. Criticality of the mission in meeting the Agency
Strategic Plan. Critical missions that absolutely must be successful may not be able to get relief from NPR requirements.
3. Acceptable risk level. If the Agency and the
customer are willing to accept a higher risk of failure, some NPR requirements may be waived.
4. National significance. A project that has great
national significance may not be able to get relief from NPR requirements.
5. Complexity. Highly complex missions may require more NPR requirements in order to keep systems compatible, whereas simpler ones may not require the same level of rigor.
6. Mission lifetime. Missions with a longer lifetime need to more strictly adhere to NPR requirements than short-lived programs/projects.
7. Cost of mission. Higher cost missions may require stricter adherence to NPR requirements to ensure proper program/project control.
8. Launch constraints. If there are several launch constraints, a project may need to be more fully compliant with Agency requirements.
3.11.3 Tailoring SE NPR Requirements Using the Compliance Matrix
NPR 7123.1 includes a Compliance Matrix (Appendix H.2) to assist programs and projects in verifying that they meet the specified NPR requirements. The Compliance Matrix documents the program/project’s compliance or intent to comply with
the requirements of the NPR or justification for tailoring. The Compliance Matrix can be used to assist in identifying where major customization of the way (e.g., formality and rigor) the NPR requirements will be accomplished and to communicate that customization to the stakeholders. The tailoring process (which can occur at any time in the program or project’s life cycle) results in deviations or waivers to the NPR requirements depending on the timing of the request. Deviations and waivers of the requirements can be submitted separately to the Designated Governing Authority or via the Compliance Matrix. The Compliance Matrix is attached to the Systems Engineering Management Plan (SEMP) when submitted for approval. Alternatively, if there is no stand-alone SEMP and the contents of the SEMP are incorporated into another document such as the project plan, the Compliance Matrix can be captured within that plan.
FIGURE 3.11-1 illustrates a notional tailoring process for a space flight project. Project management (such as the project manager/the Principal Investigator/ the task lead, etc.) assembles a project team to tailor the NPR requirements codified in the Compliance Matrix. To properly classify the project, the team (chief engineer, lead systems engineer, safety and mission assurance, etc.) needs to understand the building blocks of the project such as the needs, goals, and objectives as well as the appropriate risk posture.
Through an iterative process, the project team goes through the NPR requirements in the Compliance Matrix to tailor the requirements. A tailoring tool with suggested guidelines may make the tailoring process easier if available. Several NASA Centers including LaRC and MSFC have developed tools for use at their Centers which could be adapted for other Centers. Guidance from Subject Matter Experts (SMEs) should be sought to determine the appropriate amount of tailoring for a specific project.


36
3.0 NASA Program/Project Life Cycle
NASA SYSTEMS ENGINEERING HANDBOOK
The Compliance Matrix provides rationales for each of the NPR requirements to assist in understanding. Once the tailoring is finalized and recorded in the Compliance Matrix with appropriate rationales, the requested tailoring proceeds through the appropriate governance model for approval.
3.11.4 Ways to Tailor a SE Requirement
Tailoring often comes in three areas:
1. Eliminating a requirement that does not apply to the specific program/project.
2. Eliminating a requirement that is overly burdensome (i.e., when the cost of implementing the requirement adds more risk to the project by diverting resources than the risk of not complying with the requirement).
Inputs Outputs
Project Needs, Goals, Objectives
Tailoring Tool(s)
Approved Compliance Matrix Attached to SEMP or Project Plan
Center-level
Program Office
Engineering/Projects Directorate
PM
S&MA
CE
LSE
Risk Posture
Review/ Approve
Review/ Approve
Finalize/ Update ProjectSpecific Tailoring and Capture Waiver Rationales
Advisory Teams as Necessary
Suggest Tailoring
N
N
NY
Y
Y
Project Team Review and Refine Tailoring
Review/ Approve
FIGURE 3.11-1 Notional Space Flight Products Tailoring Process
3. Scaling the requirement in a manner that better balances the cost of implementation and the project risk.
Customizing SE practices can include the following:
1. Adjusting the way each of the 17 SE processes is implemented.
2. Adjusting the formality and timing of reviews.
3.11.4.1 Non-Applicable NPR Requirements
Each requirement in NPR 7123.1 is assessed for applicability to the individual project or program. For example, if the project is to be developed completely in-house, the requirements of the NPR’s Chapter 4 on contracts would not be applicable. If a system does not contain software, then none of the NPR requirements for developing and maintaining software would be applicable.


37
3.0 NASA Program/Project Life Cycle
NASA SYSTEMS ENGINEERING HANDBOOK
3.11.4.2 Adjusting the Scope
Depending on the project or program, some relief on the scope of a requirement may be appropriate. For example, although the governing project management directive (e.g., NPR 7120.5, 7150.2, 7120.7, 7120.8) for a program/project may require certain documents to be standalone, the SE NPR does not require any additional stand-alone documents. For small projects, many of the plans can be described in just a few paragraphs or pages. In these types of projects, any NPR requirements stating that the plans need to be stand-alone document would be too burdensome. In these cases, the information can simply be written and included as part of the project plan or SEMP. If the applicable project management directive (e.g., NPR 7120.5 or NPR 7120.8) requires documents to be stand-alone, a program/project waiver/deviation is needed. However, if there is no requirement or Center expectation for a stand-alone document, a project can customize where that information is recorded and no waiver or deviation is required. Capturing where this information is documented within the systems engineering or project management Compliance Matrix would be useful for clarity.
3.11.4.3 Formality and Timing of Reviews
The governing project management directive identifies the required or recommended life cycle for the specific type of program/project. The life cycle defines the number and timing of the various reviews; however, there is considerable discretion concerning the formality of the review and how to conduct it. NPR 7123.1, Appendix G, provides extensive guidance for suggested review entrance and success criteria. It is expected that the program/ project will customize these criteria in a manner that makes sense for their program/project. The SE NPR does not require a waiver/deviation for this customization; however, departures from review elements required by other NPRs need to be addressed by tailoring those documents.
If a program/project decides it does not need one of the required reviews, a waiver or deviation is needed. However, the SE NPR does not specify a minimum amount of spacing for these reviews. A small project may decide to combine the SRR and the SDR (or Mission Definition Review (MDR)) for example. As long as the intent for both reviews is accomplished, the SE NPR does not require a waiver or deviation. (Note that even though the SE NPR does not require it, a waiver or deviation may still be required in the governing project management NPR.) This customization and/or tailoring should be documented in the Compliance Matrix and/or the review plan or SEMP.
Unless otherwise required by the governing project management directives, the formality of the review can be customized as appropriate for the type of program/project. For large projects, it might be appropriate to conduct a very formal review with a formal Review Item Discrepancy (RID)/Request for Action (RFA) process, a summary, and detailed presentations to a wide audience including boards and pre-boards over several weeks. For small projects, that same review might be done in a few hours across a tabletop with a few stakeholders and with issues and actions simply documented in a word or PowerPoint document.
The NASA Engineering Network Systems Engineering Community of Practice, located at
https://nen.nasa.gov/web/se includes document tem
plates for milestone review presentations required by the NASA SE process.
3.11.5 Examples of Tailoring and Customization
TABLE 3.11-1 shows an example of the types of missions that can be defined based on a system that breaks projects into various types ranging from a very complex type A to a much simpler type F. When tailoring a project, the assignment of specific projects to


38
3.0 NASA Program/Project Life Cycle
NASA SYSTEMS ENGINEERING HANDBOOK
TABLE 3.11-1 Example of Program/Project Types
Criteria Type A Type B Type C Type D Type E Type F
Description of the Types of Mission
Human Space Flight or Very Large Science/ Robotic Missions
Non-Human Space Flight or Science/Robotic Missions
Small Science or Robotic Missions
Smaller Science or Technology Missions (ISS payload)
Suborbital or Aircraft or Large Ground based Missions
Aircraft or Ground based technology demonstrations
Priority (Criticality to Agency Strategic Plan) and Acceptable Risk Level
High priority, very low (minimized) risk
High priority, low risk
Medium priority, medium risk
Low priority, high risk
Low priority, high risk
Low to very low priority, high risk
National Significance Very high High Medium Medium to Low Low Very Low
Complexity Very high to high High to Medium Medium to Low Medium to Low Low Low to Very Low
Mission Lifetime (Primary Baseline Mission)
Long. >5 years Medium. 2–5 years
Short. <2 years Short. <2 years N/A N/A
Cost Guidance (estimate LCC)
High (greater than ~$1B)
High to Medium (~$500M–$1B)
Medium to Low (~$100M–$500M)
Low (~$50M–$100M) (~$10–50M) (less than $10–15M)
Launch Constraints Critical Medium Few Few to none Few to none N/A
Alternative Research Opportunities or Re-flight Opportunities
No alternative or re-flight opportunities
Few or no alternative or re-flight opportunities
Some or few alternative or re-flight opportunities
Significant alternative or re-flight opportunities
Significant alternative or re-flight opportunities
Significant alternative or re-flight opportunities
Achievement of Mission Success Criteria
All practical measures are taken to achieve minimum risk to mission success. The highest assurance standards are used.
Stringent assurance standards with only minor compromises in application to maintain a low risk to mission success.
Medium risk of not achieving mission success may be acceptable. Reduced assurance standards are permitted.
Medium or significant risk of not achieving mission success is permitted. Minimal assurance standards are permitted.
Significant risk of not achieving mission success is permitted. Minimal assurance standards are permitted.
Significant risk of not achieving mission success is permitted. Minimal assurance standards are permitted.
Examples HST, Cassini, JIMO, JWST, MPCV, SLS, ISS
MER, MRO, Discovery payloads, ISS Facility Class payloads, Attached ISS payloads
ESSP, Explorer payloads, MIDES, ISS complex subrack payloads, PA-1, ARES 1-X, MEDLI, CLARREO, SAGE III, Calipso
SPARTAN, GAS Can, technology demonstrators, simple ISS, express middeck and subrack payloads, SMEX, MISSE-X, EV-2
IRVE-2, IRVE-3, HiFIRE, HyBoLT, ALHAT, STORRM, Earth Venture I
DAWNAir, InFlame, Research, technology demonstrations


39
3.0 NASA Program/Project Life Cycle
NASA SYSTEMS ENGINEERING HANDBOOK
TABLE 3.11-2 Example of Tailoring NPR 7120 5 Required Project Products
Type A Type B Type C Type D Type E Type F
Example Project Technical Products
Concept Documentation
Fully Compliant
Fully Compliant
Fully Compliant
Tailor Tailor Tailor
Mission, Spacecraft, Ground, and Payload Architectures
Fully Compliant
Fully Compliant
Fully Compliant
Tailor Tailor Tailor
Project-Level, System and Subsystem Requirements
Fully Compliant
Fully Compliant
Fully Compliant
Fully Compliant
Tailor Tailor
Design Documentation
Fully Compliant
Fully Compliant
Fully Compliant
Fully Compliant
Tailor Tailor
Operations Concept Fully
Compliant
Fully Compliant
Fully Compliant
Tailor Tailor Tailor
Technology Readiness Assessment Documentation
Fully Compliant
Fully Compliant
Fully Compliant
Tailor Tailor Tailor
Human Systems Integration Plan
Fully Compliant
Fully Compliant
Fully Compliant
Tailor Tailor Tailor
Heritage Assessment Documentation
Fully Compliant
Fully Compliant
Fully Compliant
Tailor Tailor Tailor
Safety Data Packages
Fully Compliant
Fully Compliant
Fully Compliant
Fully Compliant
Tailor Tailor
ELV Payload Safety Process Deliverables
Fully Compliant
Fully Compliant
Fully Compliant
Fully Compliant
Fully Compliant
Not Applicable
Verification and Validation Report
Fully Compliant
Fully Compliant
Fully Compliant
Tailor Tailor Tailor
Operations Handbook
Fully Compliant
Fully Compliant
Fully Compliant
Tailor Tailor Not Applicable
End of Mission Plans Fully
Compliant
Fully Compliant
Fully Compliant
Tailor Tailor Tailor
Mission Report Fully
Compliant
Fully Compliant
Tailor Tailor Tailor Tailor
particular types should be viewed as guidance, not as rigid characterization. Many projects will have characteristics of multiple types, so the tailoring approach may permit more tailoring for those aspects of the project that are simpler and more open to risk and less tailoring for those aspects of the project where
complexity and/or risk aversion dominate. These tailoring criteria and definitions of project “types” may vary from Center to Center and from Mission Directorate to Mission Directorate according to what is appropriate for their missions. TABLE 3.11-2 shows an example of how the documentation required of
(continued)


40
3.0 NASA Program/Project Life Cycle
NASA SYSTEMS ENGINEERING HANDBOOK
Type A Type B Type C Type D Type E Type F
Example Project Plan Control Plans
Risk Management Plan
Fully Compliant
Fully Compliant
Fully Compliant
Tailor Tailor Not Applicable
Technology Development plan
Fully Compliant
Fully Compliant
Fully Compliant
Fully Compliant
Not Applicable
Not Applicable
Systems Engineering Management Plan
Fully Compliant
Fully Compliant
Fully Compliant
Tailor Tailor Tailor
Software Management plan
Fully Compliant
Fully Compliant
Tailor Tailor Tailor Tailor
Verification and Validation Plan
Fully Compliant
Fully Compliant
Tailor Tailor Tailor Tailor
Review Plan Fully
Compliant
Fully Compliant
Fully Compliant
Tailor Tailor Tailor
Integrated Logistics Support Plan
Fully Compliant
Fully Compliant
Fully Compliant
Tailor Tailor Not Applicable
Science Data Management Plan
Fully Compliant
Fully Compliant
Fully Compliant
Tailor Tailor Not Applicable
Integration Plan Fully
Compliant
Fully Compliant
Fully Compliant
Fully Compliant
Tailor Tailor
Configuration Management Plan
Fully Compliant
Fully Compliant
Fully Compliant
Fully Compliant
Tailor Tailor
Technology Transfer (formerly Export) Control Plan
Fully Compliant
Fully Compliant
Fully Compliant
Fully Compliant
Tailor Tailor
Lessons Learned Plan
Fully Compliant
Fully Compliant
Fully Compliant
Fully Compliant
Tailor Tailor
Human Rating Certification Package
Fully Compliant
Not Applicable
Not Applicable
Not Applicable
Not Applicable
Not Applicable
a program/project might also be tailored or customized. The general philosophy is that the simpler, less complex projects should require much less documentation and fewer formal reviews. Project products should be sensibly scaled.
3.11.6 Approvals for Tailoring
Deviations and waivers of the requirements for the SE NPR can be submitted separately to the requirements owners or in bulk using the appropriate Compliance Matrix found in NPR 7123.1 Appendix
H. If it is a Center that is requesting tailoring of the NPR requirements for standard use at the Center, Appendix H.1 is completed and submitted to the OCE for approval upon request or as changes to the Center processes occur. If a program/project whose responsibility has been delegated to a Center is seeking a waiver/deviation from the NPR requirements, the Compliance Matrix in Appendix H.2 is used. In these cases, the Center Director or designee will approve the waiver/deviation.


41
3.0 NASA Program/Project Life Cycle
NASA SYSTEMS ENGINEERING HANDBOOK
The result of this tailoring, whether for a Center or for a program/project, should also be captured in the next revision of the SEMP along with supporting rationale and documented approvals from the requirement owner. This allows communication of the approved waivers/deviations to the entire project
team as well as associated managers. If an independent assessment is being conducted on the program/ project, this also allows appropriate modification of expectations and assessment criteria. TABLE 3.11-3 provides some examples of tailoring captured within the H.2 Compliance Matrix.
TABLE 3.11-3 Example Use of a Compliance Matrix
Req ID
SE NPR Section
Requirement Statement
Rationale Req. Owner
Comply? Justification
SE-05 2.1.5.2 For those requirements owned by Center Directors, the technical team shall complete the Compliance Matrix in Appendix H.2
and include it in the SEMP.
For programs and projects, the Compliance Matrix in Appendix H.2 is filled out showing that the program/project is compliant with the requirements of this NPR (or a particular Center’s implementation of NPR 7123.1, whichever is applicable) or any tailoring thereof is identified and approved by the Center Director or designee as part of the program/project SEMP.
CD Fully Compliant
SE-06 2.1.6.1 The DGA shall approve the SEMP, waiver authorizations, and other key technical documents to ensure independent assessment of technical content.
The DGA, who is often the TA, provides an approval of the SEMPs, waivers to technical requirements and other key technical document to provide assurance of the applicability and technical quality of the products.
CD Fully Complaint
SE-24 4.2.1 The NASA technical team shall define the engineering activities for the periods before contract award, during contract performance, and upon contract completion in the SEMP.
It is important for both the government and contractor technical teams to understand what activities will be handled by which organization throughout the product life cycle. The contractor(s) will typically develop a SEMP or its equivalent to describe the technical activities in their portion of the project, but an overarching SEMP is needed that will describe all technical activities across the life cycle whether contracted or not.
CD Not Applicable
Project is conducted entirely in-house and therefore there are no contracts involved


42
3.0 NASA Program/Project Life Cycle
NASA SYSTEMS ENGINEERING HANDBOOK


NASA SYSTEMS ENGINEERING HANDBOOK 43
4.0 System Design Processes
T
his chapter describes the activities in the system design processes listed in FIGURE 2.1-1. The chapter is separated into sections corresponding to processes 1 to 4 listed in FIGURE 2.1-1. The tasks within each process are discussed in terms of inputs, activities, and outputs. Additional guidance is provided using examples that are relevant to NASA projects.
The system design processes are interdependent, highly iterative and recursive processes resulting in a validated set of requirements and a design solution that satisfies a set of stakeholder expectations. There are four system design processes: developing stakeholder expectations, technical requirements, logical decompositions, and design solutions.
FIGURE 4.0-1 illustrates the recursive relationship among the four system design processes. These processes start with a study team collecting and clarifying the stakeholder expectations, including the mission objectives, constraints, design drivers, operational objectives, and criteria for defining mission success. This set of stakeholder expectations and high-level requirements is used to drive an iterative design loop where a straw man architecture/design, the concept of operations, and derived requirements are developed. These three products should be consistent with
each other and will require iterations and design decisions to achieve this consistency. Once consistency is achieved, analyses allow the project team to validate the proposed design against the stakeholder expectations. A simplified validation asks the questions: Will the system work as expected? Is the system achievable within budget and schedule constraints? Does the system provide the functionality and fulfill the operational needs that drove the project’s funding approval? If the answer to any of these questions is no, then changes to the design or stakeholder expectations will be required, and the process starts again. This process continues until the system—architecture, ConOps, and requirements—meets the stakeholder expectations.
The depth of the design effort should be sufficient to allow analytical verification of the design to the requirements. The design should be feasible and credible when judged by a knowledgeable independent review team and should have sufficient depth to support cost modeling and operational assessment.
Once the system meets the stakeholder expectations, the study team baselines the products and prepares for the next phase. Often, intermediate levels of decomposition are validated as part of the process. In


44
4.0 System Design Processes
NASA SYSTEMS ENGINEERING HANDBOOK
Iterate Requirements
Program Authority
Needs, Goals and Objectives
Constraints
Success Criteria
Develop ConOps
Stakeholder Expectations
Iterate ConOps Iterate Expectations
Design Solution Definition
Derived and Allocated Requirements
• Functional • Performance • Interface • Operational • Safety • “ilities”
Validate Req. Set
Req. Meet ConOps?
Inconsistencies - Iterate
Good Yes
Requirements Definition
No - Iterate
Compare
Evaluate
Success Criteria
Iterate
Lowest Level?
No – Recursive Cycle
To Product Realization Processes
Logical Decomposition
Decomposition
• Functional Flow • Temporal Flow • Behavioral • Data Flow • States and Modes
Develop Architecture
Develop Design
ConOps
FIGURE 4.0-1 Interrelationships among the System Design Processes
SYSTEM DESIGN KEYS
• Successfully understanding and defining the mission objectives and the concept of operations are keys
to capturing the stakeholder expectations, which will translate into quality requirements and operational
efficiencies over the life cycle of the project.
• Complete and thorough requirements traceability is a critical factor in successful validation of
requirements.
• Clear and unambiguous requirements will help avoid misunderstanding when developing the overall
system and when making major or minor changes.
• Document all decisions made during the development of the original design concept in the technical data
package. This will make the original design philosophy and negotiation results available to assess future
proposed changes and modifications against.
• The validation of a design solution is a continuing recursive and iterative process during which the design
solution is evaluated against stakeholder expectations.


45
4.0 System Design Processes
NASA SYSTEMS ENGINEERING HANDBOOK
the next level of decomposition, the baselined derived (and allocated) requirements become the set of highlevel requirements for the decomposed elements and the process begins again. These system design processes are primarily applied in Pre-Phase A and continue through Phase C.
The system design processes during Pre-Phase A focus on producing a feasible design that will lead to Formulation approval. During Phase A, alternative designs and additional analytical maturity are pursued to optimize the design architecture. Phase B results in a preliminary design that satisfies the approval criteria. During Phase C, detailed, build-to designs are completed.
This is a simplified description intended to demonstrate the recursive relationship among the system design processes. These processes should be used as guidance and tailored for each study team depending on the size of the project and the hierarchical level of the study team. The next sections describe each of the four system design processes and their associated products for a given NASA mission.
4.1 Stakeholder Expectations Definition
The Stakeholder Expectations Definition Process is the initial process within the SE engine that establishes the foundation from which the system is designed and the product is realized. The main purpose of this process is to identify who the stakeholders are and how they intend to use the product. This is usually accomplished through use-case scenarios (sometimes referred to as Design Reference Missions (DRMs)) and the ConOps.
4.1.1 Process Description
FIGURE 4.1-1 provides a typical flow diagram for the Stakeholder Expectations Definition Process and identifies typical inputs, outputs, and activities to consider in defining stakeholder expectations.
4.1.1.1 Inputs
Typical inputs needed for the Stakeholder Expectations Definition Process include the following:
• Initial Customer Expectations: These are the
needs, goals, objectives, desires, capabilities, and other constraints that are received from the customer for the product within the product layer. For the top-tier products (final end item), these are the expectations of the originating customer who requested the product. For an end product within the product layer, these are the expectations of the recipient of the end item when transitioned.
• Other Stakeholder Expectations: These are the
expectations of key stakeholders other than the customer. For example, such stakeholders may be the test team that will be receiving the transitioned product (end product and enabling products) or the trainers that will be instructing the operators or managers that are accountable for the product at this layer.
• Customer Flow-down Requirements: These are
any requirements that are being flowed down or allocated from a higher level (i.e., parent requirements). They are helpful in establishing the expectations of the customer at this layer.
4.1.1.2 Process Activities
4.1.1.2.1 Identify Stakeholders
A “stakeholder” is a group or individual that is affected by or has a stake in the product or project. The key players for a project/product are called the key stakeholders. One key stakeholder is always the


46
4.0 System Design Processes
NASA SYSTEMS ENGINEERING HANDBOOK
“customer.” The customer may vary depending on where the systems engineer is working in the PBS. For example, at the topmost level, the customer may be the person or organization that is purchasing the product. For a systems engineer working three or four levels down in the PBS, the customer may be the leader of the team that takes the element and integrates it into a larger assembly. Regardless of where the systems engineer is working within the PBS, it is important to understand what is expected by the customer.
Customer Flow-down Requirements
Initial Customer Expectations
Enabling Product Support Strategies
Concept of Operations
Measures of Effectiveness
Validated Stakeholder Expectations
Other Stakeholder Expectations
From Project
Establish list of stakeholders
Define stakeholder expectations in acceptable statements
Validate that defined expectation statements reflect bidirectional traceability
Elicit stakeholder expectations
Establish operations concept and support strategies
Analyze expectation statements for measures of effectiveness
Baseline stakeholder expectations
Obtain stakeholder commitments to the validated set of expectations
Capture work products from stakeholder expectations activities
To Technical Requirements Definition and Technical Data Management Processes
To Technical Requirements Definition and Configuration Management Processes
To Technical Requirements Definition and Requirements and Interface Management Processes
FIGURE 4.1-1 Stakeholder Expectations Definition Process
Other interested parties are those who affect the project by providing broad, overarching constraints within which the customers’ needs should be
achieved. These parties may be affected by the resulting product, the manner in which the product is used, or have a responsibility for providing life cycle support services. Examples include Congress, advisory planning teams, program managers, maintainers, and mission partners. It is important that the list of stakeholders be identified early in the process, as well as the primary stakeholders who will have the most significant influence over the project.
The customer and users of the system are usually easy to identify. The other key stakeholders may be more difficult to identify and they may change depending on the type of the project and the phase the project is in. TABLE 4.1-1 provides some


47
4.0 System Design Processes
NASA SYSTEMS ENGINEERING HANDBOOK
examples of stakeholders in the life cycle phase that should be considered.
4.1.1.2.2 Understand Stakeholder Expectations
Thoroughly understanding the customer and other key stakeholders’ expectations for the project/product is one of the most important steps in the systems engineering process. It provides the foundation upon which all other systems engineering work depends. It helps ensure that all parties are on the same page and that the product being provided will satisfy the customer. When the customer, other stakeholders, and the systems engineer mutually agree on the functions, characteristics, behaviors, appearance, and performance the product will exhibit, it sets more realistic expectations on the customer’s part and helps prevent significant requirements creep later in the life cycle.
Through interviews/discussions, surveys, marketing groups, e-mails, a Statement of Work (SOW), an initial set of customer requirements, or some other means, stakeholders specify what is desired as an end state or as an item to be produced and put bounds on the achievement of the goals. These bounds may
TABLE 4.1-1 Stakeholder Identification throughout the Life Cycle
Life-Cycle Stage Example Stakeholders
Pre-Phase A NASA Headquarters, NASA Centers, Presidential Directives, NASA advisory committees, the National Academy of Sciences
Phase A Mission Directorate, customer, potential users, engineering disciplines, safety organization
Phase B Customer, engineering disciplines, safety, crew, operations, logistics, production facilities, suppliers, principle investigators
Phase C Customer, engineering disciplines, safety, crew, operations, logistics, production facilities, suppliers, principle investigators
Phase D Customer, engineering disciplines, safety, crew, operations, training, logistics, verification team, Flight Readiness Board members
Phase E Customer, system managers, operations, safety, logistics, sustaining team, crew, principle investigators, users
Phase F Customer, NASA Headquarters, operators, safety, planetary protection, public
encompass expenditures (resources), time to deliver, life cycle support expectations, performance objectives, operational constraints, training goals, or other less obvious quantities such as organizational needs or geopolitical goals. This information is reviewed, summarized, and documented so that all parties can come to an agreement on the expectations.
FIGURE 4.1-2 shows the type of information needed when defining stakeholder expectations and depicts how the information evolves into a set of high-level requirements. The yellow lines depict validation paths. Examples of the types of information that would be defined during each step are also provided.
Defining stakeholder expectations begins with the mission authority and strategic objectives that the mission is meant to achieve. Mission authority changes depending on the category of the mission. For example, science missions are usually driven by NASA Science Mission Directorate strategic plans, whereas the exploration missions may be driven by a Presidential directive. Understanding the objectives of the mission helps ensure that the project team is working toward a common vision. These goals and


48
4.0 System Design Processes
NASA SYSTEMS ENGINEERING HANDBOOK
objectives form the basis for developing the mission, so they need to be clearly defined and articulated.
The project team should also identify the constraints that may apply. A “constraint” is a condition that is to be met. Sometimes a constraint is dictated by external factors such as orbital mechanics, an existing system that must be utilized (external interface), a regulatory restriction, or the state of technology; sometimes constraints are the result of the overall budget environment. Concepts of operation and constraints also need to be included in defining the stakeholder expectations. These identify how the system should be operated to achieve the mission objectives.
NOTE: It is extremely important to involve stake
holders in all phases of a project. Such involvement
should be built in as a self-correcting feedback loop
that will significantly enhance the chances of mis
sion success. Involving stakeholders in a project
builds confidence in the end product and serves as a
validation and acceptance with the target audience.
Mission Goals
Operational Drivers Measurements Mission Drivers
Explorations
Mission Objectives
Operational Objectives
Success Criteria
Design Drivers
• Agency Strategic Plans • Announcements of Opportunity • Road Maps • Directed Missions
• Science Objectives • Exploration Objectives • Technology Demonstration Objectives • Technology Development Objectives • Programmatic Objectives
• Integration and Test • Launch • On-Orbit • Transfer • Surface • Science Data Distribution • Maintenance • Logistics • Etc.
• Launch Date • Mission Duration • Orbit • Cost Constraints • Etc.
• What measurements? • How well?
• What explorations? • What goals?
FIGURE 4.1-2 Information Flow for Stakeholder Expectations
In identifying the full set of expectations, the systems engineer will need to interact with various communities, such as those working in the areas of orbital debris, space asset protection, human systems integration, quality assurance, and reliability. Ensuring that a complete set of expectations is captured will help prevent “surprise” features from arising later in the life cycle. For example, space asset protection may require additional encryption for the forward link commands, additional shielding or filtering for RF systems, use of a different frequency, or other design changes that might be costly to add to a system that has already been developed.
4.1.1.2.3 Identify Needs, Goals, and Objectives
In order to define the goals and objectives, it is necessary to elicit the needs, wants, desires, capabilities, external interfaces, assumptions, and constraints from the stakeholders. Arriving at an agreed-to set of goals and objectives can be a long and arduous task. Proactive iteration with the stakeholders throughout the systems engineering process is the way that all parties can come to a true understanding of what should be done and what it takes to do the job. It is important


49
4.0 System Design Processes
NASA SYSTEMS ENGINEERING HANDBOOK
to know who the primary stakeholders are and who has the decision authority to help resolve conflicts.
Needs, Goals, and Objectives (NGOs) provide a mechanism to ensure that everyone (implementer, customer, and other stakeholders) is in agreement at the beginning of a project in terms of defining the problem that needs to be solved and its scope. NGOs are not contractual requirements or designs.
Needs are defined in the answer to the question “What problem are we trying to solve?” Goals address what must be done to meet the needs; i.e., what the customer wants the system to do. Objectives expand on the goals and provide a means to document specific expectations. (Rationale should be provided where needed to explain why the need, goal, or objective exists, any assumptions made, and any other information useful in understanding or managing the NGO.)
Well-written NGOs provide clear traceability from the needs, then to the goals, and then to objectives. For example, if a given goal does not support a need, or an objective does not support a goal, it should not be part of the integrated set of NGOs. This traceability helps ensure that the team is actually providing what is needed.
The following definitions (source: Applied Space Systems Engineering edited by Larson, Kirkpatrick, Sellers, Thomas, and Verma) are provided to help the reader interpret the NGOs contained in this product.
• Need: A single statement that drives everything else. It should relate to the problem that the system is supposed to solve but not be the solution. The need statement is singular. Trying to satisfy more than one need requires a trade between the two, which could easily result in failing to meet at least one, and possibly several, stakeholder expectations.
• Goals: An elaboration of the need, which constitutes a specific set of expectations for the system. Goals address the critical issues identified during the problem assessment. Goals need not be in a quantitative or measurable form, but they should allow us to assess whether the system has achieved them.
• Objectives: Specific target levels of outputs the system must achieve. Each objective should relate to a particular goal. Generally, objectives should meet four criteria. (1) They should be specific enough to provide clear direction, so developers, customers, and testers will understand them. They should aim at results and reflect what the system needs to do but not outline how to implement the solution. (2) They should be measurable, quantifiable, and verifiable. The project needs to monitor the system’s success in achieving each objective. (3) They should be aggressive but attainable, challenging but reachable, and targets need to be realistic. Objectives “To Be Determined” (TBD) may be included until trade studies occur, operations concepts solidify, or technology matures. Objectives need to be feasible before requirements are written and systems designed. (4) They should be results-oriented focusing on desired outputs and outcomes, not on the methods used to achieve the target (what, not how). It is important to always remember that objectives are not requirements. Objectives are identified during pre-Phase A development and help with the eventual formulation of a requirements set, but it is the requirements themselves that are contractually binding and will be verified against the “as-built” system design.
These stakeholder expectations are captured and are considered as initial until they can be further refined through development of the concept of operations and final agreement by the stakeholders.


50
4.0 System Design Processes
NASA SYSTEMS ENGINEERING HANDBOOK
4.1.1.2.4 Establish Concept of Operations and Support Strategies
After the initial stakeholder expectations have been established, the development of a Concept of Operations (ConOps) will further ensure that the technical team fully understands the expectations and how they may be satisfied by the product, and that understanding has been agreed to by the stakeholders. This may lead to further refinement of the initial set of stakeholder expectations if gaps or ambiguous statements are discovered. These scenarios and concepts of how the system will behave provide an implementation-free understanding of the stakeholders’ expectations by defining what is expected without addressing how (the design) to satisfy the need. It captures required behavioral characteristics and the manner in which people will interact with the system. Support strategies include provisions for fabrication, test, deployment, operations, sustainment, and disposal.
The ConOps is an important component in capturing stakeholder expectations and is used in defining requirements and the architecture of a project. It stimulates the development of the requirements and architecture related to the user elements of the system. It serves as the basis for subsequent definition documents such as the operations plan, launch and early orbit plan, and operations handbook, and it provides the foundation for the long-range operational planning activities such as operational facilities, staffing, and network scheduling.
The ConOps is an important driver in the system requirements and therefore should be considered early in the system design processes. Thinking through the ConOps and use cases often reveals requirements and design functions that might otherwise be overlooked. For example, adding system requirements to allow for communication during a particular phase of a mission may require an additional antenna in a specific
location that may not be required during the nominal mission. The ConOps should include scenarios for all significant operational situations, including known off-nominal situations. To develop a useful and complete set of scenarios, important malfunctions and degraded-mode operational situations should be considered. The ConOps is also an important aide to characterizing life cycle staffing goals and function allocation between humans and systems. In walking through the accomplishment of mission objectives, it should become clear when decisions need to be made as to what the human operators are contributing vs. what the systems are responsible for delivering.
The ConOps should consider all aspects of operations including nominal and off-nominal operations during integration, test, and launch through disposal. Typical information contained in the ConOps includes a description of the major phases; operation timelines; operational scenarios and/or DRM (see FIGURE 4.1-3 for an example of a DRM); fault management strategies, description of human interaction and required training, end-to-end communications strategy; command and data architecture; operational facilities; integrated logistic support (resupply, maintenance, and assembly); staffing levels and required skill sets; and critical events. The operational scenarios describe the dynamic view of the systems’ operations and include how the system is perceived to function throughout the various modes and mode transitions, including interactions with external interfaces, response to anticipated hazard and faults, and during failure mitigations. For exploration missions, multiple DRMs make up a ConOps. The design and performance analysis leading to the requirements should satisfy all of them.
Additional information on the development of the ConOps is discussed in Section 4.1.2.1 of the NASA Expanded Guidance for Systems Engineering docu
ment found https://nen.nasa.gov/web/se/doc-repository.


51
4.0 System Design Processes
NASA SYSTEMS ENGINEERING HANDBOOK
CONCEPT OF OPERATIONS VS. OPERATIONS CONCEPT
Concept of Operations
Developed early in Pre-Phase A by the technical team, describes the overall high-level concept of how the
system will be used to meet stakeholder expectations, usually in a time sequenced manner. It describes
the system from an operational perspective and helps facilitate an understanding of the system goals. It
stimulates the development of the requirements and architecture related to the user elements of the system.
It serves as the basis for subsequent definition documents and provides the foundation for the long-range
operational planning activities.
Operations Concept
A description of how the flight system and the ground system are used together to ensure that the concept
of operation is reasonable. This might include how mission data of interest, such as engineering or scientific
data, are captured, returned to Earth, processed, made available to users, and archived for future reference.
It is typically developed by the operational team. (See NPR 7120.5.)
100 km Low Lunar Orbit
Low Earth Orbit
Ascent Stage Expended
Lunar Surface Access Module (LSAM) Crew Exploration Vehicle
Earth Departure Stage Expended
Direct or Skip Land Entry
Earth
Moon
LSAM Performs Lunar Orbit Injection
Earth Departure Stage
FIGURE 4.1-3 Example of a Lunar Sortie DRM Early in the Life Cycle


52
4.0 System Design Processes
NASA SYSTEMS ENGINEERING HANDBOOK
Appendix S contains one possible outline for developing a ConOps. The specific sections of the ConOps will vary depending on the scope and purpose of the project.
4.1.1.2.5 Define Stakeholder Expectations in Acceptable Statements
Once the ConOps has been developed, any gaps or ambiguities have been resolved, and understanding between the technical team and stakeholders about what is expected/intended for the system/product has been achieved, the expectations can be formally documented. This often comes in the form of NGOs, mission success criteria, and design drivers. These may be captured in a document, spreadsheet, model, or other form appropriate to the product.
The design drivers will be strongly dependent upon the ConOps, including the operational environment, orbit, and mission duration requirements. For science missions, the design drivers include, at a minimum, the mission launch date, duration, and orbit, as well as operational considerations. If alternative orbits are to be considered, a separate concept is needed for each orbit. Exploration missions should consider the destination, duration, operational sequence (and system configuration changes), crew interactions, maintenance and repair activities, required training, and in situ exploration activities that allow the exploration to succeed.
4.1.1.2.6 Analyze Expectations Statements for Measures of Effectiveness
The mission success criteria define what the mission needs to accomplish to be successful. This could be in the form of science missions, exploration concept for human exploration missions, or a technological goal for technology demonstration missions. The success criteria also define how well the concept measurements or exploration activities should be accomplished. The success criteria capture the stakeholder expectations and, along with programmatic
requirements and constraints, are used within the high-level requirements.
Measures of Effectiveness (MOEs) are the measures of success that are designed to correspond to accomplishment of the system objectives as defined by the stakeholder’s expectations. They are stated from the stakeholder’s point of view and represent criteria that are to be met in order for the stakeholder to consider the project successful. As such, they can be synonymous with mission/project success criteria. MOEs are developed when the NGOs or other stakeholder expectation documentation is developed. Additional information on MOEs is contained in Section 6.7.2.4 of the NASA Expanded Guidance for SE document
at https://nen.nasa.gov/web/se/doc-repository.
4.1.1.2.7 Validate That Defined Expectation Statements Reflect Bidirectional Traceability
The NGOs or other stakeholder expectation documentation should also capture the source of the expectation. Depending on the location within the product layer, the expectation may be traced to an NGO or a requirement of a higher layer product, to organizational strategic plans, or other sources. Later functions and requirements will be traced to these NGOs. The use of a requirements management tool or model or other application is particularly useful in capturing and tracing expectations and requirements.
4.1.1.2.8 Obtain Stakeholder Commitments to the Validated Set of Expectations
Once the stakeholder and the technical team are in agreement with the expressed stakeholder expectations and the concept of operations, signatures or other forms of commitment are obtained. In order to obtain these commitments, a concept review is typically held on a formal or informal basis depending on the scope and complexity of the system (see Section 6.7). The stakeholder expectations (e.g., NGOs), MOEs, and concept of operations are presented, discussed, and refined as necessary to achieve final


53
4.0 System Design Processes
NASA SYSTEMS ENGINEERING HANDBOOK
agreement. This agreement shows that both sides have committed to the development of this product.
4.1.1.2.9 Baseline Stakeholder Expectations
The set of stakeholder expectations (e.g., NGOs and MOEs) and the concept of operations that are agreed upon are now baselined. Any further changes will be required to go through a formal or informal (depending on the nature of the product) approval process involving both the stakeholder and the technical team.
4.1.1.2.10 Capture Work Products
In addition to developing, documenting, and baselining stakeholder expectations, the ConOps and MOEs discussed above and other work products from this process should be captured. These may include key decisions made, supporting decision rationale and assumptions, and lessons learned in performing these activities.
4.1.1.3 Outputs
Typical outputs for capturing stakeholder expectations include the following:
• Validated Stakeholder Expectations: These are
the agreed-to set of expectations for this product layer. They are typically captured in the form of needs, goals, and objectives with constraints and assumptions identified. They may also be in the form of models or other graphical forms.
• Concept of Operations: The ConOps describes
how the system will be operated during the life cycle phases that will meet stakeholder expectations. It describes the system characteristics from an operational perspective and helps facilitate an understanding of the system goals and objectives and other stakeholder expectations. Examples would be the ConOps document, model, or a Design Reference Mission (DRM).
• Enabling Product Support Strategies: These
include any special provisions that might be needed for fabrication, test, deployment, operations sustainment, and disposal of the end product. They identify what support will be needed and any enabling products that will need to be developed in order to generate the end product.
• Measures of Effectiveness: A set of MOEs is
developed based on the stakeholder expectations. These are measures that represent expectations that are critical to the success of the system, and failure to satisfy these measures will cause the stakeholder to deem the system unacceptable.
Other outputs that might be generated:
• Human/Systems Function Allocation: This
describes the interaction of the hardware and software systems with all personnel and their supporting infrastructure. In many designs (e.g., human space flight) human operators are a critical total-system component and the roles and responsibilities of the humans-in-the-system should be clearly understood. This should include all human/system interactions required for a mission including assembly, ground operations, logistics, in-flight and ground maintenance, in-flight operations, etc.
4.1.2 Stakeholder Expectations Definition Guidance
Refer to Section 4.1.2 in the NASA Expanded Guidance for Systems Engineering at https://nen.
nasa.gov/web/se/doc-repository for additional guid
ance on:
• Concept of Operations (including examples), • protection of space assets, and • identification of stakeholders for each phase.


54
4.0 System Design Processes
NASA SYSTEMS ENGINEERING HANDBOOK
4.2 Technical Requirements Definition
The Technical Requirements Definition Process transforms the stakeholder expectations into a definition of the problem and then into a complete set of validated technical requirements expressed as “shall” statements that can be used for defining a design solution for the Product Breakdown Structure (PBS) and related enabling products. The process of requirements definition is a recursive and iterative one that develops the stakeholders’ requirements, product requirements, and lower level product/component requirements. The requirements should enable the description of all inputs, outputs, and required relationships between inputs and outputs, including constraints, and system interactions with operators, maintainers, and other systems. The requirements documents organize and communicate requirements to the customer and other stakeholders and the technical community.
NOTE: It is important to note that the team
must not rely solely on the requirements received to
design and build the system. Communication and
iteration with the relevant stakeholders are essential
to ensure a mutual understanding of each require
ment. Otherwise, the designers run the risk of
misunderstanding and implementing an unwanted
solution to a different interpretation of the require
ments. This iterative stakeholder communication
is a critically important part of project validation.
Always confirm that the right products and results
are being developed.
Technical requirements definition activities apply to the definition of all technical requirements from the program, project, and system levels down to the lowest level product/component requirements document.
4.2.1 Process Description
FIGURE 4.2-1 provides a typical flow diagram for the Technical Requirements Definition Process and identifies typical inputs, outputs, and activities to consider in addressing technical requirements definition.
4.2.1.1 Inputs
Typical inputs needed for the requirements process include the following:
• Baselined Stakeholder Expectations: This is the
agreed-to set of stakeholder expectations (e.g., needs, goals, objectives, assumptions, constraints, external interfaces) for the product(s) of this product layer.
• Baselined Concept of Operations: This describes
how the system will be operated during the life cycle phases to meet stakeholder expectations. It describes the system characteristics from an operational perspective and helps facilitate an understanding of the system goals, objectives, and constraints. It includes scenarios, use cases, and/or Design Reference Missions (DRMs) as appropriate for the project. It may be in the form of a document, graphics, videos, models, and/or simulations.
• Baselined Enabling Support Strategies: These
describe the enabling products that were identified in the Stakeholder Expectations Definition Process as needed to develop, test, produce, operate, or dispose of the end product. They also include descriptions of how the end product will be supported throughout the life cycle.
• Measures of Effectiveness: These MOEs were
identified during the Stakeholder Expectations Definition Process as measures that the stakeholders deemed necessary to meet in order for the project to be considered a success (i.e., to meet success criteria).


55
4.0 System Design Processes
NASA SYSTEMS ENGINEERING HANDBOOK
Other inputs that might be useful in determining the technical requirements:
• Human/Systems Function Allocation: This
describes the interaction of the hardware and software systems with all personnel and their supporting infrastructure. When human operators are a critical total-system component, the roles and responsibilities of the humans-in-the-system should be clearly understood. This should include all human/system interactions required for a mission including assembly, ground operations, logistics, in-flight and ground maintenance, in-flight operations, etc.
Technical Performance Measures
Baselined Stakeholder
Expectations Validated Technical Requirements
Baselined Concept of Operations
Measures of Effectiveness
Baselined Enabling Support Strategies
From Stakeholder Expectations Definition and Configuration Management Processes
Measures of Performance
To Logical Decomposition and Technical Data Management Processes
To Technical Assessment Process
To Logical Decomposition and Requirements and Interface Management Processes
Define performance requirements for each defined functional and behavioral expectation
performance measures
Define design and product constraints
Validate technical requirements
Establish technical requirements baseline
Define functional and behavioral expectation in technical terms
Analyze scope of problem
Define technical requirements in acceptable “shall” statements
Define measures of
Define technical
performance for each measure of effectiveness
Capture work products from technical requirements definition activities
FIGURE 4.2-1 Technical Requirements Definition Process
4.2.1.2 Process Activities
4.2.1.2.1 Define Constraints, Functional and Behavioral Expectations
The top-level requirements and expectations are initially assessed to understand the technical problem to be solved (scope of the problem) and establish the design boundary. This boundary is typically established by performing the following activities:
• Defining constraints that the design needs to adhere to or that limit how the system will be used. The constraints typically cannot be changed based on trade-off analyses.
• Identifying those elements that are already under design control and cannot be changed. This helps


56
4.0 System Design Processes
NASA SYSTEMS ENGINEERING HANDBOOK
establish those areas where further trades will be made to narrow potential design solutions.
• Identifying external and enabling systems with which the system should interact and establishing physical and functional interfaces (e.g., mechanical, electrical, thermal, human, etc.).
• Defining functional and behavioral expectations for the range of anticipated uses of the system as identified in the ConOps. The ConOps describes how the system will be operated and the possible use-case scenarios.
4.2.1.2.2 Define Requirements
A complete set of project requirements includes those that are decomposed and allocated down to design elements through the PBS and those that cut across product boundaries. Requirements allocated to the PBS can be functional requirements (what functions need to be performed), performance requirements (how well these functions should be performed), and interface requirements (product to product
interaction requirements). Crosscutting requirements include environmental, safety, human factors, and those that originate from the “-ilities” and from Design and Construction (D&C) standards. FIGURE 4.2-2 is a general overview on the flow of requirements, what they are called, and who is responsible (owns) for approving waivers.
• Functional requirements define what
functions need to be performed to
accomplish the objectives.
• Performance requirements define how well
the system needs to perform the functions.
With an overall understanding of the constraints, physical/functional interfaces, and functional/behavioral expectations, the requirements can be further defined by establishing performance and other technical criteria. The expected performance is expressed as a quantitative measure to indicate how well each product function needs to be accomplished.
EXAMPLE OF FUNCTIONAL AND PERFORMANCE REQUIREMENTS
Initial Function Statement
The Thrust Vector Controller (TVC) shall provide vehicle control about the pitch and yaw axes.
This statement describes a high-level function that the TVC must perform. The technical team needs to
transform this statement into a set of design-to functional and performance requirements.
Functional Requirements with Associated Performance Requirements
• The TVC shall gimbal the engine a maximum of 9 degrees, ± 0.1 degree.
• The TVC shall gimbal the engine at a maximum rate of 5 degrees/second ± 0.3 degrees/second.
• The TVC shall provide a force of 40,000 pounds, ± 500 pounds.
• The TVC shall have a frequency response of 20 Hz, ± 0.1 Hz.


57
4.0 System Design Processes
NASA SYSTEMS ENGINEERING HANDBOOK
NOTE: Requirements can be generated from
non-obvious stakeholders and may not directly
support the current mission and its objectives, but
instead provide an opportunity to gain additional
benefits or information that can support the Agency
or the Nation. Early in the process, the systems
engineer can help identify potential areas where the
system can be used to collect unique information
that is not directly related to the primary mission.
Often outside groups are not aware of the system
goals and capabilities until it is almost too late in
the process.
Technical requirements come from a number of sources including functional, performance, interface, environmental, safety, human interfaces, standards and in support of the “’ilities” such as reliability, sustainability, producibility and others. Consideration and inclusion of all types of requirements is needed in order to form a complete and consistent set of
Program Requirements
Project Requirements
Mission Directorate Imposed Requirements
Program Imposed Requirements
Self-Imposed Derived Requirements
Self-Imposed Derived Requirements
Likewise flow to Lower Level Systems
“Programmatic” Requirements
Technical Requirements
Owned by Program/ Project
Owned by Technical Authority
All
See note*
Ownership
Type
Flow
Ex: At least one major element shall be provided by the international community.
Ex: The spacecraft shall provide a direct Earth entry capability for 11500 m/s or greater.
Ex: The spacecraft shall provide a direct Earth entry capability for 11500 m/s or greater.
Ex: The system shall have a 1.4 factor of safety
* Requirements invoked by OCE, OSMA and OCHMO directives, technical standards and Center institutional requirements
FIGURE 4.2-2 Flow, Type and Ownership of Requirements
technical requirements from which the system will be architected and designed. FIGURE 4.2-3 shows an example of parent and child requirement flowdown.
4.2.1.2.3 Define Requirements in Acceptable Statements
Finally, the requirements should be defined in acceptable “shall” statements, which are complete sentences with a single “shall” per statement. Rationale for the requirement should also be captured to ensure the reason and context of the requirement is understood. The Key Driving Requirements (KDRs) should be identified. These are requirements that can have a large impact on cost or schedule when implemented. A KDR can have any priority or criticality. Knowing the impact that a KDR has on the design allows better management of requirements.
See Appendix C for guidance and a checklist on how to write good requirements and Appendix E for validating requirements. A well-written requirements


58
4.0 System Design Processes
NASA SYSTEMS ENGINEERING HANDBOOK
document provides several specific benefits to both the stakeholders and the technical team as shown in
TABLE 4.2-1.
System Performance Requirements
Environmental and Other Design Requirements and Guidelines
Institutional Constraints
Assumptions
Implementing Organizations
Customer
Programmatics: • Cost • Schedule • Constraints • Mission Classification
Mission Objectives
System
Functional
Requirements
Subsystem A Functional and Performance Requirements
Subsystem C
Mission
Requirements
Allocated Requirements
Derived Requirements
Subsystem X Functional and Performance Requirements
Allocated Requirements
Derived Requirements
Subsystem B
...
Mission Authority
FIGURE 4.2-3 The Flowdown of Requirements
It is useful to capture information about each of the requirements, called metadata, for future reference and use. Many requirements management tools will
request or have options for storing this type of information. TABLE 4.2-2 provides examples of the types of metadata that might be useful.
4.2.1.2.4 Validate Technical Requirements
An important part of requirements definition is the validation of the requirements against the stakeholder


59
4.0 System Design Processes
NASA SYSTEMS ENGINEERING HANDBOOK
TABLE 4.2-1 Benefits of Well-Written Requirements
Benefit Rationale
Establish the basis for agreement between the stakeholders and the developers on what the product is to do
The complete description of the functions to be performed by the product specified in the requirements will assist the potential users in determining if the product specified meets their needs or how the product should be modified to meet their needs. During system design, requirements are allocated to subsystems (e.g., hardware, software, and other major components of the system), people, or processes.
Reduce the development effort because less rework is required to address poorly written, missing, and misunderstood requirements
The Technical Requirements Definition Process activities force the relevant stakeholders to rigorously consider all of the requirements before design begins. Careful review of the requirements can reveal omissions, misunderstandings, and inconsistencies early in the development cycle when these problems are easier to correct thereby reducing costly redesign, remanufacture, recoding, and retesting in later life cycle phases.
Provide a basis for estimating costs and schedules
The description of the product to be developed as given in the requirements is a realistic basis for estimating project costs and can be used to evaluate bids or price estimates.
Provide a baseline for verification and validation
Organizations can develop their verification and validation plans much more productively from a good requirements document. Both system and subsystem test plans and procedures are generated from the requirements. As part of the development, the requirements document provides a baseline against which compliance can be measured. The requirements are also used to provide the stakeholders with a basis for acceptance of the system.
Facilitate transfer The requirements make it easier to transfer the product. Stakeholders thus find it easier to transfer the product to other parts of their organization, and developers find it easier to transfer it to new stakeholders or reuse it.
Serve as a basis for enhancement
The requirements serve as a basis for later enhancement or alteration of the finished product.
TABLE 4.2-2 Requirements Metadata
Item Function
Requirement ID Provides a unique numbering system for sorting and tracking.
Rationale Provides additional information to help clarify the intent of the requirements at the time they were written. (See “Rationale” box below on what should be captured.)
Traced from Captures the bidirectional traceability between parent requirements and lower level (derived) requirements and the relationships between requirements.
Owner Person or group responsible for writing, managing, and/or approving changes to this requirement.
Verification method Captures the method of verification (test, inspection, analysis, demonstration) and should be determined as the requirements are developed.
Verification lead Person or group assigned responsibility for verifying the requirement.
Verification level Specifies the level in the hierarchy at which the requirements will be verified (e.g., system, subsystem, element).


60
4.0 System Design Processes
NASA SYSTEMS ENGINEERING HANDBOOK
RATIONALE
The rationale should be kept up to date and include the following information:
• Reason for the Requirement: Often the reason for the requirement is not obvious, and it may be lost if
not recorded as the requirement is being documented. The reason may point to a constraint or concept
of operations. If there is a clear parent requirement or trade study that explains the reason, then it should
be referenced.
• Document Assumptions: If a requirement was written assuming the completion of a technology
development program or a successful technology mission, the assumption should be documented.
• Document Relationships: The relationships with the product’s expected operations (e.g., expectations
about how stakeholders will use a product) should be documented. This may be done with a link to the
ConOps.
• Document Design Constraints: Constraints imposed by the results from decisions made as the design
evolves should be documented. If the requirement states a method of implementation, the rationale
should state why the decision was made to limit the solution to this one method of implementation.
expectations, the mission objectives and constraints, the concept of operations, and the mission success criteria. Validating requirements can be broken into six steps:
1. Are the Requirements Written Correctly?
Identify and correct requirements “shall” statement format errors and editorial errors.
2. Are the Requirements Technically Correct? A
few trained reviewers from the technical team identify and remove as many technical errors as possible before having all the relevant stakeholders review the requirements. The reviewers should check that the requirement statements (a) have bidirectional traceability to the baselined stakeholder expectations; (b) were formed using valid assumptions; and (c) are essential to and consistent with designing and realizing the appropriate product solution form that will satisfy the applicable product life cycle phase success criteria.
3. Do the Requirements Satisfy Stakeholders?
All relevant stakeholder groups identify and remove defects.
4. Are the Requirements Feasible? All require
ments should make technical sense and be possible to achieve.
5. Are the Requirements Verifiable? All require
ments should be stated in a fashion and with enough information that it will be possible to verify the requirement after the end product is implemented.
6. Are the Requirements Redundant or Over
specified? All requirements should be unique (not redundant to other requirements) and necessary to meet the required functions, performance, or behaviors.


61
4.0 System Design Processes
NASA SYSTEMS ENGINEERING HANDBOOK
Requirements validation results are often a deciding factor in whether to proceed with the next process of Logical Decomposition or Design Solution Definition. The project team should be prepared to: (1) demonstrate that the project requirements are complete and understandable; (2) demonstrate that evaluation criteria are consistent with requirements and the operations and logistics concepts; (3) confirm that requirements and MOEs are consistent with stakeholder needs; (4) demonstrate that operations and architecture concepts support mission needs, goals, objectives, assumptions, guidelines, and constraints; and (5) demonstrate that the process for managing change in requirements is established, documented in the project information repository, and communicated to stakeholders.
4.2.1.2.5 Define MOPs and TPMs
Measures of Performance (MOPs) define the performance characteristics that the system should exhibit when fielded and operated in its intended environment. MOPs are derived from the MOEs but are stated in more technical terms from the supplier’s point of view. Typically, multiple MOPs, which are quantitative and measurable, are needed to satisfy a MOE, which can be qualitative. From a verification and acceptance point of view, MOPs reflect the system characteristics deemed necessary to achieve the MOEs.
Technical Performance Measures (TPMs) are physical or functional characteristics of the system associated with or established from the MOPs that are deemed critical or key to mission success. The TPMs are monitored during implementation by comparing the current actual achievement or best estimate of the parameters with the values that were anticipated for the current time and projected for future dates. They are used to confirm progress and identify deficiencies that might jeopardize meeting a critical system requirement or put the project at cost or schedule risk.
For additional information on MOPs and TPMs, their relationship to each other and MOEs, and examples of each, see Section 6.7.2.6.2 of the NASA Expanded Guidance for SE document at https://nen.
nasa.gov/web/se/doc-repository.
4.2.1.2.6 Establish Technical Requirement Baseline
Once the technical requirements are identified and validated to be good (clear, correct, complete, and achievable) requirements, and agreement has been gained by the customer and key stakeholders, they are baselined and placed under configuration control. Typically, a System Requirements Review (SRR) is held to allow comments on any needed changes and to gain agreement on the set of requirements so that it may be subsequently baselined. For additional information on the SRR, see Section 6.7.
4.2.1.2.7 Capture Work Products
The work products generated during the above activities should be captured along with key decisions that were made, any supporting decision rationale and assumptions, and lessons learned in performing these activities.
4.2.1.3 Outputs
• Validated Technical Requirements: This is the
approved set of requirements that represents a complete description of the problem to be solved and requirements that have been validated and approved by the customer and stakeholders. Examples of documents that capture the requirements are a System Requirements Document (SRD), Project Requirements Document (PRD), Interface Requirements Document (IRD), and a Software Requirements Specification (SRS).
• Measures of Performance: These are the iden
tified quantitative measures that, when met by the design solution, help ensure that one or more MOEs will be satisfied. There may be


62
4.0 System Design Processes
NASA SYSTEMS ENGINEERING HANDBOOK
two or more MOPs for each MOE. See Section 6.7.2.6.2in the NASA Expanded Guidance for
Systems Engineering at https://nen.nasa.gov/web/
se/doc-repository for further details.
• Technical Performance Measures: These are the
set of performance measures that are monitored and trended by comparing the current actual achievement of the parameters with that expected or required at the time. TPMs are used to confirm progress and identify deficiencies. See Section 6.7.2.6.2 in the NASA Expanded Guidance for
Systems Engineering at https://nen.nasa.gov/web/
se/doc-repository for further details.
4.2.2 Technical Requirements Definition Guidance
Refer to Section 4.2.2 of the NASA Expanded Guidance for SE document at https://nen.nasa.gov/ web/se/doc-repository for additional information on:
• types of requirements, • requirements databases, and • the use of technical standards.
4.3 Logical Decomposition
Logical decomposition is the process for creating the detailed functional requirements that enable NASA programs and projects to meet the stakeholder expectations. This process identifies the “what” that should be achieved by the system at each level to enable a successful project. Logical decomposition utilizes functional analysis to create a system architecture and to decompose top-level (or parent) requirements and allocate them down to the lowest desired levels of the project.
The Logical Decomposition Process is used to:
• Improve understanding of the defined technical requirements and the relationships among
the requirements (e.g., functional, performance, behavioral, and temporal etc.), and
• Decompose the parent requirements into a set of logical decomposition models and their associated sets of derived technical requirements for input to the Design Solution Definition Process.
4.3.1 Process Description
FIGURE 4.3-1 provides a typical flow diagram for the Logical Decomposition Process and identifies typical inputs, outputs, and activities to consider in addressing logical decomposition.
4.3.1.1 Inputs
Typical inputs needed for the Logical Decomposition Process include the following:
• Technical Requirements: A validated set of
requirements that represent a description of the problem to be solved, have been established by functional and performance analysis, and have been approved by the customer and other stakeholders. Examples of documents that capture the requirements are an SRD, PRD, and IRD.
• Technical Measures: An established set of measures based on the expectations and requirements that will be tracked and assessed to determine overall system or product effectiveness and customer satisfaction. These measures are MOEs, MOPs, and a special subset of these called TPMs. See Section 6.7.2.6.2 in the NASA Expanded Guidance for Systems Engineering at https://nen.
nasa.gov/web/se/doc-repository for further details.
4.3.1.2 Process Activities
4.3.1.2.1 Define One or More Logical Decomposition Models
The key first step in the Logical Decomposition Process is establishing the system architecture model. The system architecture activity defines the


63
4.0 System Design Processes
NASA SYSTEMS ENGINEERING HANDBOOK
underlying structure and relationships of hardware, software, humans-in-the-loop, support personnel, communications, operations, etc., that provide for the implementation of Agency, mission directorate, program, project, and subsequent levels of the requirements. System architecture activities drive the partitioning of system elements and requirements to lower level functions and requirements to the point that design work can be accomplished. Interfaces and relationships between partitioned subsystems and elements are defined as well.
From Technical
and Configuration Managemen
Requirements Definition
Requirements Definition
t Processes
To Technical Data Management Process
Derived Technical Requirements
Logical Decomposition Work Products
Baselined Technical Requirements
Measures of Performance
To Design Solution and Requirements and Interface Management Processes
Logical Decomposition Models
From Technical
and Technical Data Management Processes
To Design Solution and Configuration Management Processes
Define one or more logical decomposition models
Allocate technical requirements to logical decomposition models to form a set of derived technical requirements
Resolve derived technical requirements conflicts
Validate the resulting set of derived technical requirements
Establish the derived technical requirements baseline
Capture work products from logical decomposition activities
FIGURE 4.3-1 Logical Decomposition Process
Once the top-level (or parent) functional requirements and constraints have been established, the system designer uses functional analysis to begin to formulate a conceptual system architecture. The system architecture can be seen as the strategic organization of the functional elements of the system, laid out to enable the roles, relationships, dependencies, and interfaces between elements to be clearly
defined and understood. It is strategic in its focus on the overarching structure of the system and how its elements fit together to contribute to the whole, instead of on the particular workings of the elements themselves. It enables the elements to be developed separately from each other while ensuring that they work together effectively to achieve the top-level (or parent) requirements.
Much like the other elements of functional decomposition, the development of a good system-level architecture is a creative, recursive, collaborative, and iterative process that combines an excellent understanding of the project’s end objectives and constraints with an equally good knowledge of various potential technical means of delivering the end products.
Focusing on the project’s ends, top-level (or parent) requirements, and constraints, the system architect should develop at least one, but preferably multiple,


64
4.0 System Design Processes
NASA SYSTEMS ENGINEERING HANDBOOK
concept architectures capable of achieving program objectives. Each architecture concept involves specification of the functional elements (what the pieces do), their relationships to each other (interface definition), and the ConOps, i.e., how the various segments, subsystems, elements, personnel, units, etc., will operate as a system when distributed by location and environment from the start of operations to the end of the mission.
The development process for the architectural concepts should be recursive and iterative with feedback from stakeholders and external reviewers, as well as from subsystem designers and operators, provided as often as possible to increase the likelihood of effectively achieving the program’s desired ends while reducing the likelihood of cost and schedule overruns.
In the early stages of development, multiple concepts are generated. Cost and schedule constraints will ultimately limit how long a program or project can maintain multiple architectural concepts. For all NASA programs, architecture design is completed during the Formulation Phase. For most NASA projects (and tightly coupled programs), the baselining of a single architecture happens during Phase A. Architectural changes at higher levels occasionally occur as decomposition to lower levels produces complexity in design, cost, or schedule that necessitates such changes. However, as noted in FIGURE 2.5-1, the later in the development process that changes occur, the more expensive they become.
Aside from the creative minds of the architects, there are multiple tools that can be utilized to develop a system’s architecture. These are primarily modeling and simulation tools, functional analysis tools, architecture frameworks, and trade studies. (For example, one way of doing architecture is the Department of Defense (DOD) Architecture Framework (DODAF). A search concept is developed, and analytical models of the architecture, its elements, and their operations
are developed with increased fidelity as the project evolves. Functional decomposition, requirements development, and trade studies are subsequently undertaken. Multiple iterations of these activities feed back to the evolving architectural concept as the requirements flow down and the design matures.
4.3.1.2.2 Allocate Technical Requirements, Resolve Conflicts, and Baseline
Functional analysis is the primary method used in system architecture development and functional requirement decomposition. It is the systematic process of identifying, describing, and relating the functions a system should perform to fulfill its goals and objectives. Functional analysis identifies and links system functions, trade studies, interface characteristics, and rationales to requirements. It is usually based on the ConOps for the system of interest.
Three key steps in performing functional analysis are:
1. Translate top-level requirements into functions that should be performed to accomplish the requirements.
2. Decompose and allocate the functions to lower levels of the product breakdown structure.
3. Identify and describe functional and subsystem interfaces.
The process involves analyzing each system requirement to identify all of the functions that need to be performed to meet the requirement. Each function identified is described in terms of inputs, outputs, failure modes, consequence of failure, and interface requirements. The process is repeated from the top down so that sub-functions are recognized as part of larger functional areas. Functions are arranged in a logical sequence so that any specified operational usage of the system can be traced in an end-to-end path.


65
4.0 System Design Processes
NASA SYSTEMS ENGINEERING HANDBOOK
The process is recursive and iterative and continues until all desired levels of the architecture/system have been analyzed, defined, and baselined. There will almost certainly be alternative ways to decompose functions. For example, there may be several ways to communicate with the crew: Radio Frequency (RF), laser, Internet, etc. Therefore, the outcome is highly dependent on the creativity, skills, and experience of the engineers doing the analysis. As the analysis proceeds to lower levels of the architecture and system, and the system is better understood, the systems engineer should keep an open mind and a willingness to go back and change previously established architecture and system requirements. These changes will then have to be decomposed down through the architecture and sub-functions again with the recursive process continuing until the system is fully defined with all of the requirements understood and known to be viable, verifiable, and internally consistent. Only at that point should the system architecture and requirements be baselined.
4.3.1.2.3 Capture Work Products
The other work products generated during the Logical Decomposition Process should be captured along with key decisions made, supporting decision rationale and assumptions, and lessons learned in performing the activities.
4.3.1.3 Outputs
Typical outputs of the Logical Decomposition Process include the following:
• Logical Decomposition Models: These models
define the relationship of the requirements and functions and their behaviors. They include the system architecture models that define the underlying structure and relationship of the elements of the system (e.g., hardware, software, humansin-the-loop, support personnel, communications, operations, etc.) and the basis for the partitioning
of requirements into lower levels to the point that design work can be accomplished.
• Derived Technical Requirements: These are
requirements that arise from the definitions of the selected architecture that were not explicitly stated in the baselined requirements that served as an input to this process. Both the baselined and derived requirements are allocated to the system architecture and functions.
• Logical Decomposition Work Products: These
are the other products generated by the activities of this process.
4.3.2 Logical Decomposition Guidance
Refer to Section 4.3.2 and Appendix F in the NASA Expanded Guidance for Systems Engineering at
https://nen.nasa.gov/web/se/doc-repository for addi
tional guidance on:
• Product Breakdown Structures and • Functional Analysis Techniques.
4.4 Design Solution Definition
The Design Solution Definition Process is used to translate the high-level requirements derived from the stakeholder expectations and the outputs of the Logical Decomposition Process into a design solution. This involves transforming the defined logical decomposition models and their associated sets of derived technical requirements into alternative solutions. These alternative solutions are then analyzed through detailed trade studies that result in the selection of a preferred alternative. This preferred alternative is then fully defined into a final design solution that satisfies the technical requirements. This design solution definition is used to generate the end product specifications that are used to produce


66
4.0 System Design Processes
NASA SYSTEMS ENGINEERING HANDBOOK
the product and to conduct product verification. This process may be further refined depending on whether there are additional subsystems of the end product that need to be defined.
4.4.1 Process Description
FIGURE 4.4-1 provides a typical flow diagram for the Design Solution Definition Process and identifies typical inputs, outputs, and activities to consider in addressing design solution definition.
4.4.1.1 Inputs
There are several fundamental inputs needed to initiate the Design Solution Definition Process:
* To Implementation Process
Baselined Logical Decomposition Models
System-Speci d Requirements
To Requirements and Interface Management Processes
Initial Su Specifications
bsystem
To Stakeholder Expectations Definition and Requirements and Interface Management Processes
Product Validation Plan
To Product Validation Process
Logistics and OperateTo Procedures
To Technical Data Management Process
Enabling Product Requirements
To Stakeholder Expectations Definition or Product Implementation and Requirements and Interface Management Processes
From Logical Decomposition and Configuration Management Processes
Initiate development of enabling products
No Yes
Initiate development of next lower level products
Define alternative design solutions
Analyze each alternative design solution
Select best design solution alternative
Generate full design description of the selected solution
Verify
Capture work products from design solution definition activities
the fully defined design solution
Baseline design solution specified requirements and design descriptions
No
*
Need lower level product?
Yes
*
Enabling product exists?
End Product–Specified Requirements
Product Verification Plan
To Product Verification Process
Baselined Derived Technical Requirements
FIGURE 4.4-1 Design Solution Definition Process
• Technical Requirements: These are the customer
and stakeholder needs that have been translated into a complete set of validated requirements for the system, including all interface requirements.
• Logical Decomposition Models: Requirements
are analyzed and decomposed by one or more different methods (e.g., function, time, behavior, data flow, states, modes, system architecture, etc.) in order to gain a more comprehensive understanding of their interaction and behaviors. (See the definition of a model in Appendix B.)


67
4.0 System Design Processes
NASA SYSTEMS ENGINEERING HANDBOOK
4.4.1.2 Process Activities
4.4.1.2.1 Define Alternative Design Solutions
The realization of a system over its life cycle involves a succession of decisions among alternative courses of action. If the alternatives are precisely defined and thoroughly understood to be well differentiated in the cost-effectiveness space, then the systems engineer can make choices among them with confidence.
To obtain assessments that are crisp enough to facilitate good decisions, it is often necessary to delve more deeply into the space of possible designs than has yet been done, as illustrated in FIGURE 4.4-2. It should be realized, however, that this illustration represents neither the project life cycle, which encompasses the system development process from inception through disposal, nor the product development process by which the system design is developed and implemented.
Recognize need/ opportunity
Identify and quantify goals
Create
concepts
Identify and quantify goals
Identify and quantify goals
Create
concepts
Create
concepts
Create
concepts
Identify and quantify goals
Dotrade
studies
Dotrade
studies
Dotrade
studies
Select
design
Select
design
Select
design
Select
design
Dotrade
studies
Increase
resolution
Perform mission
Implementdecisions
Increase
resolution
Increase
resolution
FIGURE 4.4-2 The Doctrine of Successive Refinement
Each “create concepts” step in FIGURE 4.4-2 involves a recursive and iterative design loop driven by the set of stakeholder expectations where a straw man architecture/design, the associated ConOps, and the derived requirements are developed and programmatic constraints such as cost and schedule are considered. These three products should be consistent with each other and will require iterations and design decisions to achieve this consistency. This recursive and iterative design loop is illustrated in FIGURE 4.0-1.
Each “create concepts” step in FIGURE 4.4-2 also involves an assessment of potential capabilities offered by the continually changing state of technology and potential pitfalls captured through experience-based review of prior program/project lessons learned data. It is imperative that there be a continual interaction between the technology development process, crosscutting processes such as human systems integration, and the design process to ensure that the design reflects the realities of the available technology and that overreliance on immature technology is avoided.
Additionally, the state of any technology that is considered enabling should be properly monitored, and care should be taken when assessing the impact of this technology on the concept performance. This interaction is facilitated through a periodic assessment of the design with respect to the maturity of the technology required to implement the design. (See Section 4.4.2.1 in the NASA Expanded Guidance
for Systems Engineering at https://nen.nasa.gov/web/
se/doc-repository for a more detailed discussion of technology assessment.) These technology elements usually exist at a lower level in the PBS. Although the process of design concept development by the integration of lower level elements is a part of the systems engineering process, there is always a danger that the top-down process cannot keep up with the bottom-up process. Therefore, system architecture issues need to be resolved early so that the system can be modeled with sufficient realism to do reliable trade studies.
As the system is realized, its particulars become clearer—but also harder to change. See the rising


68
4.0 System Design Processes
NASA SYSTEMS ENGINEERING HANDBOOK
“Cost to Change Design Direction” in FIGURE 2.5-1. The purpose of systems engineering is to make sure that the Design Solution Definition Process happens in a way that leads to the most functional, safe, and cost-effective final system while working within any given schedule boundaries. The basic idea is that before those decisions that are hard to undo are made, the alternatives should be carefully and iteratively assessed, particularly with respect both to the maturity of the required technology and to stakeholder expectations for efficient, effective operations.
4.4.1.2.2 Create Alternative Design Concepts
Once it is understood what the system is to accomplish, it is possible to devise a variety of ways that those goals can be met. Sometimes, that comes about as a consequence of considering alternative functional allocations and integrating available subsystem design options, all of which can have technologies at varying degrees of maturity. Ideally, as wide a range of plausible alternatives as is consistent with the design organization’s charter should be defined, keeping in mind the current stage in the process of successive refinement. When the bottom-up process is operating, a problem for the systems engineer is that the designers tend to become fond of the designs they create, so they lose their objectivity; the systems engineer should stay an “outsider” so that there is more objectivity. This is particularly true in the assessment of the technological maturity of the subsystems and components required for implementation. There is a tendency on the part of technology developers and project management to overestimate the maturity and applicability of a technology that is required to implement a design. This is especially true of “heritage” equipment. The result is that critical aspects of systems engineering are often overlooked.
The creation of alternative design solutions involves assessment of potential capabilities offered by the continually changing state of technology. A continual
interaction between the technology development process and the design process ensures that the design reflects the realities of the available technology. This interaction is facilitated through periodic assessment of the design with respect to the maturity of the technology required to implement the design.
After identifying the technology gaps existing in a given design concept, it is frequently necessary to undertake technology development in order to ascertain viability. Given that resources will always be limited, it is necessary to pursue only the most promising technologies that are required to enable a given concept.
If requirements are defined without fully understanding the resources required to accomplish needed technology developments, then the program/project is at risk. Technology assessment should be done iteratively until requirements and available resources are aligned within an acceptable risk posture. Technology development plays a far greater role in the life cycle of a program/project than has been traditionally considered, and it is the role of the systems engineer to develop an understanding of the extent of program/ project impacts—maximizing benefits and minimizing adverse effects. Traditionally, from a program/ project perspective, technology development has been associated with the development and incorporation of any “new” technology necessary to meet requirements. However, a frequently overlooked area is that associated with the modification of “heritage” systems incorporated into different architectures and operating in different environments from the ones for which they were designed. If the required modifications and/or operating environments fall outside the realm of experience, then these too should be considered technology development.
To understand whether or not technology development is required—and to subsequently quantify the


69
4.0 System Design Processes
NASA SYSTEMS ENGINEERING HANDBOOK
associated cost, schedule, and risk—it is necessary to systematically assess the maturity of each system, subsystem, or component in terms of the architecture and operational environment. It is then necessary to assess what is required in the way of development to advance the maturity to a point where it can successfully be incorporated within cost, schedule, and performance constraints. A process for accomplishing this assessment is described in Appendix G. Because technology development has the potential for such significant impacts on a program/project, technology assessment needs to play a role throughout the design and development process from concept development through Preliminary Design Review (PDR). Lessons learned from a technology development point of view should then be captured in the final phase of the program.
On the first turn of the successive refinement in FIGURE 4.4-2, the subject is often general approaches or strategies, sometimes architectural concepts. On the next, it is likely to be functional design, then detailed design, and so on. The reason for avoiding a premature focus on a single design is to permit discovery of the truly best design. Part of the systems engineer’s job is to ensure that the design concepts to be compared take into account all interface requirements. Characteristic questions include: “Did you include the cabling?” or “Did you consider how the maintainers can repair the system?” When possible, each design concept should be described in terms of controllable design parameters so that each represents as wide a class of designs as is reasonable. In doing so, the systems engineer should keep in mind that the potentials for change may include organizational structure, personnel constraints, schedules, procedures, and any of the other things that make up a system. When possible, constraints should also be described by parameters.
4.4.1.2.3 Analyze Each Alternative Design Solution
The technical team analyzes how well each of the design alternatives meets the system objectives (technology gaps, effectiveness, technical achievability, performance, cost, schedule, and risk, both quantified and otherwise). This assessment is accomplished through the use of trade studies. The purpose of the trade study process is to ensure that the system architecture, intended operations (i.e., the ConOps) and design decisions move toward the best solution that can be achieved with the available resources. The basic steps in that process are:
• Devise some alternative means to meet the functional requirements. In the early phases of the project life cycle, this means focusing on system architectures; in later phases, emphasis is given to system designs.
• Evaluate these alternatives in terms of the MOPs and system life cycle cost. Mathematical models are useful in this step not only for forcing recognition of the relationships among the outcome variables, but also for helping to determine what the MOPs should be quantitatively.
• Rank the alternatives according to appropriate selection criteria.
• Drop less promising alternatives and proceed to the next level of resolution, if needed.
The trade study process should be done openly and inclusively. While quantitative techniques and rules are used, subjectivity also plays a significant role. To make the process work effectively, participants should have open minds, and individuals with different skills—systems engineers, design engineers, crosscutting specialty discipline and domain engineers, program analysts, system end users, decision scientists, maintainers, operators, and project


70
4.0 System Design Processes
NASA SYSTEMS ENGINEERING HANDBOOK
managers—should cooperate. The right quantitative methods and selection criteria should be used. Trade study assumptions, models, and results should be documented as part of the project archives. The participants should remain focused on the functional requirements, including those for enabling products. For an in-depth discussion of the trade study process, see Section 6.8. The ability to perform these studies is enhanced by the development of system models that relate the design parameters to those assessments, but it does not depend upon them.
The technical team should consider a broad range of concepts when developing the system model. The model should define the roles of crew, operators, maintainers, logistics, hardware, and software in the system. It should identify the critical technologies required to implement the mission and should consider the entire life cycle from fabrication to disposal. Evaluation criteria for selecting concepts should be established. Cost is always a limiting factor. However, other criteria, such as time to develop and certify a unit, risk, and reliability, also are critical. This stage cannot be accomplished without addressing the roles of operators and maintainers. These contribute significantly to life cycle costs and to the system reliability. Reliability analysis should be performed based upon estimates of component failure rates for hardware and an understanding of the consequences of these failures. If probabilistic risk assessment models are applied, it may be necessary to include occurrence rates or probabilities for software faults or human error events. These models should include hazard analyses and controls implemented through fault management. Assessments of the maturity of the required technology should be done and a technology development plan developed.
Controlled modification and development of design concepts, together with such system models, often permits the use of formal optimization techniques
to find regions of the design space that warrant further investigation.
Whether system models are used or not, the design concepts are developed, modified, reassessed, and compared against competing alternatives in a closedloop process that seeks the best choices for further development. System and subsystem sizes are often determined during the trade studies. The end result is the determination of bounds on the relative cost-effectiveness of the design alternatives, measured in terms of the quantified system goals. (Only bounds, rather than final values, are possible because determination of the final details of the design is intentionally deferred.) Increasing detail associated with the continually improving resolution reduces the spread between upper and lower bounds as the process proceeds.
4.4.1.2.4 Select the Best Design Solution Alternative
The technical team selects the best design solution from among the alternative design concepts, taking into account subjective factors that the team was unable to quantify, such as robustness, as well as estimates of how well the alternatives meet the quantitative requirements; the maturity of the available technology; and any effectiveness, cost, schedule, risk, or other constraints.
The Decision Analysis Process, as described in Section 6.8, should be used to make an evaluation of the alternative design concepts and to recommend the “best” design solution.
When it is possible, it is usually well worth the trouble to develop a mathematical expression, called an “objective function,” that expresses the values of combinations of possible outcomes as a single measure of cost-effectiveness, as illustrated in FIGURE 4.4-3, even if both cost and effectiveness should be described by more than one measure.


71
4.0 System Design Processes
NASA SYSTEMS ENGINEERING HANDBOOK
B
C
A
Life-Cycle Cost, Expressed in Constant Dollars
Some Aspect of Effectiveness,
Expressed in Quantitative Units
FIGURE 4.4-3 A Quantitative Objective Function, Dependent on Life Cycle Cost and All Aspects of Effectiveness
Note: The different shaded areas indicate different levels of uncertainty Dashed lines represent constant values of objective function (cost-effectiveness) Higher values of costeffectiveness are achieved by moving toward upper left A, B, and C are design concepts with different risk patterns
The objective function (or “cost function”) assigns a real number to candidate solutions or “feasible solutions” in the alternative space or “search space.” A feasible solution that minimizes (or maximizes, if that is the goal) the objective function is called an “optimal solution.” When achievement of the goals can be quantitatively expressed by such an objective function, designs can be compared in terms of their value. Risks associated with design concepts can cause these evaluations to be somewhat nebulous because they are uncertain and are best described by probability distributions.
In FIGURE 4.4-3, the risks are relatively high for design concept A. There is little risk in either effectiveness or cost for concept B, while the risk of an expensive failure is high for concept C, as is shown by the cloud of probability near the x axis with a high cost and essentially no effectiveness. Schedule factors
may affect the effectiveness and cost values and the risk distributions.
The mission success criteria for systems differ significantly. In some cases, effectiveness goals may be much more important than all others. Other projects may demand low costs, have an immutable schedule, or require minimization of some kinds of risks. Rarely (if ever) is it possible to produce a combined quantitative measure that relates all of the important factors, even if it is expressed as a vector with several components. Even when that can be done, it is essential that the underlying actors and relationships be thoroughly revealed to and understood by the systems engineer. The systems engineer should weigh the importance of the unquantifiable factors along with the quantitative data.
Technical reviews of the data and analyses, including technology maturity assessments, are an important part of the decision support packages prepared for the technical team. The decisions that are made are generally entered into the configuration management system as changes to (or elaborations of) the system baseline. The supporting trade studies are archived for future use. An essential feature of the systems engineering process is that trade studies are performed before decisions are made. They can then be baselined with much more confidence.
4.4.1.2.5 Increase the Resolution of the Design
The successive refinement process of FIGURE 4.4-2 illustrates a continuing refinement of the system design. At each level of decomposition, the baselined derived (and allocated) requirements become the set of high-level requirements for the decomposed elements, and the process begins again. One might ask, “When do we stop refining the design?” The answer is that the design effort proceeds to a depth that is sufficient to meet several needs: the design should penetrate sufficiently to allow analytical validation


72
4.0 System Design Processes
NASA SYSTEMS ENGINEERING HANDBOOK
of the design to the requirements and ConOps; it should also have sufficient depth to support cost and operations modeling and to convince a review team of a feasible design with performance, cost, and risk margins.
The systems engineering engine is applied again and again as the system is developed. As the system is realized, the issues addressed evolve and the particulars of the activity change. Most of the major system decisions (goals, architecture, acceptable life cycle cost, etc.) are made during the early phases of the project, so the successive refinements do not correspond precisely to the phases of the system life cycle. Much of the system architecture can be seen even at the outset, so the successive refinements do not correspond exactly to development of the architectural hierarchy either. Rather, they correspond to the successively greater resolution by which the system is defined.
It is reasonable to expect the system to be defined with better resolution as time passes. This tendency is formalized at some point (in Phase B) by defining a baseline system definition. Usually, the goals, objectives, and constraints are baselined as the requirements portion of the baseline. The entire baseline is then placed under configuration control in an attempt to ensure that any subsequent changes are indeed justified and affordable.
At this point in the systems engineering process, there is a logical branch point. For those issues for which the process of successive refinement has proceeded far enough, the next step is to implement the decisions at that level of resolution. For those issues that are still insufficiently resolved, the next step is to refine the development further.
4.4.1.2.6 Fully Describe the Design Solution
Once the preferred design alternative has been selected and the proper level of refinement has been
completed, then the design is fully defined into a final design solution that will satisfy the technical requirements and ConOps. The design solution definition will be used to generate the end product specifications that will be used to produce the product and to conduct product verification. This process may be further refined depending on whether there are additional subsystems of the end product that need to be defined.
The scope and content of the full design description should be appropriate for the product life cycle phase, the phase success criteria, and the product position in the PBS (system structure). Depending on these factors, the form of the design solution definition could be simply a simulation model or a paper study report. The technical data package evolves from phase to phase, starting with conceptual sketches or models and ending with complete drawings, parts list, and other details needed for product implementation or product integration. Typical output definitions from the Design Solution Definition Process are shown in
FIGURE 4.4-1 and are described in Section 4.4.1.3.
4.4.1.2.7 Verify the Design Solution
Once an acceptable design solution has been selected from among the various alternative designs and documented in a technical data package, the design solution should next be verified against the system requirements and constraints. A method to achieve this verification is by means of a peer review to evaluate the resulting design solution definition. Guidelines for conducting a peer review are discussed in Section 6.7.2.4.5.
In addition, peer reviews play a significant role as a detailed technical component of higher level technical and programmatic reviews. For example, the peer review of a component battery design can go into much more technical detail on the battery than the integrated power subsystem review. Peer reviews


73
4.0 System Design Processes
NASA SYSTEMS ENGINEERING HANDBOOK
can cover the components of a subsystem down to the level appropriate for verifying the design against the requirements. Concerns raised at the peer review might have implications on the power subsystem design and verification and therefore should be reported at the next higher level review of the power subsystem.
The verification should show that the design solution definition:
• Is realizable within the constraints imposed on the technical effort;
• Has specified requirements that are stated in acceptable statements and have bidirectional traceability with the technical requirements and stakeholder expectations; and
• Has decisions and assumptions made in forming the solution consistent with its set of technical requirements and identified system product and service constraints.
This design solution verification is in contrast to the verification of the end product described in the end product verification plan which is part of the technical data package. That verification occurs in a later life cycle phase and is a result of the Product Verification Process (see Section 5.3) applied to the realization of the design solution as an end product.
4.4.1.2.8 Validate the Design Solution
The validation of the design solution is a recursive and iterative process as shown in FIGURE 4.0-1. Each alternative design concept is validated against the set of stakeholder expectations. The stakeholder expectations drive the iterative design loop in which a straw man architecture/design, the ConOps, and the derived requirements are developed. These three
products should be consistent with each other and will require iterations and design decisions to achieve this consistency. Once consistency is achieved, functional analyses allow the study team to validate the design against the stakeholder expectations. A simplified validation asks the questions: Does the system work as expected? How does the system respond to failures, faults, and anomalies? Is the system affordable? If the answer to any of these questions is no, then changes to the design or stakeholder expectations will be required, and the process is started over again. This process continues until the systemarchitecture, ConOps, and requirements—meets the stakeholder expectations.
This design solution validation is in contrast to the validation of the end product described in the end-product validation plan, which is part of the technical data package. That validation occurs in a later life cycle phase and is a result of the Product Validation Process (see Section 5.4) applied to the realization of the design solution as an end product.
4.4.1.2.9 Identify Enabling Products
Enabling products are the life cycle support products and services (e.g., production, test, deployment, training, maintenance, and disposal) that facilitate the progression and use of the operational end product through its life cycle. Since the end product and its enabling products are interdependent, they are viewed as a system. Project responsibility thus extends to responsibility for acquiring services from the relevant enabling products in each life cycle phase. When a suitable enabling product does not already exist, the project that is responsible for the end product can also be responsible for creating and using the enabling product.
Therefore, an important activity in the Design Solution Definition Process is the identification of the enabling products and personnel that will be required


74
4.0 System Design Processes
NASA SYSTEMS ENGINEERING HANDBOOK
during the life cycle of the selected design solution and then initiating the acquisition or development of those enabling products and personnel. Need dates for the enabling products should be realistically identified on the project schedules, incorporating appropriate schedule slack. Then firm commitments in the form of contracts, agreements, and/or operational plans should be put in place to ensure that the enabling products will be available when needed to support the product life cycle phase activities. The enabling product requirements are documented as part of the technical data package for the Design Solution Definition Process.
An environmental test chamber is an example of an enabling product whose use would be acquired at an appropriate time during the test phase of a space flight system.
Special test fixtures or special mechanical handling devices are examples of enabling products that would have to be created by the project. Because of long development times as well as oversubscribed facilities, it is important to identify enabling products and secure the commitments for them as early in the design phase as possible.
4.4.1.2.10 Baseline the Design Solution
As shown earlier in FIGURE 4.0-1, once the selected system design solution meets the stakeholder expectations, the study team baselines the products and prepares for the next life cycle phase. Because of the recursive nature of successive refinement, intermediate levels of decomposition are often validated and baselined as part of the process. In the next level of decomposition, the baselined requirements become the set of high-level requirements for the decomposed elements, and the process begins again.
Baselining a particular design solution enables the technical team to focus on one design out of all the
alternative design concepts. This is a critical point in the design process. It puts a stake in the ground and gets everyone on the design team focused on the same concept. When dealing with complex systems, it is difficult for team members to design their portion of the system if the system design is a moving target. The baselined design is documented and placed under configuration control. This includes the system requirements, specifications, and configuration descriptions.
While baselining a design is beneficial to the design process, there is a danger if it is exercised too early in the Design Solution Definition Process. The early exploration of alternative designs should be free and open to a wide range of ideas, concepts, and implementations. Baselining too early takes the inventive nature out of the concept exploration. Therefore, baselining should be one of the last steps in the Design Solution Definition Process.
4.4.1.3 Outputs
Outputs of the Design Solution Definition Process are the specifications and plans that are passed on to the product realization processes. They contain the design-to, build-to, train-to, and code-to documentation that complies with the approved baseline for the system.
As mentioned earlier, the scope and content of the full design description should be appropriate for the product life cycle phase, the phase success criteria, and the product position in the PBS.
Outputs of the Design Solution Definition Process include the following:
• The System Specification: The system spec
ification contains the functional baseline for the system that is the result of the Design Solution Definition Process. The system design


75
4.0 System Design Processes
NASA SYSTEMS ENGINEERING HANDBOOK
specification provides sufficient guidance, constraints, and system requirements for the design engineers to begin developing the design.
• The System External Interface Specifications:
The system external interface specifications describe the functional baseline for the behavior and characteristics of all physical interfaces that the system has with the external world. These include all structural, thermal, electrical, and signal interfaces, as well as the human-system interfaces.
• The End-Product Specifications: The end-prod
uct specifications contain the detailed build-to and code-to requirements for the end product. They are detailed, exact statements of design particulars, such as statements prescribing materials, dimensions, and quality of work to build, install, or manufacture the end product.
• The End-Product Interface Specifications: The
end-product interface specifications contain the detailed build-to and code-to requirements for the behavior and characteristics of all logical and physical interfaces that the end product has with external elements, including the human-system interfaces.
• Initial Subsystem Specifications: The end-prod
uct subsystem initial specifications provide detailed information on subsystems if they are required.
• Enabling Product Requirements: The require
ments for associated supporting enabling products provide details of all enabling products. Enabling products are the life cycle support products, infrastructures, personnel, logistics, and services that facilitate the progression and use of the operational end product through its life cycle. They are
viewed as part of the system since the end product and its enabling products are interdependent.
• Product Verification Plan: The end-product ver
ification plan (generated through the Technical Planning Process) provides the content and depth of detail necessary to provide full visibility of all verification activities for the end product. Depending on the scope of the end product, the plan encompasses qualification, acceptance, prelaunch, operational, and disposal verification activities for flight hardware and software.
• Product Validation Plan: The end-product val
idation plan (generated through the Technical Planning Process) provides the content and depth of detail necessary to provide full visibility of all activities to validate the end product against the baselined stakeholder expectations. The plan identifies the type of validation, the validation procedures, and the validation environment that are appropriate to confirm that the realized end product conforms to stakeholder expectations.
• Logistics and Operate-to Procedures: The appli
cable logistics and operate-to procedures for the system describe such things as handling, transportation, maintenance, long-term storage, and operational considerations for the particular design solution.
Other outputs may include:
• Human Systems Integration Plan: The system
HSI Plan should be updated to indicate the numbers, skills, and development (i.e., training) required for humans throughout the full life cycle deployment and operations of the system.


76
4.0 System Design Processes
NASA SYSTEMS ENGINEERING HANDBOOK
4.4.2 Design Solution Definition Guidance
Refer to Section 4.4.2 in the NASA Expanded Guidance for Systems Engineering at https://nen.nasa.
gov/web/se/doc-repository for additional guidance on:
• technology assessment, • human capability assessment, and • integrating engineering specialties into the SE process.


NASA SYSTEMS ENGINEERING HANDBOOK 77
5.0 Product Realization
T
his chapter describes the activities in the product realization processes listed in FIGURE 2.1-1. The chapter is separated into sections corresponding to steps 5 through 9 listed in FIGURE 2.1-1. The processes within each step are discussed in terms of the inputs, the activities, and the outputs. Additional guidance is provided using examples that are relevant to NASA projects.
In the product realization side of the SE engine, five interdependent processes result in systems that meet the design specifications and stakeholder expectations. These products are produced, acquired, reused, or coded; integrated into higher level assemblies; verified against design specifications; validated against stakeholder expectations; and transitioned to the next level of the system. As has been mentioned in previous sections, products can be models and simulations, paper studies or proposals, or hardware and software. The type and level of product depends on the phase of the life cycle and the product’s specific objectives. But whatever the product, all should effectively use the processes to ensure the system meets the intended operational concept.
This effort starts with the technical team taking the output from the system design processes and using
the appropriate crosscutting functions, such as data and configuration management, and technical assessments to make, buy, or reuse subsystems. Once these subsystems are realized, they should be integrated to the appropriate level as designated by the appropriate interface requirements. These products are then verified through the Technical Assessment Process to ensure that they are consistent with the technical data package and that “the product was built right.” Once consistency is achieved, the technical team validates the products against the stakeholder expectations to ensure that “the right product was built.” Upon successful completion of validation, the products are transitioned to the next level of the system. FIGURE 5.0-1 illustrates these processes.
This is an iterative and recursive process. Early in the life cycle, paper products, models, and simulations are run through the five realization processes. As the system matures and progresses through the life cycle, hardware and software products are run through these processes. It is important to detect as many errors and failures as possible at the lowest level of integration and early in the life cycle so that changes can be made through the design processes with minimum impact to the project.


78
5.0 Product Realization
NASA SYSTEMS ENGINEERING HANDBOOK
The next sections describe each of the five product realization processes and their associated products for a given NASA mission.
DESIGN REALIZATION
PRODUCT TRANSITION PROCESS
EVALUATION PROCESSES
• Acquire • Make/Code • Reuse
Product Implementation
Product Integration
Product Verification
Product Validation
Product Transition
• Assembly • Functional Evaluation
• Functional • Environmental • Operational Testing in Integration & Test Environment
• Operational Testing in Mission Environment
• Delivery to Next Higher Level in PBS • Delivery to Operational System
FIGURE 5.0-1 Product Realization
PRODUCT REALIZATION KEYS
• Define and execute production activities.
• Generate and manage requirements for off-the-shelf hardware/software products as for all other products.
• Understand the differences between verification testing and validation testing.
• Consider all customer, stakeholder, technical, programmatic, and safety requirements when evaluating
the input necessary to achieve a successful product transition.
• Analyze for any potential incompatibilities with interfaces as early as possible.
• Completely understand and analyze all test data for trends and anomalies.
• Understand the limitations of the testing and any assumptions that are made.
• Ensure that a reused product meets the verification and validation required for the relevant system in
which it is to be used, as opposed to relying on the original verification and validation it met for the
system of its original use. Then ensure that it meets the same verification and validation as a purchased
product or a built product. The “pedigree” of a reused product in its original application should not be
relied upon in a different system, subsystem, or application.
from the bottom of the product hierarchy up towards
5.1 Product Implementation
Product implementation is the first process encountered in the SE engine that begins the movement
the Product Transition Process. This is where the plans, designs, analysis, requirements development, and drawings are realized into actual products.
Product implementation is used to generate a specified product of a project or activity through buying, making/coding, or reusing previously developed


79
5.0 Product Realization
NASA SYSTEMS ENGINEERING HANDBOOK
hardware, software, models, or studies to generate a product appropriate for the phase of the life cycle. The product should satisfy the design solution and its specified requirements.
The Product Implementation Process is the key activity that moves the project from plans and designs into realized products. Depending on the project and life cycle phase within the project, the product may be hardware, software, a model, simulations, mockups, study reports, or other tangible results. These products may be realized through their purchase from commercial or other vendors, through partial or complete reuse of products from other projects or activities, or they may be generated from scratch. The decision as to which of these realization strategies or combination of strategies will be used for the products of this project will have been made early in the life cycle using the Decision Analysis Process.
5.1.1 Process Description
FIGURE 5.1-1 provides a typical flow diagram for the Product Implementation Process and identifies typical inputs, outputs, and activities to consider in addressing product implementation.
5.1.1.1 Inputs
Inputs to the Product Implementation Process depend primarily on the decision about whether the end product will be purchased, developed from scratch, or formed by reusing part or all of products from other projects. Typical inputs are shown in
FIGURE 5.1-1.
End Product Documents and Manuals
From Configuration Management Process
Desired End Product
To Product Verification Process
End Product Design Specifications and Configuration Documentation
Product ImplementationEnabling Products
To Technical Data Management Process
Product Implementation Work Products
From existing resources or Product Transition Process
Required Raw Materials
From existing resources or external sources
Make the specified end product
Capture work products from product implementation activities
Prepare to conduct implementation
If implemented by buying:
Participate in purchase of specified end product
Prepare appropriate product support documentation
If implemented by reuse:
Participate in acquiring the reuse end product
If implemented by making: Evaluate readiness of product implementationenabling products
FIGURE 5.1-1 Product Implementation Process
• Inputs If Purchasing the End Product: If the
decision was made to purchase part or all of the products for this project, the end product design specifications are obtained from the configuration management system as well as other applicable documents.


80
5.0 Product Realization
NASA SYSTEMS ENGINEERING HANDBOOK
• Inputs If Making/Coding the End Product: For
end products that will be made/coded by the technical team, the inputs will be the configuration-controlled design specifications, manufacturing plans, manufacturing processes, manufacturing procedures, and raw materials as provided to or purchased by the project.
• Inputs Needed If Reusing an End Product: For
end products that will reuse part or all of products generated by other projects, the inputs may be the documentation associated with the product as well as the product itself. Care should be taken to ensure that these products will indeed meet the specifications and environments for this project. These would have been factors involved in the Decision Analysis Process to determine the make/ buy/reuse decision.
• Enabling Products: These would be any enabling products necessary to make, code, purchase, or reuse the product (e.g., drilling fixtures, production facilities, production lines, software development facilities, software test facilities, system integration and test facilities).
5.1.1.2 Process Activities
Implementing the product can take one of three forms:
1. Purchase/buy 2. Make/code 3. Reuse
These three forms will be discussed in the following subsections. FIGURE 5.1-1 shows what kind of inputs, outputs, and activities are performed during product implementation regardless of where in the product hierarchy or life cycle it is. These activities include preparing to conduct the implementation, purchasing/
making/reusing the product, and capturing the product implementation work product. In some cases, implementing a product may have aspects of more than one of these forms (such as a build-to-print). In those cases, the appropriate aspects of the applicable forms are used.
5.1.1.2.1 Prepare to Conduct Implementation
Preparing to conduct the product implementation is a key first step regardless of what form of implementation has been selected. For complex projects, implementation strategy and detailed planning or procedures need to be developed and documented. For less complex projects, the implementation strategy and planning need to be discussed, approved, and documented as appropriate for the complexity of the project.
The documentation, specifications, and other inputs also need to be reviewed to ensure they are ready and at an appropriate level of detail to adequately complete the type of implementation form being employed and for the product life cycle phase. For example, if the “make” implementation form is being employed, the design specifications need to be reviewed to ensure they are at a design-to level that allows the product to be developed. If the product is to be bought as a pure Commercial Off-the-Shelf (COTS) item, the specifications need to be checked to make sure they adequately describe the vendor characteristics to narrow to a single make/model of their product line.
Finally, the availability and skills of personnel needed to conduct the implementation as well as the availability of any necessary raw materials, enabling products, or special services should also be reviewed. Any special training necessary for the personnel to perform their tasks needs to be performed by this time. This is a key part of the Acceptance Data Package.


81
5.0 Product Realization
NASA SYSTEMS ENGINEERING HANDBOOK
5.1.1.2.2 Purchase, Make, or Reuse the Product
Purchase the Product
In the first case, the end product is to be purchased from a commercial or other vendor. Design/purchase specifications will have been generated during requirements development and provided as inputs. The technical team needs to review these specifications and ensure they are in a form adequate for the contract or purchase order. This may include the generation of contracts, Statements of Work (SOWs), requests for proposals, purchase orders, or other purchasing mechanisms. For major end products purchased from a vendor, the responsibilities of the Government and contractor team should be documented in the SEMP and Integration Plan. This will define, for example, whether NASA expects the vendor to provide a fully verified and validated product or whether the NASA technical team will be performing those duties. The team needs to work with the acquisition team to ensure the accuracy of the contract SOW or purchase order and to ensure that adequate documentation, certificates of compliance, or other specific needs are requested from the vendor.
For contracted purchases, as proposals come back from the vendors, the technical team should work with the contracting officer and participate in the review of the technical information and in the selection of the vendor that best meets the design requirements for acceptable cost and schedule.
As the purchased products arrive, the technical team should assist in the inspection of the delivered product and its accompanying documentation. The team should ensure that the requested product was indeed the one delivered, and that all necessary documentation, such as source code, operator manuals, certificates of compliance, safety information, or drawings have been received.
The NASA technical team should also ensure that any enabling products necessary to provide test, operations, maintenance, and disposal support for the product are also ready or provided as defined in the contract.
Depending on the strategy and roles/responsibilities of the vendor, a determination/analysis of the vendor’s verification and validation compliance may need to be reviewed. This may be done informally or formally as appropriate for the complexity of the product. For products that were verified and validated by the vendor, after ensuring that all work products from this phase have been captured, the product may be ready to enter the Product Transition Process to be delivered to the next higher level or to its final end user. For products that the technical team will verify and validate, the product will be ready for verification after ensuring that all work products for this phase have been captured.
Make/Code the Product
If the strategy is to make or code the product, the technical team should first ensure that the enabling products are ready. This may include ensuring all piece parts are available, drawings are complete and adequate, software design is complete and reviewed, machines to cut the material are available, interface specifications are approved, operators are trained and available, manufacturing and/or coding procedures/ processes are ready, software personnel are trained and available to generate code, test fixtures are developed and ready to hold products while being generated, and software test cases are available and ready to begin model generation.
The product is then made or coded in accordance with the specified requirements, configuration documentation, and applicable standards. Software development must be consistent with NPR 7150.2, NASA Software Engineering Requirements. Throughout


82
5.0 Product Realization
NASA SYSTEMS ENGINEERING HANDBOOK
this process, the technical team should work with the quality organization to review, inspect, and discuss progress and status within the team and with higher levels of management as appropriate. Progress should be documented within the technical schedules. Peer reviews, audits, unit testing, code inspections, simulation checkout, and other techniques may be used to ensure the made or coded product is ready for the verification process. Some production and coding can also be separately contracted. This is sometimes pursued as a cost control feature providing motivation for the design contractor to keep the operations costs low and not roll costs into the operations phase of a long-term contract. This is also valuable when the design contractor is not well suited for long-term continuing production operations. Small projects and activities often use small manufacturing shops to fabricate the system or major portions and small software companies to code their software. In these cases, the production and software engineers may specify some portion of the hardware production or software coding and request the remaining portions, including as-built documentation, from the manufacturing or software provider. The specified portions are contained as part of the contract statement of work in these cases. The level of process control and information provided to or from the vendor is dependent on the criticality of the systems obtained. As production proceeds and components are produced, there is a need to establish a method (Material Review Boards (MRBs) are typically used for large projects) to review any nonconformance to specifications and disposition whether the components can be accepted, reworked, or scrapped and remade.
Reuse
If the strategy is to reuse a product that already exists, extreme care should be taken to ensure that the product is truly applicable to this project and for the intended uses and the environment in which it will be used. This should have been a major factor
used in the decision strategy to make/buy/reuse. If the new environment is more extreme, requalification is needed for the component or system. Design factors of safety, margins, and other required design and construction standards should also be assessed. If the program/project requires higher factor of safety or margins, the component may not be usable or a waiver may have to be approved.
The documentation available (e.g., as-built documentation, user’s guides, operations manuals, discrepancy reports, waivers and deviations) from the reuse product should be reviewed by the technical team so that they can become completely familiar with the product and ensure it will meet the requirements in the intended environment. Any supporting manuals, drawings, or other documentation available should also be gathered.
The availability of any supporting or enabling products or infrastructure needed to complete the fabrication, coding, testing, analysis, verification, validation, or shipping of the product needs to be determined. Supporting products may be found in product manufacturing plans, processes, and procedures. If any of these products or services are lacking, they will need to be developed or arranged for before progressing to the next phase.
Special arrangements may need to be made or forms such as nondisclosure agreements may need to be acquired before the reuse product can be received.
A reused product often needs to undergo the same verification and validation as a purchased product or a built product. Relying on prior verification and validation should only be considered if the product’s verification and validation documentation meets or exceeds the verification, validation, and documentation requirements of the current project and the documentation demonstrates that the product was


83
5.0 Product Realization
NASA SYSTEMS ENGINEERING HANDBOOK
verified and validated against equivalent requirements (including environments) and expectations. The savings gained from reuse is not necessarily from reduced acceptance-level testing of the flight products, but possibly elimination of the need to fully requalify the item (if all elements are the same, including the environment and operation), elimination of the need to specify all of the internal requirements such as printed circuit board specifications or material requirements, reduced internal data products, or the confidence that the item will pass acceptance test and will not require rework.
5.1.1.2.3 Capture Work Products
Regardless of what implementation form was selected, all work products from the make/buy/reuse process should be captured, including as-built design drawings, design documentation, design models, code listings, model descriptions, procedures used, operator manuals, maintenance manuals, or other documentation as appropriate.
5.1.1.3 Outputs
• End Product for Verification: Unless the vendor
performs verification, the made/coded, purchased, or reused end product in a form appropriate for the life cycle phase is provided for the verification process. The form of the end product is a function of the life cycle phase and the placement within the system structure (the form of the end product could be hardware, software, model, prototype, first article for test, or single operational article or multiple production articles).
• End Product Documents and Manuals:
Appropriate documentation is also delivered with the end product to the verification process and to the technical data management process. Documentation may include applicable as-built design drawings; close out photos; operation, user, maintenance, or training manuals; applicable
baseline documents (configuration information such as as-built specifications or stakeholder expectations); certificates of compliance; or other vendor documentation.
• Product Implementation Work Products: Any
additional work products providing reports, records, lesson learned, assumptions, updated CM products, and other outcomes of these activities.
The process is complete when the following activities have been accomplished:
• End products are fabricated, purchased, or reuse modules are acquired.
• End products are reviewed, checked, and ready for verification.
• Procedures, decisions, assumptions, anomalies, corrective actions, lessons learned, etc., resulting from the make/buy/reuse are recorded.
5.1.2 Product Implementation Guidance
Refer to Section 5.1.2 in the NASA Expanded Guidance for Systems Engineering at https://nen.
nasa.gov/web/se/doc-repository for additional guid
ance on:
• buying off-the-shelf products and • the need to consider the heritage of products.
5.2 Product Integration
Product integration is a key activity of the systems engineer. Product integration is the engineering of the subsystem interactions and their interactions with the system environments (both natural and induced). Also in this process, lower-level products are assembled into higher-level products and checked


84
5.0 Product Realization
NASA SYSTEMS ENGINEERING HANDBOOK
to make sure that the integrated product functions properly and that there are no adverse emergent behaviors. This integration begins during concept definition and continues throughout the system life cycle. Integration involves several activities focused on the interactions of the subsystems and environments. These include system analysis to define and understand the interactions, development testing including qualification testing, and integration with external systems (e.g., launch operations centers, space vehicles, mission operations centers, flight control centers, and aircraft) and objects (i.e., planetary bodies or structures). To accomplish this integration, the systems engineer is active in integrating the different discipline and design teams to ensure system and environmental interactions are being properly balanced by the differing design teams. The result of a well-integrated and balanced system is an elegant design and operation.
Integration begins with concept development, ensuring that the system concept has all necessary functions and major elements and that the induced and natural environment domains in which the system is expected to operate are all identified. Integration continues during requirements development, ensuring that all system and environmental requirements are compatible and that the system has a proper balance of functional utility to produce a robust and efficient system. Interfaces are defined in this phase and are the pathway of system interactions. Interfaces include mechanical (i.e., structure, loads), fluids, thermal, electrical, data, logical (i.e., algorithms and software), and human. These interfaces may include support for assembly, maintenance, and testing functions in addition to the system main performance functions. The interactions that occur through all of these interfaces can be subtle and complex, leading to both intended and unintended consequences. All of these interactions need to be engineered to produce an elegant and balanced system.
Integration during the design phase continues the engineering of these interactions and requires constant analysis and management of the subsystem functions and the subsystem interactions between themselves and with their environments. Analysis of the system interactions and managing the balance of the system is the central function of the systems engineer during the design process. The system needs to create and maintain a balance between the subsystems, optimizing the system performance over any one subsystem to achieve an elegant and efficient design. The design phase often involves development testing at the component, assembly, or system level. This is a key source of data on system interactions, and the developmental test program should be structured to include subsystem interactions, human-inthe-loop evaluations, and environmental interaction test data as appropriate.
Integration continues during the operations phase, bringing together the system hardware, software, and human operators to perform the mission. The interactions between these three integrated natures of the system need to be managed throughout development and into operations for mission success. The systems engineer, program manager, and the operations team (including the flight crew from crewed missions) need to work together to perform this management. The systems engineer is not only cognizant of these operations team interactions, but is also involved in the design responses and updates to changes in mission parameters and unintended consequences (through fault management).
Finally, integration or de-integration occurs during system closeout (i.e., decommissioning and disposal). The system capabilities to support de-integration and/or disposal need to be engineered into the system from the concept definition phase. The closeout phase involves the safe disposal of flight assets consistent with U.S. policy and law and international


85
5.0 Product Realization
NASA SYSTEMS ENGINEERING HANDBOOK
treaties. This disposal can involve the safe reentry and recovery or impact in the ocean, impact on the moon, or solar trajectory. This can also involve the disassembly or repurposing of terrestrial equipment used in manufacturing, assembly, launch, and flight operations. Dispositioning of recovered flight assets also occurs during this phase. Capture of system data and archiving for use in future analysis also occurs. In all of these activities, the systems engineer is involved in ensuring a smooth and logical disassembly of the system and associated program assets.
The Product Integration Process applies not only to hardware and software systems but also to service-oriented solutions, requirements, specifications, plans, and concepts. The ultimate purpose of product integration is to ensure that the system elements function as a whole.
Product integration involves many activities that need to be planned early in the program or project in order to effectively and timely accomplish the integration. Some integration activities (such as system tests) can require many years of work and costs that need to be identified and approved through the budget cycles. An integration plan should be developed and documented to capture this planning. Small projects and activities may be able to include this as part of their SEMP. Some activities may have their integration plans captured under the integration plan of the sponsoring flight program or R&T program. Larger programs and projects need to have a separate integration plan to clearly lay out the complex analysis and tests that need to occur. An example outline for a separate integration plan is provided in Appendix H.
During project closeout, a separate closeout plan should be produced describing the decommissioning and disposal of program assets. (For example, see National Space Transportation System (NSTS) 60576, Space Shuttle Program, Transition Management
Plan). For smaller projects and activities, particularly with short life cycles (i.e., short mission durations), the closeout plans may be contained in the SEMP.
5.2.1 Process Description
FIGURE 5.2-1 provides a typical flow diagram for the Product Integration Process and identifies typical inputs, outputs, and activities to consider in addressing product integration. The activities of the Product Integration Process are truncated to indicate the action and object of the action.
5.2.1.1 Inputs
• Lower-level products to be integrated: These are
the products developed in the previous lower-level tier in the product hierarchy. These products will be integrated/assembled to generate the product for this product layer.
• End product design specifications and config
uration documentation: These are the specifi
cations, Interface Control Documents (ICDs), drawings, integration plan, procedures, or other documentation or models needed to perform the integration including documentation for each of the lower-level products to be integrated.
• Product integration-enabling products: These
would include any enabling products, such as holding fixtures, necessary to successfully integrate the lower-level products to create the end product for this product layer.
5.2.1.2 Process Activities
This subsection addresses the approach to the implementation of the Product Integration Process, including the activities required to support the process. The basic tasks that need to be established involve the management of internal and external interactions of the various levels of products and operator tasks to support product integration and are as follows:


86
5.0 Product Realization
NASA SYSTEMS ENGINEERING HANDBOOK
Product Documents and Manuals
To Product Verification Process
Lower Level Products to Be Integrated
End Product Design Specifications and Configuration Documentation
Product IntegrationEnabling Products
To Technical Data Management Process
From Product Transition Process
From Configuration Management Process
From existing resources or Product Transition Process
Integrated Product
Product Integration Work Products
Confirm that received products have been validated
Prepare the integration environment for assembly and integration
Assemble and integrate the received products into the desired end product
Obtain lower level products for assembly and integration
Capture work products from product integration activities
Prepare to conduct product integration
Prepare appropriate product support documentation
FIGURE 5.2-1 Product Integration Process
5.2.1.2.1 Prepare to Conduct Product Integration
Prepare to conduct product integration by (1) reviewing the product integration strategy/plan (see Section 6.1.2.4.4), generating detailed planning for the integration, and developing integration sequences and procedures; and (2) determining whether the product configuration documentation is adequate to conduct the type of product integration applicable for the product life cycle phase, location of the product in the system structure, and management phase success criteria.
An integration strategy is developed and documented in an integration plan. This plan, as well as supporting documentation, identifies the optimal sequence
of receipt, assembly, and activation of the various components that make up the system. This strategy should use technical, cost, and schedule factors to ensure an assembly, activation, and loading sequence that minimizes cost and assembly difficulties. The larger or more complex the system or the more delicate the element, the more critical the proper sequence becomes, as small changes can cause large impacts on project results.
The optimal sequence of assembly is built from the bottom up as components become sub-elements, elements, and subsystems, each of which should be checked prior to fitting it into the next higher assembly. The sequence will encompass any effort needed


87
5.0 Product Realization
NASA SYSTEMS ENGINEERING HANDBOOK
to establish and equip the assembly facilities; e.g., raised floor, hoists, jigs, test equipment, input/output, and power connections. Once established, the sequence should be periodically reviewed to ensure that variations in production and delivery schedules have not had an adverse impact on the sequence or compromised the factors on which earlier decisions were made.
5.2.1.2.2 Obtain Lower-Level Products for Assembly and Integration
Each of the lower-level products that is needed for assembly and integration is obtained from the transitioning lower-level product owners or a storage facility as appropriate. Received products should be inspected to ensure no damages occurred during the transitioning process.
5.2.1.2.3 Confirm That Received Products Have Been Validated
Confirm that the received products that are to be assembled and integrated have been validated to demonstrate that the individual products satisfy the agreed-to set of stakeholder expectations, including interface requirements. This validation can be conducted by the receiving organization or by the providing organization if fully documented or witnessed by the receiving representative.
5.2.1.2.4 Prepare the Integration Environment for Assembly and Integration
Prepare the integration environment in which assembly and integration will take place, including evaluating the readiness of the product integration-enabling products and the assigned workforce. These enabling products may include facilities, equipment jigs, tooling, and assembly/production lines. The integration environment includes test equipment, simulators, models, storage areas, and recording devices.
5.2.1.2.5 Assemble and Integrate the Received Products into the Desired End Product
Assemble and integrate the received products into the desired end product in accordance with the specified requirements, configuration documentation, interface requirements, applicable standards, and integration sequencing and procedures. This activity includes managing, evaluating, and controlling physical, functional, and data interfaces among the products being integrated.
Functional testing of the assembled or integrated unit is conducted to ensure that assembly is ready to enter verification testing and ready to be integrated into the next level. Typically, all or key representative functions are checked to ensure that the assembled system is functioning as expected. Formal product verification and validation will be performed in the next process.
5.2.1.2.6 Prepare Appropriate Product Support Documentation
Prepare appropriate product support documentation, such as special procedures for performing product verification and product validation. Drawings or accurate models of the assembled system are developed and confirmed to be representative of the assembled system.
5.2.1.2.7 Capture Product Integration Work Products Capture work products and related information generated while performing the Product Integration Process activities. These work products include system models, system analysis data and assessment reports, derived requirements, the procedures that were used in the assembly, decisions made and supporting rationale, assumptions that were made, identified anomalies and associated corrective actions, lessons learned in performing the assembly, and updated product configuration and support documentation.


88
5.0 Product Realization
NASA SYSTEMS ENGINEERING HANDBOOK
5.2.1.3 Outputs
The following are typical outputs from this process and destinations for the products from this process:
• Integrated product(s) with all system interactions identified and properly balanced.
• Documentation and manuals, including system
analysis models, data, and reports supporting flight-readiness rationale and available for future analysis during the operation of the system in the mission-execution phase.
• Work products, including reports, records, and non-deliverable outcomes of product integration activities (to support the Technical Data Management Process); integration strategy document; assembly/check area drawings; system/ component documentation sequences and rationale for selected assemblies; interface management documentation; personnel requirements; special handling requirements; system documentation; shipping schedules; test equipment and drivers’ requirements; emulator requirements; and identification of limitations for both hardware and software.
5.2.2 Product Integration Guidance
Refer to Section 5.2.2 in the NASA Expanded Guidance for Systems Engineering at https://nen.nasa.
gov/web/se/doc-repository for additional guidance on:
• product integration strategies, • the relationship to product implementation, • product integration support, • product integration of the design solution, • system analysis, and • interface system integration.
5.3 Product Verification
The Product Verification Process is the first of the verification and validation processes conducted on an end product. As used in the context of the systems engineering common technical processes, a product is one provided by either the Product Implementation Process or the Product Integration Process in a form suitable for meeting applicable life cycle phase success criteria. Realization is the act of implementing, integrating, verifying, validating, and transitioning the end product for use at the next level up of the system structure or to the customer. At this point, the end product can be referred to as a “realized product” or “realized end product.”
Product verification proves that an end product (whether built, coded, bought, or reused) for any element within the system structure conforms to its requirements or specifications. Such specifications and other design description documentation establish the configuration baseline of that product, which may have to be modified at a later time. Without a verified baseline and appropriate configuration controls, such later modifications could be costly or cause major performance problems.
From a process perspective, product verification and validation may be similar in nature, but the objectives are fundamentally different. A customer is interested in whether the end product provided will do what the customer intended within the environment of use. Examination of this condition is validation. Simply put, the Product Verification Process answers the critical question, “Was the end product realized right?” The Product Validation Process addresses the equally critical question, “Was the right end product realized?” When cost effective and warranted by analysis, the expense of validation testing alone can be mitigated by combining tests to perform verification and validation simultaneously.


89
5.0 Product Realization
NASA SYSTEMS ENGINEERING HANDBOOK
The outcome of the Product Verification Process is confirmation that the end product, whether achieved by implementation or integration, conforms to its specified requirements, i.e., verification of the end product. This subsection discusses the process activities, inputs, outcomes, and potential product deficiencies.
DIFFERENCES BETWEEN VERIFICATION AND VALIDATION TESTING
Testing is a detailed evaluation method of both verification and validation
Verification Testing: Verification testing relates back to the approved requirements set (such as an SRD)
and can be performed at different stages in the product life cycle. Verification tests are the official “for
the record” testing performed on a system or element to show that it meets its allocated requirements
or specifications including physical and functional interfaces. Verification tests use instrumentation and
measurements and are generally accomplished by engineers, technicians, or operator-maintainer test
personnel in a controlled environment to facilitate failure analysis.
Validation Testing: Validation relates back to the ConOps document. Validation testing is conducted
under realistic conditions (or simulated conditions) on any end product to determine the effectiveness and
suitability of the product for use in mission operations by typical users and to evaluate the results of such
tests. It ensures that the system is operating as expected when placed in a realistic environment.
5.3.1 Process Description
FIGURE 5.3-1, taken from NPR 7123.1, provides a typical flow diagram for the Product Verification Process and identifies typical inputs, outputs, and activities to consider in addressing product verification.
5.3.1.1 Inputs
Key inputs to the process are:
• The product to be verified: This product
will have been transitioned from either the Product Implementation Process or the Product Integration Process. The product will likely have been through at least a functional test to ensure
it was assembled correctly. Any supporting documentation should be supplied with the product.
• Verification plan: This plan will have been developed under the Technical Planning Process and baselined before entering this verification.
• Specified requirements baseline: These are the
requirements that have been identified to be verified for this product. Acceptance criteria should have been identified for each requirement to be verified.
• Enabling products: Any other products needed to perform the Product Verification Process. This may include test fixtures and support equipment.
Additional work products such as the ConOps, mission needs and goals, interface control drawings, testing standards and policies, and Agency standards and policies may also be needed to put verification activities into context.


90
5.0 Product Realization
NASA SYSTEMS ENGINEERING HANDBOOK
DIFFERENCES BETWEEN VERIFICATION, QUALIFICATION, ACCEPTANCE AND CERTIFICATION
Verification: Verification is a formal process, using the method of test, analysis, inspection or
demonstration, to confirm that a system and its associated hardware and software components satisfy all
specified requirements. The Verification program is performed once regardless of how many flight units may
be generated (as long as the design doesn’t change).
Qualification: Qualification activities are performed to ensure that the flight unit design will meet functional
and performance requirements in anticipated environmental conditions. A subset of the verification program
is performed at the extremes of the environmental envelope and will ensure the design will operate properly
with the expected margins. Qualification is performed once regardless of how many flight units may be
generated (as long as the design doesn’t change).
Acceptance: smaller subset of the verification program is selected as criteria for the acceptance program.
The selected Acceptance activities are performed on each of the flight units as they are manufactured and
readied for flight/use. An Acceptance Data Package is prepared for each of the flight units and shipped with
the unit. The acceptance test/analysis criteria are selected to show that the manufacturing/workmanship of
the unit conforms to the design that was previously verified/qualified. Acceptance testing is performed for
each flight unit produced.
Certification: Certification is the audit process by which the body of evidence that results from the
verification activities and other activities are provided to the appropriate certifying authority to indicate the
design is certified for flight/use. The Certification activity is performed once regardless of how many flight
units may be generated.
5.3.1.2 Process Activities
There are five major activities in the Product Verification Process: (1) prepare to conduct product verification; (2) perform verification; (3) analyze verification results; (4) preparing a product verification report; and (5) capture work products generated during the verification activities.
Product Verification is often performed by the developer that produced the end product with participation of the end user and customer. Quality Assurance
(QA) personnel are also critical in the verification planning and execution activities.
A verification approach should be adapted (tailored) to the project it supports. The project manager and systems engineer should work with the verification lead engineer to develop a verification approach and plan the activities. Many factors need to be considered in developing this approach and the subsequent verification program. These factors include: