Principles of Nano-Optics
First published in 2006, this book has become the standard reference on nano-optics. Now in its second edition, the text has been thoroughly updated to take into account new developments and research directions. While the overall structure and pedagogical style of the book remain unchanged, all existing chapters have been expanded and a new chapter has been added. Adopting a broad perspective, the authors provide a detailed overview of the theoretical and experimental concepts that are needed to understand and work in nano-optics, across subfields ranging from quantum optics to biophysics. New topics of discussion include optical antennas, new imaging techniques, Fano interference and strong coupling, reciprocity, metamaterials, and cavity optomechanics. With numerous end-of-chapter problem sets and illustrative material to expand on ideas discussed in the main text, this is an ideal textbook for graduate students entering the field. It is also a valuable reference for researchers and course teachers.
LUKAS NOVOTNY is Professor of Optics and Physics at the University of Rochester, New York, where he heads the Nano-Optics Research Group at the Institute of Optics. He received his Ph.D. from the Swiss Federal Institute of Technology (ETH Zürich) in Switzerland and later joined the Pacific Northwest National Laboratory (Washington, WA) as a research fellow. In 1999, he joined the faculty of the Institute of Optics at the University of Rochester and developed a course on nano-optics that has been taught several times at the graduate level and forms the basis of this textbook. In 2012, he joined the ETH Zürich.
BERT HECHT is Professor of Experimental Physics at the University of Würzburg. After studying physics at the University of Konstanz, he joined the IBM Zurich Research Laboratory in Rüschlikon and worked in near-field optical microscopy and plasmonics. In 1996, he received his Ph.D. from the University of Basel and then joined the Physical Chemistry Laboratory of the Swiss Federal Institute of Technology, where he worked on the combination of single-molecule spectroscopy with scanning probe techniques. In 2001, he was awarded a Swiss National Science Foundation research professorship at the University of Basel. His research interests concern the enhancement of light–matter interaction on the nanometer scale.




Principles of Nano-Optics
Second Edition
LUKAS NOVOTNY
University of Rochester, New York
ETH Zürich, Switzerland
BERT HECHT
Universität Würzburg, Germany


CAMBRIDGE UNIVERSITY PRESS Cambridge, New York, Melbourne, Madrid, Cape Town, Singapore, São Paulo, Delhi, Mexico City
Cambridge University Press The Edinburgh Building, Cambridge CB2 8RU, UK
Published in the United States of America by Cambridge University Press, New York
www.cambridge.org Information on this title: www.cambridge.org/9781107005464
©c L. Novotny and B. Hecht 2012
This publication is in copyright. Subject to statutory exception and to the provisions of relevant collective licensing agreements, no reproduction of any part may take place without the written permission of Cambridge University Press.
First published 2006 Second edition 2012
Printed in the United Kingdom at the University Press, Cambridge
A catalog record for this publication is available from the British Library
Library of Congress Catalog in Publication data Novotny, Lukas. Principles of nano-optics / Lukas Novotny, University of Rochester, New York, Bert Hecht, Universität Wiirzburg, Germany. – Second Edition. p. cm. ISBN 978-1-107-00546-4 (hardback) 1. Nanostructured materials. 2. Near-field microscopy. 3. Quantum optics. 4. Photonics. 5. Nanophotonics. I. Hecht, Bert, 1968– II. Title. TA418.9.N35N68 2012 535′.15–dc23 2012005672
ISBN 978-1-107-00546-4 Hardback
Cambridge University Press has no responsibility for the persistence or accuracy of URLs for external or third-party internet websites referred to in this publication, and does not guarantee that any content on such websites is, or will remain, accurate or appropriate.


To our families (Jessica, Leonore, Jakob, David, Rahel, Rebecca, Nadja, Jan)
and our parents
(Annemarie, Werner, Miloslav, Vera)
. . . it was worth the climb (B. B. Goldberg)




Contents
Preface to the first edition page xv Preface to the second edition xvii
1 Introduction 1 1.1 Nano-optics in a nutshell 3 1.2 Historical survey 4 1.3 Scope of the book 7 References 9
2 Theoretical foundations 12 2.1 Macroscopic electrodynamics 12 2.2 Wave equations 14 2.3 Constitutive relations 14 2.4 Spectral representation of time-dependent fields 15 2.5 Fields as complex analytic signals 16 2.6 Time-harmonic fields 16 2.7 Longitudinal and transverse fields 17 2.8 Complex dielectric constant 18 2.9 Piecewise homogeneous media 18 2.10 Boundary conditions 19 2.10.1 Fresnel reflection and transmission coefficients 20 2.11 Conservation of energy 22 2.12 Dyadic Green functions 25 2.12.1 Mathematical basis of Green functions 25 2.12.2 Derivation of the Green function for the electric field 27 2.12.3 Time-dependent Green functions 30 2.13 Reciprocity 31 2.14 Evanescent fields 32 2.14.1 Energy transport by evanescent waves 34 2.14.2 Frustrated total internal reflection 36 2.15 Angular spectrum representation of optical fields 38 2.15.1 Angular spectrum representation of the dipole field 41 Problems 42 References 43 vii


viii Contents
3 Propagation and focusing of optical fields 45 3.1 Field propagators 45 3.2 Paraxial approximation of optical fields 47 3.2.1 Gaussian laser beams 47 3.2.2 Higher-order laser modes 49 3.2.3 Longitudinal fields in the focal region 50 3.3 Polarized electric and polarized magnetic fields 52 3.4 Far-fields in the angular spectrum representation 53 3.5 Focusing of fields 56 3.6 Focal fields 60 3.7 Focusing of higher-order laser modes 64 3.8 The limit of weak focusing 68 3.9 Focusing near planar interfaces 70 3.10 The reflected image of a strongly focused spot 75 Problems 82 References 84
4 Resolution and localization 86 4.1 The point-spread function 86 4.2 The resolution limit(s) 92 4.2.1 Increasing resolution through selective excitation 94 4.2.2 Axial resolution 96 4.2.3 Resolution enhancement through saturation 98 4.3 Principles of confocal microscopy 100 4.4 Axial resolution in multiphoton microscopy 105 4.5 Localization and position accuracy 106 4.5.1 Theoretical background 107 4.5.2 Estimating the uncertainties of fit parameters 110 4.6 Principles of near-field optical microscopy 114 4.6.1 Information transfer from near-field to far-field 118 4.7 Structured-illumination microscopy 122 Problems 126 References 128
5 Nanoscale optical microscopy 131 5.1 The interaction series 131 5.2 Far-field optical microscopy techniques 134 5.2.1 Confocal microscopy 134 5.2.2 The solid immersion lens 143 5.2.3 Localization microscopy 145 5.3 Near-field excitation microscopy 148 5.3.1 Aperture scanning near-field optical microscopy 148 5.4 Near-field detection microscopy 150 5.4.1 Scanning tunneling optical microscopy 150


ix Contents
5.4.2 Field-enhanced near-field microscopy with crossed polarization 153 5.5 Near-field excitation and detection microscopy 154 5.5.1 Field-enhanced near-field microscopy 154 5.5.2 Double-passage near-field microscopy 159 5.6 Conclusion 160 Problems 160 References 161
6 Localization of light with near-field probes 165 6.1 Light propagation in a conical transparent dielectric probe 165 6.2 Fabrication of transparent dielectric probes 166 6.2.1 Tapered optical fibers 167 6.3 Aperture probes 170 6.3.1 Power transmission through aperture probes 171 6.3.2 Field distribution near small apertures 176 6.3.3 Field distribution near aperture probes 181 6.3.4 Enhancement of transmission and directionality 182 6.4 Fabrication of aperture probes 184 6.4.1 Aperture formation by focused-ion-beam milling 186 6.4.2 Alternative aperture-formation schemes 187 6.5 Optical antenna probes 188 6.5.1 Solid metal tips 188 6.6 Conclusion 195 Problems 196 References 197
7 Probe–sample distance control 201 7.1 Shear-force methods 202 7.1.1 Optical fibers as resonating beams 202 7.1.2 Tuning-fork sensors 205 7.1.3 The effective-harmonic-oscillator model 206 7.1.4 Response time 209 7.1.5 Equivalent electric circuit 211 7.2 Normal-force methods 213 7.2.1 Tuning fork in tapping mode 213 7.2.2 Bent-fiber probes 214 7.3 Topographic artifacts 214 7.3.1 Phenomenological theory of artifacts 216 7.3.2 Example of optical artifacts 219 7.3.3 Discussion 220 Problems 221 References 221


x Contents
8 Optical interactions 224 8.1 The multipole expansion 224 8.2 The classical particle–field Hamiltonian 228 8.2.1 Multipole expansion of the interaction Hamiltonian 231 8.3 The radiating electric dipole 233 8.3.1 Electric dipole fields in a homogeneous space 234 8.3.2 Dipole radiation 238 8.3.3 Rate of energy dissipation in inhomogeneous environments 239 8.3.4 Radiation reaction 240 8.4 Spontaneous decay 242 8.4.1 QED of spontaneous decay 243 8.4.2 Spontaneous decay and Green’s dyadics 245 8.4.3 Local density of states 248 8.5 Classical lifetimes and decay rates 249 8.5.1 Radiation in homogeneous environments 249 8.5.2 Radiation in inhomogeneous environments 254 8.5.3 Frequency shifts 254 8.6 Dipole–dipole interactions and energy transfer 256 8.6.1 Multipole expansion of the Coulombic interaction 256 8.6.2 Energy transfer between two particles 257 8.7 Strong coupling (delocalized excitations) 264 8.7.1 Coupled oscillators 265 8.7.2 Adiabatic and diabatic transitions 267 8.7.3 Coupled two-level systems 272 8.7.4 Entanglement 276 Problems 277 References 279
9 Quantum emitters 282 9.1 Types of quantum emitters 282 9.1.1 Fluorescent molecules 282 9.1.2 Semiconductor quantum dots 286 9.1.3 Color centers in diamond 291 9.2 The absorption cross-section 294 9.3 Single-photon emission by three-level systems 296 9.3.1 Steady-state analysis 297 9.3.2 Time-dependent analysis 298 9.4 Single molecules as probes for localized fields 303 9.4.1 Field distribution in a laser focus 305 9.4.2 Probing strongly localized fields 306 9.5 Conclusion 309 Problems 310 References 310


xi Contents
10 Dipole emission near planar interfaces 313 10.1 Allowed and forbidden light 314 10.2 Angular spectrum representation of the dyadic Green function 315 10.3 Decomposition of the dyadic Green function 317 10.4 Dyadic Green functions for the reflected and transmitted fields 318 10.5 Spontaneous decay rates near planar interfaces 321 10.6 Far-fields 323 10.7 Radiation patterns 326 10.8 Where is the radiation going? 329 10.9 Magnetic dipoles 332 10.10 The image dipole approximation 333 10.10.1 Vertical dipole 334 10.10.2 Horizontal dipole 334 10.10.3 Including retardation 335 Problems 335 References 336
11 Photonic crystals, resonators, and cavity optomechanics 338 11.1 Photonic crystals 338 11.1.1 The photonic bandgap 339 11.1.2 Defects in photonic crystals 343 11.2 Metamaterials 345 11.2.1 Negative-index materials 345 11.2.2 Anomalous refraction and left-handedness 348 11.2.3 Imaging with negative-index materials 348 11.3 Optical microcavities 350 11.3.1 Cavity perturbation 356 11.4 Cavity optomechanics 359 Problems 365 References 366
12 Surface plasmons 369 12.1 Noble metals as plasmas 370 12.1.1 Plasma oscillations 370 12.1.2 The ponderomotive force 372 12.1.3 Screening 372 12.2 Optical properties of noble metals 374 12.2.1 Drude–Sommerfeld theory 374 12.2.2 Interband transitions 375 12.3 Surface plasmon polaritons at plane interfaces 377 12.3.1 Properties of surface plasmon polaritons 380 12.3.2 Thin-film surface plasmon polaritons 381 12.3.3 Excitation of surface plasmon polaritons 383 12.3.4 Surface plasmon sensors 387


xii Contents
12.4 Surface plasmons in nano-optics 388 12.4.1 Plasmons supported by wires and particles 391 12.4.2 Plasmon resonances of more complex structures 403 12.4.3 Surface-enhanced Raman scattering 403 12.5 Nonlinear plasmonics 407 12.6 Conclusion 408 Problems 409 References 411
13 Optical antennas 414 13.1 Significance of optical antennas 414 13.2 Elements of classical antenna theory 416 13.3 Optical antenna theory 420 13.3.1 Antenna parameters 421 13.3.2 Antenna-coupled light–matter interactions 433 13.3.3 Coupled-dipole antennas 434 13.4 Quantum emitter coupled to an antenna 437 13.5 Quantum yield enhancement 440 13.6 Conclusion 443 Problems 443 References 445
14 Optical forces 448 14.1 Maxwell’s stress tensor 449 14.2 Radiation pressure 452 14.3 Lorentz force density 453 14.4 The dipole approximation 453 14.4.1 Time-averaged force 455 14.4.2 Monochromatic fields 456 14.4.3 Self-induced back-action 458 14.4.4 Saturation behavior for near-resonance excitation 459 14.4.5 Beyond the dipole approximation 462 14.5 Optical tweezers 463 14.6 Angular momentum and torque 465 14.7 Forces in optical near-fields 466 14.8 Conclusion 470 Problems 471 References 472
15 Fluctuation-induced interactions 474 15.1 The fluctuation–dissipation theorem 474 15.1.1 The system response function 475 15.1.2 Johnson noise 479 15.1.3 Dissipation due to fluctuating external fields 481


xiii Contents
15.1.4 Normal and antinormal ordering 482 15.2 Emission by fluctuating sources 483 15.2.1 Blackbody radiation 485 15.2.2 Coherence, spectral shifts, and heat transfer 486 15.3 Fluctuation-induced forces 488 15.3.1 The Casimir–Polder potential 490 15.3.2 Electromagnetic friction 494 15.4 Conclusion 497 Problems 497 References 498
16 Theoretical methods in nano-optics 500 16.1 The multiple-multipole method 500 16.2 Volume-integral methods 506 16.2.1 The volume-integral equation 508 16.2.2 The method of moments (MOM) 513 16.2.3 The coupled-dipole method (CDM) 514 16.2.4 Equivalence of the MOM and the CDM 515 16.3 Effective polarizability 517 16.4 The total Green function 518 16.5 Conclusion 519 Problems 519 References 520
Appendix A Semi-analytical derivation of the atomic polarizability 523 A.1 Steady-state polarizability for weak excitation fields 526 A.2 Near-resonance excitation in the absence of damping 528 A.3 Near-resonance excitation with damping 530
Appendix B Spontaneous emission in the weak-coupling regime 532 B.1 Weisskopf–Wigner theory 532 B.2 Inhomogeneous environments 534 References 536
Appendix C Fields of a dipole near a layered substrate 537 C.1 Vertical electric dipole 537 C.2 Horizontal electric dipole 538 C.3 Definition of the coefficients Aj, Bj, and Cj 541
Appendix D Far-field Green functions 543
Index 545




Preface to the first edition
Why should we care about nano-optics? For the same reason we care about optics! The foundations of many fields of the contemporary sciences have been established using optical experiments. To give an example, think of quantum mechanics. Blackbody radiation, hydrogen lines, or the photoelectric effect were key experiments that nurtured the quantum idea. Today, optical spectroscopy is a powerful means to identify the atomic and chemical structure of different materials. The power of optics is based on the simple fact that the energy of light quanta lies in the energy range of electronic and vibrational transitions in matter. This fact is at the core of our abilities for visual perception and is the reason why experiments with light are very close to our intuition. Optics, and in particular optical imaging, helps us to consciously and logically connect complicated concepts. Therefore, pushing optical interactions to the nanometer scale opens up new perspectives, properties and phenomena in the emerging century of the nanoworld. Nano-optics aims at the understanding of optical phenomena on the nanometer scale, i.e. near or beyond the diffraction limit of light. It is an emerging new field of study, motivated by the rapid advance of nanoscience and nanotechnology and by their need for adequate tools and strategies for fabrication, manipulation and characterization at the nanometer scale. Interestingly, nano-optics predates the trend of nanotechnology by more than a decade. An optical counterpart to the scanning tunneling microscope (STM) was demonstrated in 1984 and optical resolutions had been achieved that were significantly beyond the diffraction limit of light. These early experiments sparked a field initially called near-field optics, since it was realized quickly that the inclusion of near-fields in the problem of optical imaging and associated spectroscopies holds promise for achieving arbitrary spatial resolutions, thus providing access for optical experiments on the nanometer scale. The first conference on near-field optics was held in 1992. About seventy participants discussed theoretical aspects and experimental challenges associated with near-field optics and near-field optical microscopy. The subsequent years are characterized by a constant refinement of experimental techniques, as well as the introduction of new concepts and applications. Applications of near-field optics soon covered a large span ranging from fundamental physics and materials science to biology and medicine. Following a logical development, the strong interest in near-field optics gave birth to the fields of singlemolecule spectroscopy and plasmonics, and inspired new theoretical work associated with the nature of optical near-fields. In parallel, relying on the momentum of the flowering nanosciences, researchers started to tailor nanomaterials with novel optical properties. Photonic crystals, single-photon sources and optical microcavities are products of this effort. Today, elements of nano-optics are scattered across the disciplines. Various review articles xv


xvi Preface to the first edition
and books capture the state-of-the-art in the different subfields but there appears to be no dedicated textbook that introduces the reader to the general theme of nano-optics. This textbook is intended to teach students at the graduate level or advanced undergraduate level about the elements of nano-optics encountered in different subfields. The book evolved from lecture notes that have been the basis for courses on nano-optics taught at the Institute of Optics of the University of Rochester, and at the University of Basel. We were happy to see that students from many different departments found interest in this course, which shows that nano-optics is important to many fields of study. Not all students were interested in the same topics and, depending on their field of study, some students needed additional help with mathematical concepts. The courses were supplemented with laboratory projects that were carried out in groups of two or three students. Each team picked the project that had most affinity with their interest. Among the projects were: surface enhanced Raman scattering, photon scanning tunneling microscopy, nanosphere lithography, spectroscopy of single quantum dots, optical tweezers, and others. Towards the end of the course, students gave a presentation on their projects and handed in a written report. Most of the problems at the end of individual chapters have been solved by students as homework problems or take-home exams. We wish to acknowledge the very helpful input and inspiration that we received from many students. Their interest and engagement in this course is a significant contribution to this textbook. Nano-optics is an active and evolving field. Every time the course was taught new topics were added. Also, nano-optics is a field that easily overlaps with other fields such as physical optics or quantum optics, and thus the boundaries cannot be clearly defined. This first edition is an initial attempt to put a frame around the field of nano-optics. We would be grateful to receive input from our readers related to corrections and extensions of existing chapters and for suggestions of new topics.
Acknowledgments
We wish to express our thanks for the input we received from various colleagues and students. We are grateful to Dieter Pohl who inspired our interest in nano-optics. This book is a result of his strong support and encouragement. We received very helpful input from Andreas Lieb, Scott Carney, Jean-Jacques Greffet, Stefan Hell, Carsten Henkel, Mark Stockman, Gert Zumofen, Jer-Shing Huang, Paolo Bragioni, and Jorge Zurita-Sanchez. It was also a great pleasure to discuss various topics with Miguel Alonso, Joe Eberly, Robert Knox, and Emil Wolf at the University of Rochester.


Preface to the second edition
We are very pleased that this textbook found wide use and reasonably high demand. Since the first printing of the first edition in 2006, the field of nano-optics has gained considerable momentum and new research directions have been established. Among the new topics are metamaterials, optical antennas, and cavity optomechanics, to name but a few. The high field localization associated with metals at optical frequencies has given rise to the demonstration of truly nanoscale lasers and the high nonlinearity of metals is being used for frequency conversion in subwavelength volumes. These new trends define a clear motivation for a second edition of Principles of Nano-Optics. The overall structure of the book has been left unchanged with the exception of a new chapter on optical antennas (Chapter 13). Chapter 2 (Theoretical foundations) has been adjusted to include topics such as reciprocity and energy density in lossy media, and Chapter 4 (Resolution and localization) has been extended by including new microscopy techniques, such as structured illumination and localization microscopy. Chapter 5 received a major polish: optical microscopy is now classified in terms of interaction orders between probe and sample. On the other hand, Chapter 6 has been condensed since some nearfield techniques are no longer of general interest. Several new topics have been included in Chapter 8, which covers the theory of localized light–matter interactions. Among the new sections is a discussion of Fano interference, strong coupling between modes, and level crossing. Chapters 9 and 10 received only minor revisions, while Chapter 11 has been extended by a section on metamaterials and cavity optomechanics. Chapter 12 (Surface plasmons) has also been restructured: metals are discussed from a perspective of plasma physics leading to screening and to ponderomotive forces, which give rise to a wide range of optical nonlinearities. The chapter on optical forces (Chapter 14) has been adjusted to provide a more self-consistent perspective on dipole forces. Finally, various typos have been fixed. We thank our critical readers for pointing out several errors and for suggesting valuable changes. Despite the changes and additions it is not possible to account for all the new results and directions in the field. However, the purpose of this book is not to provide a comprehensive review, but to present the necessary foundations and concepts to understand what’s going on. In this sense, the book has remained a textbook and a reference for those seeking a conceptual understanding of the working principles of nano-optics.
xvii




1 Introduction
In the history of science, the first applications of optical microscopes and telescopes to investigate nature mark the beginnings of new eras. Galileo Galilei used a telescope to see for the first time craters and mountains on a celestial body, the Moon, and also discovered the four largest satellites of Jupiter. With this he opened the field of optical astronomy. Robert Hooke and Antony van Leeuwenhoek used early optical microscopes to observe certain features of plant tissue that were called “cells,” and to observe microscopic organisms, such as bacteria and protozoans, thus marking the beginning of optical biology. The newly developed instrumentation enabled the observation of fascinating phenomena not directly accessible to human senses. Naturally, the question of whether the observed structures not detectable within the range of normal vision should be accepted as reality at all was raised. Today, we have accepted that, in modern physics, scientific proofs are verified by indirect measurements, and the underlying laws have often been established on the basis of indirect observations. It seems that as modern science progresses it withholds more and more findings from our natural senses. In this context, the use of optical instrumentation excels among ways to study nature. This is due to the fact that because of our ability to perceive electromagnetic waves at optical frequencies our brain is used to the interpretation of phenomena associated with light, even if the structures that are observed are magnified a thousandfold. This intuitive understanding is among the most important features that make light and optical processes so attractive as a means to reveal physical laws and relationships. The fact that the energy of light lies within the energy range of electronic and vibrational transitions in matter allows us to use light for gaining unique information about the structural and dynamical properties of matter and also to perform subtle manipulations of the quantum state of matter. These unique spectroscopic capabilities associated with optical techniques are of great importance for the study of biological and solid-state nanostructures. Today we encounter a strong trend towards nanoscience and nanotechnology. This trend was originally driven by the benefits of miniaturization and integration of electronic circuits for the computer industry. More recently we have observed a paradigm shift that manifests itself in the notion that nanoscience and technology are more and more driven by the fact that, as we move to smaller and smaller scales, new physical effects that may be exploited in future technological applications become prominent. The advances in nanoscience and technology are due in large part to our newly acquired ability to measure, fabricate, and manipulate individual structures on the nanometer scale using scanning probe techniques, optical tweezers, high-resolution electron microscopes and lithography tools, focused ionbeam milling systems etc.
1


2 Introduction
The increasing trend towards nanoscience and nanotechnology makes it inevitable that we will need to study optical phenomena on the nanometer scale. Since the diffraction limit does not allow us to focus light to dimensions smaller than roughly one half of the wavelength (200 nm), traditionally it was not possible to optically interact selectively with nanoscale features. However, in recent years, several new approaches have been put forth to “shrink” the diffraction limit or even overcome it. A central goal of nano-optics is to extend the use of optical techniques to length scales beyond the diffraction limit. The most obvious potential technological applications that arise from breaking the diffraction barrier are super-resolution microscopy and ultra-high-density data storage. But the field of nanooptics is by no means limited to technological applications and instrument design. Nanooptics also opens new doors to basic research on nanometer-sized structures. Nature has developed various nanoscale structures to bring out unique optical effects. A prominent example is photosynthetic membranes, which use light-harvesting proteins to absorb sunlight and then channel the excitation energy to other neighboring proteins. The energy is guided to a so-called reaction center where it initiates charge transfer across the cell membrane. Other examples are sophisticated diffractive structures used by insects (butterflies) and other animals (peacocks) to produce attractive colors and effects. Also, nanoscale structures are used as antireflection coatings in the retinas of various insects, and naturally occurring photonic bandgaps are encountered in gemstones (opals). In recent years, we have succeeded in creating different artificial nanophotonic structures [1]. A few examples are depicted in Fig. 1.1. Single molecules are being used as local probes for electromagnetic fields and for biophysical processes, resonant metal nanostructures are
Fig. 1.1 A potpourri of man-made nanophotonic structures. (a) Strongly fluorescent molecules, (b) metal nanostructures fabricated by nanosphere lithography, (c) localized photon sources, (d) microdisk resonators (from [2]), (e) semiconductor nanostructures, (f) particle plasmons (from [3]), (g) photonic bandgap crystals (from [4]), (h) nanocomposite materials, (i) laser microcavities (from [5]), (j) single-photon sources (from [6]), (k) surface plasmon waveguides (from [7]).


3 1.1 Nano-optics in a nutshell
being exploited as sensor devices, localized photon sources are being developed for highresolution optical microscopy, extremely high Q-factors are being generated with optical microdisk resonators, nanocomposite materials are being explored for generating increased nonlinearities and collective responses, microcavities are being built for single-photon sources, surface plasmon waveguides are being implemented for planar optical networks, and photonic bandgap materials are being developed to suppress light propagation in specific frequency windows. All of these nanophotonic structures are being created to provide unique optical properties and phenomena, and the aim of this book is to establish a basis for their understanding.
1.1 Nano-optics in a nutshell
Let us try to get a quick glimpse of the very basics of nano-optics just to show that optics at the scale of a few nanometers makes perfect sense and is not forbidden by any fundamental law. In free space, the propagation of light is determined by the dispersion relation ħω =
c · ħk, which connects the wavevector k =
√
kx2 + ky2 + kz2 of a photon with its angular
frequency ω via the speed of propagation c. Heisenberg’s uncertainty relation states that the product of the uncertainty in the spatial position of a microscopic particle in a certain direction and the uncertainty in the component of its momentum in the same direction cannot become smaller than ħ/2. For photons this leads to the relation
(ħkx) · x ≥ ħ/2, (1.1)
which can be rewritten as
x≥ 1
2 kx
. (1.2)
The interpretation of this result is as follows. The spatial confinement that can be achieved for photons is inversely proportional to the spread in the magnitude of wavevector components in the respective spatial direction, here x. Such a spread in wavevector components occurs for instance in a light field that converges towards a focus, e.g. behind a lens. Such a field may be represented by a superposition of plane waves traveling at different angles (see Section 2.12). The maximum possible spread in the wavevector component kx is the total length of the free-space wavevector k = 2π/λ.1 This leads to
x≥ λ
4π , (1.3)
which is very similar to the well-known expression for the Rayleigh diffraction limit. Note that the spatial confinement that can be achieved is limited only by the spread of wavevector components in a given direction. In order to increase the spread of wavevector components we can play a mathematical trick. If we choose two arbitrary perpendicular directions in space, e.g. x and z, we can increase one wavevector component to values beyond the total
1 For a real lens this must be corrected by the numerical aperture.


4 Introduction
wavevector while at the same time requiring the wavevector in the perpendicular direction to become purely imaginary. If this is the case, then we can still fulfill the requirement for
the total length of the wavevector k =
√
kx2 + ky2 + kz2 to be 2π/λ. If we choose to increase
the wavevector in the x-direction then the possible range of wavevectors in this direction is also increased and the confinement of light is no longer limited by Eq. (1.3). However, the possibility of increased confinement has to be paid for and the currency is confinement also in the z-direction, resulting from the purely imaginary wavevector component in this direction that is necessary to compensate for the large wavevector component in the x-direction. On introducing the purely imaginary wavevector component into the expression for a plane wave we obtain exp(ikzz) = exp(−|kz|z). In one direction this leads to an exponentially decaying field, an evanescent wave, while in the opposite direction the field is exponentially increasing. Since exponentially increasing fields have no physical meaning we may safely discard the strategy just outlined to obtain a solution, and state that in free space Eq. (1.3) is always valid. However, this argument holds only for infinite free space! If we divide our infinite free space into at least two half-spaces with different refractive indices, then the exponentially decaying field in one half-space can exist without needing the exponentially increasing counterpart in the other half-space. In the other half-space a different solution that satisfies the boundary conditions for the fields at the interface may be valid. These simple arguments show that in the presence of an inhomogeneity in space the Rayleigh limit for the confinement of light is no longer strictly valid, but in principle infinite confinement of light becomes, at least theoretically, possible. This insight is the basis of nano-optics. One of the key questions in nano-optics is how material structures have to be shaped to actually realize the theoretically possible field confinement. Another key issue is the nature of the physical consequences of the presence of exponentially decaying and strongly confined fields, which we will discuss in some detail in the following chapters.
1.2 Historical survey
In order to put this text on nano-optics into the right perspective and context we deem it appropriate to start out with a very short introduction to the historical development of optics in general and the advent of nano-optics in particular. Nano-optics builds on the achievements of classical optics, the origin of which goes back to antiquity. At that time, burning glasses and the reflection law were already known and Greek philosophers (Empedocles, Euclid) speculated about the nature of light. They were the first to do systematic studies on optics. In the thirteenth century the first magnifying glasses were used. There are documents reporting the existence of eye glasses in China several centuries earlier. However, the first optical instrumentation for scientific purposes was not built until the beginning of the seventeenth century, when modern human curiosity started to awaken. It is often stated that the earliest telescope was the one constructed by


5 1.2 Historical survey
Galileo Galilei in 1609, since there is definite confirmation of its existence. Likewise, the first prototype of an optical microscope (1610) is also attributed to Galilei [8]. However, it is known that Galilei knew of a microscope built in Holland (probably by Zacharias Janssen) and that his instrument was built according to existing plans. In the sixteenth century craftsmen were already using glass spheres filled with water for the magnification of small details. As in the case of the telescope, the development of the microscope extends over a considerable period and cannot be attributed to any single inventor. A pioneer who advanced the development of the microscope, as has already been mentioned, was Antony van Leeuwenhoek. It is remarkable that the resolution of his microscope, built in 1671, was not exceeded for more than a century. At the time, his observation of red blood cells and bacteria was revolutionary. In the eighteenth and ninteenth centuries the development of the theory of light (polarization, diffraction, dispersion) helped to significantly advance optical technology and instrumentation. It was soon realized that optical resolution cannot be improved arbitrarily and that a lower bound is set by the diffraction limit. The theory of resolution was formulated by Abbe in 1873 [9] and Rayleigh in 1879 [10]. It is interesting to note, as we saw above, that there is a close relation to Heisenberg’s uncertainty principle. Different techniques such as confocal microscopy [11] were invented over the years in order to stretch the diffraction limit beyond Abbe’s limit. Today, confocal fluorescence microscopy is a key technology in biomedical research [12]. Highly fluorescent molecules that can be specifically attached to biological entities such as lipids, muscle fibers, and various cell organelles have been synthesized. This chemically specific labeling and the associated discrimination of different dyes in terms of their fluorescence emission allows scientists to visualize the interior of cells and study biochemical reactions in living environments. The invention of pulsed laser radiation propelled the field of nonlinear optics and enabled the invention of multiphoton microscopy [13]. However, multiphoton excitation is not the only nonlinear interaction that is exploited in optical microscopy. Second-harmonic, third-harmonic, and coherent anti-Stokes Raman scattering (CARS) microscopy [14] are other examples of extremely important inventions for visualizing processes with high spatial resolution. Besides nonlinear interactions, it has also been demonstrated that saturation effects can, in principle, be applied to achieve arbitrary spatial resolutions, provided that one knows what molecules are being imaged [15]. A different approach for boosting spatial resolution in optical imaging is provided by near-field optical microscopy. In principle, this technique does not rely on prior information. While it is restricted to imaging of features near the surface of a sample it provides complementary information about the surface topology similar to atomic force microscopy. A challenge in near-field optical microscopy is posed by the coupling of source (or detector) and the sample to be imaged. This challenge is absent in standard light microscopy where the light source (e.g. the laser) is not affected by the properties of the sample. Near-field optical microscopy was originally proposed in 1928 by Synge (Fig. 1.2). In a prophetic article he proposed an apparatus that comes very close to present implementations in scanning near-field optical microscopy [16, 17]. A minute aperture in an opaque plate illuminated from one side is placed in close proximity to a sample surface, thereby creating an illumination spot not limited by diffraction. The transmitted light is then collected with a microscope, and its intensity is measured with a photoelectric cell. In order


6 Introduction
to establish an image of the sample, the aperture is moved in small increments over the surface. The resolution of such an image should be limited by the size of the aperture and not by the wavelength of the illuminating light, as Synge correctly stated. It is known that Synge was in contact with Einstein about his ideas and Einstein encouraged Synge to publish his ideas. It is also known that later in his life Synge was no longer convinced about his idea and proposed alternative but, as we know today, incorrect ideas. Owing to the obvious experimental limitations at that time, Synge’s idea was not realized and was soon forgotten. Later, in 1956, O’Keefe proposed a similar set-up without knowing of Synge’s visionary idea [18]. The first experimental realization in the microwave region was performed in 1972 by Ash and Nichols, again without knowledge of Synge’s paper [19]. Using a 1.5 mm aperture, illuminated with 10 cm waves, Ash and Nichols demonstrated subwavelength imaging with a resolution of λ/60. The invention of scanning probe microscopy [20] at the beginning of the 1980s enabled distance regulation between probe and sample with high precision, and hence set the ground for a realization of Synge’s idea at optical frequencies. In 1984 Massey proposed the use of piezoelectric position control for the accurate positioning of a minute aperture illuminated at optical frequencies [21]. Shortly after, Pohl, Denk and Lanz at the IBM Rüschlikon Research Laboratory managed to solve the remaining experimental difficulties of producing a subwavelength-sized aperture: a metal-coated pointed quartz tip was “pounded” against the sample surface until some light leakage through the foremost end could be detected. In 1984 the IBM group published the first subwavelength images at optical frequencies [22] and an independent development was undertaken by Lewis et al. [23] and Fischer et al. [24]. Subsequently, the technique was systematically advanced and extended to various applications mainly by Betzig et al. [25, 26], who demonstrated
Fig. 1.2 In an April 1928 sketch sent to Albert Einstein, Edward Hutchinson Synge proposed a new microscopy method: using a tiny gold particle between two quartz slides to scatter incident light from below onto a sample. Light that didn’t strike the particle would be totally internally reflected, and an objective lens of a microscope could be positioned to accept some of the gold-scattered light. That arrangement, Synge wrote, could be used to image a biological specimen fixed to the top cover slip at a resolution below the diffraction limit. (Courtesy of the Albert Einstein Archives, Hebrew University of Jerusalem, Israel.)


7 1.3 Scope of the book
subwavelength magnetic data storage and detection of single fluorescent molecules. Over the years, various related techniques were proposed, such as the photon scanning tunneling microscope, the near-field reflection microscope, microscopes using luminescent centers as light-emitting sources, microscopes based on local plasmon interaction, microscopes based on local light scattering, and microscopes relying on the field enhancement effect near sharply pointed metal tips. All these techniques provide a confined photon flux between probe and sample. However, the confined light flux is not the only limiting factor for the achievable resolution. In order to be detectable, the photon flux needs to have a minimum intensity. These two requirements are to some extent contradictory and a compromise between light confinement and light throughput has to be found. The interested reader is referred to Ref. [17] for a more detailed account on the history of near-field optics.
1.3 Scope of the book
Traditionally, the field of optics is part of both the basic sciences (e.g. quantum optics) and applied sciences (e.g. optical communication and computing). Therefore, nano-optics can be defined as the broad spectrum of optics on the nanometer scale, ranging from nanotechnology applications to fundamental nanoscience. On the nanotechnology side, we find topics like nanolithography, high-resolution optical microscopy, and high-density optical data storage. On the basic science end, we might mention atom–photon interactions in the optical near-field and their potential applications for atom trapping and manipulation experiments. Compared with free propagating light the optical near-field is enriched by so-called virtual photons that correspond to the exponentially decaying fields introduced before. The virtual-photon picture can be used to describe local, non-propagating fields in general. These virtual photons are the same sort of particles as is also responsible for molecular binding (van der Waals and Casimir forces) and therefore have potential for selective probing of molecular-scale structures. The consideration of virtual photons in the field of quantum optics will enlarge the range of fundamental experiments and will result in new applications. The present book provides an introduction to nano-optics that reflects the full breadth of the field between applied and basic science. We start out by providing in Chapter 2 an overview of the theoretical foundations of nano-optics. Maxwell’s equations, being scale-invariant, provide a secure basis for nanooptics. Since optical near-fields are always associated with matter, we review constitutive relations and complex dielectric constants. The systems that are investigated in the context of nano-optics, as we saw, must separate into several spatial domains that are separated by boundaries. Representations of Maxwell’s equations valid in piecewise homogeneous media and the related boundary conditions for the fields are therefore derived. We then proceed with the discussion of fundamental theoretical concepts, such as the Green function and the angular spectrum representation, that are particularly useful for the discussion of nano-optical phenomena. The treatment of the angular spectrum representation leads to


8 Introduction
a thorough discussion of evanescent waves, which correspond to the new virtual-photon modes just mentioned. Light confinement is a key issue in nano-optics. To set the basis for further discussions in Chapter 3, we analyze what is the smallest possible confinement of light that can be achieved by classical means, i.e. microscope objectives and other high-numerical-aperture focusing optics. Starting out with the treatment of focused fields in the paraxial approximation, which yields the well-known Gaussian beams, we proceed by discussing focused fields beyond the paraxial approximation as they occur, for example, in modern confocal microscopes. Speaking of microscopy, spatial resolution is a key issue. There exist several definitions of the spatial resolution of an optical microscope that are related to the diffraction limit. An analysis of their physical foundations in Chapter 4 leads to the discussion of methods that can be used to enhance the spatial resolution of optical microscopy. Saturation effects and the difference between spatial position accuracy and resolution are discussed. The following three chapters then deal with more practical aspects of nano-optics related to applications in the context of near-field optical microscopy. In Chapter 5 we discuss the basic technical realizations of high-resolution microscopes, starting with confocal microscopy and proceeding with various near-field techniques that have been developed over time. Chapter 6 then deals with the central technical question of how light can be squeezed into subwavelength regions. This is the domain of the so-called optical probes, material structures that typically have the shape of pointed tips and exhibit a confined and enhanced optical field at their apex. Finally, to complete the technical section, we show how such delicate optical probes can be approached and scanned in close proximity to a sample surface of interest. A method relying on the measurement of interaction (shear) forces between probe and sample is introduced and discussed. Taken together, these three chapters provide the technical basics for understanding the current methods used in scanning near-field optical microscopy. We then proceed with a discussion of more fundamental aspects of nano-optics, i.e. light emission and optical interactions in nanoscale environments. As a starting point, we show that the light emission of a small particle (atom, molecule) with an electronic transition can be treated in the dipole approximation. We discuss the resulting fields of a radiating dipole and its interactions with the electromagnetic field in some detail. We proceed with the discussion of spontaneous decay in complex environments, which in the ultimate limit leads to the discussion of dipole–dipole interactions, energy transfer and excitonic coupling. Having discussed dipolar emitters without mentioning a real-world realization, we discuss in Chapter 9 some experimental aspects of the detection of single-quantum emitters such as single fluorescent molecules and semiconductor quantum dots. Saturation count rates and the solutions of rate equation systems are discussed as well as fascinating issues such as the non-classical photon statistics of fields emitted by quantum emitters and coherent control of wave functions. Finally we discuss how single emitters can be used to map spatially confined fields in great detail. In Chapter 10 we return to the issue of dipole emission in a nanoscale environment. Here, we treat in some detail the very important and illustrative case of dipole emission


9 References
near a planar interface. We calculate radiation patterns and decay rates of dipolar emitters and also discuss the image-dipole approximation that can be used to obtain approximate and qualitative results. If we consider multiple interfaces, instead of only one, that are arranged in a regular pattern, we obtain a so-called photonic crystal. The properties of such structures can be described in analogy to solid-state physics by introducing an optical band structure that may contain bandgaps in certain directions where propagating light cannot exist. Defects in photonic crystals lead to localized states, much like their solid-state counterparts, which are of particular interest in nano-optics since they can be considered as microscopic cavities with very high quality factors. In the same chapter we discuss optical resonators and their interaction with mechanical oscillators. This interaction makes it possible either to amplify the motion of a mechanical system or to slow it down. Chapter 12 then takes up the topic of surface plasmons. Resonant collective oscillations of the free surface charge density in metal structures of various geometries can couple efficiently to optical fields and, due to the occurrence of resonances, are associated with strongly enhanced and confined optical near-fields. We give a basic introduction to the topic, covering the optical properties of noble metals, thin-film plasmons, and particle plasmons. In the following chapter we discuss optical antennas, devices designed to convert free-propagating radiation to localized energy, and vice versa. The next chapter concentrates on optical forces. We formulate a theory based on Maxwell’s stress tensor that allows us to calculate forces of particles of arbitrary shape once the field distribution is known. We then specialize the discussion and introduce the dipole approximation valid for small particles. Practical applications discussed include the optical-tweezers principle. Finally, the transfer of angular momentum using optical fields is discussed, as well as forces exerted by optical near-fields. Another type of forces is discussed in the subsequent chapter, i.e. forces that are related to fluctuating electromagnetic fields which include the Casimir–Polder force and electromagnetic friction. On the way we also discuss the emission of radiation by fluctuating sources. The present textbook is concluded by a summary of theoretical methods used in the field of nano-optics. Hardly any predictions can be made in the field of nano-optics without using adequate numerical methods. A selection of the most powerful theoretical tools is presented and their advantages and drawbacks are discussed.
References
[1] A. J. Haes and R. P. Van Duyne, “A nanoscale optical biosensor: sensitivity and selectivity of an approach based on the localized surface plasmon resonance spectroscopy of triangular silver nanoparticles,” J. Am. Chem. Soc. 124, 10596 (2002). [2] D. K. Armani, T. J. Kippenberg, S. M. Spillane, and K. J. Vahala, “Ultra-high-Q toroid microcavity on a chip,” Nature 421, 925–928 (2003).


10 Introduction
[3] J. J. Mock, M. Barbic, D. R. Smith, D. A. Schultz, and S. Schultz, “Shape effects in plasmon resonance of individual colloidal silver nanoparticles,” J. Chem. Phys. 116, 6755–6759 (2002). [4] Y. A. Vlasov, X. Z. Bo, J. C. Sturm, and D. J. Norris, “On-chip natural assembly of silicon photonic bandgap crystals,” Nature 414, 289–293 (2001). [5] O. J. Painter, A. Husain, A. Scherer, et al., “Two-dimensional photonic crystal defect laser,” J. Lightwave Technol. 17, 2082–2089 (1999). [6] J. M. Gérard, B. Sermage, B. Gayral, et al., “Enhanced spontaneous emission by quantum boxes in a monolithic optical microcavity,” Phys. Rev. Lett. 81, 1110–1114 (1998). [7] W. L. Barnes, A. Dereux, and T. W. Ebbesen, “Surface plasmon subwavelength optics,” Nature 424, 824–830 (2003). [8] M. Born and E. Wolf, Principles of Optics, 6th edn. Oxford: Pergamon (1970). [9] E. Abbe, “Beiträge zur Theorie des Mikroskops und der mikroskopischen Wahrnehmung,” Arch. Mikroskop. Anat. 9, 413–420 (1873). [10] L. Rayleigh, “Investigations in optics, with special reference to the spectroscope,” Phil. Mag. 8, 261–274, 403–411, and 477–486 (1879). [11] M. Minsky, “Memoir on inventing the confocal scanning microscope,” Scanning 10, 128–138 (1988).
[12] J. B. Pawley (ed.) Handbook of Biological Confocal Microscopy. New York: Plenum Press (1995). [13] W. Denk, J. H. Strickler, and W. W. Webb, “2-Photon laser scanning fluorescence microscopy,” Science 248, 73–76 (1990). [14] A. Zumbusch, G. R. Holtom, and X. S. Xie, “Three-dimensional vibrational imaging by coherent anti-Stokes Raman scattering,” Phys. Rev. Lett. 82, 4142–4145 (1999). [15] T. A. Klar, S. Jakobs, M. Dyba, A. Egner, and S. W. Hell, “Fluorescence microscopy with diffraction resolution barrier broken by stimulated emission,” Proc. Nat. Acad. Sci. 97, 8206–8210 (2000). [16] E. H. Synge, “A suggested model for extending microscopic resolution into the ultramicroscopic region,” Phil. Mag. 6, 356–362 (1928). [17] L. Novotny, “The history of near-field optics,” in Progress in Optics, vol. 50, ed. E. Wolf. Amsterdam: Elsevier, pp. 137–180 (2007). [18] J. A. O’Keefe, “Resolving power of visible light,” J. Opt. Soc. Am. 46, 359–360 (1956). [19] E. A. Ash and G. Nicholls, “Super-resolution aperture scanning microscope,” Nature 237, 510–513 (1972). [20] G. Binnig, H. Rohrer, C. Gerber, and E. Weibel, “Tunneling through a controllable vacuum gap,” Appl. Phys. Lett. 40, 178–180 (1982). [21] G. A. Massey, “Microscopy and pattern generation with scanned evanescent waves,” Appl. Opt. 23, 658–660 (1984). [22] D. W. Pohl, W. Denk, and M. Lanz, “Optical stethoscopy: image recording with resolution λ/20,” Appl. Phys. Lett. 44, 651–653 (1984).
[23] A. Lewis, M. Isaacson, A. Harootunian, and A. Muray, “Development of a 500 ◦A spatial resolution light microscope,” Ultramicroscopy 13, 227–231 (1984).


11 References
[24] U. Ch. Fischer, “Optical characteristics of 0.1 μm circular apertures in a metal film as light sources for scanning ultramicroscopy,” J. Vac. Sci. Technol. B3, 386–390 (1985). [25] E. Betzig, M. Isaacson, and A. Lewis, “Collection mode nearfield scanning optical microscopy,” Appl. Phys. Lett. 61, 2088–2090 (1987). [26] E. Betzig and R. J. Chichester, “Single molecules observed by near-field scanning optical microscopy,” Science 262, 1422–1425 (1993).


2 Theoretical foundations
Light embraces the most fascinating spectrum of electromagnetic radiation. This is mainly due to the fact that the energy of light quanta (photons) lies within the energy range of electronic transitions in matter. This gives us the beauty of color and is the reason why our eyes adapted to sense the optical spectrum. Light is also fascinating because it manifests itself in the forms of waves and particles. In no other range of the electromagnetic spectrum are we more confronted with the wave–particle duality than in the optical regime. While long wavelength radiation (radiofrequencies, microwaves) is well described by wave theory, short wavelength radiation (X-rays) exhibits mostly particle properties. The two worlds meet in the optical regime. To describe optical radiation in nano-optics it is mostly sufficient to adopt the wave picture. This allows us to use classical field theory based on Maxwell’s equations. Of course, in nano-optics the systems with which the light fields interact are small (single molecules, quantum dots), which necessitates a quantum description of the material properties. Thus, in most cases we can use the framework of semiclassical theory, which combines the classical picture of fields and the quantum picture of matter. However, occasionally, we have to go beyond the semiclassical description. For example the photons emitted by a quantum system can obey non-classical photon statistics in the form of photon-antibunching (no two photons arriving simultaneously). This section summarizes the fundamentals of electromagnetic theory forming the necessary basis for this book. Only the basic properties are discussed and for more detailed treatments the reader is referred to standard textbooks on electromagnetism such as the books by Jackson [1] and Stratton [2]. The starting point is Maxwell’s equations, which were established by James Clerk Maxwell in 1873.
2.1 Macroscopic electrodynamics
In macroscopic electrodynamics the singular character of charges and their associated currents is avoided by considering charge densities ρ and current densities j. In differential form and in SI units the macroscopic Maxwell’s equations have the form 12


13 2.1 Macroscopic electrodynamics
∇ × E(r, t) = − ∂ B(r, t)
∂ t , (2.1)
∇ × H(r, t) = ∂ D(r, t)
∂ t + j(r, t), (2.2)
∇ · D(r, t) = ρ (r, t), (2.3)
∇ · B(r, t) = 0. (2.4)
where E denotes the electric field, D the electric displacement, H the magnetic field, B the magnetic induction, j the current density, and ρ the charge density. The components of these vector and scalar fields constitute a set of 16 unknowns. Depending on the medium considered, the number of unknowns can be reduced considerably. For example, in linear, isotropic, homogeneous and source-free media the electromagnetic field is entirely defined by two scalar fields. Maxwell’s equations combine and complete the laws formerly established by Faraday, Ampère, Gauss, Poisson, and others. Since Maxwell’s equations are differential equations they do not account for any fields that are constant in space and time. Any such field can therefore be added to the fields. It has to be emphasized that the concept of fields was introduced to explain the transmission of forces from a source to a receiver. The physical observables are therefore forces, whereas the fields are definitions introduced to explain the troublesome phenomenon of “action at a distance.” Notice that the macroscopic Maxwell’s equations deal with fields that are local spatial averages over microscopic fields associated with discrete charges. Hence, the microscopic nature of matter is not included in the macroscopic fields. Charge and current densities are considered as continuous functions of space. In order to describe the fields on an atomic scale it is necessary to use the microscopic Maxwell’s equations which consider all matter to be made of charged and uncharged particles. The conservation of charge is implicitly contained in Maxwell’s equations. Taking the divergence of Eq. (2.2), noting that ∇ · ∇ × H is identically zero, and substituting Eq. (2.3) for ∇ · D one obtains the continuity equation
∇ · j(r, t) + ∂ ρ (r, t)
∂ t = 0. (2.5)
The electromagnetic properties of the medium are most commonly discussed in terms of the macroscopic polarization P and magnetization M according to
D(r, t) = ε0E(r, t) + P(r, t), (2.6)
H(r, t) = μ−1
0 B(r, t) − M(r, t), (2.7)
where ε0 and μ0 are the permittivity and the permeability of vacuum, respectively. These equations do not impose any conditions on the medium and are therefore always valid.


14 Theoretical foundations
2.2 Wave equations
After substituting the fields D and B in Maxwell’s curl equations by the expressions (2.6) and (2.7) and combining the two resulting equations we obtain the inhomogeneous wave equations
∇×∇×E+ 1
c2
∂2E
∂ t2 = −μ0
∂ ∂t
(
j+ ∂P
∂t +∇ ×M
)
, (2.8)
∇×∇×H+ 1
c2
∂2H
∂t2 = ∇ × j + ∇ × ∂P
∂t − 1
c2
∂2M
∂ t2 . (2.9)
The constant c was introduced for (ε0μ0)−1/2 and is known as the vacuum speed of light. The expression in the brackets of Eq. (2.8) can be associated with the total current density
jt = js + jc + ∂ P
∂ t + ∇ × M, (2.10)
where j has been split into a source current density js and an induced conduction current density jc. The terms ∂P/∂t and ∇ × M are recognized as the polarization current density and the magnetization current density, respectively. The wave equations as stated in Eqs. (2.8) and (2.9) do not impose any conditions on the media considered and hence are generally valid.
2.3 Constitutive relations
Maxwell’s equations define the fields that are generated by currents and charges in matter. However, they do not describe how these currents and charges are generated. Thus, to find a self-consistent solution for the electromagnetic field, Maxwell’s equations must be supplemented by relations that describe the behavior of matter under the influence of the fields. These material equations are known as constitutive relations. In a non-dispersive linear and isotropic medium they have the form
D = ε0 ε E (P = ε0 χe E), (2.11)
B = μ0 μ H (M = χm H), (2.12)
jc = σ E. (2.13)
with χe and χm denoting the electric and magnetic susceptibility, respectively. For nonlinear media, the right hand sides can be supplemented by terms of higher power. Anisotropic media can be considered using tensorial forms for ε and μ. In order to account for general bianisotropic media, additional terms relating D and E to both B and H have to be introduced. For such complex media, solutions to the wave equations can be found for very special situations only. The constituent relations given above account for inhomogeneous media if the material parameters ε, μ, and σ are functions of space. The medium is called


15 2.4 Spectral representation of time-dependent fields
temporally dispersive if the material parameters are functions of frequency, and spatially dispersive if the constitutive relations are convolutions over space. An electromagnetic field in a linear medium can be written as a superposition of monochromatic fields of the form
E(r, t) = E(k, ω) cos(k · r − ωt), (2.14)
where k and ω are the wavevector and the angular frequency, respectively. In its most general form, the amplitude of the induced displacement D(r, t) can be written as1
D(k, ω) = ε0 ε(k, ω) E(k, ω). (2.15)
Since E(k, ω) is equivalent to the Fourier transform Eˆ of an arbitrary time-dependent field E(r, t), we can apply the inverse Fourier transform to Eq. (2.15) and obtain
D(r, t) = ε0
∫∫
ε ̃ (r − r′, t − t′)E(r′, t′) dr′ dt′. (2.16)
Here, ε ̃ denotes the response function in space and time. The displacement D at time t depends on the electric field at all times t′ previous to t (temporal dispersion). Additionally, the displacement at a point r also depends on the values of the electric field at neighboring points r′ (spatial dispersion). A spatially dispersive medium is therefore also called a nonlocal medium. Non-local effects can be observed at interfaces between different media or in metallic objects with sizes comparable to the mean-free path of electrons. In general, it is very difficult to account for spatial dispersion in field calculations. In most cases of interest the effect is very weak and we can safely ignore it. Temporal dispersion, on the other hand, is a widely encountered phenomenon and it is important to take it accurately into account.
2.4 Spectral representation of time-dependent fields
The spectrum ˆE(r, ω) of an arbitrary time-dependent field E(r, t) is defined by the Fourier transform
ˆE(r, ω) = 1
2π
∫∞
−∞
E(r, t) eiωt dt. (2.17)
In order that E(r, t) is a real-valued field we have to require that
Eˆ (r, −ω) = Eˆ ∗(r, ω). (2.18)
Applying the Fourier transform to the time-dependent Maxwell’s equations (2.1)–(2.4) gives
∇ × ˆE(r, ω) = iω ˆB(r, ω), (2.19)
∇ × ˆH(r, ω) = −iω ˆD(r, ω) + ˆj(r, ω), (2.20)
1 In an anisotropic medium the dielectric constant ε = ε↔ is a second-rank tensor.


16 Theoretical foundations
∇ · Dˆ (r, ω) = ρˆ (r, ω), (2.21)
∇ · Bˆ (r, ω) = 0. (2.22)
Once the solution for ˆE(r, ω) has been determined, the time-dependent field is calculated by the inverse transform as
E(r, t) =
∫∞
−∞
ˆE(r, ω) e−iωt dω. (2.23)
Thus, the time dependence of a non-harmonic electromagnetic field can be Fourier transformed and every spectral component can be treated separately as a monochromatic field. The general time dependence is obtained from the inverse transform.
2.5 Fields as complex analytic signals
The relationship (2.18) indicates that the positive-frequency region contains all the information of the negative-frequency region. If we restrict the integration in Eq. (2.23) to positive frequencies, we obtain what is called a complex analytic signal [3]
E+(r, t) =
∫∞
0
ˆE(r, ω) e−iωt dω, (2.24)
with the superscript “+” denoting that only positive frequencies are included. Similarly, we can define a complex analytic signal E− that accounts only for negative frequencies. The truncation of the integration range causes E+ and E− to become complex functions of time. Because E is real, we have [E+]∗ = E−. By taking the Fourier transform of E+(r, t) and E−(r, t) we obtain ˆE+(r, ω) and ˆE−(r, ω), respectively. It turns out that Eˆ + is identical to Eˆ for ω > 0 and it is zero for negative frequencies. Similarly, ˆE− is identical to ˆE for ω < 0 and it is zero for positive frequencies. Consequently, ˆE = ˆE+ + Eˆ −. In quantum mechanics, ˆE− is associated with the creation operator aˆ† and ˆE+ with the annihilation operator ˆa.
2.6 Time-harmonic fields
The time dependence in the wave equations can be easily separated to obtain a harmonic differential equation. A monochromatic field can then be written as2
E(r, t) = Re{E(r) e−iωt} = 1
2
[
E(r) e−iωt + E∗(r) eiωt]
, (2.25)
2 This can also be written as E(r, t) = Re{E(r)}cos(ωt) + Im{E(r)}sin(ωt).


17 2.7 Longitudinal and transverse fields
with similar expressions for the other fields. Notice that E(r, t) is real, whereas the spatial part E(r) is complex. The symbol E will be used both for the real, time-dependent field and for the complex spatial part of the field. The introduction of a new symbol is avoided in order to keep the notation simple. It is convenient to represent the fields of a time-harmonic field by their complex amplitudes. Maxwell’s equations can then be written as
∇ × E(r) = iωB(r), (2.26)
∇ × H(r) = −iωD(r) + j(r), (2.27)
∇ · D(r) = ρ (r), (2.28)
∇ · B(r) = 0, (2.29)
which is equivalent to Maxwell’s equations (2.19)–(2.22) for the spectra of arbitrary timedependent fields. Thus, the solution for E(r) is equivalent to the spectrum ˆE(r, ω) of an arbitrary time-dependent field. It is obvious that the complex field amplitudes depend on the angular frequency ω, i.e. E(r) = E(r, ω). However, ω is usually not included in the argument. Also the material parameters ε, μ, and σ are functions of space and frequency, i.e. ε = ε(r, ω), σ = σ (r, ω), and μ = μ(r, ω). For simpler notation, we will often drop the argument in the fields and material parameters. It is the context of the problem that determines which of the fields E(r, t), E(r), or ˆE(r, ω) is being considered.
2.7 Longitudinal and transverse fields
For some problems it is favorable to represent a field vector E in terms of a transverse field E⊥ and a longitudinal field E‖, that is
E(r) = E⊥(r) + E‖(r), (2.30)
with ∇ × E‖ = 0 and ∇ · E⊥ = 0. The meaning of ‘transverse’ and ‘longitudinal’ is best
seen in reciprocal space, where E(r) = ∫
k ˆE(k) exp(ik · r) dk. We then obtain ik× ˆE‖ = 0
and ik · ˆE⊥ = 0 (c.f. Section 2.15), that is Eˆ ‖ points in the direction of the k vector and
ˆE⊥ perpendicular to it. E‖ is also called solenoidal and E⊥ irrotational. The statement in Eq. (2.30) directly follows from Helmholtz’s theorem, which states that any vector field can be written as E = −∇φ + ∇ ×A. Here, ∇φ is associated with a longitudinal field because ∇ × (∇φ) = 0. Similarly, ∇ ×A is transverse because ∇ · (∇ ×A) = 0. Evidently, because ∇ · B = 0 the magnetic field is purely transverse. On the other hand, since ∇ · E = −ρ/ε, it follows that the electric field generated by charges is longitudinal. Note, however, that the current density j = j⊥ + j‖ gives rise to both transverse and longitudinal electric fields. It has to be emphasized that E⊥ and E‖ are a mathematical construct and that they have no physical meaning. Only when they are added together do we obtain a fully retarded and causal field.


18 Theoretical foundations
2.8 Complex dielectric constant
With the help of the linear constitutive relations we can express Maxwell’s curl equations (2.26) and (2.27) in terms of E(r) and H(r). We then multiply both sides of the first equation by μ−1 and then apply the curl operator to both sides. After the expression ∇ × H has been substituted by the second equation we obtain
∇ × μ−1 ∇ × E − ω2
c2
[ε + iσ/(ωε0)] E = iωμ0js. (2.31)
It is common practice to replace the expression in the brackets on the left-hand side by a complex dielectric constant, i.e.
[ε + iσ/(ω ε0)] → ε. (2.32)
In this notation one does not distinguish between conduction currents and polarization currents. Energy dissipation is associated with the imaginary part of the dielectric constant. With the new definition of ε, the wave equations for the complex fields E(r) and H(r) in linear, isotropic, but inhomogeneous media are
∇ × μ−1 ∇ × E − k2
0 ε E = iωμ0 js, (2.33)
∇ × ε−1 ∇ × H − k2
0 μ H = ∇ × ε−1 js, (2.34)
where k0 = ω/c denotes the vacuum wavenumber. These equations are also valid for
anisotropic media if the substitutions ε → ε↔ and μ → μ↔ are performed. The complex dielectric constant will be used throughout this book.
2.9 Piecewise homogeneous media
In many physical situations the medium is piecewise homogeneous. In this case the entire space is divided into subdomains in which the material parameters are independent of position r. In principle, a piecewise homogeneous medium is inhomogeneous and the solution can be derived from Eqs. (2.33) and (2.34). However, the inhomogeneities are entirely confined to the boundaries and it is convenient to formulate the solution for each subdomain separately. These solutions must be connected with each other via the interfaces to form the solution for all space. Let the interface between two homogeneous domains Di and Dj be denoted as ∂Dij. If εi and μi designate the constant material parameters in subdomain Di, the wave equations in that domain read as
(∇2 + k2
i )Ei = −iωμ0 μi ji + ∇ρi
ε0 εi
, (2.35)
(∇2 + k2
i )Hi = −∇ × ji, (2.36)


19 2.10 Boundary conditions
where ki = (ω/c)√μi εi is the wavenumber and ji and ρi are the sources in domain Di. To obtain these equations, the identity ∇ × ∇ × = −∇2 + ∇∇ · was used and Maxwell’s equation (2.3) was applied. Equations (2.35) and (2.36) are also denoted as the inhomogeneous vector Helmholtz equations. In most practical applications, such as scattering problems, there are no source currents or charges present and the Helmholtz equations are homogeneous.
2.10 Boundary conditions
Since the material properties are discontinuous on the boundaries, Eqs. (2.35) and (2.36) are valid only in the interior of the subdomains. However, Maxwell’s equations must also hold for the boundaries. Owing to the discontinuity it turns out to be difficult to apply the differential forms of Maxwell’s equations, but there is no problem with the corresponding integral forms. The latter can be derived by applying the theorems of Gauss and Stokes to the differential forms (2.1)–(2.4), which yields ∫
∂S
E(r, t) · ds = −
∫
S
∂
∂ t B(r, t) · ns da, (2.37)
∫
∂S
H(r, t) · ds =
∫
S
[
j(r, t) + ∂
∂ t D(r, t)
]
· ns da, (2.38)
∫
∂V
D(r, t) · ns da =
∫
V
ρ (r, t) dV, (2.39)
∫
∂V
B(r, t) · ns da = 0. (2.40)
In these equations, da denotes a surface element, ns the normal unit vector to the surface, ds a line element, ∂V the surface of the volume V, and ∂S the border of the surface S. The integral forms of Maxwell’s equations lead to the desired boundary conditions if they are applied to a sufficiently small part of the considered boundary. In this case the boundary looks flat and the fields are homogeneous on both sides (Fig. 2.1). Consider a small rectangular path ∂S along the boundary as shown in Fig. 2.1(a). As the area S (enclosed by the path ∂S) is arbitrarily reduced, the electric and magnetic fluxes through S become zero. This does not necessarily apply for the source current, since a surface current density K might be present. The first two of Maxwell’s equations then lead to the boundary conditions for the tangential field components3
n × (Ei − Ej) = 0 on ∂Dij, (2.41)
n × (Hi − Hj) = K on ∂Dij, (2.42)
3 Notice that n and ns are different unit vectors: ns is perpendicular to the surfaces S and ∂V, whereas n is perpendicular to the boundary ∂Dij.


20 Theoretical foundations
S
S
.
n
Dij
Di Dj
V
.
n
Dij
Di
Dj
V
(a) (b)
Fig. 2.1 Integration paths for the derivation of the boundary conditions on the interface ∂Dij between two adjacent domains Di and Dj.
where n is the unit normal vector on the boundary. A relation for the normal field components can be obtained by considering an infinitesimal rectangular box with volume V and surface ∂V according to Fig. 2.1(b). If the fields are considered to be homogeneous on both sides and if a surface charge density σ is assumed, Maxwell’s third and fourth equations lead to the boundary conditions for the normal field components:
n · (Di − Dj) = σ on ∂Dij, (2.43)
n · (Bi − Bj) = 0 on ∂Dij. (2.44)
In most practical situations there are no sources in the individual domains, and K and σ consequently vanish. The four boundary conditions (2.41)–(2.44) are not independent of each other since the fields on both sides of ∂Dij are linked by Maxwell’s equations. It can be easily shown, for example, that the conditions for the normal components are automatically satisfied if the boundary conditions for the tangential components hold everywhere on the boundary and Maxwell’s equations are fulfilled in both domains.
2.10.1 Fresnel reflection and transmission coefficients
Applying the boundary conditions to a simple plane wave incident on a single planar interface leads to the familiar Fresnel reflection and transmission coefficients. A detailed derivation can be found in many textbooks, e.g. [4], pages 36ff. We only briefly mention the results. An arbitrarily polarized plane wave E1 exp(ik1 · r − iωt) can always be written as the superposition of two orthogonally polarized plane waves. It is convenient to choose these polarizations parallel or perpendicular to the plane of incidence defined by the k-vector of the plane wave and the surface normal n of the plane interface
E1 = E(s)
1 + E(p)
1 . (2.45)


21 2.10 Boundary conditions
E1r
(s)
(a)
k1r
E1
(s)
k1
1
r
||
E2
(s)
k2
E 1r
(p)
(b)
k1r
E1
(p)
k1 1
r
||
E2
(p)
k2
ε2, μ 2 ε1, μ 1
ε2, μ 2 ε1, μ 1
θθ
Fig. 2.2 Reflection and refraction of a plane wave at a plane interface: (a) s-polarization and (b) p-polarization.
E(s)
1 is parallel to the interface while E(p)
1 is perpendicular to the wavevector k and E(s)
1. The indices (s) and (p) stand for the German words senkrecht (perpendicular) and parallel (parallel), respectively, and refer to the plane of incidence. Upon reflection or transmission at the interface, the polarizations (s) and (p) are conserved. As shown in Fig. 2.2, we denote the dielectric constants of the medium of incidence and the medium of transmittance as ε1 and ε2, respectively. The same designation applies to the magnetic permeability μ. Similarly, we distinguish between incident and reflected as well as transmitted wavevectors k1, k1r, and k2. Using the coordinate system shown in Fig. 2.2, it follows from the boundary conditions that
k1 = (kx, ky, kz1 ), |k1| = k1 = ω
c
√ε1μ1, (2.46)
k2 = (kx, ky, kz2 ), |k2| = k2 = ω
c
√ε2μ2. (2.47)
Thus, the transverse components of the wavevector (kx, ky) are conserved and the magnitudes of the longitudinal wavenumbers are given by
kz1 =
√
k2
1 − (kx2 + ky2), kz2 =
√
k2
2 − (kx2 + ky2). (2.48)
The transverse wavenumber k‖ =
√
kx2 + ky2 can be expressed conveniently in terms of the
angle of incidence θ1 as
k‖ =
√
kx2 + ky2 = k1 sin θ1, (2.49)
which, according to Eqs. (2.48), also allows us to express kz1 and kz2 in terms of θ1. It follows from the boundary conditions that the amplitudes of the reflected and transmitted waves can be represented as
E(s)
1r = E(s)
1 rs(kx, ky), E(p)
1r = E(p)
1 rp(kx, ky), (2.50)
E(s)
2 = E(s)
1 ts(kx, ky), E(p)
2 = E(p)
1 tp(kx, ky),


22 Theoretical foundations
where the Fresnel reflection and transmission coefficients are defined as4
rs(kx, ky) = μ2kz1 − μ1kz2
μ2kz1 + μ1kz2
, rp(kx, ky) = ε2kz1 − ε1kz2
ε2kz1 + ε1kz2
, (2.51)
ts(kx, ky) = 2μ2kz1
μ2kz1 + μ1kz2
, tp(kx, ky) = 2ε2kz1
ε2kz1 + ε1kz2
√ μ2ε1
μ1ε2
. (2.52)
As indicated by the superscripts, these coefficients depend on the polarization of the incident plane wave. The coefficients are functions of kz1 and kz2 , which can be expressed in terms of kx and ky and thus in terms of the angle of incidence θ1. The sign of the Fresnel coefficients depends on the definition of the electric field vectors shown in Fig. 2.2. For a plane wave at normal incidence (θ1 = 0), rs and rp differ by a factor of −1. Notice that the transmitted waves can be either plane waves or evanescent waves. This aspect will be discussed in Section 2.14.
2.11 Conservation of energy
The equations established so far describe the behavior of electric and magnetic fields. They are a direct consequence of Maxwell’s equations and the properties of matter. Although the electric and magnetic fields were initially postulated to explain the forces in Coulomb’s and Ampère’s laws, Maxwell’s equations do not provide any information about the energy or forces in a system. The basic Lorentz law describes the forces acting on moving charges only. As the Abraham–Minkowski controversy shows, the forces acting on an arbitrary object cannot be extracted from a given electrodynamic field in a consistent way. It is also interesting, that Coulomb’s and Ampère’s laws were sufficient to establish the Lorentz force law. Although later the field equations were completed by adding the Maxwell displacement current, the Lorentz law remained unchanged. There is less controversy regarding the energy. Although also not a direct consequence of Maxwell’s equations, Poynting’s theorem provides a plausible relationship between the electromagnetic field and its energy content. For later reference, Poynting’s theorem will be outlined below. If the scalar product of the field E and Eq. (2.2) is subtracted from the scalar product of the field H and Eq. (2.1) the following equation is obtained:
H · (∇ × E) − E · (∇ × H) = −H · ∂B
∂t − E · ∂D
∂ t − j · E. (2.53)
On noting that the expression on the left is identical to ∇ · (E × H), integrating both sides over space and applying Gauss’s theorem, the above equation becomes ∫
∂V
(E × H) · n da = −
∫
V
[
H · ∂B
∂t + E · ∂D
∂t +j·E
]
dV. (2.54)
4 For symmetry reasons, some authors omit the square-root term in the coefficient tp. In this case, tp refers to the ratio of transmitted and incident magnetic field. We adopt the definition from Born & Wolf [4].


23 2.11 Conservation of energy
Although this equation already forms the basis of Poynting’s theorem, more insight is provided when B and D are substituted by the generally valid equations (2.6) and (2.7).
Equation (2.54) then reads ∫
∂V
(E × H) · n da + 1
2
∂ ∂t
∫
V
[
D·E+B·H
]
dV
=−
∫
V
j · E dV − 1
2
∫
V
[
E · ∂P
∂t − P · ∂E
∂t
]
dV − μ0
2
∫
V
[
H · ∂M
∂t − M · ∂H
∂t
]
dV .
(2.55)
This equation is a direct conclusion of Maxwell’s equations and has therefore the same validity. Poynting’s theorem is more or less an interpretation of the equation above. It states that the first term is equal to the net energy flow in or out of the volume V, the second term is equal to the time rate of change of electromagnetic energy inside V and the remaining terms on the right-hand side are equal to the rate of energy dissipation inside V. According to this interpretation
S = (E × H) (2.56)
represents the energy flux density and
W=1
2
[
D·E+B·H
]
(2.57)
is the density of electromagnetic energy. If the medium within V is linear and nondispersive, the two last terms in Eq. (2.55) equal zero and the only term accounting for energy dissipation is j · E. The vector S is called the Poynting vector. In principle, the curl of any vector field can be added to S without changing the conservation law (2.55), but it is convenient to make the choice as stated in (2.56). Of special interest is the mean time value of S. This quantity describes the net power flux density and is needed for the evaluation of radiation patterns. Assuming that the fields
are harmonic in time, linear, and non-dispersive, the time average of Eq. (2.55) becomes ∫
∂V
〈S〉 · n da = − 1
2
∫
V
Re{j∗ · E}dV, (2.58)
where we have used complex notation. The term on the right defines the mean energy dissipation within the volume V. 〈S〉 represents the time average of the Poynting vector,
〈S〉 = 1
2 Re{E × H∗}. (2.59)
In the far-field, the electromagnetic field is purely transverse. Furthermore, the electric and magnetic fields are in phase and the ratio of their amplitudes is constant. In this case 〈S〉 can be expressed in terms of the electric field alone as
〈S〉 = 1
2
√ ε0 ε
μ0 μ |E|2nr, (2.60)
where nr represents the unit vector in the radial direction and the inverse of the square root denotes the wave impedance.


24 Theoretical foundations
Energy density in dispersive and lossy media
The two last terms in Eq. (2.55) strictly vanish only in a linear medium with no dispersion and no losses. The only medium fulfilling these conditions is vacuum. For all other media, the last two terms only vanish approximately. In this section we consider a linear medium with a frequency-dependent and complex ε and μ. Let us return to the Poynting theorem stated in Eq. (2.54). While the left-hand side denotes the power flowing in or out of the volume V, the right-hand side denotes the power dissipated or generated in the volume V. The three terms on the right-hand side are of similar form and so we start by considering first the electric energy term E·(∂D/∂t). The electric energy density wE at the time t is
wE(r, t) =
∫t
−∞
E(r, t′) · ∂D(r, t′)
∂ t′ dt′. (2.61)
We now express the fields E and D in terms of their Fourier transforms as E(t′) =
∫ ˆE(ω)exp[−iωt′]dω and D(t′) = ∫ ˆD(ω)exp[−iωt′]dω, respectively. In the last expres
sion we substitute ω = −ω′ and obtain D(t′) = ∫ Dˆ ∗(ω′)exp[iω′t′]dω′, where we used Dˆ (−ω′) = Dˆ ∗(ω′) since D(t) is real (c.f. Eq. (2.18)). Using the linear relation Dˆ = ε0ε ˆE and inserting the Fourier transforms in Eq. (2.61) yields
wE(r, t) = ε0
∫∞
−∞
∫∞
−∞
ω′ ε∗(ω′)
ω′ − ω Eˆ (ω)· ˆE∗(ω′) ei(ω′−ω)tdω′ dω, (2.62)
where we have carried out the differentiation and integration over time and assumed that the fields were zero at t → −∞. For later purposes it is advantageous to represent the above result in different form. Using the substitutions u′ = −ω and u = −ω′ and making use of Eˆ (−u) = ˆE∗(u) and ε(−u) = ε∗(u) gives an expression similar to Eq. (2.62) but in terms of u and u′. Finally, we add this expression to Eq. (2.62) and take one half of the resulting sum, which yields [5]
wE(r, t) = ε0
2
∫∞
−∞
∫∞
−∞
[ ω′ε∗(ω′) − ωε(ω) ω′ − ω
]
ˆE(ω)·Eˆ ∗(ω′) ei(ω′−ω)t dω′ dω. (2.63)
Similar expressions are obtained for the magnetic term H·(∂B/∂t) and the dissipative term j·E in Eq. (2.54). If ε(ω) is a complex function then wE accounts not only for the energy density built up in the medium but also for the energy transferred to the medium, such as heat dissipation. This contribution becomes indistinguishable from the term j·E in Eq. (2.54) as has already been discussed in Section 2.8. Thus, the imaginary part of ε can be included in the conductivity σ (c.f. Eq. (2.32)) and accounted for in the term j·E through the linear relationship ˆj = σ Eˆ . Therefore, to discuss the energy density it suffices to consider only the real part of ε, which we’re going to denote as ε′. Let us now consider a monochromatic field represented by Eˆ (r, ω) = E0(r) [δ(ω − ω0) + δ(ω + ω0)]/2. Inserting into Eq. (2.63) yields four terms: two that are constant in time and two that oscillate in time. Upon averaging over an oscillation period 2π/ω0 the oscillatory terms vanish and only the constant terms survive. For these terms we must view the expression in brackets in Eq. (2.63) as a limit; that is,
ωl′i→mω
[ ω′ ε′(ω′) − ωε′(ω) ω′ − ω
]
= d [ω ε′(ω)]
dω
∣∣∣∣ω=ω0
. (2.64)


25 2.12 Dyadic Green functions
Thus, the cycle average of Eq. (2.63) yields
w ̄E(r) = ε0d [ω ε′(ω)]
4d ω
∣∣∣∣ω=ω0
|E0(r)|2. (2.65)
A similar result can be derived for the magnetic term H·(∂B/∂t). It can be shown that Eq. (2.65) also holds for quasi-monochromatic fields that have frequency components ω only in a narrow range about a center frequency ω0. Such fields can be represented as
E(r, t) = Re{E ̃ (r, t)} = Re{E0(r, t) e−iω0t}, (2.66)
which is known as the slowly varying amplitude approximation. Here, E0(r, t) is the slowly varying (complex) amplitude and ω0 is the “carrier” frequency. The envelope E0 spans over many oscillations of frequency ω0. Expressing the field amplitudes in terms of time-averages, that is |E0|2 = 2 〈E(t)·E(t)〉, we can express the total cycle-averaged energy density W ̄ as
W ̄ =
[
ε0
d [ω ε′(ω)] dω
〈
E·E
〉
+ μ0
d [ω μ′(ω)] dω
〈
H·H
〉]
, (2.67)
where E = E(r, t) and H = H(r, t) are the time-dependent fields. Notice that ω is the center frequency of the spectra of E and H. For a medium with negligible dispersion this
expression reduces to the familiar W ̄ = (1/2) [ε0ε′|E0|2+ μ0μ′ |H0|2], which follows from Eq. (2.57) using the dispersion-free constitutive relations. Because of d(ωε′)/dω > 0 and d(ωμ′)/dω > 0 the energy density is always positive, even for metals with ε′ < 0. A detailed discussion on energy density in dispersive and lossy materials can be found in Refs. [5, 6].
2.12 Dyadic Green functions
An important concept in field theory is the Green function: the fields due to a point source.
In electromagnetic theory, the dyadic Green function ↔ G is essentially defined by the electric field E at the field point r generated by a radiating electric dipole p located at the source point r′. In mathematical terms this reads as
E(r) = ω2μ0μ ↔ G (r, r′)p. (2.68)
To understand the basic idea of Green functions we will first consider a general mathematical point of view.
2.12.1 Mathematical basis of Green functions
Consider the following general, inhomogeneous equation:
LA(r) = B(r). (2.69)


26 Theoretical foundations
L is a linear operator acting on the vector field A representing the unknown response of the system. The vector field B is a known source function and makes the differential equation inhomogeneous. A well-known theorem for linear differential equations states that the general solution is equal to the sum of the complete homogeneous solution (B = 0) and a particular inhomogeneous solution. Here, we assume that the homogeneous solution (A0) is known. We thus need to solve for an arbitrary particular solution. Usually it is difficult to find a solution of Eq. (2.69) and it is easier to consider the special inhomogeneity δ(r − r′), which is zero everywhere, except in the point r = r′. Then, the linear equation reads as
LGi(r, r′) = niδ(r − r′) (i = x, y, z), (2.70)
where ni denotes an arbitrary constant unit vector. Here Gi is the solution of L for the source niδ(r − r′), while A is the solution of L for the source B. In general, the vector field Gi depends on the location r′ of the inhomogeneity δ(r − r′). Therefore, the vector r′ has been included in the argument of Gi. The three equations given by Eq. (2.70) can be written in closed form as
L ↔ G (r, r′) = I↔ δ(r − r′), (2.71)
where the operator L acts on each column of G↔ separately and I↔ is the unit dyad. The
function ↔ G fulfilling Eq. (2.71) is known as the dyadic Green function.
Next, assume that Eq. (2.71) has been solved and that ↔ G is known. Postmultiplying
Eq. (2.71) by B(r′) on both sides and integrating over the volume V in which B = 0 gives
∫
V
L G↔ (r, r′)B(r′)dV′ =
∫
V
B(r′)δ(r − r′)dV′. (2.72)
The right-hand side simply reduces to B(r) and with Eq. (2.69) it follows that
LA(r) =
∫
V
L G↔ (r, r′)B(r′)dV′. (2.73)
If on the right-hand side the operator L is taken out of the integral, the solution of Eq. (2.69) can be expressed as
A(r) =
∫
V
↔ G (r, r′)B(r′)dV′. (2.74)
Thus, the solution of the original equation can be found by integrating the product of the dyadic Green function and the inhomogeneity B over the source volume V.
The assumption that the operators L and ∫ dV′ can be interchanged is not strictly valid
and special care must be applied if the integrand is not well-behaved. Most often G↔ is singular at r = r′ and an infinitesimal exclusion volume surrounding r = r′ has to be introduced [7, 8]. Depolarization of the principal volume must be treated separately, resulting
in a term (L↔) depending on the geometrical shape of the volume. Furthermore, in numerical schemes the principal volume has a finite size, giving rise to a second correction term,
which is commonly designated by ↔ M. As long as we consider field points outside of the source volume V, i.e. r ∈ V, we do not need to consider these tricky issues. However, the topic of the principal volume will be taken up in Chapter 16.


27 2.12 Dyadic Green functions
2.12.2 Derivation of the Green function for the electric field
The derivation of the Green function for the electric field is most conveniently accomplished by considering the time-harmonic vector potential A and the scalar potential φ in an infinite and homogeneous space characterized by the constants ε and μ. In this case, A and φ are defined by the relationships
E(r) = iωA(r) − ∇φ(r), (2.75)
H(r) = 1
μ0μ ∇ × A(r). (2.76)
We can insert these equations into Maxwell’s second equation (2.27) and obtain
∇ × ∇ × A(r) = μ0μj(r) − iωμ0με0ε[iωA(r) − ∇φ(r)], (2.77)
where we used D = ε0εE. The potentials A and φ are not uniquely defined by Eqs. (2.75) and (2.76). We are still free to define the value of ∇ · A, which we choose as
∇ · A(r) = iωμ0με0εφ(r). (2.78)
A condition that fixes the redundancy of Eqs. (2.75) and (2.76) is called a gauge condition. The gauge chosen through Eq. (2.78) is the so-called Lorenz gauge. Using the mathematical identity ∇ × ∇ × = −∇2 + ∇∇ · together with the Lorenz gauge we can rewrite
Eq. (2.77) as
[
∇2 + k2]
A(r) = −μ0μj(r), (2.79)
which is the inhomogeneous Helmholtz equation. It holds independently for each component Ai of A. A similar equation can be derived for the scalar potential φ,
[
∇2 + k2]
φ(r) = −ρ(r)/(ε0ε). (2.80)
Thus, we obtain four scalar Helmholtz equations of the form
[
∇2 + k2]
f (r) = −g(r). (2.81)
To derive the scalar Green function G0(r, r′) for the Helmholtz operator we replace the source term g(r) by a single point source δ(r − r′) and obtain
[
∇2 + k2]
G0(r, r′) = −δ(r − r′). (2.82)
The coordinate r denotes the location of the field point, i.e. the point at which the fields are to be evaluated, whereas the coordinate r′ designates the location of the point source. Once we have determined G0 we can state the particular solution for the vector potential in Eq. (2.79) as
A(r) = μ0μ
∫
V
j(r′) G0(r, r′) dV′. (2.83)


28 Theoretical foundations
A similar equation holds for the scalar potential. Both solutions require the knowledge of the Green function defined through Eq. (2.82). In free space, the only physical solution of this equation is [1]
G0(r, r′) = e±ik|r − r′|
4π |r − r′| . (2.84)
The solution with the plus sign denotes a spherical wave that propagates out of the origin, whereas the solution with the minus sign is a wave that converges towards the origin. In the following we retain only the outwards propagating wave. The scalar Green function can be introduced into Eq. (2.83) and the vector potential can be calculated by integrating over the source volume V. Thus, we are in a position to calculate the vector potential and scalar potential for any given current distribution j and charge distribution ρ. Notice that the Green function in Eq. (2.84) applies only to a homogeneous three-dimensional space. The Green function of a two-dimensional space or a half-space will have a different form. So far we have reduced the treatment of Green functions to the potentials A and φ because this allows us to work with scalar equations. The formalism becomes more involved when we consider the electric and magnetic fields. The reason for this is that a source current in the x-direction leads to an electric and magnetic field with x-, y-, and z-components. This is different for the vector potential: a source current in x gives rise to a vector potential with just an x-component. Thus, in the case of the electric and magnetic fields we need a Green function that relates all components of the source to all components of the fields, or, in other words, the Green function must be a tensor. This type of Green function is called a dyadic Green function and has been introduced in the previous section. To determine the dyadic Green function we start with the wave equation for the electric field Eq. (2.33). In a homogeneous space it reads as
∇ × ∇ × E(r) − k2 E(r) = iωμ0μ j(r). (2.85)
We can define for each component of j a corresponding Green function. For example, for jx we have
∇ × ∇ × Gx(r, r′) − k2Gx(r, r′) = δ(r − r′)nx, (2.86)
r
r′
E(r)
j(r′) G(r,r′)
V
Fig. 2.3 Illustration of the dyadic Green function G↔(r,r’). The Green function renders the electric field at the field point r due to a single point source j at the source point r’. Since the field at r depends on the orientation of j the Green function must account for all possible orientations in the form of a tensor.


29 2.12 Dyadic Green functions
where nx is the unit vector in the x-direction. A similar equation can be formulated for a point source in the y- and z-directions. In order to account for all orientations we write as the general definition of the dyadic Green function for the electric field [9]
∇ × ∇× ↔ G(r, r′) − k2↔ G(r, r′) = I↔δ(r − r′), (2.87)
I↔ being the unit dyad (unit tensor). The first column of the tensor ↔ G corresponds to the field due to a point source in the x-direction, the second column to the field due to a point source in the y-direction, and the third column is the field due to a point source in the z-direction. Thus a dyadic Green function is just a compact notation for three vectorial Green functions. As before, we can view the source current in Eq. (2.85) as a superposition of point
currents. Thus, if we know the Green function ↔ G we can state a particular solution of Eq. (2.85) as
E(r) = iωμμ0
∫
V
↔ G(r, r′)j(r′)dV′. (2.88)
However, this is a particular solution and we need to add any homogeneous solutions E0. Thus, the general solution turns out to be
E(r) = E0(r) + iωμ0μ
∫
V
↔ G(r, r′) j(r′)dV′ r ∈/ V. (2.89)
The corresponding magnetic field reads as
H(r) = H0(r) +
∫
V
[
∇ × ↔ G(r, r′)
]
j(r′)dV′ r ∈/ V. (2.90)
These equations are called volume integral equations. They are very important since they form the basis for various formalisms such as the method of moments, the LippmannSchwinger equation, and the coupled-dipole method. We have limited the validity of the volume integral equations to the space outside the source volume V in order to avoid the
apparent singularity of G↔ at r = r′. This limitation will be relaxed in Chapter 16. In order to solve Eqs. (2.89) and (2.90) for a given distribution of currents, we still need
to determine the explicit form of ↔ G. Introducing the Lorenz gauge Eq. (2.78) into Eq. (2.75) leads to
E(r) = iω
[
1+ 1
k2 ∇∇·
]
A(r). (2.91)
The first column vector of ↔ G, i.e. Gx, defined in Eq. (2.86) is simply the electric field due to a point source current j = (iωμ0)−1δ(r − r′)nx. The vector potential originating from this source current is, according to Eq. (2.83),
A(r) = (iω)−1G0(r, r′)nx. (2.92)
Upon inserting this vector potential into Eq. (2.91) we find
Gx(r, r′) =
[
1+ 1
k2 ∇∇ ·
]
G0(r, r′)nx, (2.93)


30 Theoretical foundations
with similar expressions for Gy and Gz. The only thing remaining to be done is to tie the three solutions together to form a dyad. With the definition ∇ · [G0
I↔] = ∇G0 the dyadic
Green function ↔ G can be calculated from the scalar Green function G0 in Eq. (2.84) as
↔ G(r, r′) =
[ I↔ + 1
k2 ∇∇
]
G0(r, r′). (2.94)
2.12.3 Time-dependent Green functions
The time dependence in the wave equations can be separated and the resulting harmonic differential equation for the time behavior is easily solved. A monochromatic field can be represented in the form of Eq. (2.25) and any other time-dependent field can be generated by a Fourier transform (sum of monochromatic fields). However, for the study of ultrafast phenomena it is of advantage to retain the explicit time behavior. In this case we have to generalize the definition of A and φ as5
E(r, t) = − ∂
∂t A(r, t) − ∇φ(r, t), (2.95)
H(r, t) = 1
μ0μ ∇ × A(r, t), (2.96)
from which we find the time-dependent Helmholtz equation in the Lorenz gauge (cf. Eq. (2.79)) [
∇2 − n2
c2
∂2
∂t2
]
A(r, t) = −μ0μ j(r, t). (2.97)
A similar equation holds for the scalar potential φ. The definition of the scalar Green function is now generalized to [
∇2 − n2
c2
∂2
∂t2
]
G0(r, r′; t, t′) = −δ(r − r′)δ(t − t′). (2.98)
The point source is now defined with respect to space and time. The solution for G0 is [1]
G0(r, r′; t, t′) =
δ
(
t′ − [t ∓ (n/c)|r − r′|] )
4π |r − r′| , (2.99)
where the minus sign is associated with the response at a time t later than t′. Using G0
we can construct the time-dependent dyadic Green function ↔ G(r, r′; t, t′) as in the previous case. Since we shall mostly work with time-independent Green functions we avoid further details and refer the interested reader to specialized books on electrodynamics. Working with time-dependent Green functions accounts for arbitrary-time behavior but it is very difficult to incorporate dispersion. Time-dependent processes in dispersive media are more conveniently solved using Fourier transforms of monochromatic fields.
5 We assume a non-dispersive medium, i.e. ε(ω) = ε and μ(ω) = μ.


31 2.13 Reciprocity
2.13 Reciprocity
The reciprocity theorem generally states that the source and detector of electromagnetic fields can be interchanged without affecting the physical situation. The derivation of the reciprocity theorem is formally the same as the derivation of Poynting’s theorem in Section 2.11. For simplicity we restrict the discussion to purely monochromatic fields represented by complex amplitudes. Let us consider two spatially separate volumes V1 and V2 with the current densities j1 and j2, respectively. j1 creates the fields E1 and H1, and j2 gives rise to fields E2 and H2. We write Maxwell’s curl equations separately for the two fields as
∇ × E1 = iωB1,
∇ × H1 = −iωD1 + j1,
∇ × E2 = iωB2,
∇ × H2 = −iωD2 + j2.
We now multiply the first equation by H2, the second by E2, the third by H1, and the fourth by E1, and then subtract the sum of the latter two equations from the sum of the first two equations, which yields
(H2 · ∇ × E1 − E1 · ∇ × H2) + (E2 · ∇ × H1 − H1 · ∇ × E2)
= iω(H2 · B1 − H1 · B2) − iω(E2 · D1 − E1 · D2) + (j1 · E2 − j2 · E1).
(2.100)
The left-hand side is identical to ∇ · (E1 × H2 − E2 × H1). Furthermore, assuming linear constitutive relations the first two terms on the right-hand side cancel out and we arrive at
∇ · (E1 × H2 − E2 × H1) = j1 · E2 − j2 · E1, (2.101)
which is the Lorentz reciprocity theorem with sources [10, 11]. We now integrate Eq. (2.101) over a spherical volume with large radius and assume that all sources and objects, such as scatterers, are finite in size, Then, after making use of Gauss’s theorem and the fact that far-fields are transverse to the surface normal of the spherical volume, the term on the left-hand side in Eq. (2.101) vanishes and we obtain
∫
V1
j1 · E2 dV =
∫
V2
j2 · E1 dV, (2.102)
where we have reduced the integration volume to regions where the currents are non-zero. Equation (2.102) is of central importance and is widely used in antenna theory. For lossless media, the reciprocity theorem is equivalent to time reversibility. However, in dissipative media time-reversibility is lost whereas the reciprocity theorem remains valid [11]. At first sight, the expressions in Eq. (2.102) look similar to the right-hand side of Eq. (2.58). However, there are no complex conjugates in Eq. (2.102) and reciprocity is not just another statement of energy conservation.


32 Theoretical foundations
Let us now express the fields E1 and E2 in Eq. (2.102) in terms of their source cur
rents. This can be done using Eq. (2.88) by means of the Green dyadic ↔ G. The equality in Eq. (2.102) then leads to
↔ G(r1, r2) = ↔ G(r2, r1). (2.103)
Thus, reciprocity implies that the Green dyadic is symmetric and that it isn’t affected by interchanging the source and the detector.
2.14 Evanescent fields
Evanescent fields play a central role in nano-optics. The word evanescent derives from the Latin word evanescere and has meanings like vanishing from notice or imperceptible. Evanescent fields can be described by plane waves of the form Eei(kr−ωt). They are characterized by the fact that at least one component of the wavevector k describing the direction of propagation is imaginary. In the spatial direction defined by the imaginary component of k the wave does not propagate but rather decays exponentially. Evanescent fields are of major importance for the understanding of optical fields that are confined to subwavelength dimensions. This section discusses the basic properties of evanescent waves and introduces simple experimental arrangements for their creation and measurement. Evanescent waves never occur in a homogeneous medium but are inevitably connected to the interaction of light with inhomogeneities [12]. The simplest case of an inhomogeneity is a plane interface. Let us consider a plane wave impinging on such a flat interface between two media characterized by optical constants ε1, μ1 and ε2, μ2. As discussed in Section 2.10.1, the presence of the interface will lead to a reflected wave and a refracted wave whose amplitudes and directions are described by Fresnel coefficients and by Snell’s law, respectively. To derive the evanescent wave generated by total internal reflection at the surface of a dielectric medium, we refer to the configuration shown in Fig. 2.2. We choose the x-axis to be in the plane of incidence. Using the symbols defined in Section 2.10.1, the complex transmitted field vector can be expressed as
E2 =
⎡
⎢⎢⎣
−E(p)
1 tp(kx) kz2 /k2
E(s)
1 ts (kx)
E(p)
1 tp(kx) kx/k2
⎤
⎥⎥⎦ eikxx+ikz2 z, (2.104)
which can be expressed entirely in terms of the angle of incidence θ1 using kx = k1 sin θ1. Note that we suppressed the harmonic time factor exp(−iωt). With this substitution the longitudinal wavenumbers can be written as (cf. Eq. (2.48))
kz1 = k1
√
1 − sin2θ1, kz2 = k2
√
1 − n ̃2 sin2θ1, (2.105)


33 2.14 Evanescent fields
where we introduced the relative index of refraction
n ̃ =
√ε1μ1
√ε2μ2
. (2.106)
For  ̃n > 1, with increasing θ1 the argument of the square root in the expression for kz2 gets smaller and smaller and eventually becomes negative. The critical angle θc can be defined by the condition
1 − n ̃2 sin2θ1 = 0, (2.107)
which describes a refracted plane wave with zero wavevector component in the z-direction (kz2 = 0). Consequently, the refracted plane wave travels parallel to the interface. Solving for θ1 yields
θc = arcsin(1/ ̃n). (2.108)
For a glass/air interface at optical frequencies, we have ε2 = 1, ε1 = 2.25, and μ1 = μ2 = 1, yielding a critical angle θc = 41.8◦. For θ1 > θc, kz2 becomes imaginary. Expressing the transmitted field as a function of the angle of incidence θ1 results in
E2 =
⎡
⎢⎢⎣
−iE(p)
1 tp(θ1)
√ ̃n2 sin2θ1 − 1
E(s)
1 ts(θ1)
E(p)
1 tp(θ1)  ̃n sin θ1
⎤
⎥⎥⎦ ei sin(θ1) k1xe−γ z, (2.109)
where the decay constant γ is defined by
γ = k2
√
 ̃n2 sin2θ1 − 1 . (2.110)
This equation describes a field that propagates along the surface but decays exponentially into the medium of transmittance. Thus, a plane wave incident at an angle θ1 > θc creates an evanescent wave. Excitation of an evanescent wave with a plane wave at supercritical incidence (θ1 > θc) is referred to as total internal reflection (TIR). For the glass/air interface considered above and an angle of incidence of θ1 = 45◦, the decay constant is γ = 2.22/λ. This means that already at a distance of ≈λ/2 from the interface the timeaveraged field is a factor of e smaller than it is at the interface. At a distance of ≈2λ the field becomes negligible. The larger the angle of incidence θ1 the faster the decay will be. Note that the Fresnel coefficients depend on θ1. For θ1 > θc they become complex numbers and, consequently, the phase of the reflected and transmitted wave is shifted relative to the incident wave. This phase shift is the origin of the so-called Goos–Hänchen shift. Furthermore, for p-polarized excitation, it results in elliptic polarization of the evanescent wave with the field vector rotating in the plane of incidence (see e.g. [13] and Problem 2.5). Evanescent fields as described by Eq. (2.109) can be produced by directing a beam of light into a glass prism as sketched in Fig. 2.4(b). Experimental verification for the existence of this rapidly decaying field in the optical regime relies on approaching a transparent body to within λ/2 of the interface that supports the evanescent field. As shown in Fig. 2.5, this can be accomplished, for example, by using a sharp transparent fiber that converts the


34 Theoretical foundations
Fig. 2.4 Excitation of an evanescent wave by total internal reflection. (a) An evanescent wave is created in a medium if the plane wave is incident at an angle θ1 > θc. (b) Actual experimental realization using a prism and a weakly focused Gaussian beam.
evanescent field at its tip into a guided mode propagating along the fiber [14]. This measurement technique is called photon scanning tunneling microscopy and will be discussed later in Chapter 5. For p- and s-polarized evanescent waves, the intensity of the evanescent wave can be larger than that of the input beam. To see this we set z = 0 in Eq. (2.109) and we write for an s- and p-polarized plane wave separately the intensity ratio |E2(z = 0)|2/|E1(z = 0)|2. This ratio is equal to the absolute square of the Fresnel transmission coefficient tp,s. These transmission coefficients are plotted in Fig. 2.6 for the example of a glass/air interface. For p- (s-)polarized light the transmitted evanescent intensity is up to a factor of 9 (4) larger than the incoming intensity. The maximum enhancement is found at the critical angle of TIR. The physical reason for this enhancement is a surface polarization that is induced by the incoming plane wave which is also represented by the boundary condition (2.43). A similar enhancement effect, but a much stronger one, can be obtained when the glass/air interface is covered by a thin layer of a noble metal. Here, so-called surface plasmon polaritons can be excited. We will discuss this and similar effects in more detail in Chapter 12.
2.14.1 Energy transport by evanescent waves
For non-absorbing media and for supercritical incidence, all the power of the incident wave is reflected. This effect is known as total internal reflection (TIR). One can predict that because no losses occur upon reflection at the interface there is no net energy transport into the medium of transmittance. In order to prove this fact we have to investigate the time-averaged energy flux across a plane parallel to the interface. This can be done by considering the z-component of the Poynting vector (cf. Eq. (2.59))
〈S〉z = 1
2 Re
(
ExHy∗ − EyHx∗
)
, (2.111)


35 2.14 Evanescent fields
where all fields are evaluated in the upper medium, i.e. the medium of transmittance. Applying Maxwell’s equation (2.26) to the special case of a plane or evanescent wave allows us to express the magnetic field in terms of the electric field as
H=
√ ε0ε μ0μ
[( k
k
)
×E
]
. (2.112)
On introducing the expressions for the transmitted field components of E and H into Eq. (2.111), it is straightforward to prove that 〈S〉z vanishes (Problem 2.4) and that there is no net energy transport in the direction normal to the interface. On the other hand, when considering the energy transport along the interface (〈S〉x), a non-zero result is found:
〈S〉x = 1
2
√ ε2μ2
ε1μ1
sin θ1
(∣∣ts∣∣2 ∣∣∣E(s)
1
∣∣∣2 + ∣∣tp∣∣2 ∣∣∣E(p)
1
∣∣∣2)
e−2γ z. (2.113)
Thus, an evanescent wave transports energy along the surface, in the direction of the transverse wavevector. The absence of a net energy flow normal to the surface does not mean that there is no energy contained in an evanescent wave. For example, the local field distribution can be mapped out by using the fluorescence of a single molecule as a local probe.6 The rate R at which the fluorophore emits photons when excited by the optical electric field is given by
3.0
2.5
2.0
P (nW)
1.5
1.0
0.5
0.0 100 200 300
Z(nm)
400 500
0 200 400 600 800 1000
X(nm)
Fig. 2.5 Spatial modulation of the standing evanescent wave along the propagation direction of two interfering waves (x-axis) and the decay of the intensity in the z-direction. The ordinate represents the measured optical power. From [14].
6 Excitation of fluorescence using evanescent waves is quite popular in biological imaging. Since only a thin slice of the sample is illuminated, background is drastically reduced. The technique is known as total internal reflection fluorescence (TIRF) microscopy [15].


36 Theoretical foundations
R ∼ |p · E|2 , (2.114)
where p is the absorption dipole moment of the molecule. As an example, for s-polarized fields the fluorescence rate of a molecule with a non-zero dipole component along the y-axis at a distance z above the interface will be
R (z) ∼
∣∣∣tsE(s)
1
∣∣∣2
e−2γ z, (2.115)
decaying twice as fast as the electric field itself. Notice that a molecule can be excited even though the average Poynting vector vanishes.
2.14.2 Frustrated total internal reflection
Evanescent fields can be converted into propagating radiation if they interact with matter [12]. This phenomenon is among the most important effects in near-field optical microscopy since it explains how information about subwavelength structures is transported into the far-field. We shall discuss the physics behind this conversion by considering a very simple model. A plane interface will be used in order to create an evanescent wave by TIR as before. A second parallel plane interface is then advanced towards the first interface until the gap d is within the range of the typical decay length of the evanescent wave. A possible way to realize this experimentally is to close together two prisms with very flat or slightly curved surfaces as indicated in Fig. 2.7(b). The evanescent wave then interacts with the second interface and can be partly converted into propagating radiation. This situation is analogous to quantum mechanical tunneling through a potential barrier. The geometry of the problem is sketched in Fig. 2.7(a). The fields are most conveniently expressed in terms of partial fields that are restricted to a single medium. The partial fields in media 1 and 2 are written as a superposition of incident and reflected waves, whereas for medium 3 there is only a transmitted wave. The propagation character of these waves, i.e. whether they are evanescent or propagating in either of the three media, can be determined from the magnitude of the longitudinal
0
0 20 40 60 80
p
s
|tp,s|2(z=0)
2
4
6
8
angle of incidence θ1 (degrees)
Fig. 2.6 Intensity enhancement on top of a glass surface irradiated by a plane wave with variable angle of incidence θ1. For pand s-polarized waves, the enhancement peaks at the critical angle θc = 41.8◦ marked by the dotted line.


37 2.14 Evanescent fields
wavenumber in each medium in analogy to Eq. (2.105). The longitudinal wavenumber in medium j reads
kjz =
√
k2
j − k‖2 = kj
√
1 − (k1/kj)2 sin2θ1, j ∈ {1, 2, 3}, (2.116)
where kj = njk0 = nj(ω/c) and nj = √εjμj. In the following a layered system with n2 < n3 < n1 will be discussed, which includes the system sketched in Fig. 2.7. This leads to three regimes for the angle of incidence in which the transmitted intensity as a function of the gap width d shows different behavior.
1. For θ1 < arcsin(n2/n1) or k‖ < n2k0, the field is entirely described by propagating plane waves. The intensity transmitted to a detector far away from the second interface (in the far-field) will not vary substantially with gapwidth, but will only show rather weak interference undulations. 2. For arcsin(n2/n1) < θ1 < arcsin(n3/n1) or n2k0 < k‖ < n3k0 the partial field in medium 2 is evanescent, but in medium 3 it is propagating. At the second interface evanescent waves are converted into propagating waves. The intensity transmitted to a remote detector will decrease strongly with increasing gapwidth. This situation is referred to as frustrated total internal reflection (FTIR).
3. For θ1 > arcsin (n3/n1) or k‖ > n3k0 the waves in layer 2 and in layer 3 are evanescent and no intensity will be transmitted to a remote detector in medium 3.
If we chose θ1 such that case 2 is realized (FTIR), the transmitted intensity I(d) will reflect the steep distance dependence of the evanescent wave(s) in medium 2. However, as shown in Fig. 2.8, I(d) deviates from a purely exponential behavior because the field in medium 2 is a superposition of two evanescent waves of the form
ε2, μ2
ε3, μ3
ε1, μ1
Fig. 2.7 Transmission of a plane wave through a system of two parallel interfaces. In frustrated total internal reflection (FTIR), the evanescent wave created at interface B is partly converted into a propagating wave by the interface A of a second medium. (a) Configuration and definition of parameters. A and B are interfaces between media 2 and 3 and 1 and 2, respectively. The reflected waves are omitted for clarity. (b) The experimental set-up used to observe frustrated total internal reflection.


38 Theoretical foundations
c1e−γ z + c2e+γ z. (2.117)
The second term originates from the reflection of the primary evanescent wave (first term) at the second interface and its magnitude (c2) depends on the material properties. Figure 2.8 shows typical transmission curves for two different angles of incidence. This figure also shows that the decay measured in FTIR deviates from a simple exponential decay. In the next section, the importance of evanescent waves for the rigorous theoretical description of arbitrary optical fields near sources or material boundaries will be discussed.
2.15 Angular spectrum representation of optical fields
The angular spectrum representation is a mathematical technique to describe optical fields in homogeneous media. Optical fields are described as a superposition of plane waves and evanescent waves, both of which are physically intuitive solutions of Maxwell’s equations. The angular spectrum representation has been found to be a very powerful method for the description of laser-beam propagation and light focusing. Furthermore, in the paraxial limit, the angular spectrum representation becomes identical with the framework of Fourier optics, which extends its importance even further. We will use the angular spectrum representation extensively in Chapters 3 and 4 to discuss strongly focused laser beams and limits of spatial resolution. By the angular spectrum representation we understand the series expansion of an arbitrary field in terms of plane (and evanescent) waves with variable amplitudes and propagation directions. Assume we know the electric field E(r) at any point r = (x, y, z) in space.
d/
0.2 0.4 0.6 0.8 1
0
0.2
0.4
0.6
0.8
1
0
transmitted intensity
(a)
(b)
(c)
Fig. 2.8 Transmission in a system of three media with parallel interfaces as a function of the gap d between the two interfaces. A p-polarized plane wave excites the system. The material constants are n1 = 2, n2 = 1, and n3 = 1.51. This leads to critical angles θc of 30◦ and 49.25◦. For angles of incidence θ1 between 0◦ and 30◦ the gap dependence shows interference-like behavior (here θ1 = 0◦, dash–dotted line, curve (a)). For angles between 30◦ and 49.25◦ the transmission (monotonically) decreases with increasing gap width (here θ1 = 35◦, full line, curve (b)). Curve (c) shows the intensity of the evanescent wave in the absence of the third medium.


39 2.15 Angular spectrum representation
For example, E(r) can be the solution of an optical scattering problem, as shown in Fig. 2.9, for which E = Einc + Escatt. In the angular spectrum picture, we draw an arbitrary axis z and consider the field E in a plane z = constant transverse to the chosen axis. In this plane we can evaluate the two-dimensional Fourier transform of the field E as
ˆE(kx, ky; z) = 1
4π2
∫∞
−∞
∫
E(x, y, z) e−i[kx x + ky y] dx dy, (2.118)
where x, y are the Cartesian transverse coordinates and kx, ky the corresponding spatial frequencies or reciprocal coordinates. Similarly, the inverse Fourier transform reads as
E(x, y, z) =
∫∞
−∞
∫
ˆE(kx, ky; z) ei[kx x + ky y] dkx dky. (2.119)
Notice that in the notation of Eqs. (2.118) and (2.119) the field E = (Ex, Ey, Ez) and its Fourier transform ˆE = (Eˆ x, Eˆ y, Eˆ z) represent vectors. Thus, the Fourier integrals hold separately for each vector component. So far we have imposed no requirements on the field E, but we will assume that in the transverse plane the medium is homogeneous, isotropic, linear and source-free. Then, a time-harmonic, optical field with angular frequency ω has to satisfy the vector Helmholtz equation
(∇ 2 + k2)E(r) = 0, (2.120)
where k is determined by k = (ω/c)n and n = √με is the index of refraction. In order to get the time-dependent field E(r, t) we use the convention
E(r, t) = Re{E(r)e−iωt}. (2.121)
Einc
Escatt
z
z = const.
Fig. 2.9 In the angular spectrum representation the fields are evaluated in planes (z = constant) perpendicular to an arbitrarily chosen axis z.


40 Theoretical foundations
On inserting the Fourier representation of E(r) (Eq. (2.119)) into the Helmholtz equation and defining
kz ≡
√
(k2 − kx2 − ky2) with Im{kz} ≥ 0 (2.122)
we find that the Fourier spectrum Eˆ evolves along the z-axis as
ˆE(kx, ky; z) = Eˆ (kx, ky; 0) e±ikzz. (2.123)
The ± sign specifies that we have two solutions that need to be superimposed: the + sign refers to a wave propagating into the half-space z > 0 whereas the − sign denotes a wave propagating into z < 0. Equation (2.123) tells us that the Fourier spectrum of E in an arbitrary image plane located at z = constant can be calculated by multiplying the spectrum in the object plane at z = 0 by the factor exp(±i kz z). This factor is called the propagator in reciprocal space. In Eq. (2.122) we defined that the square root leading to kz renders a result with positive imaginary part. This ensures that the solutions remain finite for z → ±∞. On inserting the result of Eq. (2.123) into Eq. (2.119) we finally find for arbitrary z
E(x, y, z) =
∫∞
−∞
∫
ˆE(kx, ky ; 0) ei[kx x + ky y ± kz z] dkx dky, (2.124)
which is known as the angular spectrum representation. In a similar way, we can also represent the magnetic field H by an angular spectrum as
H(x, y, z) =
∫∞
−∞
∫
Hˆ (kx, ky ; 0) ei[kx x + ky y ± kz z] dkx dky. (2.125)
By using Maxwell’s equation H = (iωμμ0)−1(∇ × E) we find the following relationship between the Fourier spectra ˆE and ˆH:
Hˆ x = Zμ−ε1[(ky/k)Eˆ z − (kz/k)Eˆ y], (2.126)
Hˆ y = Zμ−ε1[(kz/k)Eˆ x − (kx/k)Eˆ z],
Hˆ z = Zμ−ε1[(kx/k)Eˆ y − (ky/k)Eˆ x],
where Zμε = √(μ0μ)/(ε0ε) is the wave impedance of the medium. Although the angular spectra of E and H satisfy the Helmholtz equation they are not yet rigorous solutions of Maxwell’s equations. We still have to require that the fields are divergence-free, i.e. ∇ · E = 0 and ∇ · H = 0. These conditions restrict the k-vector to directions perpendicular to the spectral amplitudes (k · Eˆ = k · ˆH = 0). For the case of a purely dielectric medium with no losses the index of refraction n is a real and positive quantity. The wavenumber kz is then either real or imaginary and turns the factor exp(±i kz z) into an oscillatory or exponentially decaying function. For a certain (kx, ky) pair we then find two different characteristic solutions:


41 2.15 Angular spectrum representation
k
E
kz
kx
φ
x
z
x
z
(a) (b)
kx2 + ky2 = k2
kx
ky
plane waves
evanescent waves
(c)
Fig. 2.10 (a) Representation of a plane wave propagating at an angle φ to the z axis. (b) Illustration of the transverse spatial frequencies of plane waves incident from different angles. The transverse wavenumber (kx2 + ky2)1/2 depends on the angle of incidence and is limited to the interval [0 . . . k]. (c) The transverse wavenumbers kx and ky of plane waves are restricted to a circular area with radius k. Evanescent waves fill the space outside the circle.
Plane waves: ei[kx x + ky y]e±i|kz|z, kx2 + ky2 ≤ k2,
Evanescent waves: ei[kx x + ky y]e−|kz||z|, kx2 + ky2 > k2. (2.127)
Hence, we find that the angular spectrum is indeed a superposition of plane waves and evanescent waves. Plane waves are oscillating functions in z and are restricted by the condition kx2 + ky2 ≤ k2. On the other hand, for kx2 + ky2 > k2 we encounter evanescent waves with an exponential decay along the z-axis. Figure 2.10 shows that the larger the angle between the k-vector and the z-axis is, the larger the oscillation frequency in the transverse plane will be. A plane wave propagating in the direction of z has no oscillation frequency in the transverse plane (kx2 + ky2 = 0), whereas, in the other limit, a plane wave propagating at right angles to z exhibits the highest spatial oscillation frequency in the transverse plane (kx2 + ky2 = k2). Even higher spatial frequencies are covered by evanescent waves. In principle, an infinite bandwidth of spatial frequencies can be achieved. However, the higher the spatial frequencies of an evanescent wave are, the faster the field decay along the z-axis will be. Therefore, practical limitations make the bandwidth finite.
2.15.1 Angular spectrum representation of the dipole field
Strongly localized sources such as dipoles are most conveniently described in a spherical coordinate system. The corresponding solutions of the wave equation are called multipoles. In order to couple these solutions with the angular spectrum picture we need to express the localized sources in terms of plane waves and evanescent waves. Let us start with the vector potential A of an oscillating dipole with its axis aligned along an arbitrary z-axis. The vector potential can be expressed as a one-component vector field as (cf. Eq. (2.92))
A(x, y, z) = A(x, y, z)nz = −ikZμε
4π
eik√x2 + y2 + z2
√
x2 + y2 + z2 nz. (2.128)


42 Theoretical foundations
Besides a constant factor, the expression on the right-hand side corresponds to the scalar Green function (2.84). According to Eqs. (2.76) and (2.91) the electric and magnetic fields are obtained from A as
E(x, y, z) = iω
(
1+ 1
k2 ∇∇ ·
)
A(x, y, z), (2.129)
H(x, y, z) = 1
μ0μ ∇ × A(x, y, z). (2.130)
Thus, the electromagnetic field of the dipole can be constructed from the function exp(ikr)/r, where r = (x2 + y2 + z2)1/2 is the radial distance from the dipole’s origin. To find an angular spectrum representation of the dipole’s electric and magnetic field we need first to find the angular spectrum of the function exp(ikr)/r. This is not a trivial task because the function exp(ikr)/r is singular at r = 0 and therefore not divergence-free at its origin. The homogeneous Helmholtz equation is therefore not valid in the present case. Nevertheless, using complex contour integration it is possible to derive an angular spectrum representation of the function exp(ikr)/r. Since the derivation can be found in other textbooks [3] we state here only the result, which is
eik√x2 + y2 + z2
√
x2 + y2 + z2 = i
2π
∫∞
−∞
∫ eikxx + ikyy + ikz|z|
kz
dkx dky. (2.131)
We have to require that the real and imaginary parts of kz stay positive for all values of kx and ky in the integration. The result (2.131) is known as the Weyl identity [16]. In Chapter 10 we shall use the Weyl identity to calculate dipole emission near planar interfaces.
Problems
2.1 Derive the dyadic Green function ↔ G by substituting the scalar Green function G0 into Eq. (2.94). Discuss the distance dependence |r − r′|. 2.2 Consider an interface between two media 1 and 2 with dielectric constants ε1 = 2.25 and ε2 = 1, respectively. The magnetic permeabilities are equal to unity. A p-polarized plane wave with wavelength λ = 532 nm is incident from medium 1 at an angle of incidence of θ1. Express the Fresnel reflection coefficient in terms of amplitude A and phase . Plot A and as functions of θ1. What are the consequences for the reflected wave? 2.3 Consider the refraction of a plane wave at a plane interface and derive Snell’s law by using the invariance of the transverse wavevector k‖. 2.4 Show that the z-component of the time-averaged Poynting vector 〈S〉z vanishes for an evanescent field propagating in the x-direction. 2.5 Analyze the polarization state of an evanescent field propagating in the x-direction created by total internal reflection of a p-polarized plane wave. Calculate the timedependent electric field E2(x, t) = (E2,x(x, t), 0, E2,z(x, t)) just on top of the interface


43 References
(z = 0). For a fixed position x, the electric field vector E2 defines a curve in the (x, z) plane as the time runs from 0 to λ/c. Determine and plot the shapes of these curves as a function of the position x. For numerical values choose θ1 = 60◦ and n ̃ = 1.5. 2.6 Calculate the transmitted intensity for a system of two glass half-spaces (n = 1.5) separated by an air gap (d) and as a function of the angle of incidence θ1. Determine the transmission function for s-polarized excitation. Normalize the transmission function with the value obtained for θ1 = 0◦. Repeat for p-polarized excitation. 2.7 Derive Eq. (2.123) by inserting the inverse Fourier transform in Eq. (2.119) into the Helmholtz equation (2.120). Assume that the Fourier spectrum is known in the plane z = 0.
2.8 Using the Weyl identity (2.131), derive the spatial spectrum Eˆ (kx, ky; z) of an electric dipole at r0 = (0, 0, z0) with dipole moment p = (p, 0, 0). Consider the asymptotic limit z → ∞ and solve for the electric field E. 2.9 Apply Eq. (2.67) to a small metallic particle described by a free-electron gas. For which frequency is the energy density highest? How do losses scale with frequency? When is the ratio of energy density to energy loss smallest?
References
[1] J. D. Jackson, Classical Electrodynamics, 2nd edn. New York: Wiley (1975). [2] J. A. Stratton, Electromagnetic Theory. New York: McGraw-Hill (1941).
[3] L. Mandel and E. Wolf, Optical Coherence and Quantum Optics. New York: Cambridge University Press (1995). [4] M. Born and E. Wolf, Principles of Optics, 7th edn. New York: Cambridge University Press (1999). [5] F. S. S. Rosa, D. A. R. Dalvit, and P. W. Milonni, “Electromagnetic energy, absorption, and Casimir forces: Uniform dielectric media in thermal equilibrium,” Phys. Rev. A 81, 033812 (2010); “Electromagnetic energy, absorption, and Casimir forces. II. Inhomogeneous dielectric media,” Phys. Rev. A 84, 053813 (2011). [6] L. D. Landau, E. M. Lifshitz, and L. P. Pitaevskii, Electrodynamics of Continuous Media, 2nd edn. Amsterdam: Elsevier (1984). [7] A. D. Yaghjian, “Electric dyadic Green’s functions in the source region,” Proc. IEEE 68, 248–263 (1980). [8] J. V. Bladel, “Some remarks on Green’s dyadic for infinite space,” IRE Trans. Antennas Propag. 9, 563–566 (1961). [9] C. T. Tai, Dyadic Green’s Functions in Electromagnetic Theory, 2nd edn. New York: IEEE Press (1993).
[10] H. A. Lorentz, Versl. Gewone Vergad. Afd. Natuurkd. Koninkl. Ned. Akad. Wetenschap 4, 176–188 (1896); H. A. Lorentz, “The theorem of Poynting concerning the energy in the electromagnetic field and two general propositions concerning the propagation of light,” in Collected Papers, vol. III. Den Haag: Martinus Nijhoff, pp. 1–11 (1936).


44 Theoretical foundations
[11] R. Carminati, M. Nieto-Vesperinas, and J.-J. Greffet, “Reciprocity of evanescent electromagnetic waves,” J. Opt. Soc. Am. A 15, 706–712 (1998). [12] E. Wolf and M. Nieto-Vesperinas, “Analyticity of the angular spectrum amplitude of scattered fields and some of its consequences,” J. Opt. Soc. Am. A 2, 886–889 (1985). [13] S. Sund, J. Swanson, and D. Axelrod, “Cell membrane orientation visualized by polarized total internal reflection fluorescence,” Biophys. J. 77, 2266–2283 (1999). [14] A. Meixner, M. Bopp, and G. Tarrach, “Direct measurement of standing evanescent waves with a photon scanning tunneling microscope,” Appl. Opt. 33, 7995–8000 (1994). [15] D. Axelrod, N. Thompson, and T. Burghardt, “Total internal reflection fluorescent microscopy,” J. Microsc. 129, 19–28 (1983). [16] H. Weyl, “Ausbreitung elektromagnetischer Wellen über einem ebenen Leiter,” Ann. Phys. 60, 481–500 (1919).


3 Propagation and focusing of optical fields
In this chapter we use the angular spectrum representation outlined in Section 2.15 to discuss field distributions in strongly focused laser beams. The same formalism is applied to understand how the fields in a given reference plane are mapped to the far-field. The theory is relevant for the understanding of confocal and multiphoton microscopy, single-emitter experiments, and the understanding of resolution limits. It also defines the framework for different topics to be discussed in later chapters.
3.1 Field propagators
In Section 2.15 we have established that, in a homogeneous space, the spatial spectrum ˆE of an optical field E in a plane z = constant (the image plane) is uniquely defined by the spatial spectrum in a different plane z = 0 (the object plane) according to the linear relationship
ˆE(kx, ky; z) = Hˆ (kx, ky; z) ˆE(kx, ky; 0), (3.1)
where Hˆ is the so-called propagator in reciprocal space
Hˆ (kx, ky; z) = e±ikz z, (3.2)
which is also referred to as the optical transfer function (OTF) in free space. Remember that the longitudinal wavenumber is a function of the transverse wavenumber, i.e. kz = [k2 − (kx2 + ky2)]1/2, where k = nk0 = nω/c = n2π/λ. The ± sign indicates that the field can propagate in the positive- and/or negative-z direction. Equation (3.1) can be interpreted in terms of linear response theory: Eˆ (kx, ky; 0) is the input, Hˆ is a filter function, and ˆE(kx, ky; z) is the output. The filter function describes the propagation of an arbitrary spectrum through space. Hˆ can also be regarded as the response function because it describes the field at z due to a point source at z = 0. In this sense, it is directly related to the Green
function G↔. The filter Hˆ is an oscillating function for (kx2 + ky2) < k2 and an exponentially decreas
ing function for (kx2 + ky2) > k2. Thus, if the image plane is sufficiently separated from the object plane, the contribution of the decaying parts (evanescent waves) is zero and the integration can be reduced to the circular area (kx2 + ky2) ≤ k2. In other words, the 45


46 Propagation and focusing of optical fields
image at z is a low-pass-filtered representation of the original field at z = 0. The spatial frequencies (kx2 + ky2) > k2 of the original field are filtered out during propagation and the information on high spatial variations gets lost. Hence, there is always a loss of information on propagating from near- to far-field and only structures with lateral dimensions larger than
x≈ 1
k= λ
2π n (3.3)
can be imaged with sufficient accuracy. Here, n is the index of refraction. This equation is qualitative and we will provide a more detailed discussion in Chapter 4. In general, higher resolution can be obtained by using a higher index of refraction of the embodying system (substrate, lenses, etc.) or shorter wavelengths. Theoretically, resolutions down to a few nanometers can be achieved by using far-ultraviolet radiation or X-rays. The central idea of near-field optics is to increase the bandwidth of spatial frequencies by retaining the evanescent components of the source fields. Let us now determine how the fields themselves evolve. For this purpose we denote the transverse coordinates in the object plane at z = 0 as (x′, y′) and those in the image plane at z = constant as (x, y). The fields in the image plane are described by the angular spectrum (2.124). We just have to express the Fourier spectrum Eˆ (kx, ky ; 0) in terms of the fields in the object plane. Similarly to Eq. (2.118), this Fourier spectrum can be represented as
ˆE(kx, ky; 0) = 1
4π2
∫∞
−∞
∫
E(x′, y′, 0) e−i[kx x′ + ky y′] dx′ dy′. (3.4)
After insertion into Eq. (2.124) we find the following expression for the field E in the image plane z = constant:
E(x, y, z) = 1
4π 2
∫∞
−∞
∫
E(x′, y′; 0)
∫∞
−∞
∫
ei [kx (x−x′) + ky (y−y′) ± kz z] dx′ dy′ dkx dky
= E(x, y; 0) ∗ H(x, y; z). (3.5)
This equation describes an invariant filter with the following impulse response (propagator in direct space)
H(x, y; z) =
∫∞
−∞
∫
ei [kx x + ky y ± kz z] dkx dky. (3.6)
H is simply the inverse Fourier transform of the propagator in reciprocal space Hˆ (3.2). The field at z = constant is represented by the convolution of H with the field at z = 0.


47 3.2 Paraxial approximation of optical fields
3.2 Paraxial approximation of optical fields
In many optical problems the light fields propagate along a certain direction z and spread out only slowly in the transverse direction. Examples include laser-beam propagation and optical waveguide applications. In these examples the wavevectors k = (kx, ky, kz) in the angular spectrum representation are almost parallel to the z-axis and the transverse wavenumbers (kx, ky) are small compared with k. We can then expand the square root of Eq. (2.122) in a series as
kz = k
√
1 − (kx2 + ky2)/k2 ≈ k − kx2 + ky2
2 k . (3.7)
This approximation is called the paraxial approximation and it considerably simplifies the analytical integration of the Fourier integrals. In the following we shall apply the paraxial approximation to find a description for weakly focused laser beams.
3.2.1 Gaussian laser beams
We consider a fundamental laser beam with a linearly polarized, Gaussian field distribution in the beam waist
E(x′, y′, 0) = E0e
− x′2 + y′2
w20 , (3.8)
where E0 is a constant-field vector in the transverse (x, y) plane. We have chosen z = 0 at the beam waist. The parameter w0 denotes the beam-waist radius. We can calculate the spatial Fourier spectrum at z = 0 as1
ˆE(kx, ky; 0) = 1
4π2
∫∞
−∞
∫
E0e
− x′2 + y′2
w20 e−i [kx x′ + ky y′] dx′ dy′
= E0
w2
0
4π e−(kx2+ ky2) w420 , (3.9)
which is again a Gaussian function. We now insert this spectrum into the angular spectrum representation Eq. (2.124) and replace kz by its paraxial expression in Eq. (3.7)
E(x, y, z) = E0
w2
0
4 π eikz
∫∞
−∞
∫
e−(kx2+ ky2)
( w420 + i z
2k
)
ei[kx x + ky y] dkx dky. (3.10)
This equation can be integrated and gives as a result the familiar paraxial representation of a Gaussian beam
E(x, y, z) = E0 eikz
1 + 2iz/(kw2
0) e
− (x2+y2)
w20
1
1 + 2iz/(kw20) . (3.11)
1 We have ∫−∞∞ exp(−ax2 + ibx)dx = √π/a exp[−b2/(4a)] and ∫−∞∞ x exp(−ax2 + ibx)dx = ib√π exp[−b2/
(4a)]/(2a3/2).


48 Propagation and focusing of optical fields
To get a better feeling for a paraxial Gaussian beam we set ρ2 = x2 + y2, define a new parameter z0 as
z0 = kw2
0
2 , (3.12)
and rewrite Eq. (3.11) as
E(ρ, z) = E0
w0
w(z) e− ρ2
w2(z) ei [kz−η(z) + kρ2/(2R(z))] (3.13)
with the following symbols:
w(z) = w0(1 + z2/z2
0)1/2 beam radius,
R(z) = z(1 + z2
0/z2) wavefront radius, (3.14)
η(z) = arctan(z/z0) phase correction.
The transverse size of the beam is usually defined by the value of ρ = √
x2 + y2 for which the electric field amplitude has decreased to a value of 1/e of its center value:
|E(x, y, z)|/|E(0, 0, z)| = 1/e. (3.15)
It can be shown that the surface defined by this equation is a hyperboloid whose asymptotes enclose an angle
θ= 2
kw0
(3.16)
with the z-axis. From this equation we can directly find the correspondence between the numerical aperture (NA = n sin θ ) and the beam angle as NA ≈ 2n/(kw0). Here we used the fact that, in the paraxial approximation, θ is restricted to small beam angles. Another property of the paraxial Gaussian beam is that, close to the focus, the beam stays roughly collimated over a distance 2z0. z0 is called the Rayleigh range and denotes the
distance from the beam waist to where the beam radius has increased by a factor of √2. It is important to notice that along the z-axis (ρ = 0) the phases of the beam deviate from those of a plane wave. If at z → −∞ the beam was in phase with a reference plane wave, then at z → +∞ the beam will be exactly out of phase with the reference wave. This phase
z
2/ (kw0)
ρ
2z0
ρ
θ
1/e
w(z)
|E|
Fig. 3.1 Illustration and main characteristics of a paraxial Gaussian beam. The beam has a Gaussian field distribution in the transverse plane. The surfaces of constant field strength form a hyperboloid along the z-axis.


49 3.2 Paraxial approximation of optical fields
shift is called the Gouy phase shift and has practical implications in nonlinear confocal microscopy [1]. The 180◦ phase change happens gradually as the beam propagates through its focus. The phase variation is described by the factor η(z) in Eq. (3.14). The tighter the focus the faster the phase variation will be. A qualitative picture of a paraxial Gaussian beam and some of its characteristics are shown in Fig. 3.1 and more detailed descriptions can be found in other textbooks [2, 3]. It is important to notice that, once the paraxial approximation is introduced, the field E no longer satisfies Maxwell’s equations. The error becomes larger the smaller the beamwaist radius w0 is. When w0 becomes comparable to the reduced wavelength λ/n we have to include higher-order terms in the expansion of kz in Eq. (3.7). However, the series expansion converges very poorly for strongly focused beams and one needs to find a more accurate description. We shall return to this topic at a later stage. Another important aspect of Gaussian beams is that they do not exist, no matter how rigorous the theory that describes them! The reason is that a Gaussian beam profile demands a Gaussian Fourier spectrum. However, the Gaussian Fourier spectrum is infinite and contains evanescent components that are not available in a realistic situation. Thus, a Gaussian beam must always be regarded as an approximation. The tighter the focus, the broader the Gaussian spectrum and the more contradictory the Gaussian beam profile will be. Hence, it actually does not make much sense to include higher-order corrections to the paraxial approximation.
3.2.2 Higher-order laser modes
A laser beam can exist in different transverse modes. It is the laser cavity that determines which type of transverse mode is emitted. The most commonly encountered higher beam modes are Hermite–Gaussian and Laguerre–Gaussian beams. The former are generated in cavities with rectangular end mirrors whereas the latter are observed in cavities with circular end mirrors. In the transverse plane, the fields of these modes extend over larger distances and have sign variations in the phase. Since the fundamental Gaussian mode is a solution of a linear homogeneous partial differential equation, namely the Helmholtz equation, any combinations of spatial derivatives of the fundamental mode are also solutions to the same differential equation. Zauderer [4] pointed out that Hermite–Gaussian modes EnHm can be generated from the fundamental mode E according to
EH
nm(x, y, z) = wn + m
0
∂n
∂ xn
∂m
∂ym E (x, y, z), (3.17)
where n and m denote the order and degree of the beam, respectively. Laguerre–Gaussian modes EnL,m are derived in a similar way as
EL
nm(x, y, z) = knw2n + m
0 eikz ∂ n
∂ zn
(∂
∂x + i ∂
∂y
)m {
E (x, y, z) e−ikz}
. (3.18)
Thus, any higher-order modes can be generated by simply applying Eqs. (3.17) and (3.18). It can be shown that Laguerre–Gaussian modes can be generated as a


50 Propagation and focusing of optical fields
(a) (b)
(c) (d)
500 nm
x
y
Fig. 3.2 Intensity (|E|2) in the focal plane (z = 0) of the first four Hermite–Gaussian modes: (a) (00) mode (Gaussian mode), (b) (10) mode, (c) (01) mode, and (d) (11) mode. The wavelength and beam angle are λ = 800 nm and θ = 28.65◦, respectively. The arrows indicate the polarization directions of the individual lobes.
superposition of a finite number of Hermite–Gaussian modes and vice versa. The two sets of modes are therefore not independent. Note that the parameter w0 represents the beam waist only for the Gaussian beam and that for higher-order modes the amplitude E0 does not correspond to the field at the focal point. Figure 3.2 shows the fields in the focal plane (z = 0) for the first four Hermite–Gaussian modes. As indicated by the arrows, the polarizations of the individual maxima are either in phase or 180◦ out of phase with each other. The commonly encountered doughnut modes with a circular intensity profile can be described by a superposition of Hermite–Gaussian or Laguerre–Gaussian modes. Linearly polarized doughnuts are simply defined by the fields EL
01 or EL
11. An azimuthally polarized
doughnut mode is a superposition of two perpendicularly polarized EH
01 fields and a radially
polarized doughnut mode is a superposition of two perpendicularly polarized EH
10 fields.
3.2.3 Longitudinal fields in the focal region
The paraxial Gaussian beam is a transverse electromagnetic (TEM) beam, i.e. it is assumed that the electric and magnetic fields are always transverse to the propagation direction.


51 3.2 Paraxial approximation of optical fields
(a) (b) (c)
1 μm
x10
z
x
Fig. 3.3 Fields of the Gaussian beam depicted in the polarization plane (x, z). The wavelength and beam angle are λ = 800 nm and θ = 28.65◦, respectively. (a) Time-dependent power density; (b) total electric field intensity (|E|2); (c) longitudinal electric field intensity (|Ez|2).
However, in free space the only true TEM solutions are infinitely extended fields such as plane waves. Therefore, even a Gaussian beam must possess field components polarized in the direction of propagation. In order to estimate these longitudinal fields we apply the divergence condition ∇ · E = 0 to the x-polarized Gaussian beam, i.e.
Ez = −
∫ [∂
∂x Ex
]
dz. (3.19)
Ez can be derived using the angular spectrum representation of the paraxial Gaussian beam Eq. (3.10). In the focal plane z = 0 we obtain
Ez(x, y, 0) = −i 2 x
kw2
0
Ex(x, y, 0), (3.20)
where Ex corresponds to the Gaussian beam profile defined in Eq. (3.8). The prefactor shows that the longitudinal field is 90◦ out of phase with respect to the transverse field and that it is zero on the optical axis. Its magnitude depends on the tightness of the focus. Figures 3.3 and 3.4 show the calculated total and transverse electric field distributions for the Gaussian beam and the Hermite–Gaussian (10) beam, respectively. While the longitudinal electric field of the fundamental Gaussian beam is always zero on the optical axis, it exhibits two lobes to the sides of the optical axis. Displayed on a cross-section through the beam waist, the two lobes are aligned along the polarization direction. The longitudinal electric field of the Hermite–Gaussian (10) mode, on the other hand, has its maximum


52 Propagation and focusing of optical fields
(a) (b) (c)
1 μm
x3
z
x
Fig. 3.4 Fields of the Hermite–Gaussian (10) mode. Same scaling and definitions as in Fig. 3.3.
at the beam focus with a much larger field strength. This longitudinal field qualitatively follows from the 180◦ phase difference and the polarization of the two corresponding field maxima in Fig. 3.2, since the superposition of two similarly polarized plane waves propagating at angles ±φ to the z-axis with 180◦ phase difference also leads to a longitudinal field component. It has been proposed that one could use the longitudinal fields of the Hermite–Gaussian (10) mode to accelerate charged particles along the beam axis in linear particle accelerators [5]. The longitudinal (10) field has also been applied to image the spatial orientation of molecular transition dipoles [6, 7]. In general, the (10) mode is important for all experiments that require the availability of a longitudinal field component. We shall see in Section 3.6 that the longitudinal field strength of a strongly focused higher-order laser beam can even exceed the transverse field strength.
3.3 Polarized electric and polarized magnetic fields
If we send an optical beam through a polarizer, we eliminate one of the two transverse field components. The transmitted field is then called polarized electric. In fact, any propagating optical field can be split into a polarized electric (PE) and a polarized magnetic (PM) field:
E = EPE + EPM. (3.21)
For a PE field, the electric field is linearly polarized when projected onto the transverse plane. Similarly, for a PM field the magnetic field is linearly polarized when projected


53 3.4 Far-fields in the angular spectrum representation
onto the transverse plane. Let us first consider a PE field for which we can choose EPE = (Ex, 0, Ez). On requiring that the field is divergence free (∇ · EPE = 0) we find that
Eˆ z(kx, ky ; 0) = − kx
kz
Eˆ x(kx, ky ; 0), (3.22)
which allows us to express the fields EPE and HPE in the form
EPE(x, y, z) =
∫∞
−∞
∫
Eˆ x(kx, ky ; 0) 1
kz
[kznx − kxnz] ei[kx x + ky y ± kz z] dkx dky, (3.23)
HPE(x, y, z) = Zμ−ε1
∫∞
−∞
∫
Eˆ x(kx, ky ; 0) 1
kkz
[−kxkynx + (k2
x + k2
z )ny
− kykznz] ei[kx x + ky y ± kz z] dkx dky, (3.24)
where nx, ny, nz are unit vectors along the x, y, z axes. To derive HPE we used the relations in Eq. (2.126). To derive the corresponding PM fields we require that HPM = (0, Hy, Hz). After following the same procedure as before one finds that in the PM solution the expressions for the electric and magnetic fields are simply interchanged:
EPM(x, y, z) = Zμε
∫∞
−∞
∫
Hˆ y(kx, ky ; 0) 1
kkz
[(k2
y + k2
z )nx − kxkyny
+ kxkznz] ei[kx x + ky y ± kz z] dkx dky, (3.25)
HPM(x, y, z) =
∫∞
−∞
∫
Hˆ y(kx, ky ; 0) 1
kz
[kzny − kynz] ei[kx x + ky y ± kz z] dkx dky. (3.26)
It is straightforward to demonstrate that in the paraxial limit the PE and PM solutions are identical. In this case they become identical with a TEM solution. The decomposition of an arbitrary optical field into a PE field and a PM field has been achieved by setting one transverse field component to zero. The procedure is similar to the commonly encountered decomposition into transverse electric (TE) and transverse magnetic (TM) fields for which one longitudinal field component is set to zero (see Problem 3.2).
3.4 Far-fields in the angular spectrum representation
In this section we will derive the important result that Fourier optics and geometrical optics naturally emerge from the angular spectrum representation. Consider a particular (localized) field distribution in the plane z = 0. The angular spectrum representation tells us how this field propagates and how it is mapped onto other planes z = z0. Here, we ask what the field will be in a very remote plane. Vice versa, we


54 Propagation and focusing of optical fields
can ask what field will result when we focus a particular far-field onto an image plane. Let us start with the familiar angular spectrum representation of an optical field
E(x, y, z) =
∫∞
−∞
∫
ˆE(kx, ky ; 0) ei[kx x + ky y ± kz z] dkx dky. (3.27)
We are interested in the asymptotic far-zone approximation of this field, i.e. in the evaluation of the field at a point r = r∞ at an infinite distance from the object plane. The dimensionless unit vector s in the direction of r∞ is given by
s = (sx, sy, sz) =
(x
r, y
r, z
r
)
, (3.28)
where r = (x2 + y2 + z2)1/2 is the distance of r∞ from the origin. To calculate the far-field E∞ we require that r → ∞ and rewrite Eq. (3.27) as
E∞(sx, sy) = lim
kr→∞
∫∫
(kx2 + ky2) ≤ k2
ˆE(kx, ky ; 0) eikr
[ kx
k sx+ ky
k sy ± kz
k sz
]
dkx dky, (3.29)
where sz =
√
1 − (sx2 + sy2). Because of their exponential decay, evanescent waves do not
contribute to the fields at infinity. We therefore reject their contribution and reduce the integration range to (kx2 + ky2) ≤ k2. The asymptotic behavior of the double integral as kr → ∞ can be evaluated by the method of stationary phase. For a clear outline of this method we refer the interested reader to Section 3.3 of Ref. [3]. Without going into details,
s
z
z=0
Fig. 3.5 Illustration of the far-field approximation. According to the angular spectrum representation, a point in the source plane z = 0 emits plane waves in all possible directions. However, a distant detector (kr 1) measures only the plane wave that propagates towards it (in the direction of the unit vector s). The fields of all other plane waves are cancelled out by destructive interference.


55 3.4 Far-fields in the angular spectrum representation
the result of Eq. (3.29) can be expressed as
E∞(sx, sy) = −2π iksz ˆE(ksx, ksy ; 0) eikr
r . (3.30)
This equation tells us that the far-fields are entirely defined by the Fourier spectrum of the fields ˆE(kx, ky; 0) in the object plane if we make the replacements kx → ksx and ky → ksy. This simply means that the unit vector s satisfies
s = (sx, sy, sz) =
( kx
k , ky
k , kz
k
)
, (3.31)
which implies that only one plane wave with the wavevector k = (kx, ky, kz) of the angular spectrum at z = 0 contributes to the far-field at a point located in the direction of the unit vector s (see Fig. 3.5). The effect of all other plane waves is cancelled out by destructive interference. This beautiful result allows us to treat the field in the far-zone as a collection of rays with each ray being characterized by a particular plane wave of the original angular spectrum representation (geometrical optics). On combining Eqs. (3.30) and (3.31) we can express the Fourier spectrum ˆE in terms of the far-field as
Eˆ (kx, ky ; 0) = ire−ikr
2π kz
E∞
( kx
k , ky
k
)
, (3.32)
keeping in mind that the vector s is entirely defined by kx and ky. This expression can be substituted into the angular spectrum representation (Eq. 3.27) as
E(x, y, z) = ire−ikr
2π
∫∫
(kx2 + ky2) ≤ k2
E∞
( kx
k , ky
k
)
ei [kx x + ky y ± kz z] 1
kz
dkx dky. (3.33)
Thus, as long as evanescent fields are not part of our system, the field E and its far-field E∞ form essentially a Fourier-transform pair at z = 0. The only deviation is given by the kz terms. In the approximation kz ≈ k, the two fields form a perfect Fourier-transform pair. This is the limit of Fourier optics. As an example consider the diffraction at a rectangular aperture with sides 2Lx and 2Ly in an infinitely thin conducting screen, which we choose to be our object plane (z = 0). A plane wave illuminates the aperture at normal incidence from the back. For simplicity we assume that the field in the object plane has a constant field amplitude E0, whereas the screen blocks all of the field outside of the aperture. The Fourier spectrum at z = 0 is then
Eˆ (kx, ky; 0) = E0
4π2
∫ +Ly
−Ly
∫ +Lx
−Lx
e−i [kx x′ + ky y′] dx′ dy′
= E0
LxLy π2
sin(kxLx)
kxLx
sin(kyLy)
kyLy
, (3.34)
With Eq. (3.30) we now determine the far-field as
E∞(sx, sy) = −ikszE0
2LxLy π
sin(ksx Lx)
ksx Lx
sin(ksy Ly)
ksy Ly
eikr
r , (3.35)
which, in the paraxial limit kz ≈ k, agrees with Fraunhofer diffraction.


56 Propagation and focusing of optical fields
Equation (3.30) is an important result. It links the near-fields of an optical problem with the corresponding far-fields. While in the near-field a rigorous description of fields is necessary, the far-fields are well approximated by the laws of geometrical optics.
3.5 Focusing of fields
The limit of classical light confinement is achieved with highly focused laser beams. Such beams are used in fluorescence spectroscopy to investigate molecular interactions in solutions and the kinetics of single molecules on interfaces [6]. Highly focused laser beams also play a key role in confocal microscopy and optical data storage, where resolutions on the order of λ/4 are achieved. In optical tweezers, focused laser beams are used to trap particles and to move and position them with high precision [8]. All these fields require a theoretical understanding of strongly focused light. The fields of a focused laser beam are determined by the boundary conditions of the focusing optical element and the incident optical field. In this section we will study the focusing of a paraxial optical field by an aplanatic optical lens as shown in Fig. 3.6. In our theoretical treatment we will follow the theory established by Richards and Wolf [9, 10]. The fields near the optical lens can be formulated by the rules of geometrical optics. In this approximation the finiteness of the optical wavelength is neglected (k → ∞) and the energy is transported along light rays. The average energy density is propagated with the velocity v = c/n in the direction perpendicular to the geometrical wavefronts. To describe an aplanatic lens we need two rules: (1) the sine condition and (2) the intensity law. These rules are illustrated in Fig. 3.7. The sine condition states that each optical ray that emerges from or converges to the focus F of an aplanatic optical system intersects its conjugate ray on a sphere of radius f (the Gaussian reference sphere), where f is the focal length of the lens. By “conjugate ray,” one understands the refracted or incident ray that propagates parallel to the optical axis. The distance h between the optical axis and the conjugate ray is given by
f
Einc
n1 n2
Fig. 3.6 Focusing of a laser beam by an aplanatic lens.


57 3.5 Focusing of fields
h = f sin θ, (3.36)
θ being the divergence angle of the conjugate ray. Thus, the sine condition is a prescription for the refraction of optical rays at the aplanatic optical element. The intensity law is nothing other than a statement of energy conservation: the energy flux along each ray must remain constant. As a consequence, the electric field strength of a spherical wave has to scale as 1/r, r being the distance from the origin. The intensity law ensures that the energy incident on the aplanatic lens equals the energy that leaves the lens. We know that the power transported by a ray is dP = (1/2)Zμ−ε1|E|2dA, where Zμε is the wave impedance and dA is an infinitesimal cross-section perpendicular to the ray propagation. Thus, as indicated in Fig. 3.7(b), the fields before and after refraction must satisfy
|E2| = |E1|
√ n1
n2
√ μ2
μ1
(cos θ )1/2. (3.37)
Since in practically all media the magnetic permeability at optical frequencies is equal
to one (μ = 1), we will drop the term √μ2/μ1 for the sake of having more convenient notation. Using the sine condition, our optical system can be represented as shown in Fig. 3.8. The incident light rays are refracted by the reference sphere of radius f . We denote an arbitrary point on the surface of the reference sphere by (x∞, y∞, z∞) and an arbitrary field point near the focus by (x, y, z). The two points are also represented by the spherical coordinates ( f , θ , φ) and (r, θ, φ), respectively. To describe refraction of the incident rays at the reference sphere we introduce the unit vectors nρ, nφ, and nθ , as shown in Fig. 3.8. nρ and nφ are the unit vectors of a cylindrical coordinate system, whereas nθ and nφ are the unit vectors of a spherical coordinate system. We recognize that the reference sphere transforms a cylindrical coordinate system (incoming beam) into a spherical coordinate system (focused beam). Refraction at the reference sphere is most conveniently calculated by splitting the incident vector Einc into two
components denoted as E(s)
inc and E(p)
inc. The indices (s) and (p) stand for s-polarization and p-polarization, respectively. In terms of the unit vectors we can express the two fields as
F
incident ray
f
h = f sin θ
θ
dA 2
dA 1
E1
E2
dA 1 = dA 2 cos
(a) (b)
z
refracted ray
reference sphere
zF
θ
n1 n2
μ1 μ2
θ
Fig. 3.7 (a) The sine condition of geometrical optics. The refraction of light rays at an aplanatic lens is determined by a spherical surface with radius f . (b) The intensity law of geometrical optics. The energy carried along a ray must stay constant.


58 Propagation and focusing of optical fields
E(s)
inc = [Einc · nφ
] nφ , E(p)
inc = [Einc · nρ
] nρ. (3.38)
As shown in Fig. 3.8 these two fields refract differently at the spherical surface. While the unit vector nφ remains unaffected, the unit vector nρ is mapped into nθ . Thus, the total refracted electric field, denoted by E∞, can be expressed as
E∞ =
[
ts[Einc · nφ
] nφ + tp[Einc · nρ
] nθ
] √ n1
n2
(cos θ )1/2. (3.39)
For each ray we have included the corresponding transmission coefficients ts and tp as defined in Eqs. (2.52). The factor outside the brackets is a consequence of the intensity law to ensure energy conservation. The subscript ∞ was added to indicate that the field is evaluated at a large distance from the focus (x, y, z) = (0, 0, 0). The unit vectors nρ, nφ, nθ can be expressed in terms of the Cartesian unit vectors nx, ny, nz using the spherical coordinates θ and φ defined in Fig. 3.8:
nρ = cos φ nx + sin φ ny, (3.40)
nφ = −sin φ nx + cos φ ny, (3.41)
nθ = cos θ cos φ nx + cos θ sin φ ny − sin θ nz. (3.42)
On inserting these vectors into Eq. (3.39) we obtain
E∞(θ , φ) = ts(θ )
⎡
⎣Einc(θ , φ) ·
⎛
⎝
−sin φ cos φ 0
⎞
⎠
⎤
⎦
⎛
⎝
−sin φ cos φ 0
⎞
⎠
√ n1
n2
(cos θ )1/2
+ tp(θ )
⎡
⎣Einc(θ , φ) ·
⎛
⎝
cos φ sin φ 0
⎞
⎠
⎤
⎦
⎛
⎝
cos φ cos θ sin φ cos θ −sin θ
⎞
⎠
√ n1
n2
(cos θ )1/2,
(3.43)
which is the field in Cartesian vector components just to the right of the reference sphere of the focusing lens. We can also express E∞ in terms of the spatial frequencies kx and ky by using the substitutions
kx = k sin θ cos φ, ky = k sin θ sin φ, kz = k cos θ . (3.44)
(x∞, y∞, z∞)
f
z
θ
Einc
y
x
φ
nρ
nθ
nφ
nφ
Fig. 3.8 Geometrical representation of the aplanatic system and definition of coordinates.


59 3.5 Focusing of fields
The resulting far-field on the reference sphere is then of the form E∞(kx/k, ky/k) and can be inserted into Eq. (3.33) to rigorously calculate the focal fields. Thus, the field E near the focus of our lens is entirely determined by the far-field E∞ on the reference sphere. All rays propagate from the reference sphere towards the focus (x, y, z) = (0, 0, 0) and there are no evanescent waves involved. Owing to the symmetry of our problem it is convenient to express the angular spectrum representation Eq. (3.33) in terms of the angles θ and φ instead of kx and ky. This is easily accomplished by using the substitutions in Eq. (3.44) and expressing the transverse coordinates (x, y) of the field point as
x = ρ cos φ, y = ρ sin φ. (3.45)
In order to replace the planar integration over kx, ky by a spherical integration over θ , φ we must transform the differentials as
1
kz
dkx dky = k sin θ dθ dφ, (3.46)
which is illustrated in Fig. 3.9. We can now express the angular spectrum representation of the focal field (Eq. 3.33) as
E(ρ, φ, z) = − ikf e−ikf
2π
θmax
∫
0
∫2π
0
E∞(θ , φ) eikz cos θ eikρ sin θ cos(φ−φ) sin θ dφ dθ . (3.47)
We have replaced the distance r∞ between the focal point and the surface of the reference sphere by the focal length f of the lens.2 We have also limited the integration over θ to the finite range [0 . . . θmax] because any lens will have a finite size. Furthermore, since all fields propagate in the positive-z direction we retained only the + sign in the exponent of Eq. (3.33). Equation (3.47) is the central result of this section. Together with Eq. (3.43), it allows us to calculate the focusing of an arbitrary optical field Einc by an aplanatic lens with focal length f and numerical aperture
NA = n sin θmax (0 < θmax < π/2), (3.48)
k2 sinθ dθ dφ
kz
θ
dkx dky
dkx dky = cos θ[k2 sin θ dθ dφ]
Fig. 3.9 Illustration of the substitution (1/kz)dkx dky = k sin θ dθ dφ. The factor 1/kz = 1/(k cos θ ) ensures that the differential areas on the plane and on the sphere stay equal.
2 The ‘−’ sign originates from taking the farfield at z → −∞. In Eq. (3.33) the farfield is evaluated at z → +∞.


60 Propagation and focusing of optical fields
where n = n2 is the index of refraction of the surrounding medium. The field distribution in the focal region is entirely determined by the far-field E∞. As we shall see in the next section, the properties of the laser focus can be engineered by adjusting the amplitude and phase profile of E∞.
3.6 Focal fields
Typically, the back-aperture of a microscope objective is a couple of millimeters in diameter. In order to make use of the full NA of the objective, the incident field Einc has to fill or overfill the back-aperture. Thus, because of the large diameter of the incident beam, it is reasonable to treat it in the paraxial approximation. Let us assume that Einc is entirely polarized along the x-axis, i.e.
Einc = Eincnx. (3.49)
Furthermore, we assume that the waist of the incoming beam coincides with the lens so that it hits the lens with a planar phase front. For simplicity we also assume that we have a lens with good antireflection coating so that we can neglect the Fresnel transmission coefficients,
tsθ = tp
θ = 1. (3.50)
With these assumptions the far-field E∞ in Eq. (3.43) can be expressed as
E∞(θ , φ) = Einc(θ , φ) [cos φ nθ − sin φ nφ
] √n1/n2 (cos θ )1/2
= Einc(θ , φ) 1
2
⎡
⎣
(1 + cos θ ) − (1 − cos θ ) cos(2φ) −(1 − cos θ) sin(2φ) −2 cos φ sin θ
⎤
⎦
√ n1
n2
(cos θ )1/2,
(3.51)
where the last expression is represented in Cartesian vector components. To proceed we need to specify the amplitude profile of the incoming beam Einc. We will concentrate on the three lowest Hermite–Gaussian modes displayed in Fig. 3.2. The first of these modes corresponds to the fundamental Gaussian beam and the other two can be generated according to Eq. (3.17) of Section 3.2.2. On expressing the coordinates (x∞, y∞, z∞) in Fig. 3.8 in terms of the spherical coordinates ( f , θ , φ) we find
(0,0) mode: Einc = E0 e−(x2∞+y2∞)/w2
0 = E0 e−f 2 sin2θ/w2
0 , (3.52)
(1,0) mode:
Einc = E0(2 x∞/w0)e−(x2∞+y2∞)/w2
0 = (2E0f /w0) sin θ cos φ e−f 2 sin2θ/w2
0 , (3.53)
(0,1) mode:
Einc = E0(2 y∞/w0) e−(x2∞+y2∞)/w2
0 = (2E0f /w0) sin θ sin φ e−f 2 sin2θ/w2
0 . (3.54)


61 3.6 Focal fields
The factor fw(θ ) = exp(−f 2 sin2θ/w2
0) is common to all modes. The focal field E will depend on how much the incoming beam is expanded relative to the size of the lens. Since the aperture radius of our lens is equal to f sin θmax we define the filling factor f0 as
f0 = w0
f sin θmax
, (3.55)
which allows us to write the exponential function in Eqs. (3.52)–(3.54) in the form
fw(θ ) = e
−1
f02
sin2 θ sin2θmax . (3.56)
This function is called the apodization function and can be viewed as a pupil filter. We now have all the necessary ingredients to compute the field E near the focus. With the mathematical relations
∫2π
0
cos(nφ)eix cos(φ−φ) dφ = 2π (in)Jn(x)cos(nφ), (3.57)
∫2π
0
sin(nφ)eix cos(φ−φ) dφ = 2π (in)Jn(x)sin(nφ)
we can carry out the integration over φ analytically. Here, Jn is the nth-order Bessel function. The final expressions for the focal field now contain a single integration over the variable θ. It is convenient to use the following abbreviations for the integrals:
I00 =
θmax
∫
0
fw(θ )(cos θ )1/2 sin θ (1+cos θ )J0(kρ sin θ ) eikz cos θ dθ , (3.58)
I01 =
θmax
∫
0
fw(θ )(cos θ )1/2 sin2θ J1(kρ sin θ ) eikz cos θ dθ , (3.59)
I02 =
θmax
∫
0
fw(θ )(cos θ )1/2 sin θ (1−cos θ )J2(kρ sin θ ) eikz cos θ dθ , (3.60)
I10 =
θmax
∫
0
fw(θ )(cos θ )1/2 sin3θ J0(kρ sin θ ) eikz cos θ dθ , (3.61)
I11 =
θmax
∫
0
fw(θ )(cos θ )1/2 sin2θ (1+3 cos θ )J1(kρ sin θ ) eikz cos θ dθ , (3.62)


62 Propagation and focusing of optical fields
I12 =
θmax
∫
0
fw(θ )(cos θ )1/2 sin2θ (1−cos θ )J1(kρ sin θ ) eikz cos θ dθ , (3.63)
I13 =
θmax
∫
0
fw(θ )(cos θ )1/2 sin3θ J2(kρ sin θ ) eikz cos θ dθ , (3.64)
I14 =
θmax
∫
0
fw(θ )(cos θ )1/2 sin2θ (1 − cos θ )J3(kρ sin θ ) eikz cos θ dθ , (3.65)
where the function fw(θ ) is given by Eq. (3.56). Notice, that these integrals are functions of the coordinates (ρ, z), i.e. Iij = Iij(ρ, z). Thus, for each field point we have to evaluate these integrals numerically. Using these abbreviations we can now express the focal fields of the various modes as
(0,0) mode:
E(ρ, φ, z) = − ikf
2
√ n1
n2
E0e−ikf
⎡
⎣
I00 + I02 cos(2φ) I02 sin(2φ) −2iI01 cos φ
⎤
⎦,
H(ρ, φ, z) = − ikf
2Zμε
√ n1
n2
E0e−ikf
⎡
⎣
I02 sin(2φ) I00 − I02 cos(2φ) −2iI01 sin φ
⎤
⎦,
(3.66)
(1,0) mode:
E(ρ, φ, z) = − ikf 2
2w0
√ n1
n2
E0e−ikf
⎡
⎣
iI11 cos φ + iI14 cos(3φ) −iI12 sin φ + iI14 sin(3φ) −2I10 + 2I13 cos(2φ)
⎤
⎦,
H(ρ, φ, z) = − ikf 2
2w0 Zμε
√ n1
n2
E0e−ikf
⎡
⎣
−iI12 sin φ + iI14 sin(3φ) i(I11 +2I12)cos φ − iI14 cos(3φ) 2I13 sin(2φ)
⎤
⎦,
(3.67)
(0,1) mode:
E(ρ, φ, z) = − ikf 2
2w0
√ n1
n2
E0e−ikf
⎡
⎣
i(I11 +2I12) sin φ + iI14 sin(3φ) −iI12 cos φ − iI14 cos(3φ) 2I13 sin(2φ)
⎤
⎦,
H(ρ, φ, z) = − ikf 2
2w0 Zμε
√ n1
n2
E0e−ikf
⎡
⎣
−iI12 cos φ − iI14 cos(3φ) iI11 sin φ − iI14 sin(3φ) −2I10 − 2I13 cos(2φ)
⎤
⎦.
(3.68)
For completeness, we have also listed the magnetic fields for the three modes. They can be derived in the same way by using the corresponding paraxial input fields H∞ with the magnetic field axis along the y-axis. Notice that only the zeroth-order Bessel function


63 3.6 Focal fields
x 653 x 17.2
x1
x 1.28
x 10445
x 2.53
f 0 = 0.5
f0=1.0 0=2.0 0=
f0=0.1 f0=0.2
−1 −0.5 0 0.5 1 −0.5 0 0.5 −0.5 0 0.5 x/λ, y/λ x/λ, y/λ x/λ, y/λ
|E|2
|E|2
1
ff
Fig. 3.10 Influence of the filling factor f0 of the back-aperture on the sharpness of the focus. A lens with NA = 1.4 is assumed and the index of refraction is 1.518. The figure shows the magnitude of the electric field intensity |E|2 in the focal plane z = 0. The dashed curves have been evaluated along the x-direction (plane of polarization) and the solid curves along the y-direction. All curves have been scaled to an equal amplitude. The scaling factor is indicated in the figures. The larger the filling factor, the bigger the deviation between the solid and dashed curves, indicating the importance of polarization effects.
possesses a non-vanishing value at its origin. As a consequence, only the (1, 0) mode has a longitudinal electric field (Ez) at its focus. In the limit fw = 1 the fields for the (0, 0) mode are identical with the solutions of Richards and Wolf [10]. According to Eq. (3.56), this limit is reached for f0 → ∞, which corresponds to an infinitely overfilled back-aperture of the focusing lens. This situation is identical with that of a plane wave incident on the lens. Figure 3.10 demonstrates the effect of the filling factor f0 on the confinement of the focal fields. In these examples we used an objective with a numerical aperture of 1.4 and an index of refraction of 1.518, which corresponds to a maximum collection angle of 68.96◦. It is obvious that the filling factor is important for the quality of the focal spot and thus for the resolution in optical microscopy. It is important to notice that with increasing field confinement at the focus the focal spot becomes more and more elliptical. Whereas in the paraxial limit the spot is perfectly circular, a strongly focused beam has a spot that is elongated in the direction of polarization. This observation has important consequences: as we aim towards higher resolutions by using spatially confined light we need to take the vector nature of the fields into account. Scalar theories become insufficient. Figure 3.11 shows field plots for the electric field for a filling factor of f0 = 1 and an NA = 1.4 objective lens. This figure depicts the total electric field intensity E2 in the plane of incident polarization (x, z) and perpendicular to it (y, z). The three images to the side show the intensities of the different field components in the focal plane z = 0. The maximum relative values are Max[Ey2]/Max[Ex2] = 0.003 and
Max[Ez2]/Max[Ex2] = 0.12. Thus, an appreciable amount of the electric field energy is in the longitudinal field. How can we experimentally verify the calculated focal fields? An elegant method is to use a single dipolar emitter, such as a single molecule, to probe the field (Fig. 3.12).


64 Propagation and focusing of optical fields
Fig. 3.11 Contour plots of constant |E|2 in the focal region of a focused Gaussian beam (NA = 1.4, n = 1.518, f0 = 1): (a) in the plane of incident polarization (x, z); (b) in the plane perpendicular to the plane of incident polarization (y, z). A logarithmic scaling is used, with a factor of 2 difference between adjacent contour lines. Images (c), (d), and (e) show the magnitudes of the individual field components |Ex|2, |Ey|2, and |Ez|2, respectively, in the focal plane (z = 0).
The molecule can be embedded into the surrounding medium with index n and moved with accurate translators to any position r = (x, y, z) = (ρ, φ, z) near the laser focus. The excitation rate of the molecule depends on the product E · p, with p being the transition dipole moment of the molecule. The excited molecule then relaxes with a certain rate and probability by emitting a fluorescence photon. We can use the same aplanatic lens to collect the emitted photons and direct them onto a photodetector. The fluorescence intensity (photon counts per second) will be proportional to |E · p|2. Thus, if we know the dipole orientation of the molecule, we can determine the field strength of the exciting field at the molecule’s position. For example, a molecular dipole aligned with the x-axis will render the x-component of the focal field. We can then translate the molecule to a new position and determine the field at this new position. Thus, point by point we can establish a map of the magnitude of the electric field component that points along the molecular dipole axis. With the x-aligned molecule we should be able to reproduce the pattern shown in Fig. 3.11(c) if we scan the molecule point by point in the plane z = 0. This has been demonstrated in various experiments and will be discussed in Chapter 9.
3.7 Focusing of higher-order laser modes
So far, we have discussed focusing of the fundamental Gaussian beam. What about the (10) and (01) modes? We have calculated those in order to synthesize doughnut modes with arbitrary polarization. Depending on how we superimpose those modes, we obtain


65 3.7 Focusing of higher-order laser modes
z
y
x
2 μm
Fig. 3.12 Single-molecule excitation patterns. A sample with isolated single molecules is raster scanned in the focal plane of a strongly focused laser beam. For each pixel, the fluorescence intensity is recorded and encoded in the color scale. The excitation rate in each pixel is determined by the relative orientation of the local electric field vector and the molecular absorption dipole moment. Using the known field distribution in the laser focus allows the dipole moments to be reconstructed from the recorded patterns. Compare the patterns marked x, y, and z with those in Fig. 3.11.
Linearly polarized doughnut mode:
LP = HG10 nx + i HG01 nx (3.69)
Radially polarized doughnut mode:
RP = HG10 nx + HG10 ny (3.70)
Azimuthally polarized doughnut mode:
AP = −HG01 nx + HG01 ny. (3.71)
Here, HGij nl denotes a Hermite–Gaussian (ij) mode polarized along the unit vector nl. The linearly polarized doughnut mode is identical with the Laguerre–Gaussian (01) mode defined in Eq. (3.18) and it is easily calculated by adding the fields of Eqs. (3.67) and (3.68) with a 90◦ phase delay. To determine the focal fields of the other two doughnut modes we need to derive the focal fields for the y-polarized modes. This is easily accomplished by rotating the existing fields in Eqs. (3.67) and (3.68) by 90◦ around the z-axis. The resulting focal fields turn out to be
Radially polarized doughnut mode:
E(ρ, φ, z) = − ikf 2
2w0
√ n1
n2
E0e−i kf
⎡
⎣
i(I11 − I12)cos φ i(I11 − I12)sin φ −4I10
⎤
⎦,
H(ρ, φ, z) = − ikf 2
2w0 Zμε
√ n1
n2
E0e−ikf
⎡
⎣
−i(I11 + 3I12)sin φ i(I11 + 3I12)cos φ 0
⎤
⎦,
(3.72)


66 Propagation and focusing of optical fields
Azimuthally polarized doughnut mode:
E(ρ, φ, z) = − ikf 2
2w0
√ n1
n2
E0e−ikf
⎡
⎣
i(I11 + 3I12)sin φ −i(I11 + 3I12)cos φ 0
⎤
⎦,
H(ρ, φ, z) = − ikf 2
2w0 Zμε
√ n1
n2
E0e−ikf
⎡
⎣
i(I11 − I12)cos φ i(I11 − I12)sin φ −4I10
⎤
⎦.
(3.73)
With the definition of the integrals
Irad = I11 − I12 =
θmax
∫
0
fw(θ )(cos θ )3/2 sin2θ J1(kρ sin θ ) eikz cos θ dθ , (3.74)
Iazm = I11 + 3I12 =
θmax
∫
0
fw(θ )(cos θ )1/2 sin2θ J1(kρ sin θ ) eikz cos θ dθ (3.75)
we see that to describe the focusing of radially polarized and azimuthally polarized doughnut modes we need to evaluate totally two integrals. The radial and azimuthal symmetries are easily seen by transforming the Cartesian field vectors into cylindrical field vectors as
Eρ = cos φ Ex + sin φ Ey,
Eφ = −sin φ Ex + cos φ Ey, (3.76)
and similarly for the magnetic field. While the radially polarized focused mode has a rotationally symmetric longitudinal electric field Ez, the azimuthally polarized focused mode has a rotationally symmetric longitudinal magnetic field Hz. As shown in Fig. 3.13 the longitudinal field strength |Ez|2 increases with increasing numerical aperture. At a numerical aperture of NA ≈ 1 the magnitude of |Ez|2 becomes larger than the magnitude of the radial field |Eρ|2. This is important for applications that require strong longitudinal fields. Figure 3.14 shows field plots for the focused radially polarized beam using the same parameters and settings as in Fig. 3.11. More detailed discussions of the focusing of radially and azimuthally polarized beams are presented in Refs. [11–13]. The field distribution in the beam focus has been measured using single molecules as probes [7] and by the knife-edge method [13]. Although laser beams can be adjusted to a higher mode by manipulating the laser resonator, it is desirable to convert a fundamental Gaussian beam into a higher-order mode externally without perturbing the laser characteristics. Such a conversion can be realized by inserting phase plates into different regions in the beam cross-section [14]. As shown in Fig. 3.15, the conversion to a Hermite–Gaussian (10) mode is favored by bisecting the fundamental Gaussian beam with the edge of a thin phase plate which shifts the phase of one half of the beam by 180◦. The incident beam has to be polarized perpendicular to the edge of the phase plate and subsequent spatial filtering has to be performed to reject higher-order modes. A related approach makes use of half-coated mirrors to delay one half of the laser


67 3.7 Focusing of higher-order laser modes
0 0.2 0.4 0.6 0.8 1 1.2 1.4
1
2
3
4
5
6
0
numerical aperture
|Ez|2
|Eρ |2
n = 1.518
Fig. 3.13 Ratio of the longitudinal and transverse electric field intensities |Ez|2/|Eρ|2 of a radially polarized doughnut mode as a function of the numerical aperture ( f0 = 1, n = 1.518). |Eρ|2 has its maximum on a ring in the plane z = 0, whereas the maximum of |Ez|2 is at the origin (x, y, z) = (0, 0, 0). According to the figure, the maximum longitudinal electric energy density can be more than five times larger than the maximum transverse electric energy density.
beam. In this case, the beam passes twice through the bisected part and hence the thickness of the coated part must be λ/4. Other mode-conversion schemes make use of external four-mirror ring cavities or interferometers [15, 16]. The approach shown in Fig. 3.16(a) was developed by Youngworth and Brown to generate azimuthally and radially polarized beams [11, 12]. It is based on a Twyman–Green interferometer with half-coated mirrors. The polarization of the incoming Gaussian beam is adjusted to 45◦. A polarizing beamsplitter divides the power of the beam into two orthogonally polarized beams. Each of the beams passes a λ/4 phase plate which makes the beams circularly polarized. Each beam then reflects from an end mirror. One half of each mirror has a λ/4 coating which, after reflection, delays one half of the beam by 180◦ with respect to the other half. Each of the two reflected beams passes through the λ/4 plate again and becomes converted into equal amounts of orthogonally polarized Hermite–Gaussian (10) and (01) modes. Subsequently, one of these modes will be rejected by the polarizing beamsplitter whereas the other will be combined with the corresponding mode from the other interferometer arm. Whether a radially polarized mode or an azimuthally polarized mode is generated depends on the positioning of the half-coated end mirrors. To produce the other mode one needs to simply rotate the end mirrors by 90◦. The two modes from the different interferometer arms need to be in phase, which requires adjustability of the path length. The correct polarization can always be verified by sending the output beam through a polarizer and by selectively blocking the beam in one of the two interferometer arms. Since the mode conversion is not 100% efficient one needs to spatially filter the output beam to reject any undesired modes. This is accomplished by focusing the output beam onto a pinhole with adjusted diameter. To obviate the need for noise- and drift-sensitive interferometers, Dorn et al. implemented a single-path mode-conversion scheme for radially and azimuthally polarized beams [13]. As shown in Fig. 3.16(b), a laser beam is sent through a λ/2 waveplate


68 Propagation and focusing of optical fields
Fig. 3.14 (a) Contour plots of constant |E|2 in the focal region of a focused radially polarized doughnut mode (NA = 1.4, n = 1.518, f0 = 1) in the (ρ, z) plane. The intensity is rotationally symmetric with respect to the z-axis. A logarithmic scaling is used with a factor of 2 difference between adjacent contour lines. Images (b), (c), and (d) show the magnitudes of the individual field components |Ez|2, |Eρ|2, and |Ey|2, respectively, in the focal plane (z = 0). A linear scale is used.
consisting of four segments. The optical axis of each segment is oriented such that the field is rotated to point in the radial direction. Subsequent spatial filtering extracts the desired mode with very high purity. A phase plate as shown in Fig. 3.16(b) can be fabricated by cutting two λ/2 plates into four quadrants each, and then assembling the pieces into two new phase plates. This mode-conversion principle can be generalized to waveplates with many elements such as liquid-crystal spatial light modulators.
3.8 The limit of weak focusing
Before we proceed to the next section we need to verify that our formulas for the focused fields render the familiar paraxial expressions for the limit of small θmax. In this limit we may make the approximations cos θ ≈ 1 and sin θ ≈ θ . However, for the phase factor in the exponent of the integrals I00 . . . I14 we need to retain the second-order term, i.e. cos θ ≈ 1−θ 2/2, because the first-order term alone would cancel out the θ dependence. For small arguments x, the Bessel functions behave like Jn(x) ≈ xn. Using these approximations, a comparison of the integrals I00 . . . I14 shows that the integral I00 is of lowest order in θ , followed by I11 and I12. Whereas I00 defines the paraxial Gaussian mode, the other two remaining integrals determine the paraxial Hermite–Gaussian (1, 0) and (0, 1) modes. In


69 3.8 The limit of weak focusing
E
E
E
Ek
k
π
Fig. 3.15 Generation of a Hermite–Gaussian (10) beam. A fundamental Gaussian beam is bisected at the edge of a 180◦ phase plate. The polarization of the incident beam is perpendicular to the edge of the phase plate. The arrangement delays one half of the beam by 180◦ and therefore favors the conversion to the Hermite–Gaussian (10) mode. A subsequent spatial filter rejects any modes of higher order than the (10) mode.
principle, the integration of I00, I10 and I11 can now be carried out analytically. However, since the results lead to inconvenient Lommel functions we reduce our discussion to the focal plane z = 0. Furthermore, we assume an overfilled back-aperture of the lens ( f0 1) so that the apodization function fw(θ ) can be considered constant. Using the substitution x = kρ θ we find
I00 ≈ 2
kρ
kρ θmax
∫
0
x J0(x) dx = 2θ 2
max
J1(kρ θmax)
kρ θmax
. (3.77)
The paraxial field of the focused Gaussian beam in the focal plane turns out to be
E ≈ −ikf θ 2
maxE0 e−ikf J1(kρ θmax)
kρ θmax
nx. (3.78)
This is the familiar expression for the point-spread function in the paraxial limit. Abbe’s and Rayleigh’s definitions of the resolution limit are closely related to the expression above as we shall see in Section 4.1. The focal fields of the (1, 0) and (0, 1) modes in the paraxial limit can be derived in a similar way as
(1,0) mode:
E ∝ θ3
max[J2(kρ θmax)/(kρ θmax)] cos φ nx, (3.79)
(0,1) mode:
E ∝ θ3
max[J2(kρ θmax)/(kρ θmax)] sin φ nx. (3.80)
In all cases, the radial dependence of the paraxial focal fields is described by Bessel functions, not by the original Gaussian envelope. After passing through the lens the beam shape in the focal plane becomes oscillatory. These spatial oscillations can be viewed as diffraction lobes and are a consequence of the boundary conditions imposed by the aplanatic


70 Propagation and focusing of optical fields
E
E
k
k
E
E
E
E
: = 1:1
pol. BS spatial
filter
circ. pol
lin. pol
half-coated mirror
half-coated mirror
circ. pol lin. pol lin. pol
(a) (b)
Fig. 3.16 Two different mode-conversion schemes for the generation of radially and azimuthally polarized modes. (a) Using a Twyman–Green interferometer. The incident beam is polarized at 45◦ and is split by a polarizing beamsplitter into two orthogonally polarized beams of equal power. Each beam is then turned circularly polarized and reflected off a half-coated end mirror. (b) Using a “composite waveplate” consisting of four quadrants with different optical axes. Each segment is oriented such that the field is rotated to point in the radial direction. In both schemes, the outgoing beam needs to be spatially filtered to reject unwanted higher-order modes. (Abbreviations: circ. pol, circular polarization; lin. pol, linear polarization). See the text for details.
lens. We have assumed f0 → ∞ and we can reduce the oscillatory behavior by reducing f0 (see Fig. 3.10). However, this is at the expense of the spot size. The fact that the spot shape is described by an Airy function and not by a Gaussian function is very important. In fact, there are no freely propagating Gaussian beams! The reason is, as outlined in Section 3.2.1, that a Gaussian profile has a Gaussian Fourier spectrum, which is never zero and only asymptotically approaches zero as kx, ky → ∞. Thus, for a Gaussian profile we need to include evanescent components, even if their contribution is small. The oscillations in the Airy profile arise from the hard cut-off at high spatial frequencies. The smoother this cut-off the less oscillatory the beam profile will be.
3.9 Focusing near planar interfaces
Many applications in optics involve laser beams that are strongly focused near planar surfaces. Examples are confocal microscopy, for which objective lenses with NA > 1 are used, optical microscopy or data storage based on solid immersion lenses, and optical tweezers, whereby laser light is focused into a liquid to trap tiny particles. The angular spectrum representation is well suited to solve for the fields since the planar interface is a constant coordinate surface. For simplicity we assume that we have a single interface between two dielectric media with indices n1 and n2 (see Fig. 3.17). The interface is located at z = z0 and the focused field Ef illuminates the interface from the left (z < z0). While the spatial frequencies kx and ky are the same on each side of the interface, kz is not. Therefore, we


71 3.9 Focusing near planar interfaces
f
Einc
z = z0
z
n1 n2
Fig. 3.17 Focusing of a laser beam near an interface at z = z0 between two dielectric media with refractive indices n1 and n2.
specify kz in the domain z < z0 by kz1 defined by kz1 = (k2
1 − kx2 − ky2)1/2. Similarly we
define kz2 = (k2
2 − kx2 − ky2)1/2 for the domain z > z0. The wavenumbers are determined by k1 = (ω/c)n1 and k2 = (ω/c)n2, respectively. The interface leads to reflection and transmission. Therefore, the total field can be represented as
E=
{ Ef + Er, z < z0,
Et, z > z0, (3.81)
where Er and Et represent the reflected and transmitted fields, respectively. The refraction of plane waves at planar interfaces is described by Fresnel reflection coefficients (rs, rp) and transmission coefficients (ts, tp), which were defined in Chapter 2 (Eqs. (2.51) and (2.52)). As indicated by the superscripts, these coefficients depend on the polarization of the field. We therefore need to split each plane wave component in the angular spectrum representation of the field E into an s-polarized part and a p-polarized part,
E = E(s) + E(p). (3.82)
E(s) is parallel to the interface while E(p) is perpendicular to the wavevector k and E(s). The decomposition of the incoming focused field Ef into s- and p-polarized fields has already been done in Section 3.5. According to Eq. (3.39) we obtain the s- and p-polarized fields by projecting Ef along the unit vectors nθ and nφ, respectively. Equation (3.43) represents the refracted far-field as a sum of s- and p-polarized fields expressed in terms of θ and φ. Using the substitutions of Eq. (3.44) we are able to express the far-field in terms of the spatial frequencies kx and ky. In the case in which Ef originates from a paraxial beam polarized in the x-direction we can express the far-field as (cf. Eq. (3.51))
E∞ = Einc
( kx
k , ky
k
)⎡ ⎣
ky2 + kx2 kz1 /k1 −kxky + kxkykz1 /k1 0 − (kx2 + ky2)kx/k1
⎤
⎦
√kz1 /k1
kx2 + ky2
, (3.83)


72 Propagation and focusing of optical fields
where the first terms in the bracket specify the s-polarized field and the second ones the ppolarized field. Notice that according to Fig. 3.16 we consider a lens with the same medium on both sides, i.e. n1 = n = n′. E∞ is the asymptotic far-field in the direction of the unit vector s = (kx/k, ky/k, kz1 /k) and corresponds to the field on the surface of the reference sphere of the focusing lens. In terms of E∞, the angular spectrum representation of the incident focused beam is given by (c.f. Eq. (3.33))
Ef(x, y, z) = − if e−ik1f
2π
∫
kx ,ky
∫
E∞
( kx
k , ky
k
)1
kz1
ei [kx x + ky y + kz1 z] dkx dky. (3.84)
To determine the reflected and transmitted fields (Er, Et) we define the following angular spectrum representations:
Er(x, y, z) = − if e−ik1f
2π
∫
kx ,ky
∫
Er∞
( kx
k , ky
k
)1
kz1
ei [kx x + ky y − kz1 z] dkx dky, (3.85)
Et(x, y, z) = − if e−ik1f
2π
∫
kx ,ky
∫
Et∞
( kx
k , ky
k
)1
kz2
ei [kx x + ky y + kz2 z] dkx dky. (3.86)
Notice that in order to ensure that the reflected field propagates in the backward direction we had to change the sign of kz1 in the exponent. We also made sure that the transmitted wave propagates with the longitudinal wavenumber kz2 . In the next step we invoke the boundary conditions at z = z0, which leads to explicit expressions for the as-yet-undefined far-fields Er∞ and Et∞. Using the Fresnel reflection or transmission coefficients we obtain
Er∞ = −Einc
( kx
k , ky
k
)
e2i kz1z0
⎡
⎢⎣
−rsky2 + rpkx2 kz1 /k1
rskxky + rpkxkykz1 /k1
0 + rp(kx2 + ky2)kx/k1
⎤
⎥⎦
√kz1 /k1
kx2 + ky2
, (3.87)
Et∞ = Einc
( kx
k , ky
k
)
ei (kz1 −kz2 )z0
⎡
⎢⎣
tsky2 + tpkx2 kz2 /k2
−tskxky + tpkxkykz2 /k2
0 − tp(kx2 + ky2)kx/k2
⎤
⎥⎦ kz2
kz1
√kz1 /k1
kx2 + ky2
. (3.88)
These equations together with Eqs. (3.83)–(3.86) define the solution of our problem. They hold for an interface between two materials characterized by constant εi and μi. This is straightforward to verify by evaluating the boundary conditions at z = z0 (Problem 3.7). We are now able to evaluate the field distribution near a plane interface illuminated by a strongly focused laser beam. The field depends on the amplitude profile Einc of the incident paraxial beam (cf. Eqs. (3.52)–(3.54)) and on the defocus z0. The defocus essentially introduces a phase factor into the expressions for Er∞ and Et∞. Although we concentrated on a single interface, the results are easily adapted to a multiply layered interface


73 3.9 Focusing near planar interfaces
by introducing generalized Fresnel reflection/transmission coefficients that account for the total structure (cf. Ref. [17]). In the next step, we can use the relations (3.44) to perform a transformation to spherical coordinates. As before, we are able to reduce the double integrals to single integrals by involving Bessel functions. We avoid going into further details and instead discuss some important aspects that result from this theory. In the example of Fig. 3.18 a Gaussian beam is focused by an aplanatic objective lens of NA = 1.4 on a glass/air interface at z0 = 0. The most characteristic features in the field plots are the standing-wave patterns in the denser medium. These standing-wave patterns occur at angles θ beyond the critical angle of total internal reflection θc. To understand this let us have a look at a single plane wave in the angular spectrum representation of the incident
y= 0
x=0
x
z
y
z
8λ
Fig. 3.18 Contour plots of constant |E|2 in the focal region of a Gaussian beam (NA = 1.4, n = 1.518, f0 = 2) focused on a glass/air interface (n1 = 1.518, n2 = 1). A logarithmic scaling is used, with a factor of 2 difference between adjacent contour lines. The critical angle for total internal reflection is θc = 41.2◦. All plane-wave components incident from angles larger than θc are totally reflected at the interface and interfere with the incoming waves.


74 Propagation and focusing of optical fields
focused field Ef. This plane wave is characterized by the two transverse wavenumbers kx and ky, its polarization, and the complex amplitude given by the Fourier spectrum ˆEf. The transverse wavenumbers are the same on each side of the interface, but the longitudinal wavenumbers kz are not, since they are defined as
kz1 =
√
k2
1 − (kx2 + ky2) , kz2 =
√
k2
2 − (kx2 + ky2). (3.89)
On eliminating kx and ky we obtain
kz2 =
√
kz21 + (k2
2 − k2
1). (3.90)
Let θ denote the angle of incidence of the plane wave so that
kz1 = k1 cos θ . (3.91)
Equation (3.90) can then be written as
kz2 = k2
√
1 − k2
1
k2
2
sin2θ . (3.92)
It follows that kz2 can be either real or imaginary, depending on the sign of the expression under the square root. This in turn depends on the angle θ . We find that for angles larger than
θc = arcsin
( n2
n1
)
(3.93)
kz2 is imaginary. Thus, for θ > θc the plane wave considered is totally reflected at the interface, giving rise to an evanescent wave on the other side of the interface. The standing-wave patterns seen in Fig. 3.18 are a direct consequence of this phenomenon: all the supercritical (θ > θc) plane wave components of the incident focused field are totally reflected at the interface. The standing-wave pattern is due to the equal superposition of incident and reflected plane-wave components. Owing to total internal reflection an appreciable amount of laser power is reflected at the interface. The ratio of reflected to transmitted power can be further increased by using a larger filling factor or a higher numerical aperture. For example, in applications based on solid immersion lenses with numerical apertures of 1.8–2 over 90% of the beam power is reflected at the interface. An inspection of the focal spot reveals that the interface further increases the ellipticity of the spot shape. Along the polarization direction (x) the spot is almost twice as big as in the direction perpendicular to it (y). Furthermore, the interface enhances the strength of the longitudinal field component Ez. At the interface, just outside the focusing medium (z > −z0), the maximum relative intensity values for the different field components are Max[Ey2]/Max[Ex2] = 0.03 and Max[Ez2]/Max[Ex2] = 0.43. Thus, compared with the situation in which no interface is present (cf. Fig. 3.11), the longitudinal field intensity is roughly four times stronger. How can we understand this phenomenon? According to the boundary conditions at the interface, the transverse field components Ex and Ey have to be continuous across the interface. However, the longitudinal field scales as
Ez1 ε1 = Ez2 ε2. (3.94)


75 3.10 The reflected image of a strongly focused spot
With ε2 = 2.304 we find that Ez2 changes by a factor of 5.3 from one side to the other side of the interface. This qualitative explanation is in reasonable agreement with the calculated values. In the focal plane, the longitudinal field has its two maxima just to the side of the optical axis. These two maxima are aligned along the polarization direction and give rise to the elongated spot size. The relative magnitude of Max[Ey2] is still small, but it is increased by a factor of 10 by the presence of the interface. In order to map the dipole orientation of arbitrarily oriented single molecules it is desirable that all three excitation field components (Ex, Ey, Ez) in the focus are of comparable magnitude. It has been demonstrated that this can be achieved by annular illumination for which the center part of the focused laser beam is suppressed [18]. This can be achieved by placing a central obstruction such as a circular disk in the excitation beam. In this situation, the integration of plane-wave components runs over the angular range [θmin . . . θmax] instead of, as before, over the full range [0 . . . θmax]. By using annular illumination we reject the plane-wave components with propagation directions close to the optical axis, thereby suppressing the transverse electric field components. As a consequence, the longitudinal field components in the focus will be enhanced compared with the transverse components. Furthermore, the local polarization of the interface due to the longitudinal fields gives rise to a strong enhancement of the Ey fields. Hence, strong longitudinal fields are a prerequisite for generating strong Ey fields close to interfaces. It is possible to prepare the annular beam such that the three patterns in Fig. 3.11(c)–(e) are of comparable magnitude [18].
3.10 The reflected image of a strongly focused spot
It is interesting to further investigate the properties of the reflected field Er given by Eqs. (3.85) and (3.87). The image of the reflected spot can be experimentally recorded as shown in Fig. 3.19. A 45◦ beamsplitter reflects part of the incoming beam upwards where it is focused by a high NA objective lens near a planar interface. The distance between the focus (z = 0) and the interface is designated by z0. The reflected field is collected by the same lens, transmitted through the beamsplitter and then focused by a second lens onto the image plane. There are four different media involved and we specify them with the refractive indices defined in Fig. 3.19. We are interested in calculating the resulting field distribution in the image plane. It will be shown that, for the case in which the beam is incident from the optically denser medium, the image generated by the reflected light is strongly aberrated. The reflected far-field Er∞ before it is refracted by the first lens has been calculated in Eq. (3.87). It is straightforward to refract this field at the two lenses and refocus it onto the image plane. The two lenses perform transformations between spherical and cylindrical systems. In Section 3.5 it has been shown that the lens refracts the unit vector nρ into the unit vector nθ , or vice versa, whereas the unit vector nφ remains unaffected. In order to oversee the entire imaging process we follow the light path from the beginning. The incoming field Einc is an x-polarized, paraxial beam defined as (Eq. (3.49))


76 Propagation and focusing of optical fields
Einc
Er
BS
n1
n2
n3
f
f'
n1
n2
n3
z0
h
θ
θ′
f
f'
sin θ
sin θ′ = f ′
f
n0
Fig. 3.19 Experimental set-up for the investigation of the reflected image of a diffraction-limited focused spot. A linearly polarized beam is reflected by a beamsplitter (BS) and focused by a high-NA objective lens with focal radius f onto an interface between two dielectric media with refractive indices n1 and n2. The reflected field is collected by the same lens, transmitted through the beamsplitter and refocused by a second lens with focal radius f ′.
Einc = Eincnx, (3.95)
where Einc is an arbitrary beam profile. Expressed in cylindrical coordinates the field has the form
Einc = Einc
[cos φ nρ − sin φ nφ
] . (3.96)
After refraction at the first lens f it turns into
E = Einc
[cos φ nθ − sin φ nφ
] √ n0
n1
(cos θ )1/2. (3.97)
The field is now reflected at the interface. The Fresnel reflection coefficient rp accounts for the reflection of nθ -polarized fields whereas rs accounts for the reflection of nφ-polarized fields. We obtain for the reflected field
E = Eince2ikz1 z0 [−cos φ rp nθ − sin φ rs nφ
] √ n0
n1
(cos θ )1/2, (3.98)
where z0 denotes the defocus (cf. Eq. (3.87)). Next, the field is refracted by the same lens f as


77 3.10 The reflected image of a strongly focused spot
E = Eince2ikz1 z0 [−cos φ rp nρ − sin φ rs nφ
] , (3.99)
and propagates as a collimated beam in the negative-z direction. Expressed in Cartesian field components the field reads as
Er∞ = −Eince2ikz1 z0
[
[cos2φ rp − sin2φ rs]nx + sin φ cos φ[rp + rs]ny
]
. (3.100)
This is the field immediately after refraction at the reference sphere f . For an incident field focused on a perfectly reflecting interface located at z0 = 0 the reflection coefficients are rp = 1 and rs = −1.3 In this case we simply obtain E∞
ref = −Einc nx, which is, apart from the minus sign, identical with the assumed input field of Eq. (3.49). The difference in sign indicates that the reflected field is “upside down.” In order to calculate the reflected collimated beam anywhere along the optical axis we have to make the substitutions sin θ = ρ/f and cos θ = [1 − (ρ/f )2]1/2, where ρ denotes the radial distance from the optical axis (see Problem 3.8). This allows us to plot the field distribution in a cross-sectional plane through the collimated reflected beam. We find that the Fresnel reflection coefficients modify the polarization and amplitude profile of the beam, and, more importantly, also its phase profile. For the case of no defocus (z0 = 0) phase variations arise only at radial distances ρ > ρc for which the Fresnel reflection coefficients become complex numbers. The critical distance corresponds to ρc = f n2/n1 and is the radial distance associated with the critical angle of total internal reflection (θc = arcsin(n2/n1)). Since ρc < f there are no aberrations if n2 > n1. We now proceed to the refraction at the second lens f ′. Immediately after refraction the reflected field reads as
E = Eince2ikz1 z0 [−cos φ rp nθ′ − sin φ rs nφ
] √ n0
n3
(cos θ ′)1/2, (3.101)
where we introduced the new azimuth angle θ ′ as defined in Fig. 3.19. The field now corresponds to the far-field Er∞ that we need in Eq. (3.33) to calculate the field distribution in the image space. We express this field in Cartesian field components using the relations in Eqs. (3.41)–(3.42) for nθ′ and nφ and obtain
Er∞ = −Eince2i kz1 z0
⎡
⎢⎣
rp cos θ ′ cos2φ − rs sin2φ
rp cos θ ′ sin φ cos φ + rs sin φ cos φ
rp sin θ ′ cos φ + 0
⎤
⎥⎦
√ n0
n3
(cos θ ′)1/2.
(3.102)
This far-field can now be introduced into Eq. (3.47), which, after being adapted to the current situation, reads as
E(ρ, φ, z) = − ik3 f ′e−ik3f ′
2π
θ∫′max
0
∫2π
0
Er∞(θ ′, φ)e−ik3 z cos θ′ eik3 ρ sin θ′ cos(φ−φ) sin θ ′ dφ dθ ′. (3.103)
3 Notice that the reflection coefficients rs and rp for a plane wave at normal incidence differ by a factor of −1, i.e. rs(θ = 0) = −rp(θ = 0).


78 Propagation and focusing of optical fields
Notice that we had to change the sign in one of the exponents in order to ensure that the field propagates in the negative-z direction. To proceed, we could express the longitudinal wavenumbers kz1 and kz2 in terms of the angle θ ′. This would also make the reflection and
transmission coefficients functions of θ′. However, it is more convenient to work with θ and transform the integral in Eq. (3.103) correspondingly. As indicated in Fig. 3.19 the angles θ and θ′ are related by
sin θ
sin θ ′ = f ′
f , (3.104)
which allows us to express the new longitudinal wavenumber kz3 in terms of θ as
kz3 = k3
√
1 − ( f /f ′)2 sin2θ . (3.105)
With these relationships we can perform a substitution in Eq. (3.105) and represent the integration variables by θ and φ. The Fresnel reflection coefficients rs(θ ) and rp(θ ) are given by Eqs. (2.51) together with the expressions for the longitudinal wavenumbers kz1 and kz2 in Eqs. (3.91) and (3.92). For the lowest three Hermite–Gaussian beams, explicit expressions for Einc(θ , φ) have been stated in Eqs. (3.52)–(3.54) and the angular dependence in φ can be integrated analytically by using Eq. (3.57). Thus, we are now able to calculate the field near the image focus. In practically all optical systems the second focusing lens has a much larger focal length than the first one, i.e. f /f ′ 1. We can therefore reduce the complexity of the expressions considerably by making the approximation
[1 ± ( f /f ′)2 sin2θ ]1/n ≈ 1 ± 1
n
(f
f′
)2
sin2θ . (3.106)
If we retain only the lowest orders in f /f ′, the image field can be represented by
E(ρ, φ, z) = − ik3 f ′e−ik3(z+f ′)
2π
f2
f ′2
θ∫max
0
∫2π
0
Er∞(θ , φ)e(i/2)k3 z( f /f ′)2 sin2θ
× eik3 ρ ( f /f ′)sin θ cos(φ − φ) sin θ cos θ dφ dθ , (3.107)
where Er∞ reads as
Er∞(θ , φ) = −Einc(θ , φ)e2ik1z0 cos θ
⎡
⎣
rp cos2φ − rs sin2φ sin φ cos φ(rp + rs) 0
⎤
⎦
√ n0
n3
. (3.108)
In order to keep the discussion within bounds we will assume that the incident field Einc is a fundamental Gaussian beam as defined in Eq. (3.52). Using the relations in Eq. (3.57) we can integrate the φ dependence and finally obtain
E(ρ, φ, z) = E0
k3 f 2
2f ′ i e−i k3(z+f ′)
√ n0
n3
[
(I0r −I2r cos(2φ))nx − I2r sin(2φ)ny
] ,
(3.109)


79 3.10 The reflected image of a strongly focused spot
with
I0r(ρ, z) =
θmax
∫
0
fw(θ )cos θ sin θ [rp(θ ) − rs(θ )]J0(k3 ρ sin θ f /f ′)
× exp
[
(i/2)k3z( f /f ′)2 sin2θ + 2ik1z0 cos θ
]
dθ, (3.110)
I2r(ρ, z) =
θmax
∫
0
fw(θ )cos θ sin θ [rp(θ ) + rs(θ )]J2(k3 ρ sin θ f /f ′)
× exp
[
(i/2)k3z( f /f ′)2 sin2θ + 2ik1z0 cos θ
]
dθ, (3.111)
where fw is the apodization function defined in Eq. (3.56). We find that the spot depends on the Fresnel reflection coefficients and the defocus defined by z0. The latter simply adds an additional phase delay for each plane-wave component. If the upper medium n2 is a perfect conductor we have rp = −rs = 1 and the integral I2r vanishes. In this case the reflected spot is linearly polarized and rotationally symmetric. In order to discuss the field distributions in the image plane we choose n1 = 1.518 for the object space, n3 = 1 for the image space, and a numerical aperture of 1.4 (θmax = 67.26◦) for the objective lens. For the ideally reflecting interface, the images in the lower row of Fig. 3.20 depict the electric field intensity |Er|2 as a function of slight defocus. It is evident that the spot shape and size are not significantly affected by the defocus. However, as shown in the upper row in Fig. 3.20 the situation is very different if the medium beyond the interface has a lower index than the focusing medium, i.e. if n2 < n1. In this case, the reflected spot changes strongly as a function of defocus. The spot shape deviates considerably from a Gaussian spot and resembles the spot of an optical system with axial astigmatism. The overall size of the spot is increased and the polarization is not preserved since I0r and I2r are of comparable magnitude. The patterns displayed in Fig. 3.20 can be verified in the laboratory. However, some care has to be applied when using dichroic beamsplitters since they have slightly different characteristics for s- and p-polarized light. In fact, the patterns in Fig. 3.20 depend sensitively on the relative magnitudes of the two superposed polarizations. Using a polarizer in the reflected beam path allows us to examine the two polarizations separately, as shown in Fig. 3.21. Notice that the focus does not coincide with the interface when the intensity of the reflected pattern is maximized. The focus coincides with the interface when the center of the reflected pattern (I0(ρ, z)) has maximum intensity. The images in Figs. 3.20 and 3.21 display the electric energy density, which is the quantity that is detected by optical detectors such as a CCD. On the other hand, the total energy density, and the magnitude of the time-averaged Poynting vector, render rotationally symmetric patterns. How can we understand the appearance of the highly aberrated spot in the case of a glass/air interface? The essence lies in the nature of total internal reflection. All planewave components with angles of incidence in the range [0 . . . θc], θc being the critical angle of total internal reflection (≈41.2◦ for a glass/air interface), are partly transmitted and partly reflected at the interface. Both reflection coefficients rs and rp are real numbers


80 Propagation and focusing of optical fields
Fig. 3.20 Reflected images of a diffraction-limited focused spot. The spot is moved in steps of λ/4 across the interface. z0 is positive (negative) when the focus is below (above) the interface. The primary focusing objective lens has a numerical aperture of 1.4. The index of refraction is n1 = 1.518 and the filling factor f0 = 2. The upper row shows the situation for a glass/air interface (n2 = 1) and the lower row is for a glass/metal interface (ε2 → −∞). Large aberrations are observed in the case of the glass/air interface because the totally internally reflected plane-wave components generate a second virtual focus above the interface. The arrow indicates the direction of polarization of the primary incoming beam, and the numbers indicate the factors by which the images have been multiplied to boost the contrast of the images.
and there are no phase shifts between incident and reflected waves. On the other hand, the plane-wave components in the range [θc . . . θmax] are totally reflected at the interface. In this case the reflection coefficients become complex-valued functions imposing a phase shift between incident and reflected waves. This can be viewed as an additional path difference between incident and reflected waves similar to the Goos–Hänchen shift [19]. It displaces the apparent reflection point beyond the interface thereby creating a second, virtual focus [21]. In order to visualize this effect we plot in Fig. 3.22 only the scattered field (transmitted and reflected) of Fig. 3.18. If we detected this radiation on the surface of an enclosing sphere with large radius, the direction of radiation would appear as indicated by the two lines which obviously intersect above the interface. Although all reflected radiation originates at the interface, there is an apparent origin above the interface. If we follow the radiation maxima from the far-field towards the interface we see that close to the interface the radiation bends towards the focus to ensure that the origin of the radiation does indeed come from the focal spot. We thus find the important result that the reflected light associated with the angular range [0 . . . θc] originates from the real focal point on the interface, whereas the light associated