Support de cours officiel du cours de Modélisation : Représentations et analyse des modèles de première année de CentraleSupélec écrit par les personnes suivantes, mentionnées ici en ordre alphabétique : Thomas Chevet (Département Automatique, Laboratoire des Signaux et Systèmes), Marie-Anne Lefebvre (Institut d’Électronique et de Télécommunications de Rennes), Véronique Letort - Le Chevalier (Département de Mathématiques, Laboratoire MICS), Cristina Maniu (Département Automatique, Laboratoire des Signaux et Systèmes), Guillaume Sandou (Département Automatique, Laboratoire des Signaux et Systèmes) et Cristina Vlad (Département Automatique, Laboratoire des Signaux et Systèmes). Merci de signaler toute erreur que vous constateriez à
modelisation.cours@centralesupelec.fr.
Deuxième édition, 20 novembre 2019




Remerciements
La première partie de ce document a comme base de départ entre autres le polycopié du cours de Signaux et Systèmes 2 (Antoine et al., 2014) du cursus Ingénieur Supélec et reprend une grande partie du texte d’origine pour sa première partie. Ainsi, nous tenons à remercier nos collègues Jacques Antoine, Jean-Luc Collette, Gilles Duc, Hervé Guéguen et Daniel Poulton pour ce partage. La modélisation par réseaux de Petri a été largement inspirée du polycopié du cours de Grafcet et réseaux de Petri (Chlique, 2000), cursus Ingénieur Supélec. Nous remercions Pierre Chlique pour ce partage. Nous remercions Gilles Duc et Anne-Laure Castelier pour la relecture et leurs suggestions pour l’amélioration du document.
iii




Notations
a Notation pour un nombre scalaire a Notation pour un vecteur A Notation pour une matrice AT Transposée de la matrice A Tr(A) Trace de la matrice A det(A) Déterminant de la matrice A ‖a‖ Norme euclidienne du vecteur a N Ensemble des nombres entiers naturels Z Ensemble des nombres entiers R Ensemble des nombres réels R+ Ensemble des nombres réels positifs
R∗+ Ensemble des nombres réels strictement positifs
L1(R) Espace des fonctions sommables D(I) Ensemble des fonctions à support compact de classe C∞ dans I Re(a) Partie réelle du nombre complexe a Im(a) Partie imaginaire du nombre complexe a Pf(a) Partie finie de a VP Valeur principale de Cauchy X(f ) = F {x(t)}(f ) Transformée de Fourier du signal x(t) p Variable de Laplace X(p) = L{x(t)}(p) Transformée de Laplace du signal x(t) H(p) Fonction de transfert d’un système linéaire invariant dans le temps, à temps continu H(z) Fonction de transfert d’un système linéaire invariant dans le temps, à temps discret p(n) = P[X = n] Fonction de masse de la variable aléatoire X discrète P[X < x] Probabilité que la variable aléatoire X soit inférieure à x P[X|Y ] Probabilité conditionnelle de X sachant Y E[X] Espérence de la variable aléatoire X Var[X] Variance de la variable aléatoire X Cov[X, Y ] Covariance des variables aléatoires X et Y X ∼ N (μ, σ2) Variable aléatoire X gaussienne (ou normale), avec espérance μ et variance σ2 δ Impulsion de Dirac 1 Echelon unitaire x ∗ y Produit de convolution des signaux x et y R = (P, T, Arc) Réseau de Petri avec les ensembles des places P = {P1, . . . , PnP },
des transitions T = {tr1, . . . , trnT } et des arcs orientés Arc
A Notation générale pour un automate θ Vecteur des paramètres θˆ Vecteur des paramètres estimés à partir de données expérimentales
v




Table des matières
Remerciements iii
Notations v
1 Introduction 1 1.1 Objectifs et liens avec d’autres cours . . . . . . . . . . . . . . . . . . . . . . . . . . 1 1.2 Organisation du polycopié . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2
2 Du système à la formalisation mathématique 5 2.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 2.1.1 Notion de système . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 2.1.2 Modèles et Modélisation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6 2.1.3 Représentations des systèmes : différentes approches . . . . . . . . . . . . . 7 2.2 Représentations par schéma blocs . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9 2.3 Représentation par variables d’état . . . . . . . . . . . . . . . . . . . . . . . . . . . 11 2.4 Modélisation à évènements discrets . . . . . . . . . . . . . . . . . . . . . . . . . . . 13 2.5 Classification des systèmes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14 2.5.1 Nombre d’entrées/sorties . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14 2.5.2 Critère temporel . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15 2.5.3 Linéarité . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15 2.5.4 Invariance dans le temps . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16 2.5.5 Causalité . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16 2.5.6 Évolution au cours du temps . . . . . . . . . . . . . . . . . . . . . . . . . . 16 2.6 Modèles de signaux certains . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16 2.6.1 Echelon unité ou échelon de Heaviside . . . . . . . . . . . . . . . . . . . . . 17 2.6.2 Impulsion de Dirac . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17 2.6.3 Signal sinusoïdal . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17
I Modélisation des systèmes à état continu au sens d’un système dy
namique 19
3 Modélisation sous forme de représentation d’état 21 3.1 Définition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21 3.1.1 Équation d’état et équation de sortie . . . . . . . . . . . . . . . . . . . . . . 22 3.2 Stabilité d’un point d’équilibre ou d’une trajectoire d’équilibre . . . . . . . . . . . 24 3.3 Linéarisation autour d’un point d’équilibre . . . . . . . . . . . . . . . . . . . . . . . 26 3.3.1 Théorème de superposition . . . . . . . . . . . . . . . . . . . . . . . . . . . 26 3.3.2 Linéarisation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27 3.4 Résolution des équations d’état d’un système linéaire . . . . . . . . . . . . . . . . . 29 3.4.1 Régime libre . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29 3.4.2 Régime forcé . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29 3.4.3 Cas particulier des systèmes linéaires et invariants . . . . . . . . . . . . . . 30 3.4.4 Méthodes de calcul de l’exponentielle matricielle . . . . . . . . . . . . . . . 30 3.5 Stabilité asymptotique . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33
vii


viii Table des matières
3.6 Analyse des systèmes discrets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34 3.6.1 Modélisation des systèmes linéaires discrets par variables d’état . . . . . . . 34 3.6.2 Résolution des équations d’état . . . . . . . . . . . . . . . . . . . . . . . . . 34 3.6.3 Stabilité asymptotique . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35
4 Modélisation sous forme de fonction de transfert 37 4.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37 4.2 Notions préliminaires : transformation de Fourier, de Laplace, en z . . . . . . . . . 37 4.2.1 Notions de base sur la transformation de Fourier . . . . . . . . . . . . . . . 37 4.2.2 Transformation de Laplace . . . . . . . . . . . . . . . . . . . . . . . . . . . 39 4.2.3 Transformation en z . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43 4.3 Représentation temporelle des systèmes . . . . . . . . . . . . . . . . . . . . . . . . 46 4.3.1 Réponses impulsionnelle et indicielle des systèmes linéaires invariants à temps discret . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46 4.3.2 Relation de convolution dans les systèmes linéaires invariants . . . . . . . . 47 4.4 Etude des systèmes linéaires et invariants par fonction de transfert . . . . . . . . . 48 4.4.1 Fonction de transfert . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48 4.4.2 Stabilité EBSB . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49 4.4.3 Réponse en fréquence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51 4.4.4 Passage état – transfert. Formes compagnons . . . . . . . . . . . . . . . . . 53
5 Analyse des performances des systèmes dynamiques 59 5.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59 5.2 Diagramme de Bode des systèmes à temps continu . . . . . . . . . . . . . . . . . . 59 5.2.1 Définition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59 5.2.2 Systèmes du 1er ordre . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60 5.2.3 Systèmes du 2ème ordre . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61 5.2.4 Méthode pratique de tracé asymptotique . . . . . . . . . . . . . . . . . . . . 62 5.3 Diagramme de Bode des systèmes numériques . . . . . . . . . . . . . . . . . . . . . 64 5.3.1 1er ordre tout pôle . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64 5.3.2 2ème ordre tout pôle . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65 5.4 Diagramme de Bode des systèmes passe-tout, à déphasage minimal ou avec retard pur . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66 5.4.1 Systèmes passe-tout . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66 5.4.2 Systèmes à déphasage minimal . . . . . . . . . . . . . . . . . . . . . . . . . 67 5.4.3 Systèmes avec retard pur . . . . . . . . . . . . . . . . . . . . . . . . . . . . 68 5.5 Analyse temporelle . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69 5.5.1 Systèmes analogiques . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69 5.6 Conclusion de la partie I . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73
II Modélisation des systèmes à état discret 75
6 Introduction sur la modélisation des systèmes à état discret 77 6.1 Problématique . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77 6.2 Motivation et structure de la partie II . . . . . . . . . . . . . . . . . . . . . . . . . 77 6.3 Définition des systèmes à évènements discrets . . . . . . . . . . . . . . . . . . . . . 80
7 Modélisation des systèmes à évènements discrets non temporisés 81 7.1 Modélisation par automate . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 81 7.1.1 Définition et exemple d’automate . . . . . . . . . . . . . . . . . . . . . . . . 81 7.1.2 Propriétés des automates . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83 7.1.3 Composition des automates . . . . . . . . . . . . . . . . . . . . . . . . . . . 85 7.1.4 Analyse d’un système à évènements discrets non temporisé représenté par un automate . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 88 7.1.5 Utilisation de la notion de langage par les automates . . . . . . . . . . . . . 89 7.2 Modélisation par réseau de Petri non temporisés . . . . . . . . . . . . . . . . . . . 90


Table des matières ix
7.2.1 Réseaux de Petri autonomes . . . . . . . . . . . . . . . . . . . . . . . . . . . 91 7.2.2 Propriétés des modèles représentés par réseaux de Petri . . . . . . . . . . . 95 7.2.3 Analyse par réduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 97 7.2.4 Analyse linéaire . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99 7.2.5 Réseaux non autonomes synchronisés . . . . . . . . . . . . . . . . . . . . . . 102
8 Modélisation des systèmes à évènements discrets temporisés 103 8.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103 8.2 Structure d’horloge . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103 8.3 Automates temporisés . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 105 8.3.1 Définition et simulation d’un automate temporisé . . . . . . . . . . . . . . . 105 8.4 Automates temporisés avec gardes . . . . . . . . . . . . . . . . . . . . . . . . . . . 106 8.4.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 106 8.4.2 Ajout d’invariants . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 108 8.4.3 Formalisation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 108 8.4.4 Parallélisation d’automates temporisés avec gardes . . . . . . . . . . . . . . 109 8.5 Systèmes hybrides . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 110 8.5.1 Présentation informelle . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 110 8.5.2 Description formelle . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 111 8.6 Réseaux de Petri temporisés . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 112 8.6.1 Définition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 113
9 Automates stochastiques 115 9.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115 9.2 Structure d’horloge stochastique . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115 9.3 Automate temporisé stochastique . . . . . . . . . . . . . . . . . . . . . . . . . . . . 116 9.4 Processus de Poisson . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 116 9.4.1 Définition de la densité de probabilité . . . . . . . . . . . . . . . . . . . . . 116 9.4.2 Moyenne et variance du processus de Poisson . . . . . . . . . . . . . . . . . 117 9.4.3 Propriétés du processus de Poisson . . . . . . . . . . . . . . . . . . . . . . . 118 9.4.4 Intérêt du processus de Poisson . . . . . . . . . . . . . . . . . . . . . . . . . 119 9.5 Autres types de processus . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 119 9.5.1 Loi d’Erlang ou processus de renouvellement . . . . . . . . . . . . . . . . . 119 9.5.2 Distribution de Rayleigh . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 119 9.6 Conclusion de la partie II . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 120
III Méthodes pour l’identification et l’évaluation des modèles 121
10 Identification 123 10.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123 10.1.1 Démarche générale pour l’identification . . . . . . . . . . . . . . . . . . . . 123 10.1.2 Classification sommaire des méthodes . . . . . . . . . . . . . . . . . . . . . 123 10.2 Analyse indicielle . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124 10.2.1 Procédure expérimentale . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124 10.2.2 Identification par une fonction de transfert du premier ordre . . . . . . . . 125 10.2.3 Identification par la méthode de Strejć . . . . . . . . . . . . . . . . . . . . . 126 10.2.4 Identification par une fonction de transfert du second ordre . . . . . . . . . 128 10.3 Analyse harmonique . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 129 10.3.1 Procédure expérimentale . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 129 10.4 Méthode générale statistique . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130 10.4.1 Principe général de la méthode statistique d’identification de modèle . . . . 130 10.4.2 Estimation paramétrique par la méthode des moindres carrés . . . . . . . . 131 10.4.3 Interprétation statistique . . . . . . . . . . . . . . . . . . . . . . . . . . . . 132 10.4.4 Notions d’optimisation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 136 10.5 Évaluation et sélection de modèles . . . . . . . . . . . . . . . . . . . . . . . . . . . 139


x Table des matières
10.5.1 Quelques critères d’évaluation . . . . . . . . . . . . . . . . . . . . . . . . . . 140 10.5.2 Sélection de modèle . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 142
11 Analyse d’incertitude et de sensibilité 147 11.1 Contexte et objectifs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 147 11.1.1 Notations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 147 11.1.2 Analyse d’incertitude : définition et objectifs . . . . . . . . . . . . . . . . . 147 11.1.3 Analyse de sensibilité : définition et objectifs . . . . . . . . . . . . . . . . . 148 11.2 Modélisation de l’incertitude . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149 11.2.1 Terminologie . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149 11.2.2 Sources d’incertitude sur les facteurs . . . . . . . . . . . . . . . . . . . . . . 150 11.2.3 Définition générale de l’incertitude . . . . . . . . . . . . . . . . . . . . . . . 151 11.2.4 Modélisation des incertitudes de type A . . . . . . . . . . . . . . . . . . . . 152 11.2.5 Modélisation des incertitudes de type B . . . . . . . . . . . . . . . . . . . . 157 11.3 Méthodes de propagation des incertitudes . . . . . . . . . . . . . . . . . . . . . . . 160 11.3.1 Méthode des intervalles ou théorie des erreurs maximales ou approche min-max161 11.3.2 Approximation de la variance par méthode de Taylor : méthode dite de la combinaison des variances . . . . . . . . . . . . . . . . . . . . . . . . . . . . 162 11.3.3 Propagation des incertitudes par méthode de Monte-Carlo . . . . . . . . . . 164 11.4 Analyse de sensibilité . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 166 11.4.1 Méthodes locales . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 166 11.4.2 Méthode d’analyse de sensibilité globale pour un modèle linéaire ou quasilinéaire : indices SRC . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 167 11.4.3 Méthode d’analyse de sensibilité globale pour un modèle quelconque : indices de Sobol . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 169 11.5 Conclusion de la partie III . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 172
Annexe A Transformée de Laplace de signaux usuels 173
Annexe B Transformée en z de signaux usuels 175
Annexe C Termes techniques en anglais 177
Annexe D Convolution 179
Annexe E Rappels de probabilités 183
Annexe F Rappels de calcul différentiel 191
Annexe G Algorithme d’estimation des indices de Sobol 193


Chapitre 1
Introduction
Les progrès technologiques et scientifiques actuels n’auraient pas pu être possibles sans la compréhension et l’évolution des systèmes complexes faisant intervenir des domaines variés d’application comme l’énergie, les télécommunications, le transport, l’aéronautique et le spatial, la robotique, l’économie et la finance, la santé etc. Afin de pouvoir maîtriser le comportement des systèmes complexes, il s’avère nécessaire de modéliser leur comportement de façon quantitative ou qualitative, en tenant compte d’une bonne connaissance du système réel. La modélisation de systèmes a un rôle essentiel pour la commande des systèmes, ainsi que pour l’analyse des interactions entre les divers composants d’un système ou entre différents systèmes. En fonction des hypothèses faites en lien avec le but de la modélisation, des modèles plus simples (utilisés pour la synthèse des lois de commande) ou plus complets (utilisés pour l’analyse du comportement du système réel) peuvent être élaborés. Ce polycopié contient les outils nécessaires pour représenter différents types de systèmes en choisissant une modélisation adéquate (continue ou discrète), pour analyser leur comportement vis-à-vis des divers signaux appliqués en entrée du système, pour faire une analyse de sensibilité et pour valider les modèles choisis selon les hypothèses prises en compte.
1.1 Objectifs et liens avec d’autres cours
A l’issue de ce cours, vous serez capables de représenter et analyser l’évolution d’un système au moyen d’un modèle exploitable analytiquement ou numériquement, adapté à l’objectif de modélisation, déterminé en termes d’hypothèses de modélisation, de représentativité et de niveau de complexité, et d’en déterminer le domaine de validité. Pour cela, vous serez capables de choisir et justifier l’échelle temporelle et spatiale d’intérêt, ainsi que la représentation la plus opportune. Puis, à partir de données expérimentales, vous serez capables de concevoir une structure de modèle et d’en identifier les paramètres, malgré les bruits de mesure inhérents, et finalement d’évaluer les modèles proposés. Ce cours présente une vision générale de différentes approches de modélisation et permet également de voir comment les différentes étapes de la démarche s’articulent entre elles. Il s’appuie sur des notions enseignées dans le cours de Convergence, intégration, probabilités, équations aux dérivées partielles, ainsi que sur des notions d’analyse et des bases d’algorithmique et physique. Ce cours constitue le principal pré-requis du cours de tronc commun d’Automatique en deuxième année, qui permettra de synthétiser des lois de commande à partir d’un modèle dynamique. De plus, certaines notions enseignées pendant ce cours seront approfondies lors de prochains cours de tronc commun, de séquences thématiques, de cours électifs ou lors de divers projets dans le cadre des pôles projets associés. On peut citer notamment les cours d’Optimisation ou de Statistiques et Machine Learning dont on verra en partie III de ce cours toute l’utilité dans la démarche de modélisation. Des renvois à d’autres cours émailleront ainsi ce document, qui constitue à ce titre une sorte de fil-rouge reliant entre elles et donnant du sens à différentes activités pédagogiques du cursus.
1


2 Chapitre 1. Introduction
1.2 Organisation du polycopié
Chapitre 2 - Du système à la formalisation mathématique
Ce chapitre introduit d’abord la notion de système et ensuite les différentes approches de modélisation des systèmes qui seront proposées dans ce polycopié. Ensuite, la taxonomie des modèles est abordée. Une démarche de modélisation des systèmes est proposée, permettant de représenter différentes classes de systèmes, partant d’un système simple (composé de sous-systèmes) et allant jusqu’à la modélisation des systèmes complexes (systèmes multi-agents ou systèmes de systèmes). Partie I - Modélisation des systèmes à état continu au sens d’un système dynamique Chapitre 3 - Modélisation sous forme de représentation d’état
En revenant sur la problématique de la représentation des systèmes dynamiques à temps continu ou à temps discret, ce chapitre introduit le concept de variables d’état qui joue un rôle fondamental pour l’étude des systèmes dynamiques, qu’ils soient linéaires ou non. Nous allons également voir comment le concept de modèle linéaire tangent (autour d’un point de fonctionnement ou d’une trajectoire) permet d’approcher par un système linéaire le comportement d’un système non linéaire. La résolution explicite de l’équation d’état linéaire, ainsi que l’analyse de stabilité par étude des valeurs propres sont proposées.
Chapitre 4 - Modélisation sous forme de fonction de transfert
Les principaux outils permettant l’étude des systèmes linéaires et des signaux qui leur sont associés sont présentés dans le chapitre 4. Les transformées de Fourier (pour les signaux à temps continu ou discret), de Laplace (pour les signaux à temps continu) et la transformée en z (pour les signaux à temps discret) sont brièvement introduites. Les transformées de Laplace et en z permettent de définir la représentation d’un système dynamique par fonction de transfert, qui ne s’applique qu’aux systèmes linéaires et qui joue un rôle fondamental aussi bien pour le traitement des signaux que pour l’analyse des systèmes. Un premier aperçu de l’utilisation de la fonction de transfert (qui ne s’intéresse qu’à la relation entre l’entrée et la sortie d’un système) est donné dès ce chapitre. Celui-ci s’achève par l’analyse de stabilité des systèmes linéaires donnés sous la forme d’une fonction de transfert (à temps continu ou discret). Ensuite, le lien avec la représentation par variables d’état est proposé.
Chapitre 5 - Analyse des performances des systèmes dynamiques
Ce chapitre est principalement dédié à l’étude fréquentielle des systèmes élémentaires d’ordre 1 ou 2 (c’est-à-dire décrits par une équation différentielle linéaire d’ordre 1 ou 2, ou encore par une fonction de transfert rationnelle dont le numérateur et le dénominateur sont des polynômes de degré 1 ou 2), d’où l’on va déduire plus généralement le diagramme du Bode des systèmes d’ordres plus élevés. Le cas des systèmes numériques d’ordre 1 et 2 est également proposé, puis sont présentés les systèmes passe-tout et à déphasage minimal. Enfin, on étudie les systèmes avec retard pur, qui présentent une fonction de transfert non rationnelle. Après avoir rappelé comment représenter la réponse en fréquence d’un système linéaire dans le plan de Bode, nous étudions l’influence de la position des pôles et des zéros sur les réponses temporelles. La réponse impulsionnelle, la réponse indicielle, ainsi que la réponse à une rampe seront analysées. Là encore, les systèmes à temps continu et discret sont traités en parallèle. Partie II - Modélisation des systèmes à état discret Chapitre 6 - Introduction sur la modélisation des systèmes à état discret
Nous présentons dans la deuxième partie la modélisation des systèmes à évènements discrets. Ce type de système est caractérisé par de brusques transitions du système dans l’espace d’état en réponse à la survenue d’évènements. De nombreux systèmes physiques travaillant dans des modes opératoires différents, partageant des ressources ou reposant sur un ordonnancement des tâches (réseaux informatiques, systèmes de production, réseaux de transport, etc.) peuvent ainsi se modéliser en adoptant ce point de vue.
Chapitre 7 - Modélisation des systèmes à évènements discrets non temporisés
Après un chapitre introductif présentant de manière informelle les types de modèles inhérents à ces systèmes, nous aborderons tout d’abord dans le chapitre 7 les systèmes à évènements discrets non temporisés. Pour ces systèmes, le temps n’apparaît pas de façon explicite dans la modélisation, et seule la séquence d’évènements agissant sur le système est considérée pour en décrire l’évolution. Les principaux outils de modélisation de tels systèmes, à savoir les automates et les réseaux de Pétri sont successivement présentés ainsi que les propriétés à analyser pour ces modèles.


1.2. Organisation du polycopié 3
Chapitre 8 - Modélisation des systèmes à évènements discrets temporisés
Nous traitons ensuite au chapitre 8 le cas des systèmes à évènements discrets temporisés où la dimension temporelle est ajoutée au formalisme de modélisation pour décrire le fonctionnement du système. En considérant le cas des automates temporisés, une horloge est ainsi associée à chaque évènement pour orchestrer la séquence d’évènements. Le cas des automates avec gardes et invariants est ensuite présenté, permettant d’associer des conditions à chaque état et chaque transition. L’extension aux systèmes hybrides où chaque état discret est caractérisé par une dynamique continue différente est enfin exposée, permettant d’englober une large classe de systèmes et faisant le lien avec les développements des systèmes à état continu de la première partie. Chapitre 9 - Automates stochastiques
Cette deuxième partie de modélisation des systèmes à évènements discrets se conclut par une brève présentation de processus stochastiques nécessaires à la modélisation de ces systèmes au chapitre 9. En effet, l’arrivée d’évènements n’est que rarement connue à l’avance et correspond, du point de vue de la modélisation du système le recevant, à un processus aléatoire. L’accent est mis dans ce chapitre sur le processus de Poisson qui est de prime importance dans ce contexte. Partie III - Méthodes pour l’identification et l’évaluation des modèles
Dans cette partie, l’objectif est de confronter le modèle à la réalité, soit via un comportement attendu, soit de manière quantitative via des observations collectées sur le système réel. Chapitre 10 - Identification
Ce chapitre développe la problématique de l’identification, c’est-à-dire la question de savoir comment spécifier un modèle mathématique à partir de données expérimentales et éventuellement de connaissances a priori. La question posée est de savoir comment fixer la structure d’un modèle et les valeurs de ses paramètres de sorte qu’il permette de reproduire ’au mieux’ un comportement attendu ou des valeurs observées expérimentalement sur le système réel. Nous introduirons tout d’abord des approches simples, comme l’analyse indicielle ou l’analyse harmonique, qui peuvent être mises en œuvre dans des cas particuliers. Puis nous présenterons la méthode générale d’identification de modèle paramétrique à partir de données expérimentales. Cette méthode inclut des étapes concernant l’évaluation et la sélection de modèles. Des méthodes pour tester de manière fiable les propriétés du modèle en terme de reproduction fidèle de la réalité d’une part et prédictives d’autre part, ainsi que des critères permettant de choisir entre deux (ou plusieurs) modèles candidats seront discutés dans ce chapitre.
Chapitre 11 - Analyse d’incertitude et de sensibilité
Dans la phase d’analyse et d’évaluation du modèle, ainsi qu’en préalable à son utilisation comme outil de prédiction ou comme support à la prise de décision, il est important de pouvoir quantifier le degré de fiabilité des sorties du modèle, que l’on caractérise notamment par leur incertitude. Ce chapitre présente les méthodes de modélisation de l’incertitude (comment représenter le manque d’information lié à un paramètre ou à une grandeur d’entrée ?) et les méthodes de propagation de l’incertitude qui permettent de quantifier l’incertitude obtenue sur une sortie du modèle en fonction des incertitudes sur ses paramètres ou entrées. Lorsque l’incertitude sur une sortie est trop importante, cela peut pénaliser fortement l’utilisation possible du modèle : il faut alors trouver des moyens d’y remédier. Pour cela, on présentera des méthodes d’analyse de sensibilité globale qui permettent notamment de quantifier la contribution des différents facteurs à l’incertitude de la sortie afin de pouvoir mieux cibler les actions de réduction de l’incertitude et revaloriser ainsi l’utilité du modèle développé. Il est important de noter que, dans la pratique, les étapes présentées ici (identification, évaluation et sélection de modèles, analyse d’incertitude et de sensibilité) ne s’effectuent pas de manière linéaire, mais de manière cyclique dans le processus de développement du modèle. Par exemple, l’analyse de sensibilité peut aussi répondre à la question de sélection des paramètres à identifier dans un modèle présentant des problèmes d’identifiabilité (i.e. dans lequel il n’est pas possible d’estimer de manière fiable tous les paramètres à la fois).




Chapitre 2
Du système à la formalisation
mathématique
2.1 Introduction
2.1.1 Notion de système
2.1.1.1 Définitions
Un système représente un ensemble d’éléments en interaction entre eux et éventuellement avec l’environnement, qui se coordonnent pour concourir à un résultat. Parmi les caractéristiques d’un système, on peut citer l’interdépendance de ses éléments, ainsi que l’influence du et vers le milieu extérieur via les entrées et les sorties. Le mot système est d’origine grecque σν`στ ημα signifiant combinaison, assemblage, composition. Parmi les synonymes du mot système se trouve : procédé, processus (avec leurs équivalents anglais process, plant ).
La notion de système est utilisée dans divers domaines. Selon Larousse, un système informatique est vu comme un ensemble de moyens d’acquisition, de traitement, de stockage et de restitution de données, et de moyens de télécommunication mis en œuvre pour une application ou un ensemble d’applications spécifiés. Un système social est un modèle théorique qui décrit et analyse l’interaction sociale humaine. Dans le domaine de l’Automatique, le concept de système dynamique représente tout système évoluant avec le temps, selon des lois que l’on cherchera à identifier et qui peuvent être déterministes ou stochastiques.
2.1.1.2 Niveaux hiérarchiques
Les systèmes utilisés en pratique étant souvent complexes, une décomposition d’un système en sous-systèmes peut être envisagée dans la phase de modélisation d’un système. La démarche consiste à décomposer le système en sous-systèmes élémentaires effectuant une seule tâche simple, à étudier le comportement de chaque sous-système et le comportement global tenant compte des interactions entre les différents sous-systèmes. Quand plusieurs systèmes indépendants (appelés agents 1 dans ce contexte) interagissent dans un environnement afin de répondre à un but commun ils forment ce que l’on appelle un système multi-agents. La notion de système multi-agents a été utilisée au départ dans le domaine de l’Intelligence Artificielle, étant caractérisée par le nombre de ses agents, l’environnement dans lequel les agents interagissent et le niveau d’autonomie des agents. Les caractéristiques principales de tels systèmes sont l’autonomie de chaque agent, la communication entre les agents et la coordination pour un but commun. La notion de systèmes (dynamiques) multi-agents est également utilisée en Automatique afin de modéliser et de piloter des applications complexes comme le vol
1. Un agent est une entité matérielle ou logicielle qui se trouve dans un certain environnement, et qui est capable d’actions autonomes dans l’environnement afin de répondre à ses objectifs.
5


6 Chapitre 2. Du système à la formalisation mathématique
en formation de plusieurs drones, le comportement des piétons dans une foule, la fluidité de la circulation automobile etc. Une autre structure de hiérarchisation des systèmes est ce que l’on appelle les systèmes de systèmes, définis comme des systèmes de grande taille, intégrant plusieurs sous-systèmes, possiblement multidisciplinaires, autonomes, mais inter-connectés, afin de satisfaire un besoin global. Parmi les caractéristiques des systèmes de systèmes on trouve l’indépendance opérationnelle, l’autonomie de gestion et de répartition géographique des systèmes constitutifs, le développement évolutif et le comportement émergent. Ces types de systèmes correspondent par exemple au réseau national/européen de distribution d’énergie électrique, au réseau de contrôle du trafic aérien au niveau européen, aux constellations de satellites etc.
2.1.2 Modèles et Modélisation
Au sens premier, le mot modèle, issu du latin modulus, désigne ’une œuvre ou un objet que l’on imite, que l’on reproduit ; ce qui sert d’exemple, de type, de norme’ (dictionnaire de l’Académie Française). Par un glissement sémantique de l’objet imité à l’objet imitant, un modèle désigne également une représentation, pouvant être par exemple de type physique, graphique ou mathématique, qui formalise les relations unissant les différents éléments d’un système, d’un processus, d’une structure, en vue de faciliter la compréhension de certains mécanismes, d’en prévoir le comportement, ou de permettre la validation d’une hypothèse. C’est de manière générale une représentation simplifiée de la réalité, qui peut, ou pas, être accompagnée d’une écriture mathématique. La notion de modèle peut prendre des sens très différents selon les domaines : par exemple en biologie, on parlera de ’modèle’ pour désigner un organisme (plante, animal). La modélisation est l’activité visant à représenter un objet ou un phénomène du monde réel par une instance du système formel choisi. Le terme simulation désignera ici la méthode qui permet de mettre en œuvre un modèle, généralement via un outil informatique permettant d’interpréter la représentation choisie pour le modèle. La simulation permet notamment d’obtenir des valeurs calculées ou prédites qui pourront être confrontées à des valeurs observées sur le système réel afin d’en évaluer la concordance. Enfin, on peut terminer en insistant sur le fait qu’un modèle est toujours une simplification du fonctionnement du système réel. Dans ce cours, nous nous intéresserons principalement aux modèles correspondant à des représentations des systèmes sous forme mathématique (d’équations) ou sous forme de graphes.
Objet ou phénomène réel
Modélisation
Modèle conceptuel
Modèle formel
Simulateur
Simulation
Etude logique et analytique
Objectif
Résultats de la simulation
Comparaison Validation
Observations Mesures
Expérimentation Echantillonnage
Utilisation
Figure 2.1 – Illustration de la démarche de modélisation
La figure 2.1 illustre bien la démarche de modélisation que nous avons pour objectif de présenter


2.1. Introduction 7
dans ce cours : en fonction de l’objectif formulé, l’objet ou le phénomène d’intérêt est traduit par un modèle conceptuel ou formel (parties I et II : représentations de systèmes à états continus ou discrets) dont on peut, d’une part, étudier les propriétés de manière analytique, d’autre part, simuler le comportement de manière généralement numérique. Les résultats de l’étude analytique ainsi que ceux de la simulation peuvent alors être confrontés à des informations recueillies sur le système réel (partie III), ce qui conduira soit à la mise en utilisation du modèle, soit à le remettre en cause ou bien à indiquer un besoin de collecte de données expérimentales supplémentaires.
2.1.2.1 Définitions des composantes d’un modèle : vocabulaire
Nous avons vu qu’un système (ou processus) est une partie d’un ensemble que nous appréhendons comme un tout et qui interagit avec son environnement. L’activité de modélisation va consister à identifier sur ce système, parfois de manière arbitraire ou subjective (biais de vision du modélisateur) et, en tout cas, toujours en fonction de l’objectif recherché pour la modélisation, un certain nombre de composantes :
— des grandeurs caractérisant le système lui-même, c’est-à-dire permettant de décrire son activité interne de manière aussi exhaustive que possible, les variables d’état.
— des variables dont le système subit l’action, les entrées, parfois aussi appelées co-variables. Si les entrées peuvent être maîtrisées, c’est-à-dire imposées par un utilisateur externe (par exemple un thermostat), on parlera d’entrée de commande. Il existe également des entrées de perturbation, vues comme des actions de l’environnement qui ne sont pas manipulées par l’utilisateur (par exemple des conditions météorologiques agissant sur un système). Une étude plus approfondie de ces notions sera réalisée dans le cours d’Automatique.
— des variables auxquelles le modélisateur s’intéresse, les sorties. Les sorties fournissent la réponse du système aux entrées et dépendent généralement de son état interne, c’est-à-dire de ses variables d’état. Elles peuvent être mesurées (elles sont alors dites observables) ou non. La fonction définissant une sortie observable sera appelée fonction d’observation.
— les différentes fonctions ou représentations liant les variables d’état, d’entrée et de sortie peuvent faire apparaitre un certain nombre de constantes, que l’on appellera des paramètres 2 du modèle. Ces paramètres sont spécifiques au système considéré et peuvent, ou pas, être mesurés. Ce peut être par exemple un taux de naissance, un coefficient de frottement, une masse, la constante de gravitation, etc. Certains paramètres pourront être déterminés avec précision et d’autres, même mesurables, feront l’objet d’incertitudes dont il faudra déterminer les conséquences sur les sorties du modèle.
2.1.3 Représentations des systèmes : différentes approches
Deux approches, qu’on pourrait presque qualifier de deux philosophies, se présentent pour la démarche de modélisation d’un système. L’approche dite mécaniste ou par modèle de connaissance consiste à s’appuyer sur toutes les connaissances disponibles sur les mécanismes de fonctionnement du système afin d’en rendre compte dans le modèle. C’est généralement la démarche adoptée en modélisation en physique où les équations décrivant le système à identifier sont généralement bien connues et issues de lois génériques souvent très précises, au sens où elles permettent de représenter le phénomène réel de manière très fiable (penser à un moteur électrique, par exemple, ou aux lois de la gravitation). Ces modèles restent néanmoins valables seulement dans un certain domaine de validité, c’est-à-dire sous certaines conditions (par exemple les lois de la mécanique générale versus celles de la mécanique quantique). Cette approche peut aussi être mise en œuvre même si le système et les lois qui le régissent sont mal connues, dès lors qu’on s’attache à proposer une vision explicative du fonctionnement du système. Les paramètres du modèle ont alors une interprétation physique. Ce type d’approche peut être réalisé même en l’absence de données. L’approche empirique ou par modèle de comportement intervient en particulier lorsque les équations décrivant le système sont inconnues ou bien trop complexes pour une simulation détaillée
2. Parfois ces paramètres peuvent varier dans le temps (par exemple la masse d’un réservoir à essence au fur et à mesure de la consommation lors du déplacement de la voiture).


8 Chapitre 2. Du système à la formalisation mathématique
(par exemple des phénomènes d’échange de chaleur dans un four). Le modélisateur a alors pour objectif de déterminer un modèle simple, qui se comporte comme une bonne approximation du système, même s’il ne représente pas tous les mécanismes internes : le modèle doit simplement être en mesure de reproduire le comportement du système, c’est-à-dire la façon dont il transforme ses entrées en sorties. Ce type d’approche repose donc fortement sur la disponibilité de données : on parle aussi dans ce cas d’approche ’data-driven’ (guidée par les données). Les méthodes de type apprentissage automatique (machine learning) s’apparentent à cette approche. Il faut noter que de nombreux modèles sont construits selon un mélange des deux approches. Par exemple, on pourra avoir une description mécaniste de la déformation d’un matériau en réponse à une contrainte, dont le coefficient module de Young aura une variation en réponse à la température qui aura été déterminée par une relation issue d’une démarche empirique (en utilisant un jeu de données acquises sur des expériences systématiques d’étude de l’effet de la température).
Exemple 2.1.1. On peut illustrer ces deux approches sur un exemple, dans lequel elles conduisent toutes deux au même type de modèle. En 1934, deux faisans mâles et six femelles ont été introduits sur une île sur la côte près de Washington. Au cours des 5 années suivantes, la population a connu une croissance d’allure exponentielle (Lack 1954, figure 2.2). La méthode empirique consisterait ici à choisir une forme de modèle, par exemple en introduisant une fonction de type exponentiel f (t) = aebx, où a et b sont des paramètres, et à en estimer les paramètres à partir des données. Si les données étaient beaucoup plus nombreuses ou à évolution complexe, on pourrait utiliser un réseau de neurones récurrent, par exemple. La méthode mécaniste consiste à essayer de formaliser le processus de reproduction des faisans. Sous un certain nombre d’hypothèses, entre autres qu’on ne distingue pas entre mâle et femelle et que l’on peut considérer la population comme continue, on va écrire un modèle sous la forme d’une
équation différentielle : dx(t)
dt = r · x(t), où r représente le taux de reproduction. La résolution de
cette équation conduit également à une fonction de forme exponentielle dont on estimera les paramètres r et x0 (qui, cette fois, ont des interprétations biologiques) à partir des données. L’intérêt de l’approche mécaniste est que la construction du modèle, en elle-même, fait progresser vers une meilleure compréhension du processus ou du système étudié. Elle possède en revanche un certain nombre de limites (complexité, processus mal représentés lorsque mal connus) et de nombreux modèles dits ’mécanistes’ comportent en réalité souvent un certain nombre de composantes empiriques pour certains sous-processus modélisés.
1937 1938 1939 1940 1941 1942
0
200
400
600
800
1000
1200
1400
Année
Nombre de faisans
Figure 2.2 – Evolution des faisans
2.1.3.1 Sur l’approche par modèle de comportement (empirique)
L’approche par modèle de comportement pour la représentation des systèmes est essentiellement fonctionnelle, c’est-à-dire qu’elle permet de représenter les systèmes en tenant compte des échanges des flux dans une architecture de fonctions. En Automatique et Cybernétique, les modèles de comportement intègrent des aspects continus et/ou événementiels, i.e. impliquant des évolutions fondées sur une succession d’états et de transitions. En Informatique, des modèles sémantiques (plus précisément des modèles de données) sont utilisés pour répondre aux problématiques liées à l’abstraction du logiciel.


2.2. Représentations par schéma blocs 9
Comme on le verra dans la suite de ce chapitre il existe plusieurs types de représentations du comportement d’un système qui ont bien sûr toutes leurs avantages et leurs limitations en fonction de l’utilisation que l’on veut en faire et dont l’équivalence est à étudier. Une première façon d’aborder l’étude des systèmes dans le cadre d’une modélisation comportementale est de considérer qu’il s’agit d’entités qui reçoivent des signaux d’entrée et qui les transforment en de nouveaux signaux de sortie. La transformation effectuée par le système peut alors être assimilée à la manière dont il réagit à des stimuli et donc à son comportement. Pour certains systèmes (dits systèmes dynamiques) cette description doit prendre en compte la composante temporelle des différents signaux ; c’est-à-dire qu’à un instant donné la valeur d’un signal de sortie ne dépend pas uniquement de la valeur des signaux d’entrées à cet instant mais également de leurs valeurs aux instants précédents 3. Un problème fondamental que pose alors leur étude est de pouvoir décrire cette transformation que réalise le système. Depuis Descartes, l’approche occidentale pour prendre en compte la complexité est de décomposer les systèmes dans une démarche descendante, d’étudier chacun des sous-systèmes puis de revenir au système global. Pour les systèmes qui nous intéressent ici cette démarche se traduit par la composition des représentations comportementales des sous-systèmes afin d’en déduire le comportement global. Comme nous le verrons, cette approche demande de prendre quelques précautions pour certains systèmes. Il est donc important de comprendre le processus de modélisation qui permet de passer d’un système à sa représentation comportementale. Enfin nous verrons comment le comportement des systèmes peut être caractérisé par certaines propriétés structurelles c’est-à-dire inhérentes au système lui-même. Cette question de la composition des modèles comportementaux des systèmes physiques (choix d’équations implicites ou explicites, définition de ports d’interaction et affectation en entrées et sorties, prise en compte des contraintes algébriques, etc.) et les problèmes qu’elle induit par exemple au niveau de la simulation est un problème fondamental pour l’ingénieur qui doit construire des modèles de systèmes complexes en prenant en compte les contraintes économiques de temps et de coût de développement de ce modèle. Cette activité de modélisation ne peut pas être parfaite. La modélisation est donc effectuée pour répondre à un objectif particulier et repose sur un ensemble d’hypothèses simplificatrices. Lorsqu’on utilise le modèle pour mener certaines études et que l’on en tire des conclusions il faut s’assurer que l’on est bien dans un cadre où les hypothèses sont respectées et que les conclusions restent valables pour le système réel.
2.2 Représentations par schéma blocs
Lorsque le système dont on veut représenter le comportement est complexe, il est souvent intéressant de faire apparaître sa structure fonctionnelle et ses sous-systèmes, de représenter ceuxci puis de les composer pour obtenir une représentation du système global. Dans ce but, il est possible de représenter les sous-systèmes par des blocs possédant des points d’entrée et de sortie correspondant aux signaux d’entrée et de sortie du système (figure 2.3).
Système 1
e3
e2
e1 s1
s2
Figure 2.3 – Représentation par bloc
La composition est traduite dans cette représentation en reliant les points d’entrée et de sortie des blocs pour indiquer l’égalité des signaux. Ainsi, sur la figure 2.4, il est possible de représenter la composition des systèmes ”Système1” et ”Système2” par la connexion de leurs entrées et sorties, comme par exemple Système1.s1 et Système2.e1, qui assure l’égalité des signaux associés.
3. Dans ce document on considérera des systèmes dont la composante ’temporelle’ correspond à la notion usuelle du temps et est représentée par l’ensemble des réels (cas des systèmes continus) ou des entiers (cas des systèmes discrets) même s’il s’agit d’un cas particulier puisque d’un point de vue théorique la notion de systèmes dynamiques ne demande pour la composante temporelle que l’existence d’un ensemble muni d’une relation d’ordre.


10 Chapitre 2. Du système à la formalisation mathématique
Cette représentation graphique par schémas blocs permet également de prendre en compte des niveaux hiérarchiques d’abstraction de la représentation comportementale puisqu’on peut englober le système issu de la composition dans un nouveau bloc qui possède ses propres entrées et sorties. Les règles d’abstraction qui assurent la cohérence de la représentation sont relativement simples et consistent principalement à assurer que les entrées (respectivement les sorties) d’un bloc sont connectées aux entrées (respectivement aux sorties) des blocs de niveaux inférieurs.
Système 1
s1 e1
e2
Système 2 s1 s1
e1
e3
ee12 s2 s2
Figure 2.4 – Composition de blocs
Exemple 2.2.1 (Échangeur de chaleur). On s’intéresse aux températures en sortie T1 et T2 d’un échangeur de chaleur en fonction des débits d’entrée Q1 et Q2 et des températures d’entrée θ1 et θ2. Les équations suivantes permettent de modéliser le système d’échangeur :
C1T ̇1(t) = k1Q1(t) (θ1(t) − T1(t)) + 1
R (T2(t) − T1(t)) (2.2.1)
C2T ̇2(t) = k2Q2(t) (θ2(t) − T2(t)) + 1
R (T1(t) − T2(t)) (2.2.2)
avec C1, C2 les capacités thermiques du fluide, R la résistance thermique et k1, k2 les coefficients d’échange du fluide. En linéarisant ce modèle autour d’un point de fonctionnement 4 défini par Q10, Q20, T10 et T20, ce modèle peut se mettre sous la forme du schéma bloc donné dans la figure suivante, avec
N1(p) = C1p +
(
k1Q10 + 1
R
)
, N2(p) = C2p +
(
k2Q20 + 1
R
)
, a = k1Q10, b = k2Q20, c = 1/R,
∆1 = k1 (θ10 − T10) and ∆2 = k2 (θ20 − T20).
∆1
∆2
1 N1(p)
1 N2(p)
c
c
a
b
+
+
+
+
T1(p)
T2(p)
Q1(p)
Q2(p)
θ1(p)
θ2(p)
+
+
Figure 2.5 – Schéma bloc d’un échangeur de chaleur
4. Cette notion est abordée au Chapitre 3.


2.3. Représentation par variables d’état 11
Cet exemple a permis de mettre en évidence un schéma bloc à base de fonctions de transfert qui seront étudiées dans le Chapitre 4.
2.3 Représentation par variables d’état
Lorsqu’on représente le comportement d’un système par la relation qui relie ses signaux de sortie à ses signaux d’entrée on peut formellement considérer le système comme une application de l’espace des signaux d’entrée dans l’espace des signaux de sortie. Si on veut connaître la réponse du système il est nécessaire de connaître l’ensemble des signaux d’entrée depuis l’origine des temps pour pouvoir calculer leur image par l’application. Ceci reste vrai même si on ne s’intéresse à la réponse du système qu’à partir d’un certain instant et que les entrées avant cet instant restent inconnues. Il est donc intéressant de disposer d’une représentation qui permet de résumer tout le passé du système afin de pouvoir déterminer quelles seront ses réponses à des signaux d’entrée à partir d’un certain instant sans connaître toute l’histoire de ces signaux. Dans ce but, nous allons introduire la notion d’état d’un système qui est définie comme un ensemble de grandeurs qu’il faut connaître à un instant donné pour pouvoir déterminer l’évolution du système à partir de cet instant, connaissant un modèle mathématique et les signaux appliquées à l’entrée.
L’équation d’état est un ensemble d’équations différentielles (voir le cours Convergence, intégration, probabilités, équations aux dérivées partielles) du premier ordre décrivant le système à temps continu :
x ̇ (t) = f (x(t), u(t), t)
y(t) = g (x(t), u(t), t) (2.3.1)
ou un ensemble d’équations de récurrence d’ordre 1 décrivant un système à temps discret :
xk+1 = f (xk, uk, k)
yk = g (xk, uk, k) (2.3.2)
Exemple 2.3.1 (Modèle d’un satellite). La trajectoire d’un satellite autour de la terre peut être considérée comme plane. Les équations de la mécanique qui définissent cette trajectoire en coordonnées polaires dans ce plan sont les suivantes :
r ̈(t) = r(t)θ ̇2(t) − GM
r2(t) + 1
m u1(t) (2.3.3)
θ ̈(t) = − 2r ̇(t)θ ̇(t)
r(t) + 1
mr(t) u2(t) (2.3.4)
où G représente la constante de gravitation, M la masse de la terre, m la masse du satellite et u1 et u2 correspondent aux composantes radiale et tangentielle de la force délivrée par les moteurs du satellite. Si on ne s’intéresse qu’à la composante radiale de la position il est possible, en différenciant les équations (2.3.3) et (2.3.4), d’en éliminer la composante tangentielle et d’expliciter par une équation différentielle la relation entre le signal de sortie (r(t)) et les signaux d’entrée (u1(t) et u2(t)).
Si on introduit le vecteur x défini par x = (r r ̇ θ ̇)T , les équations (2.3.3) et (2.3.4) peuvent se réécrire :
x ̇ (t) =


x2(t)
x1(t)x23(t) − GM
x21(t) + 1
m u1(t)
− 2x2(t)x3(t)
x1(t) + 1
mx1(t) u2(t)

 (2.3.5)
qui peut s’écrire sous la forme suivante, où f est une fonction vectorielle non différentielle :
x ̇ (t) = f (x(t), u(t))


12 Chapitre 2. Du système à la formalisation mathématique
Si on s’intéresse à la composante radiale de la position, considérée comme la sortie du système, la valeur de cette sortie est donnée par :
y(t) = (1 0 0) x(t) (2.3.6)
Exemple 2.3.2 (Modèle d’un circuit électrique). Considérons le circuit électrique de la figure 2.6 pour lequel il est possible de commander la tension e(t) qui est donc l’entrée du système.
e
R1 i1 R2 i2
CL
+
Figure 2.6 – Exemple de circuit électrique
Si on s’intéresse au courant qui circule dans R1 qui est donc considéré comme une sortie du système, la relation qui relie les signaux d’entrée et de sortie est définie par l’équation (2.3.7), dont la résolution pour un signal d’entrée donné permet de connaître le signal de sortie :
R1LC ̈i1(t) + (R1R2C + L) i ̇1(t) + (R1 + R2) i1(t) = LCe ̈(t) + R2Ce ̇(t) + e(t) (2.3.7)
Si on s’intéresse au courant dans R2 considéré comme une autre sortie du système la relation entre l’entrée et cette deuxième sortie est définie par l’équation (2.3.8) :
R1LC ̈i2(t) + (R1R2C + L) i ̇2(t) + (R1 + R2) i2(t) = e(t) (2.3.8)
On obtient donc autant d’équations différentielles à résoudre que de sorties. Il est cependant possible de remarquer que l’évolution des grandeurs électriques ne dépend pas des grandeurs observées et que pour un signal d’entrée donné la valeur de la tension aux bornes de la capacité, par exemple, est la même quelle que soit la sortie. En considérant la tension aux bornes de la capacité et le courant dans l’inductance il est possible de modéliser le comportement du circuit par les équations (2.3.9) et (2.3.10) :
C dVC (t)
dt = e(t) − VC (t)
R1
− i2(t) (2.3.9)
L di2(t)
dt = VC (t) − R2i2(t) (2.3.10)
En considérant le vecteur x = (VC i2
)T cette équation peut se réécrire en l’équation (2.3.11) qui est toujours valide quels que soient les signaux observés :
 ̇x(t) =


−1
R1C − 1
C
1
L − R2
L

 x(t) +


1
R1C
0

 e(t) (2.3.11)
Si on veut connaître les signaux correspondant aux courants i1 et i2 il suffit d’introduire le
vecteur y = (i1 i2
)T dont la valeur est définie par l’équation (2.3.12) :
y(t) =

− 1
R1
0
01

 x(t) +
(1
R1
0
)
e(t) (2.3.12)
L’introduction du vecteur x permet ici encore de séparer dans la représentation comportementale une relation dynamique (équation (2.3.11)) qui est valable quelles que soient les grandeurs observées et une relation statique qui définit les grandeurs observées (équation (2.3.12)).


2.4. Modélisation à évènements discrets 13
Cette forme de représentation d’état est très générale. Néanmoins, pour certains systèmes 5 il est nécessaire de prendre en compte un vecteur d’état hybride comportant une composante homogène à Rn dont l’évolution peut être prise en compte par une équation de type (2.3.1) et une autre composante logique dont l’évolution est spécifiée par une machine d’état.
2.4 Modélisation à évènements discrets
Les modèles de systèmes physiques sont souvent des modèles à base d’équations différentielles (temps continu) ou des équations aux différences (temps discret) tels que nous venons de les introduire. Pour un certain nombre de systèmes, ce type de représentation n’est pas approprié. Ainsi, il existe par exemple des systèmes réels (par exemple des convertisseurs de puissance) qui sont composés de sous-processus continus qui sont démarrés, reconfigurés et arrêtés par une commande logique à état discrets. Un système à évènements discrets est un système dynamique défini par un espace d’états discrets et par des évolutions (appelées trajectoires) fondées sur une succession d’états et de transitions. Les transitions sont étiquetées par des symboles (appelés évènements). Il existe plusieurs outils pour la modélisation des systèmes à évènements discrets : les automates (à états finis 6 ou temporisés 7), le grafcet (utilisé pour la modélisation des machines évoluant en parallèle), les réseaux de Petri (qui sont des graphes formés de deux types de noeuds : des places et des transitions, reliées par des arcs orientés) et les StateCharts (formalisme de description graphique pour les systèmes réactifs complexes, caractérisés habituellement par les mots clés suivants : automates, profondeur, orthogonalité et communication par diffusion). Les automates ou machines à états permettent de modéliser explicitement l’espace d’état d’un système. Les automates sont particulièrement bien adaptés à la modélisation de la logique de commande, notamment pour les systèmes critiques. En effet, les automates se prêtent à des méthodes formelles d’analyse qui permettent de valider certaines propriétés. Enfin, il est facile d’implémenter un automate aussi bien en logiciel qu’en matériel. Un inconvénient des automates est leur faible expressivité : il s’agit d’une modélisation d’assez bas niveau et de petites modifications de la spécification d’un système peuvent entraîner de grands changements dans la structure d’un automate. Un autre inconvénient est que le nombre d’états d’un automate peut devenir très grand, même pour un système de complexité modérée. En combinant les automates (qui sont purement séquentiels) avec des modèles qui supportent le parallélisme, on peut modéliser des systèmes complexes avec des automates ayant un nombre gérable d’états. Par exemple, les StateCharts, qui sont maintenant utilisés par UML pour modéliser les aspects dynamiques d’un objet, combinent les automates avec un modèle réactif synchrone. Lorsque l’on combine des automates avec des équations différentielles, on obtient un modèle de système dynamique hybride.
Exemple 2.4.1 (Exemple d’automate). La figure 2.7 montre un automate qui modélise le fonctionnement d’un répondeur téléphonique. Les entrées du système sont : sonnerie (signal d’appel), décroché (le combiné est décroché), fin_annonce (la lecture de l’annonce est terminée), fin_message (la fin du message est détectée – présence de la tonalité par exemple). Les sorties sont : répondre (répondre à l’appel et commencer à lire l’annonce), enregistrer (commencer à enregistrer le message), messages (un ou plusieurs messages ont été enregistrés). Les états du système sont : attente (état de repos du système), 1 sonn. (on a compté une sonnerie), 2 sonn. (on a compté 2 sonneries), annonce (on a compté 3 sonneries et on a lancé la lecture de l’annonce), enregistre (l’annonce est terminée, on a lancé l’enregistrement du message). Les transitions marquées par le symbole ⊥ sont prises lorsqu’aucune entrée n’est présente. Les transitions marquées par sinon sont prises lorsqu’une entrée autre que celles pour lesquelles existe une transition explicite est présente. Les transitions ⊥ qui bouclent sur un état sans produire de sortie ne sont en général pas indiquées sur le diagramme d’un automate. Ces transitions ne sont utiles que lorsqu’on compose
5. C’est par exemple le cas d’un radiateur électrique dans une pièce à qui on fixe une température à assurer θe signal d’entrée et qui pour ce faire met en marche sa résistance lorsque la température est inférieure à (θe − h) et l’éteint lorsque la température est supérieure à (θe + h). 6. Un automate à états finis est un automate avec un nombre fini d’états. 7. Les automates temporisés sont des automates à états discrets finis auxquels on a associé une horloge.


14 Chapitre 2. Du système à la formalisation mathématique
un automate avec un autre, l’un des automates étant parfois amené à ne rien faire (to stutter : bégayer, balbutier) pendant que l’autre réagit à une entrée.
attente
1 sonn. 2 sonn.
enregistre
annonce
sonnerie
sinon
⊥
sonnerie
sinon
sonnerie/répondre
⊥
sinon
fin_annonce/enregistrer
sinon ⊥
fin_message, décroché/messages
sinon
⊥
Figure 2.7 – Automate d’un répondeur téléphonique
2.5 Classification des systèmes
Cette partie propose une classification des systèmes selon divers critères.
2.5.1 Nombre d’entrées/sorties
Un système est un dispositif présentant un certain nombre d’entrées (signaux d’entrée) et de sorties (signaux de sortie) ; il réalise une application de l’espace des signaux d’entrée dans celui des signaux de sortie (figure 2.8).
Système
u1
ui
uN
y1
yj
yM
......
......
Figure 2.8 – Système


2.5. Classification des systèmes 15
2.5.1.1 Systèmes monovariables
Définition 2.5.1
Un système avec une seule entrée et une seule sortie est appelé système monovariable ou système SISO (Single-Input Single-Output ).
2.5.1.2 Systèmes multivariables
Définition 2.5.2
Un système avec plusieurs entrées et plusieurs sorties est appelé système multivariable ou système MIMO (Multiple-Input Multiple-Output ).
Un système avec plusieurs entrées et une seule sortie est appelé système MISO (Multiple-Input Single-Output ). Un système avec une seule entrée et plusieurs sorties est appelé système SIMO (Single-Input Multiple-Output ).
Exemple 2.5.1 (Systèmes multivariables). Robots, drones etc.
Dans la suite, sauf indication contraire, on s’intéresse aux systèmes à une entrée et une sortie.
2.5.2 Critère temporel
2.5.2.1 Système continu
Définition 2.5.3
Un système est dit continu (ou analogique) si les signaux d’entrée et de sortie sont des signaux à temps continu.
Exemple 2.5.2. Filtres analogiques, moteurs, gyroscopes etc.
2.5.2.2 Système discret
Définition 2.5.4
Un système est dit discret (ou numérique) si les signaux d’entrées et de sorties sont des signaux à temps discret.
Exemple 2.5.3. Filtres numériques, systèmes de gestion de production etc.
2.5.2.3 Système hybride entrée/sortie
Définition 2.5.5
Un système est dit hybride (ou mixte) si les entrées sont des signaux à temps continu (respectivement discret) et les sorties sont des signaux à temps discret (respectivement continu).
Exemple 2.5.4. Convertisseurs de puissance, systèmes en commutation etc.
2.5.3 Linéarité
Définition 2.5.6
Un système est dit linéaire si à toute combinaison linéaire des signaux d’entrée correspond la même combinaison linéaire des signaux de sortie.
Exemple 2.5.5. Soit un système linéaire à une entrée u et une sortie y. Si y1 et y2 sont les réponses aux actions u1 et u2, la réponse à λu1 + μu2 sera λy1 + μy2.
Tout système qui ne respecte pas cette propriété est un système non linéaire.


16 Chapitre 2. Du système à la formalisation mathématique
2.5.4 Invariance dans le temps
Définition 2.5.7
Soit y(t) la réponse du système à l’action u(t). Le système est dit invariant dans le temps (ou stationnaire ou permanent ) si, quel que soit le décalage τ , y (t − τ ) est la réponse à l’action u (t − τ ).
Un système réel n’est quasiment jamais stationnaire : même les systèmes conçus par l’homme ne le sont pas à cause du vieillissement des composants qui modifie la relation entrée/sortie. On considère en pratique qu’un système est invariant dans le temps si cette modification est imperceptible dans la fenêtre d’observation du système.
Exemple 2.5.6. A l’échelle de la minute, un filtre LC est un système invariant contrairement à l’appareil de production de la parole qui est non stationnaire. Ce dernier peut être considéré comme stationnaire à l’échelle de la dizaine de millisecondes.
Une classe particulière de systèmes est représentée par les systèmes linéaires et invariants dans le temps.
2.5.5 Causalité
Définition 2.5.8
Un système est dit causal si sa réponse à un instant donné ne dépend que des valeurs de l’entrée aux instants précédents.
Autrement dit, si on considère un système au repos auquel on applique une action u(t) nulle pour t inférieur à t0, le système sera dit causal si la sortie y(t) est nulle pour t inférieur à t0. Bien que la plupart des systèmes réels soient causaux, il peut être intéressant dans certains cas (filtre numérique fonctionnant à temps différé par exemple) d’étudier des systèmes non causaux.
Exemple 2.5.7. Un retard pur est un système causal : y(t) = u(t − τ ). Le filtre numérique de la figure 2.9 est un système non causal puisque y(k) = u(k − 1) + u(k) + u(k + 1).
u(k + 1)
retard
u(k)
retard
u(k − 1)
y(k)
Figure 2.9 – Filtre numérique non causal
2.5.6 Évolution au cours du temps
Définition 2.5.9
Un système est dit statique si ses sorties ne dépendent que des valeurs présentes des entrées. Sinon il est dynamique.
Exemple 2.5.8 (Système dynamique). Système avec une sortie décrite par exemple par y(k) = f (u(k), u(k − 1)), où u(k) représente le signal d’entrée.
2.6 Modèles de signaux certains
Enfin, pour terminer ce chapitre d’introduction, on définit un certain nombre de signaux de base qui seront utilisés dans le cours : l’échelon, l’impulsion et le signal sinusoïdal. De manière générale, un signal à temps continu est une fonction du temps et un signal à temps discret est une suite infinie de réels.


2.6. Modèles de signaux certains 17
2.6.1 Echelon unité ou échelon de Heaviside
La figure 2.10 présente l’échelon unité ou échelon de Heaviside (noté 1 dans ce polycopié). Il s’agit d’une modélisation très simple de la mise en marche d’un dispositif.
1
t
1(t)
Cas continu
1
k
1(k)
Cas discret
Figure 2.10 – Echelon de Heaviside
2.6.2 Impulsion de Dirac
Formellement, la distribution de Dirac en 0 est la forme linéaire définie sur D(I), l’ensemble des fonctions à support compact de classe C∞ dans I ou ensemble des fonctions-test, par :
∀Φ ∈ D(I), Φ(0) =
∫ +∞
−∞
δ(t)Φ(t)dt (2.6.1)
L’impulsion de Dirac peut être vue comme la « dérivée », au sens des distributions, de l’échelon de Heaviside. Elle correspond physiquement à un phénomène infiniment bref et infiniment intense. C’est un signal théorique très utile pour caractériser des systèmes, bien qu’elle ne soit pas réalisable physiquement car la fonction qui lui serait associée (par exemple si la distribution était régulière) devrait vérifier des conditions du type :
δ(t) = 0 si t 6= 0 (2.6.2) δ(0) = +∞ (2.6.3)
et
∫ +∞
−∞
δ(t)dt = 1 (2.6.4)
ce qui n’est pas possible. Du fait de son utilité importante dans ce cours, on s’autorisera cependant la notation abusive de l’impulsion de Dirac sous forme d’une fonction. Dans le cas discret, l’impulsion discrète δ(k) est la suite nulle partout sauf au point k = 0 où elle vaut 1.
2.6.3 Signal sinusoïdal
Dans le cas continu, un signal sinusoïdal est défini par :
x(t) = A sin(2πf0t + φ) (2.6.5)
La fréquence du signal est f0, sa pulsation est ω0 = 2πf0, son amplitude est A et sa phase est φ. Dans le cas de signaux discrets, un signal sinusoïdal peut être défini par :
x(k) = A sin(2πν0k + φ) (2.6.6)
où ν0 est la fréquence du signal sinusoïdal. Il s’agit ici d’une grandeur sans dimension appartenant
à l’intervalle
[
−1
2, 1
2
]
. En effet, les signaux de fréquence ν0 + n, avec n entier, définissent la même
suite de nombres, avec ν0 appelée la fréquence réduite.




Première partie
Modélisation des systèmes à état
continu au sens d’un système
dynamique
19




Chapitre 3
Modélisation sous forme de
représentation d’état
3.1 Définition
Soit S un système à temps continu ayant pour entrée le signal vectoriel u(t).
Définition 3.1.1
Une représentation d’état du comportement dynamique de S est la donnée d’un vecteur x et d’une équation différentielle du type :
 ̇x(t) = f (x(t), u(t), t) (3.1.1)
avec u(t) ∈ Rm le vecteur d’entrée et x ∈ Rn le vecteur d’état formé par les variables d’état xi(t) qui représentent un ensemble de n variables indépendantes x1(t), x2(t), ..., xn(t) choisies telles que leur seule donnée à un instant t = t0 suffit à décrire, de façon exhaustive, l’état du système à l’instant t0.
C’est-à-dire que toute grandeur du système peut être déterminée, à l’instant t, à partir des xi (t0) et des ui (τ ), pour τ ∈ [t0, t]. Les équations (2.3.5) et (2.3.11) sont du type de l’équation (3.1.1) pour les exemples de satellite et de circuit électrique.
L’équation (3.1.1) est appelée équation dynamique (équation d’évolution ou première équation d’état ) du système. Il est possible de lui adjoindre une équation d’observation (ou équation de sortie) qui permet de définir les sorties du système :
y(t) = g (x(t), u(t), t) (3.1.2)
avec y(t) ∈ Rp le vecteur de sortie du système. Cette définition s’étend au cas des systèmes à temps discret par la donnée d’un vecteur x, d’une équation dynamique récurrente et d’une équation d’observation.
Définition 3.1.2
Un système à temps discret sous forme d’état est donné par :
x(k + 1) = f (x(k), u(k), k)
y(k) = g (x(k), u(k), k) (3.1.3)
Remarque 3.1.1. Pour un système donné, la représentation d’état n’est pas unique.
L’intérêt de disposer d’une telle représentation est qu’elle va en général permettre le calcul des réponses du système à des signaux d’entrée à partir d’un instant particulier si la valeur du vecteur
21


22 Chapitre 3. Modélisation sous forme de représentation d’état
d’état à cet instant est connue. Son intérêt est également qu’à partir de l’étude de f il est possible de donner des propriétés du système sans calculer les réponses à des signaux particuliers. Une première propriété qu’il est ainsi possible d’étudier est l’existence et l’unicité de la solution de l’équation (3.1.1) dans le cas continu 1 (problème de Cauchy). Il est ainsi possible de montrer que si la fonction f est continûment dérivable, c’est-à-dire si sa dérivée selon chacun de ses arguments existe et est continue, alors pour tout instant t0, tout état initial x0 et tout signal u(t) il existe un unique signal vectoriel x(t) défini sur un intervalle I contenant t0, solution de (3.1.1) et tel que x (t0) = x0. Ce résultat classique de la théorie des équations différentielles est un résultat local puisque l’unicité de la solution n’est garantie que pour un intervalle contenant t0. Cependant dans la pratique des systèmes étudiés dans ce cours, cet intervalle s’étendra sur l’ensemble des réels considéré comme la composante temporelle des différents signaux.
Définition 3.1.3
Un système invariant est un système dont la dynamique ne dépend pas du temps mais uniquement du vecteur d’état et de la commande.
Ainsi, un système non linéaire invariant dans le temps s’écrit sous la forme suivante :
— A temps continu :
x ̇ (t) = f (x(t), u(t))
y(t) = g (x(t), u(t)) (3.1.4)
— A temps discret :
x(k + 1) = f (x(k), u(k))
y(k) = g (x(k), u(k)) (3.1.5)
3.1.1 Équation d’état et équation de sortie
L’ensemble des valeurs xi (t0) résumant le passé du système, son évolution pour t > t0 est uniquement fonction de ces valeurs xi (t0) et des actions ui(t) (pour t > t0). Pour chaque variable d’état xi(t) il existe donc une fonction fi telle que :
dxi(t)
dt = fi (x1(t), x2(t), . . . , xn(t), u1(t), u2(t), . . . , um(t))
Si le système est linéaire 2, les fonctions fi ont une forme linéaire :
dxi(t)
dt =
∑n
k=1
aik(t)xk(t) +
m ∑
k=1
bik (t)uk (t)
On obtient alors la première équation d’état d’un système linéaire :
dx(t)
dt = A(t)x(t) + B(t)u(t) (3.1.8)
1. Les conditions d’existence de solutions à l’équation (3.1.3) sont simples à déterminer et sont liées au domaine de définition de f . 2. Un système est dit à dynamique linéaire si et seulement si :
∀x1, x2, u1, u2, t f (x1 + x2, u1 + u2, t) = f (x1, u1, t) + f (x2, u2, t)
∀x, u, λ ∈ R, t f (λx, λu, t) = λf (x, u, t) (3.1.6)
Il est dit à observation linéaire si et seulement si :
∀x1, x2, u1, u2, t g (x1 + x2, u1 + u2, t) = g (x1, u1, t) + g (x2, u2, t)
∀x, u, λ ∈ R, t g (λx, λu, t) = λg (x, u, t) (3.1.7)
Un système sous forme d’état est un système linéaire s’il respecte les propriétés (3.1.6) et (3.1.7).


3.1. Définition 23
où x(t) est le vecteur d’état x(t) =


x1(t) x2...(t)
xn(t)

 et u(t) est le vecteur source u(t) =


u1(t) u2...(t)
um(t)

.
A s’appelle la matrice d’évolution ; elle est de dimension n × n. B s’appelle la matrice d’entrée (ou de commande) ; elle est de dimension n × m. De même, les variables d’état suffisant à décrire l’état du système les sorties yj(t) s’expriment sous la forme :
yj(t) = hj (x1(t), x2(t), . . . , xn(t), u1(t), u2(t), . . . , um(t))
Si le système est linéaire, on obtient la deuxième équation d’état :
y(t) = C(t)x(t) + D(t)u(t) (3.1.9)
où y(t) est le vecteur de sortie y(t) =


y1(t) y2...(t)
yp(t)

.
C s’appelle la matrice d’observation ; elle est de dimension p × n. D s’appelle la matrice de transmission directe ; elle est de dimension p × m.
Si l’on récapitule, un système à temps continu, linéaire variant dans le temps, s’écrit sous la forme :
x ̇ (t) = A(t)x(t) + B(t)u(t)
y(t) = C(t)x(t) + D(t)u(t) (3.1.10)
Remarque 3.1.2. (i) Si le système est linéaire ET stationnaire (ou invariant dans le temps), les matrices A, B, C et D sont indépendantes du temps : A(t) = A, B(t) = B, C(t) = C, D(t) = D.
(ii) Pour un système donné, plusieurs vecteurs d’état sont possibles pour représenter le système. On passe d’un vecteur d’état à un autre par une matrice M inversible appelée matrice de transformation. Soit x(t) un vecteur d’état ; z(t) = M x(t) satisfait la nouvelle équation d’état :
dz(t)
dt = M AM −1z(t) + M Bu(t) = A′z(t) + B′u(t)
La représentation d’un système par variables d’état n’est donc pas unique. En toute rigueur on devrait parler d’une représentation d’état et non de la représentation d’état.
(iii) Dans certains ouvrages, la première équation d’état s’appelle l’équation d’état et la deuxième équation d’état porte le nom d’équation de sortie ou équation de mesure.
Ces propriétés sont données pour des systèmes continus, mais elles peuvent s’étendre sans difficulté au cas des systèmes à temps discret, linéaire et invariant dans le temps modélisés par les équations (3.1.3). Les équations d’état du système sont alors exprimées par les équations (3.1.11) :
x(k + 1) = A(k)x(k) + B(k)u(k)
y(k) = C(k)x(k) + D(k)u(k) (3.1.11)
Comme on le verra dans la suite de ce cours qui se concentre sur les systèmes linéaires invariants, ceux-ci possèdent un certain nombre de caractéristiques qui facilitent leur étude. En particulier la linéarité assure que les propriétés (stabilité, etc.) sont des propriétés structurelles du système qui ne dépendent donc pas d’une utilisation particulière de celui-ci.


24 Chapitre 3. Modélisation sous forme de représentation d’état
3.2 Stabilité d’un point d’équilibre ou d’une trajectoire d’équilibre
La stabilité d’un système correspond intuitivement au fait que le système ”ne va pas diverger et garder un comportement maîtrisable”. Considérons un système à temps continu dont le comportement est décrit par l’équation d’état 3 dynamique la plus générale (3.1.1) et tel que l’entrée u(t) soit fixée à une valeur quelconque u. Cette équation peut alors s’écrire :
x ̇ (t) = fu (x(t), t) (3.2.1)
Définition 3.2.1
Le point  ̄x de l’espace d’état est un point d’équilibre d’un système à temps continu si fu ( ̄x, t) = 0, ∀t.
Définition 3.2.2
Un point d’équilibre est stable au sens de Lyapunov si lorsque l’état du système est déplacé dans un voisinage de  ̄x il reste dans un voisinage du point d’équilibre, ce qui peut formellement s’énoncer par l’équation (3.2.2) où x (t0) est l’état à l’instant t0 et x(t) est la solution de (3.2.1) définie par ces conditions initiales :
∀ε > 0, ∃δ (ε, t0) tq ‖x ̄ − x (t0)‖ < δ (ε, t0) ⇒ ‖x(t) − x ̄‖ < ε, ∀t > t0 (3.2.2)
Définition 3.2.3
Le point d’équilibre est asymptotiquement stable s’il est stable et si l’état tend vers ce point d’équilibre lorsqu’il a été déplacé. Ceci revient à ajouter la condition (3.2.3) à la condition (3.2.2) :
tli→m∞ ‖x(t) − x ̄‖ = 0 (3.2.3)
Si le point d’équilibre est asymptotiquement stable il est parfois possible de caractériser la convergence de l’état vers ce point.
Définition 3.2.4
Le point d’équilibre sera dit exponentiellement stable s’il est possible de majorer l’évolution de la distance entre l’état et le point d’équilibre par une exponentielle décroissante.
Cette stabilité exponentielle demande l’existence de deux réels positifs M et α indépendants de t0 et de x (t0) tels que l’on ait :
‖x(t) − x ̄‖ ≤ M ‖x (t0) − x ̄‖ e−α(t−t0) (3.2.4)
Ces différentes définitions sont données ici dans le cas des systèmes continus et se transposent facilement au cas des systèmes discrets.
Définition 3.2.5
Un point d’équilibre (ou point fixe 4) d’un système à temps discret décrit par xk+1 = fu (xk, k) est un point qui satisfait x ̄ = fu (x ̄, k) ∀k.
Ces considérations sur la stabilité sont locales et ne préjugent pas du comportement du système sur l’ensemble de son domaine de fonctionnement. Elles correspondent d’autre part à une vue statique du système et il est parfois plus pertinent d’en considérer une vue dynamique. Par exemple si on s’intéresse au comportement d’une fusée en vol la notion de point d’équilibre n’est pas très utile. Il est alors plus intéressant d’introduire une notion de stabilité de trajectoire qui va caractériser la capacité du système à suivre cette trajectoire.
3. Pour cette partie l’équation d’observation n’est pas nécessaire. 4. Le terme de ’point fixe’ est utilisé principalement dans le cas des systèmes discrets mais peut également être utilisé pour un système continu.


3.2. Stabilité d’un point d’équilibre ou d’une trajectoire d’équilibre 25
Reprenons donc un système défini par l’équation d’état (3.1.1) et considérons que l’entrée du système est un signal vectoriel prédéfini u1(t). Le choix d’une valeur initiale 5 pour le vecteur d’état définit complètement la trajectoire suivie par la solution de (3.1.1). Notons Φx(t) cette trajectoire solution de (3.1.1) en réponse à l’entrée u1(t) définie par la valeur initiale x du vecteur d’état. Définition 3.2.6
La trajectoire Φx0 (t) définie par le point initial x0 est stable si et seulement si :
∀ε, ∃δ(ε) tq ‖x0 − x1‖ < δ(ε) ⇒ ‖Φx0(t) − Φx1(t)‖ < ε, ∀t (3.2.5)
Cette propriété peut s’illustrer par l’exemple en dimension 1 de la figure 3.1. La donnée du point initial x0 définit une trajectoire qui est stable si, lorsqu’on choisit un écart ǫ, il est possible de trouver un voisinage de x0 tel que les trajectoires définies par les points de ce voisinage soient toutes dans le ’tube’ généré par la trajectoire initiale et l’écart.
x0
t
x
δ(ε)
ε
Φx0 (t)
Φx1 (t)
Figure 3.1 – Stabilité d’une trajectoire
En considérant z(t) = Φx(t)−Φx0 (t) et en dérivant cette expression il est possible, étant donnée la définition des trajectoires Φx, d’écrire l’équation (3.2.6), et donc en réutilisant la définition de z(t), l’équation (3.2.7). Cette équation peut alors s’écrire sous la forme (3.2.8) où la fonction w dépend de x0 et de u1(t) :
z ̇ (t) = f (Φx(t), u1(t), t) − f (Φx0(t), u1(t), t) (3.2.6) z ̇ (t) = f (z(t) + Φx0 (t), u1(t), t) − f (Φx0(t), u1(t), t) (3.2.7)
z ̇ (t) = w (z(t), t) (3.2.8)
Il est aisé de vérifier que le point z = 0 est un point d’équilibre de ce nouveau système. Il est alors possible de voir que la condition (3.2.5) pour la trajectoire du système initial est équivalente à la condition (3.2.2) pour ce point d’équilibre du nouveau système dynamique. Il sera donc possible d’étudier la stabilité d’une trajectoire en se ramenant à l’étude de la stabilité d’un point d’équilibre. Une dernière notion de stabilité, utile en traitement du signal, est la notion de stabilité entrée bornée sortie bornée (EBSB) qui exprime le fait que la norme de la sortie du système est bornée pour tout signal d’entrée de norme bornée. Définition 3.2.7
Un système défini par :
 ̇x(t) = f (x(t), u(t), t)
y(t) = g (x(t), u(t), t)
5. Dans cette partie nous considérons, sans perte de généralité, que l’instant initial est l’instant t = 0.


26 Chapitre 3. Modélisation sous forme de représentation d’état
est stable entrée bornée sortie bornée (EBSB) par le fait que quel que soit le couple état-instant initial (x0, t0), la condition (3.2.9), où N est un nombre fini ne dépendant pas de t0, est vérifiée :
‖u(t)‖ < M < ∞, ∀t > t0 ⇒ ‖y(t)‖ < N (M, x0) (3.2.9)
Comme on pourra le voir par la suite ces différentes notions de stabilité peuvent parfois se rejoindre lorsqu’on s’intéresse à des classes particulières de systèmes mais dans le cas le plus général elles correspondent à des propriétés différentes.
3.3 Linéarisation autour d’un point d’équilibre
3.3.1 Théorème de superposition
Une propriété fondamentale issue de la linéarité du système est le théorème de superposition qui permet de considérer la réaction du système à un signal d’entrée comme la somme de réactions élémentaires. Considérons un système décrit par les équations (3.1.10) 6 dont l’état initial à l’instant t0 est considéré comme étant le vecteur nul (x (t0) = 0). Soient Φ1(t) la solution de l’équation dynamique définie par ces conditions initiales et le signal d’entrée u1(t) et Φ2(t) celle définie par ces mêmes conditions et le signal u2(t). Soit Φ(t) la solution de l’équation dynamique définie par ces conditions initiales et le signal d’entrée u(t) = u1(t) + u2(t). On a Φ(t) = Φ1(t) + Φ2(t) puisque la solution est unique et que Φ1(t) + Φ2(t) est une solution. Si on s’intéresse aux signaux de sortie, il est alors facile de voir que la sortie correspondant à u(t) = u1(t) + u2(t) est la somme de la sortie correspondant à u1(t) et de celle correspondant à u2(t). Par un raisonnement similaire, si nous considérons le même système mais que nous considérons maintenant que le signal d’entrée est toujours le vecteur nul il est aisé de vérifier que la réponse du système définie par la condition initiale x (t0) = x1 + x2 est la somme des réponses définies par x (t0) = x1 et x (t0) = x2.
Enfin si Φ1(t) est la solution définie par x (t0) = 0 et u(t) = u1(t) et Φ2(t) celle définie par x (t0) = x0 et u(t) = 0 il est possible de vérifier que Φ(t) = Φ1(t)+ Φ2(t) est la solution définie par x (t0) = x0 et u(t) = u1(t). La réponse du système à une condition initiale et un signal d’entrée est donc la somme de la réponse aux conditions initiales seules (entrée nulle) et de la réponse au signal d’entrée seul (condition initiale nulle). Une conséquence importante de ce théorème de superposition est la possibilité d’étudier les réactions des systèmes à plusieurs entrées comme la somme de systèmes à une entrée (figure 3.2). En effet tout signal vectoriel à k composantes peut être considéré, par décomposition dans une base de l’espace de dimension k, comme la somme de k signaux dont une seule composante est non nulle. Les réactions à ces signaux à une composante définissent alors autant de systèmes à une entrée.
Système
e3
e2
e1 s
Système 3
Système 2
Système 1
e1
e2
e3
s
Figure 3.2 – Système multi-entrées
6. Encore une fois le cas des systèmes discrets sera considéré par adaptation du cas continu.


3.3. Linéarisation autour d’un point d’équilibre 27
Dans la suite de ce cours les systèmes considérés seront en général des systèmes à une entrée puisque, pour les systèmes linéaires, les propriétés des systèmes à plusieurs entrées se déduisent facilement de celles des systèmes à une entrée définis par chacune des entrées.
3.3.2 Linéarisation
Lorsque le système ne respecte pas les contraintes (3.1.6) et (3.1.7), il n’est pas linéaire, son étude est alors plus compliquée et demande l’utilisation d’outils mathématiques plus complexes. Cependant si on n’a pas besoin d’étudier le système sur l’ensemble de l’espace d’état mais seulement au voisinage d’une position d’équilibre il est possible d’utiliser un modèle linéaire tangent au modèle non-linéaire en ce point d’équilibre. Par exemple si on considère un satellite géo-stationnaire on n’a pas besoin d’étudier le comportement du système, défini par l’équation (2.3.5), dans tout l’espace d’état mais seulement dans un voisinage du point d’équilibre
((
3
√ GM
ω ̄2 0 ω ̄
)T (0 0)T
)
qui définit sa trajectoire nominale à la vitesse orbitale ω ̄. Pour étudier les systèmes non linéaires on effectuera donc souvent une linéarisation autour d’un point d’équilibre en considérant le modèle linéaire tangent au point d’équilibre. L’idée de base est très simple à illustrer pour une fonction d’une variable (figure 3.3), la tangente à la courbe (x, f (x)) au point (x ̄, f (x ̄)) est alors la droite d’équation :
y − f (x ̄) = f ′ (x ̄) (x − x ̄)
x ̄
f (x ̄)
x
f (x)
Figure 3.3 – Linéarisé tangent
Pour une fonction réelle de plusieurs variables, c’est-à-dire de Rn dans R, ceci se généralise par la formule suivante (voir aussi la section de rappels de calcul différentiel F) :
y − f (x ̄1, x ̄2, . . . , x ̄n) = ∂f
∂x1
(x ̄1, x ̄2, . . . , x ̄n) · (x1 − x ̄1)
+ ∂f
∂x2
(x ̄1, x ̄2, . . . , x ̄n) · (x2 − x ̄2)
+ · · · + ∂f
∂xn
(x ̄1, x ̄2, . . . , x ̄n) · (xn − x ̄n) (3.3.1)
Si on s’intéresse à un système dynamique défini par les équations (3.1.1) et (3.1.2) au voisinage du point d’équilibre ( ̄x, u ̄), il est possible d’appliquer la formule (3.3.1) pour chacune des composantes du vecteur dérivé et du vecteur de sortie et on peut écrire, en faisant intervenir les matrices


28 Chapitre 3. Modélisation sous forme de représentation d’état
jacobiennes :
x ̇ (t) =


∂f1 ∂x1
(x ̄, u ̄, t) · · · ∂f1
∂xn
( ̄x, u ̄, t)
... . . . ... ∂fn ∂x1
(x ̄,  ̄u, t) · · · ∂fn
∂xn
( ̄x, u ̄, t)

 (x(t) − x ̄)
+


∂f1 ∂u1
(x ̄,  ̄u, t) · · · ∂f1
∂um
(x ̄,  ̄u, t)
... . . . ... ∂fn ∂u1
( ̄x, u ̄, t) · · · ∂fn
∂um
(x ̄,  ̄u, t)

 (u(t) −  ̄u)
(3.3.2)
y(t) − y ̄ =


∂g1 ∂x1
( ̄x,  ̄u, t) · · · ∂g1
∂xn
(x ̄, u ̄, t)
... . . . ... ∂gp ∂x1
( ̄x,  ̄u, t) · · · ∂gp
∂xn
(x ̄, u ̄, t)

 (x(t) − x ̄)
+


∂g1 ∂u1
( ̄x, u ̄, t) · · · ∂g1
∂um
(x ̄,  ̄u, t)
... . . . ... ∂gp ∂u1
( ̄x, u ̄, t) · · · ∂gp
∂um
(x ̄,  ̄u, t)

 (u(t) −  ̄u)
(3.3.3)
Si on introduit les nouvelles variables  ̃x(t) = x(t) −  ̄x, u ̃(t) = u(t) −  ̄u, y ̃(t) = y(t) − y ̄, on voit que ces équations s’écrivent :
 ̃x ̇ (t) = A(t) ̃x(t) + B(t) ̃u(t)
y ̃(t) = C(t) ̃x(t) + D(t) ̃u(t) (3.3.4)
Ces équations définissent bien un système linéaire tangent au système d’origine dans un voisinage du point d’équilibre. L’étude de ce système permettra la mise en évidence de propriétés locales du système d’origine. On a notamment le résultat suivant.
Remarque 3.3.1. Le point d’équilibre (x(t), u(t)) = (x ̄, u ̄) du système non linéaire est asymptotiquement (respectivement exponentiellement) stable si et seulement si le point d’équilibre (x ̃(t), u ̃(t)) = (0, 0) du système linéaire tangent en (x ̄,  ̄u) est asymptotiquement (respectivement exponentiellement) stable.
L’intérêt de ce résultat est qu’on dispose de méthodes simples et efficaces pour tester la stabilité dans le cas d’un système linéaire. Le cas des systèmes discrets se déduit facilement de cette étude en procédant de façon similaire, puisque les différenciations qui sont effectuées pour obtenir le modèle linéaire sont faites par rapport aux composantes des vecteurs d’état et d’entrée et non par rapport au temps.
Exemple 3.3.1 (Modèle de satellite (suite)). Reprenons l’exemple du satellite modélisé par l’équation (2.3.5) et intéressons nous à son comportement autour de la trajectoire définie par le point
d’équilibre vu précédemment
((α ̄ 0 ω ̄)T (0 0)T )
, en notant α ̄ = 3
√ GM
ω ̄2 :
x ̇ (t) =


x2(t)
x1(t)x3(t)2 − GM
x1(t)2 + 1
m u1(t)
− 2x2(t)x3(t)
x1(t) + 1
mx1(t) u2(t)

 (3.3.5)


3.4. Résolution des équations d’état d’un système linéaire 29
En utilisant les conventions précédentes le modèle tangent à ce point d’équilibre est alors le suivant :
x ̇ ̃(t) =


01 0
3ω ̄2 0 2α ̄ω ̄ 0 − 2ω ̄
α ̄ 0

  ̃x(t) +


00 1
m0
01
mα ̄

  ̃u(t) (3.3.6)
3.4 Résolution des équations d’état d’un système linéaire
On se propose de résoudre la première équation d’état, qui est une équation différentielle matricielle du premier ordre, en deux temps. On étudie tout d’abord l’équation sans second membre (régime libre) puis on cherche une solution particulière de l’équation avec second membre (régime forcé).
3.4.1 Régime libre
Il s’agit de résoudre :
dx(t)
dt = A(t)x(t)
avec la condition initiale x (t0) = x0. Cette équation étant linéaire ainsi que le système, et étant donnée la définition des variables d’état, la solution s’exprime linéairement en fonction de x0 sous la forme : x(t) = Φ (t, t0) x0 (3.4.1)
Φ (t, t0) s’appelle la matrice de transition du système ; elle est de dimension n × n. Cette matrice de transition possède les propriétés suivantes :
Φ(t, t) = I (3.4.2)
Φ (t2, t0) = Φ (t2, t1) Φ (t1, t0) (3.4.3)
Φ (t2, t1) = (Φ (t1, t2))−1 (3.4.4) dΦ
dt (t, t0) = A(t)Φ (t, t0) (3.4.5)
3.4.2 Régime forcé
Il s’agit de résoudre :
dx(t)
dt = A(t)x(t) + B(t)u(t) (3.4.6)
connaissant la solution générale de l’équation homogène établie ci-dessus. On cherche une solution particulière xp(t) avec, par exemple, la méthode de variation de la constante :
xp(t) = Φ (t, t0) x0(t) ⇒ dxp(t)
dt = dΦ
dt (t, t0) x0(t) + Φ (t, t0) dx0
dt (t)
= A(t)Φ (t, t0) x0(t) + Φ (t, t0) dx0
dt (t)
d’où en utilisant (3.4.6) et (3.4.5) :
Φ (t, t0) dx0
dt (t) = B(t)u(t) ⇔ dx0
dt (t) = (Φ (t, t0))−1 B(t)u(t)
Finalement :
x0(t) =
∫t
t0
(Φ (τ, t0))−1 B (τ ) u (τ ) dτ
et, compte tenu des propriétés de Φ on a :
xp(t) = Φ (t, t0) x0(t) = Φ (t, t0)
∫t
t0
(Φ (τ, t0))−1 B(τ )u(τ )dτ =
∫t
t0
Φ (t, τ ) B(τ )u(τ )dτ


30 Chapitre 3. Modélisation sous forme de représentation d’état
La solution de la première équation d’état est donc :
x(t) = Φ (t, t0) x (t0) +
∫t
t0
Φ (t, τ ) B(τ )u(τ )dτ (3.4.7)
La solution de la deuxième équation d’état est donc :
y(t) = C(t)
[
Φ (t, t0) x (t0) +
∫t
t0
Φ(t, τ )B(τ )u(τ )dτ
]
+ D(t)u(t) (3.4.8)
La difficulté de cette résolution réside dans le calcul de la matrice de transition Φ (t, τ ) qui fait appel à des techniques de résolution numérique sauf dans le cas où le système est linéaire ET invariant auquel cas cette matrice peut se calculer analytiquement. Nous allons voir plusieurs méthodes de calcul de Φ(t, τ ) dans ce cas.
3.4.3 Cas particulier des systèmes linéaires et invariants
Lorsque la matrice A est indépendante du temps, l’équation :
dΦ
dt (t, t0) = AΦ (t, t0)
se résout par analogie avec les cas scalaire en recherchant une solution sous la forme de la somme d’une série entière matricielle :
Φ (t, t0) = A0 + A1 (t − t0) + A2 (t − t0)2 + · · · + Ak (t − t0)k + · · ·
⇒ dΦ
dt (t, t0) = 0 + A1 + 2A2 (t − t0) + · · · + kAk (t − t0)k−1 + · · ·
Or :
dΦ
dt (t, t0) = AΦ (t, t0) = A
[
A0 + A1 (t − t0) + A2 (t − t0)2 + · · · + Ak (t − t0)k + · · ·
]
d’où en identifiant les deux développements on obtient :
A1 = AA0 ; A2 = 1
2 AA1 ; · · · ; Ak = 1
k AAk−1
La propriété Φ (t, t) = I nous donne A0 = I. On aboutit alors au développement suivant pour Φ (t, t0) :
Φ (t, t0) = I + A (t − t0) + 1
2! A2 (t − t0)2 + · · · + 1
k! Ak (t − t0)k + · · ·
Ce développement matriciel rappelle celui de l’exponentielle dans le cas scalaire ; pour cette raison on note de façon symbolique :
Φ (t, t0) = eA(t−t0)
La solution de la première équation d’état s’écrit alors :
x(t) = eA(t−t0)x (t0) +
∫t
t0
eA(t−τ)B(τ )u(τ )dτ (3.4.9)
3.4.4 Méthodes de calcul de l’exponentielle matricielle
3.4.4.1 Utilisation du développement en série
Cette méthode consiste à calculer directement le développement en série vu ci-dessus en calculant les différentes puissances de A. On ne l’utilise que si le calcul peut se faire simplement.


3.4. Résolution des équations d’état d’un système linéaire 31
Exemple 3.4.1.
A=
(0 1 00
)
⇒ A2 =
(0 0 00
)
= Ak pour k ≥ 2 ⇒ eA(t−t0) = I + A (t − t0) =
(1 t − t0 01
)
A=
(0 1 0 −a
)
⇒ A2 =
(0 −a 0 a2
)
⇒ . . . Ak =
(
0 (−a)k−1 0 (−a)k
)
⇒ eA(t−t0) =

1 1 − e−a(t−t0)
a
0 e−a(t−t0)


3.4.4.2 Méthode des modes
Cette méthode consiste à effectuer un changement de vecteur d’état (changement de base) de sorte que la nouvelle matrice d’évolution A′ soit diagonale ; en d’autres termes cette méthode consiste à diagonaliser la matrice A.
A′ =


λ1 0 · · · 0 0 λ2 · · · 0
... ... . . . ...
0 0 · · · λn

 ⇒ Φ (t, t0) = eA′(t−t0) =


eλ1(t−t0) 0 · · · 0
0 eλ2(t−t0) · · · 0
... ... . . . ...
0 0 · · · eλn(t−t0)


Exemple 3.4.2. A =
(0 1 0 −a
)
de valeurs propres λ1 = 0 et λ2 = −a d’où :
A′ =
(0 0 0 −a
)
⇒ eA′(t−t0) =
(1 0
0 e−a(t−t0)
)
On cherche maintenant à déterminer M . On a par exemple :
Ax1 = λ1x1 = 0 ⇒ x1 =
(1
0
)
et :
Ax2 = λ2x2 = −ax2 ⇒ x2 =
(1
−a
)
d’où :
M=
(1 1 0 −a
)
et M −1 =


11
a
0 −1
a


soit finalement :
eA(t−t0) =

1 1 − e−a(t−t0)
a
0 e−a(t−t0)


3.4.4.3 Formule de Sylvester
Cette méthode s’applique lorsque les valeurs propres de la matrice d’évolution A sont toutes distinctes. On a alors :
eA(t−t0) =
∑n
i=1
eλi (t−t0 )


∏n
j=1,j6=i
A − λjI λi − λj

 (3.4.10)


32 Chapitre 3. Modélisation sous forme de représentation d’état
Exemple 3.4.3. A =
(0 1 0 −a
)
de valeurs propres λ1 = 0 et λ2 = −a :
eA(t−t0) = A + aI
a + e−a(t−t0) A
−a = 1 − e−a(t−t0)
a A+I
d’où :
eA(t−t0) =

1 1 − e−a(t−t0)
a
0 e−a(t−t0)


3.4.4.4 Interpolation de Sylvester
On utilise cette méthode notamment lorsque les valeurs propres de A ne sont pas toutes distinctes. Le processus consiste à remplir un tableau de n lignes et n + 1 colonnes comme suit : — à chaque valeur propre simple correspond une ligne :
1 λ1 λ21 · · · λn−1
1 eλ1(t−t0)
— à chaque valeur propre double correspond deux lignes ; la première est identique à celle des valeurs propres simples, la deuxième est la dérivée de la première :
1 λ2 λ22 · · · λn−1
2 eλ2(t−t0)
0 1 2λ2 · · · (n − 1) λn−2
2 (t − t0) eλ2(t−t0)
— à chaque valeur propre triple correspond trois lignes ; la première est identique à celle des valeurs propres simples, la deuxième est la dérivée de la première et la troisième est la dérivée de la deuxième :
1 λ3 λ23 · · · λn−1
3 eλ3(t−t0)
0 1 2λ3 · · · (n − 1) λn−2
3 (t − t0) eλ3(t−t0)
0 0 2 · · · (n − 1) (n − 2) λn−3
3 (t − t0)2 eλ3(t−t0)
et ainsi de suite pour les valeurs propres d’ordre supérieur à 3. On complète alors le tableau par
une (n + 1)ième ligne égale à :
I A A2 · · · An−1 eA(t−t0)
La méthode de Sylvester consiste à calculer formellement le déterminant de la matrice obtenue ; on déduit alors la matrice de transition en écrivant que ce déterminant est nul.
Exemple 3.4.4. A =
(0 1 0 −a
)
de valeurs propres λ1 = 0 et λ2 = −a. Le tableau est ici égal à :
10 1
1 −a e−a(t−t0)
I A eA(t−t0)
Son déterminant ∆ développé par rapport à la dernière ligne est :
∆=I
∣∣∣∣ 0 1
−a e−a(t−t0)
∣∣∣∣ − A
∣∣∣∣1 1
1 e−a(t−t0)
∣∣∣∣ + eA(t−t0)
∣∣∣∣1 0
1 −a
∣∣∣∣
= aI − A
(
e−a(t−t0) − 1
)
− aeA(t−t0)
Ainsi :
∆ = 0 ⇒ eA(t−t0) = I − A e−a(t−t0) − 1
a=

1 1 − e−a(t−t0)
a
0 e−a(t−t0)




3.5. Stabilité asymptotique 33
3.4.4.5 Utilisation de la transformée de Laplace
Cette sous-section fait appel à la notion de transformée de Laplace qui sera expliquée dans le chapitre suivant.
La première équation d’état est une équation différentielle qui peut se résoudre en appliquant la transformée de Laplace. On se place ici dans le cas des systèmes invariants.
L
{ dx(t) dt
}
(p) = L {Ax(t) + Bu(t)} (p) ⇔ pX(p) − x (t0) e−pt0 = AX(p) + BU (p)
d’où :
X(p) = (pI − A)−1 (x (t0) e−pt0 + BU (p)) (3.4.11)
En identifiant cette équation avec l’équation temporelle :
x(t) = eA(t−t0)x (t0) +
∫t
t0
eA(t−τ )Bu(τ )dτ
on déduit que (pI − A)−1e−pt0 est la transformée de Laplace de eA(t−t0).
Exemple 3.4.5.
A=
(0 1 0 −a
)
⇒ pI − A =
(p −1 0 p+a
)
⇒ (pI − A)−1 e−pt0 =


e−pt0
p
e−pt0
p(p + a)
0 e−pt0
p+a


En utilisant les transformées usuelles, on en déduit :
eA(t−t0) =

1 1 − e−a(t−t0)
a
0 e−a(t−t0)


3.5 Stabilité asymptotique
Pour un système linéaire, toute trajectoire est stable si et seulement si le point d’équilibre x = 0 de x ̇ (t) = Ax(t) est stable. D’après le tableau de Sylvester, chaque terme de eAt est de la forme :
n ∑
k=1
pk(t)eλkt (3.5.1)
où pk(t) =
nk −1
∑
i=0
αiti est un polynôme de degré nk − 1, avec nk l’ordre de multiplicité de λk.
On en déduit les conditions pour :
1. la stabilité asymptotique : x(t) = eA(t−t0)x(t0) tend vers 0, ∀x(t0) si et seulement si ∀k,
eλkt → 0, ce qui est équivalent à ∀k, Re(λk) < 0
2. la stabilité au sens de Lyapunov : x(t) = eA(t−t0)x(t0) reste borné ∀x(t0) si ∀k, Re(λk) < 0 ou Re(λk) = 0 avec nk = 1. En effet, pour une multiplicité nk = 2 avec λk = jωk, le polynome pk(t)eλkt = (α0 + α1t)eλkt ne sera pas borné. On remarque aussi que s’il y a convergence asymptotique, elle est aussi exponentielle.
Remarque 3.5.1. En résumé, un système continu linéaire invariant dans le temps est :
1. stable asymptotiquement et exponentiellement si et seulement si les valeurs propres de la matrice d’évolution A ont toutes une partie réelle strictement négative ; 2. stable au sens de Lyapunov si la matrice d’évolution A a uniquement – des valeurs propres avec la partie réelle strictement négative ; – les valeurs propres à partie réelle nulle ont une multiplicité égale à 1 ; 3. instable dans les autres cas.
En pratique, cette condition pourra être testée entre autres en calculant le polynôme caractéristique det (λI − A) de la matrice A, puis en appliquant le critère de Routh (paragraphe 4.4.2.3.1).


34 Chapitre 3. Modélisation sous forme de représentation d’état
3.6 Analyse des systèmes discrets
3.6.1 Modélisation des systèmes linéaires discrets par variables d’état
Reprenons l’équation donnant l’évolution de l’état d’un système continu entre deux instants t0 et t :
x(t) = Φ (t, t0) x (t0) +
∫t
t0
Φ (t, τ ) B(τ )u(τ )dτ
et appliquons cette équation entre deux instants tk et tk+1 en supposant l’entrée u(t) constante (égale à u (tk)) entre ces deux instants. L’évolution du système entre tk et tk+1 s’exprime alors par :
x (tk+1) = Φ (tk+1, tk) x (tk) +
(∫ tk+1
tk
Φ (tk+1, τ ) B(τ )dτ
)
u(tk )
En posant :
F (k) = Φ (tk+1, tk) et G(k) =
∫ tk+1
tk
Φ (tk+1, τ ) B(τ )dτ
on obtient :
x (tk+1) = F (k)x (tk) + G(k)u (tk)
Si le système est permanent et que les instants tk sont multiples d’une période d’échantillonnage T , on obtient :
F (k) = Φ(tk+1, tk) = eA(tk+1−tk) = eAT (3.6.1)
G(k) =
∫ tk+1
tk
Φ (tk+1, τ ) B(τ )dτ =
∫T
0
eA(T −θ)Bdθ =
∫T
0
eAuBdu
G(k) = A−1 (eAT − I) B si A est inversible
(3.6.2)
F (k) = F et G(k) = G sont alors deux matrices constantes et les équations d’état du système
sont : { x(k + 1) = F x(k) + Gu(k)
y(k) = Cx(k) + Du(k) (3.6.3)
Remarque : Comme dans le cas scalaire, si T est ”petit”, on peut faire l’approximation :
eAT ≈ I + AT
On obtient alors comme première équation d’état :
x(k + 1) ≈ (I + AT ) x(k) + BT u(k)
c’est-à-dire : x(k + 1) − x(k)
T ≈ Ax(k) + Bu(k)
ce qui revient à dire que l’on a fait l’approximation classique (d’autant plus justifiée que T est petit) suivante : ( dx
dt
)
t=kT
≈ x(k + 1) − x(k)
T
3.6.2 Résolution des équations d’état
La résolution de la première équation dans le domaine temporel se fait en procédant par récurrence :
x(n + 1) = F n+1x(0) +
∑n
k=0
F n−kGu(k) (3.6.4)


3.6. Analyse des systèmes discrets 35
Il est en général plus intéressant d’utiliser la transformée en z (qui sera détaillée dans le chapitre suivant) pour résoudre la première équation d’état afin d’éviter les multiplications de matrices :
Z {x(k + 1)} (z) = Z {F x(k) + Gu(k)} (z) ⇔ zX(z) = F X(z) + GU (z)
d’où :
X(z) = (zI − F )−1 GU (z) (3.6.5)
Il suffit ensuite de revenir dans l’espace des temps pour obtenir x(n) afin d’avoir accès à y(n) par la deuxième équation d’état.
Remarque 3.6.1. Le calcul de (zI − F )−1 peut se faire en utilisant l’algorithme de LeverrierSouriau.
3.6.3 Stabilité asymptotique
En considérant la relation (3.6.4) pour une entrée u(k) nulle, on établit facilement que x(n) tend vers 0 pour toute condition initiale x(0) si et seulement si toutes les valeurs propres λi de F vérifient |λi| < 1.
Remarque 3.6.2. En résumé, un système discret linéaire invariant dans le temps est :
1. stable asymptotiquement et exponentiellement si et seulement si les valeurs propres de la matrice d’évolution F ont toutes un module strictement inférieur à 1 ;
2. stable au sens de Lyapunov si la matrice d’évolution F a uniquement – des valeurs propres de module strictement inférieur à 1 ; – les valeurs propres de module 1 ont une multiplicité égale à 1 ;
3. instable dans les autres cas.
Cette considération peut être testée en appliquant le critère de Jury (paragraphe 4.4.2.3.2) au polynôme caractéristique de F .




Chapitre 4
Modélisation sous forme de fonction
de transfert
4.1 Introduction
Ce chapitre présente les méthodes qui peuvent être mises en œuvre dans le cas de l’analyse de systèmes linéaires invariants dans le temps (stationnaires). Nous allons voir comment mobiliser les outils mathématiques (que nous introduirons) que sont la transformée de Laplace (pour les systèmes à temps continu) et la transformée en z (pour les systèmes à temps discret) pour analyser un système linéaire et stationnaire à partir d’une représentation externe de type entrée/sortie. Des approches permettant le passage entre les deux représentations externe (fonction de transfert) et interne (représentation d’état) sont également proposées. Une partie des méthodes que nous allons présenter dans ce cours s’appuient sur deux notions mathématiques importantes : — la transformée de Laplace, qui sera utile pour les systèmes à temps continus ; — la transformée en z, utile pour les systèmes à temps discrets.
Ces deux opérateurs héritent de formalismes et propriétés définis pour la transformée de Fourier et sa version discrète, que l’on commencera donc par introduire.
4.2 Notions préliminaires : transformation de Fourier, de Laplace, en z
4.2.1 Notions de base sur la transformation de Fourier
La transformation de Fourier est un outil incontournable pour caractériser un signal en faisant le lien entre le domaine temporel et domaine fréquentiel. En vue de son utilisation dans ce cours, nous en introduisons ici la définition sur l’espace L1(R) des fonctions sommables et quelques unes de ses propriétés, qui seront explicitées dans le cours de Convergence, intégration, probabilités, équations aux dérivées partielles et étendues à d’autres espaces fonctionnels, ce qui permettra de traiter des classes plus larges de signaux.
Définition 4.2.1
Dans ce cours, nous définissons la transformée de Fourier d’une fonction sommable 1par :
X(f ) = F {x(t)}(f ) =
∫ +∞
−∞
x(t)e−2πjftdt (4.2.1)
1. x(t) absolument sommable vérifie
∫ +∞
−∞
|x(t)| dt < +∞.
37


38 Chapitre 4. Modélisation sous forme de fonction de transfert
La transformation de Fourier associe à une fonction x de la variable temporelle t une fonction X d’une variable pouvant s’interpréter comme une variable fréquentielle f . La transformée de Fourier d’une fonction sommable sur R est continue et bornée sur R et tend vers 0 en ±∞ (théorème de Riemann-Lebesgue). Si x est la valeur réelle, le module de la transformée de Fourier est une fonction paire et sa phase est une fonction impaire. La connaissance de X(f ) dans le domaine positif est donc suffisante dans le cas où x(t) est à valeurs réelles. Le tableau 4.1 contient la transformée de Fourier des signaux usuels. On note que ce tableau inclut la transformée de Fourier de l’impulsion de Dirac, δ, qui repose sur la définition de la transformation de Fourier sur l’espace des distributions (voir cours de Convergence, intégration, probabilités, équations aux dérivées partielles).
x(t) X(f )
1 δ0(f )
e2πjf0t δf0 (f )
δ0(t) 1
δf0 (t) e−2πjf0t
sin(2πf0t) 1
2j δf0 (f ) − 1
2j δ−f0 (f )
cos(2πf0t) 1
2 δf0 (f ) + 1
2 δ−f0 (f )
x(t) = 1 si t ∈ [0, T ]
x(t) = 0 sinon T e−πjfT sin(πf T )
πf T
Tableau 4.1 – Transformées de Fourier des fonctions usuelles (cas continu)
Définition 4.2.2
Dans le cas discret, la transformée de Fourier discrète d’un signal x(k) est définie de façon similaire :
X(ν) = F {x(k)}(ν) =
k=+∞
∑
k=−∞
x(k)e−2πjνk (4.2.2)
La transformée de Fourier discrète est définie pour tout signal x(k) absolument sommable, i.e. :
k=+∞
∑
k=−∞
|x(k)| < +∞ (4.2.3)
De plus, la transformée de Fourier discrète X(ν), lorsqu’elle est définie, est une fonction pé
riodique de période 1. La connaissance de X(ν) sur l’intervalle
[
0, 1
2
]
est donc suffisante pour les
signaux à valeur réelle. Le tableau 4.2 contient la transformée de Fourier des signaux usuels dans le cas discret, où δ est l’impulsion discrète. On peut noter que la transformée de Fourier n’est pas définie pour des signaux laissant apparaître des divergences exponentielles (de la forme tkeat avec a > 0) qui apparaissent couramment dans les systèmes réels étudiés. Pour cette raison, les transformées de Laplace (pour les signaux à temps continu) et en z (pour les signaux à temps discret) ont été introduites afin de pouvoir étudier ces phénomènes d’instabilité, caractérisés par des signaux à divergence exponentielle, dans les systèmes linéaires.


4.2. Notions préliminaires : transformation de Fourier, de Laplace, en z 39
x(k) X(ν)
1 δ0(ν)
e2πjak δa(ν)
ak, k ≥ 0, |a| < 1 1
1 − ae−2πjν
δ(k − a) e−2πjνa
sin(2πν0k) 1
2j δν0 (ν) − 1
2j δ−ν0 (ν)
cos(2πν0k) 1
2 δν0 (ν) + 1
2 δ−ν0 (ν)
x(k) = 1 si k ∈ [0, N − 1]
x(k) = 0 sinon e−πjν(N−1) sin(πνN )
sin(πν)
Tableau 4.2 – Transformées de Fourier des fonctions usuelles (cas discret)
4.2.2 Transformation de Laplace
La transformée de Laplace permet l’étude des phénomènes d’instabilité dans le cas des signaux à temps continu. L’idée est d’ajouter à l’argument imaginaire pur j2πf une partie réelle notée σ que l’on choisira de façon à faire converger l’intégrale suivante appelée transformée de Laplace bilatérale du signal x(t) :
X(p) = L {x(t)} (p) =
∫ +∞
−∞
x(t)e−ptdt en posant p = σ + j2πf (4.2.4)
X(p) est une fonction de la variable complexe p.
Remarque : Dans la littérature anglo-saxone, p est noté s.
4.2.2.1 Existence de la transformée de Laplace
Soit X(p) la transformée de Laplace du signal x(t). Alors :
|X(p)| =
∣∣∣∣
∫ +∞
−∞
x(t)e−ptdt
∣∣∣∣ ≤
∫ +∞
−∞
|x(t)| e−σtdt
Donc la transformée de Laplace existe si
∫ +∞
−∞
|x(t)| e−σtdt existe.
On va montrer que X(p) existe si x(t) est localement sommable et a une croissance dite ”au plus exponentielle”. Supposons que :
{ ∃ (A > 0, α, t1 ≥ 0) tel que |x(t)| ≤ Aeαt, ∀t ≥ t1 ∃ (B > 0, β, t2 ≤ 0) tel que |x(t)| ≤ Beβt, ∀t ≤ t2
Alors :
|X(p)| ≤
∫ +∞
−∞
|x(t)| e−σtdt =
∫ t2
−∞
|x(t)| e−σtdt +
∫ t1
t2
|x(t)| e−σtdt +
∫ +∞
t1
|x(t)| e−σtdt
donc :
|X(p)| ≤ B
∫ t2
−∞
e(β−σ)tdt +
∫ t1
t2
|x(t)| e−σtdt + A
∫ +∞
t1
e(α−σ)t dt


40 Chapitre 4. Modélisation sous forme de fonction de transfert
Or : 

∫ t2
−∞
e(β−σ)tdt existe si σ < β
∫ t1
t2
|x(t)| e−σtdt existe puisqu’on a supposé x(t) localement sommable
∫ +∞
t1
e(α−σ)tdt existe si σ > α
La transformée de Laplace existe donc pour α < Re (p) < β. Soit σ1 et σ2 la plus petite (respectivement la plus grande) des valeurs possibles de α (respectivement β) ; on appelle domaine de convergence (ou bande de convergence) de X(p) l’intervalle ]σ1, σ2[.
Exemple 4.2.1. Soit le signal x(t) =
{ eat si t ≥ 0, a > 0
0 si t < 0 . Sa transformée de Laplace est :
X(p) =
∫ +∞
0
eate−ptdt =
[ e(a−p)t
a−p
]+∞
0
=1
p − a si Re(p) = σ > a
Son domaine de convergence est ]a, +∞[.
4.2.2.2 Propriétés de la transformée de Laplace
Etant donné la ressemblance entre l’expression de la transformée de Laplace (X(p)) et celle de la transformée de Fourier (F {x(t)}), les propriétés de X(p) sont analogues à celles de F {x(t)}.
4.2.2.2.1 Linéarité L’intégrale étant une fonction linéaire, on vérifie aisément que L{λx(t) + μy(t)}(p) = λL{x(t)}(p) + μL{y(t)}(p). Le domaine de convergence de L{λx(t) + μy(t)}(p) est l’intersection des domaines de convergence de L{x(t)}(p) et de L{y(t)}(p).
4.2.2.2.2 Décalage temporel, décalage en p Soient x(t) et y(t) = x(t − τ ) :
Y (p) =
∫ +∞
−∞
y(t)e−ptdt =
∫ +∞
−∞
x(t − τ )e−ptdt =
∫ +∞
−∞
x(u)e−p(u+τ )du
Y (p) = e−pτ
∫ +∞
−∞
x(u)e−pudu = e−pτ X(p)
y(t) = x(t − τ ) ⇔ Y (p) = e−pτ X(p) (4.2.5)
Un décalage temporel de x(t) se traduit par une multiplication de X(p) par une exponentielle complexe.
L{x(t)}(p) =
∫ +∞
−∞
x(t)e−ptdt = X(p)
L{x(t)e−at}(p) =
∫ +∞
−∞
x(t)e−ate−ptdt =
∫ +∞
−∞
x(t)e−(p+a)tdt = X(p + a)
L{x(t)e−at}(p) = X(p + a) (4.2.6)
Un décalage de X(p) se traduit par une multiplication de x(t) par une exponentielle complexe.


4.2. Notions préliminaires : transformation de Fourier, de Laplace, en z 41
4.2.2.2.3 Transformée d’un produit de convolution Soient deux signaux x(t) et y(t). Leur produit de convolution est donné par :
L{(x ∗ y) (t)}(p) =
∫ +∞
−∞
(∫ +∞
−∞
x(u)y(t − u)du
)
e−ptdt =
∫ +∞
−∞
∫ +∞
−∞
x(u)y(t − u)e−ptdtdu
L{(x ∗ y) (t)}(p) =
∫ +∞
−∞
x(u)e−pudu } {{ }
X (p)
∫ +∞
−∞
y(t − u)e−p(t−u)dt } {{ }
Y (p)
L{(x ∗ y) (t)}(p) = X(p)Y (p) (4.2.7)
La transformée de Laplace transforme un produit de convolution en un produit. Les deux transformées X(p) et Y (p) devant exister, le domaine de convergence de L{(x ∗ y) (t)}(p) est l’intersection des domaines de convergence de L{x(t)}(p) et de L{y(t)}(p).
4.2.2.2.4 Intégration, dérivation Soit un signal x(t) continu et X(p) sa transformée de Laplace.
L
{ dx dt
}
(p) =
∫ +∞
−∞
dx
dt e−ptdt = [x(t)e−pt]+∞
−∞ + p
∫ +∞
−∞
x(t)e−ptdt = [x(t)e−pt]+∞
−∞ + pX(p)
x(t) étant à croissance au plus exponentielle, on a :
{ ∣∣x(t)e−pt∣∣ ≤ exp ((σ1 − Re(p)) t) quand t → +∞
∣∣x(t)e−pt∣∣ ≤ exp ((σ2 − Re(p)) t) quand t → −∞
d’où :
L
{ dx dt
}
(p) = pX(p) ; σ1 < Re(p) < σ2
Remarque 4.2.1. Le domaine de convergence de L
{ dx dt
}
(p) est égal à celui de L {x(t)} (p).
Remarque 4.2.2. L’expression trouvée ci-dessus conduit à considérer la variable p au sens d’un calcul symbolique comme un opérateur de dérivation. La transformée de Laplace devient alors un outil puissant pour résoudre certaines équations différentielles.
x(t) d
dt y(t) = dx
dt
X(p) p Y (p) = pX(p)
Si x(t) présente une discontinuité de première espèce en t = t0, en scindant l’intégrale en deux parties on trouve :
L
{ dx dt
}
(p) = pX(p) + (x (t0−
) − x (t0+
)) e−t0p ; σ1 < Re(p) < σ2
Par exemple, si x(t) est un signal causal :
L
{ dx
dt u(t)
}
(p) = pX(p) − x (0+) ; σ1 < Re(p) < σ2 (4.2.8)
Remarque 4.2.3. De même, on démontre :
L
{∫ t
0
x(u)du
}
(p) = 1
p X(p) (4.2.9)


42 Chapitre 4. Modélisation sous forme de fonction de transfert
4.2.2.2.5 Multiplication par la variable d’évolution Dans les domaines où elle est définie, la convergence de la transformée de Laplace est absolue ; on peut donc écrire :
dX (p)
dp = d
dp
(∫ +∞
−∞
x(t)e−ptdt
) =
∫ +∞
−∞
d dp
(x(t)e−pt) dt
=
∫ +∞
−∞
−tx(t)e−ptdt pour σ1 < Re(p) < σ2
soit :
L{tx(t)}(p) = − dX(p)
dp ; σ1 < Re(p) < σ2
En réitérant ce processus, on obtient, de façon générale :
L{tnx(t)}(p) = (−1)n dnX(p)
dpn ; σ1 < Re(p) < σ2 (4.2.10)
4.2.2.2.6 Valeur initiale, valeur finale Soit x(t) un signal causal de transformée X(p). Lorsque les deux limites suivantes existent, on a les relations :


tl→i 0m+ x(t) = lim
Re(p)→+∞ pX(p) théorème de la valeur initiale
lim
t→+∞ x(t) = pli→m0 pX(p) théorème de la valeur finale (4.2.11)
4.2.2.3 Transformée de Laplace inverse
Le calcul de la transformée de Laplace inverse est donné par l’expression suivante (formule de Bromwitch-Wagner) :
x(t) = L−1{X(p)}(t) = 1
2πj VP
(∫ σ0+j∞
σ0 −j∞
X (p)ept dp
)
(4.2.12)
où j = √−1, σ1 < σ0 < σ2 et VP représente la valeur principale de Cauchy. Le calcul de cette intégrale de la variable complexe fait appel au théorème des résidus, théorème important du domaine de l’analyse fonctionnelle complexe mais qui sort du cadre de ce cours. En conséquence, dans ce cours, on se ramènera systématiquement à des formes de fonctions connues telles que présentées dans le paragraphe 4.2.2.4 suivant.
4.2.2.4 Transformées usuelles
Le tableau 4.3 donne la transformée de Laplace des principales fonctions causales (pour lesquelles on a donc σ2 = +∞) rencontrées en traitement du signal. Le calcul de X(p) en fonction de x(t) s’obtient facilement en utilisant les propriétés données en 4.2.2.2. Ce tableau sera en revanche très pratique pour trouver x(t) connaissant X(p) sans utiliser la transformée de Laplace inverse vue en 4.2.2.3. Dans le tableau 4.3, δ0(t) représente l’impulsion de Dirac et 1(t) représente la fonction échelon de Heaviside.
Exemple 4.2.2 (Résolution d’une équation différentielle). On recherche les signaux x(t) causaux vérifiant l’équation différentielle suivante :
d2x
dt2 + dx
dt + x = 0
avec les conditions limites x(t = 0) = x(0) et dx
dt (t = 0) = x′(0).


4.2. Notions préliminaires : transformation de Fourier, de Laplace, en z 43
x(t) X(p) σ1
δ0(t) 1 −∞
δ(n)
0 (t) pn −∞
1(t) 1
p0
1(t)e−at 1
p + a −a
1(t)tne−at n!
(p + a)n+1 −a
1(t) sin (ωt) e−at ω
(p + a)2 + ω2 −a
1(t) cos (ωt) e−at p + a
(p + a)2 + ω2 −a
xm(t) ∗
+∑∞
k=0
δ(t − kT ) Xm(p)
1 − e−T p σm1
(signal périodique de motif période xm(t))
Tableau 4.3 – Transformées de Laplace des fonctions usuelles
En appliquant la transformée de Laplace à cette équation, on obtient :
(p2 + p + 1) X(p) = (1 + p)x(0) + x′(0)
⇔ X(p) = p + 1
p2 + p + 1 x(0) + 1
p2 + p + 1 x′(0)
soit :
X(p) =


1 2
√23
√3
2
(
p+ 1
2
)2
+
( √3
2
)2 +
p+ 1
2
(
p+ 1
2
)2
+
( √3
2
)2


x(0)
+ √23
√3
2
(
p+ 1
2
)2
+
( √3
2
)2 x′(0)
D’où, en utilisant les transformées usuelles :
x(t) = e− 1
2t
(
√23
(1
2 x(0) + x′(0)
)
sin
( √3
2t
)
+ cos
( √3
2t
)
x(0)
)
u(t)
4.2.3 Transformation en z
La transformée en z permet l’étude des phénomènes d’instabilité dans le cas des signaux à temps discret. Définie à partir de la transformée de Fourier discrète, l’idée est d’ajouter à l’argument imaginaire pur j2πν une partie réelle notée σ que l’on choisira de façon à faire converger la somme suivante appelée transformée en z du signal x(k) :
X(z) = Z {x(k)} (z) =
+∑∞
k=−∞
x(k)z−k en posant z = eσ+j2πν (4.2.13)
X(z) est une fonction de la variable complexe z.


44 Chapitre 4. Modélisation sous forme de fonction de transfert
4.2.3.1 Existence de la transformée en z
Soit X(z) la transformée en z du signal x(k). Alors :
|X(z)| =
∣∣∣∣∣
+∑∞
k=−∞
x(k)z−k
∣∣∣∣∣ ≤
+∑∞
k=−∞
|x(k)| ρ−k en posant z = ρejθ
Donc la transformée en z existe si
+∑∞
k=−∞
|x(k)| ρ−k existe.
On va montrer que X(z) existe si x(k) a une croissance dite ”au plus exponentielle”. Supposons
que : { ∃ (A > 0, α ≥ 0, k1 ≥ 0) tel que |x(k)| ≤ Aαk, ∀k ≥ k1 ≥ 0 ∃ (B > 0, β ≥ 0, k2 ≤ 0) tel que |x(k)| ≤ Bβk, ∀k ≤ k2 ≤ 0
Alors :
|X(z)| ≤
+∑∞
k=−∞
|x(k)| ρ−k =
k ∑2
k=−∞
|x(k)| ρ−k +
k1 −1
∑
k=k2 +1
|x(k)| ρ−k +
+∑∞
k=k1
|x(k)| ρ−k
donc :
|X(z)| ≤ B
k ∑2
k=−∞
(β
ρ
)k
+
k1 −1
∑
k=k2 +1
|x(k)| ρ−k + A
+∑∞
k=k1
(α
ρ
)k
Or : 

k ∑2
k=−∞
(β
ρ
)k
existe si ρ < β
+∑∞
k=k1
(α
ρ
)k
existe si ρ > α
La transformée en z existe donc pour α < |z| < β. Soit R1 et R2 la plus petite (respectivement la plus grande) des valeurs possibles de α (respectivement β) ; on appelle domaine de convergence ou couronne de convergence de X(z) la surface comprise entre les cercles de rayon R1 et R2.
Exemple 4.2.3. Soit le signal x(k) =
{ ak si k ≥ 0, a > 0
0 si k < 0 . Sa transformée en z est :
X(z) =
+∑∞
k=−∞
akz−k =
+∑∞
k=0
(az−1)k =
[1
1 − az−1
]+∞
0
si ∣∣az−1∣∣ < 1 ⇔ |z| > a
Sa couronne de convergence est l’extérieur du disque de rayon a.
4.2.3.2 Propriétés de la transformée en z
Etant donné la ressemblance entre l’expression de la transformée de Laplace (X(p)) et celle de la transformée en z, les propriétés de X(z) sont analogues à celles de X(p).
4.2.3.2.1 Linéarité L’opérateur somme étant une fonction linéaire, on vérifie que :
Z {λx(k) + μy(k)} (z) = λZ{x(k)}(z) + μZ{y(k)}(z).
Le domaine de convergence de Z{λx(k) + μy(k)}(z) est l’intersection des domaines de convergence de Z{x(k)}(z) et de Z{y(k)}(z).


4.2. Notions préliminaires : transformation de Fourier, de Laplace, en z 45
4.2.3.2.2 Décalage temporel Soient x(k) et y(k) = x(k − k0). Alors :
Y (z) =
+∑∞
k=−∞
y(k)z−k =
+∑∞
k=−∞
x(k − k0)z−k =
+∑∞
k=−∞
x(k )z −(k+k0 )
y(k) = x(k − k0) ⇔ Y (z) = z−k0X(z) (4.2.14)
Un décalage temporel de x(k) de k0 échantillons se traduit par une multiplication de X(z) par
z−k0. Cette propriété conduit à considérer la variable z−1 au sens du calcul symbolique comme un opérateur retard de 1 échantillon.
x(k) retard d’un
échantillon y(k) = x(k − 1)
X (z )
z−1 Y (z) = z−1X(z)
4.2.3.2.3 Multiplication par une exponentielle Soit y(k) = akx(k) :
Y (z) =
+∑∞
k=−∞
akx(k)z−k =
+∑∞
k=−∞
x(k)
(z
a
)−k
=X
(z
a
)
; |a| R1 < |z| < |a| R2
Z {akx(k)} (z) = X
(z
a
) (4.2.15)
4.2.3.2.4 Transformée d’un produit de convolution Soient deux signaux x(k) et y(k). Le produit de convolution de deux signaux discrets est donné par :
Z {(x ∗ y) (k)} (z) =
+∑∞
k=−∞
[ +∑∞
l=−∞
x(k − l)y(l)
]
z−k =
+∑∞
k=−∞
+∑∞
l=−∞
x(k − l)y(l)z−(k−l)z−l
Z {(x ∗ y) (k)} (z) =
+∑∞
l=−∞
y(l)z−l
} {{ }
Y (z)
+∑∞
u=−∞
x(u)z−u
} {{ }
X (z)
Z {(x ∗ y) (k)} (z) = X(z)Y (z) (4.2.16)
La transformée en z transforme un produit de convolution en un produit. Les deux transformées X(z) et Y (z) devant exister, le domaine de convergence de Z {(x ∗ y) (k)} (z) est l’intersection des domaines de convergence de Z{x(k)}(z) et de Z{y(k)}(z).
4.2.3.2.5 Multiplication par la variable d’évolution Dans les domaines où elle est définie, la convergence de la transformée en z est absolue ; on peut donc écrire :
dX (z )
dz = d
dz
( +∑∞
k=−∞
x(k)z−k
)
=
+∑∞
k=−∞
d dz
(x(k)z −k )
=−
+∑∞
k=−∞
kx(k)z−k−1 pour R1 < |z| < R2
soit :
Z{kx(k)}(z) = −z dX(z)
dz ; R1 < |z| < R2


46 Chapitre 4. Modélisation sous forme de fonction de transfert
En réitérant ce processus, on obtient de façon générale :
Z {knx(k)} (z) =
(
−z d
dz
)n
X(z) ; R1 < |z| < R2 (4.2.17)
où
(
−z d
dz
)n
signifie que l’on applique n fois à X(z) l’opérateur −z d
dz .
4.2.3.2.6 Valeur initiale, valeur finale Soit x(k) un signal causal de transformée X(z). Lorsque les deux limites suivantes existent, on a les relations :


x(0) = lim
|z|→+∞ X(z) théorème de la valeur initiale
lim
n→+∞ x(k) = zli→m1
(1 − z−1) X(z) théorème de la valeur finale (4.2.18)
4.2.3.3 Transformée en z inverse
Le calcul de la transformée en z inverse est donné par l’expression suivante :
x(k) = Z−1 {X(z)} (k) = 1
2πj
∮
Γ
X(z)zk−1dz (4.2.19)
où Γ est un cercle centré sur l’origine et appartenant à la couronne de convergence de X(z). Comme pour la transformée de Laplace inverse, le calcul de cette intégrale de la variable complexe sort du cadre de ce cours et on se ramènera aux formes des transformées en z de signaux usuels telles que listées dans le paragraphe 4.2.3.4 suivant.
4.2.3.4 Transformées en z usuelles
De même que pour la transformée de Laplace, le tableau 4.4 donne la transformée en z pour des signaux discrets usuels causaux (pour lesquels on a donc R2 = ∞). Il sera très pratique pour trouver x(k) connaissant X(z) sans utiliser la transformée en z inverse vue en 4.2.3.3. Dans le tableau 4.4, δ0(k) représente l’impulsion discrète et 1(k) représente la fonction échelon de Heaviside.
x(k) X(z) R1
δ0(k) 1 0
1(k) 1
1 − z−1 1
k1(k) z−1
(1 − z−1)2 1
ak1(k) 1
1 − az−1 |a|
ak cos (k2πν) 1(k) 1 − z−1a cos(2πν)
1 − 2z−1a cos(2πν) + a2z−2 |a|
ak sin (k2πν) 1(k) z−1a sin(2πν)
1 − 2z−1a cos(2πν) + a2z−2 |a|
Tableau 4.4 – Transformées en z des fonctions usuelles
4.3 Représentation temporelle des systèmes
4.3.1 Réponses impulsionnelle et indicielle des systèmes linéaires invariants à temps discret


4.3. Représentation temporelle des systèmes 47
Définition 4.3.1
La réponse impulsionnelle d’un système discret est la sortie y(k) = h(k) en réponse à l’entrée u(k) = δ(k), où δ(k) est l’impulsion discrète (voir figure 4.1).
Dans le cas de systèmes causaux, cette réponse impulsionnelle est nulle pour les temps négatifs.
Système Σ
u(k) = δ(k) y(k) = h(k)
k
u(k)
k
h(k)
Figure 4.1 – Réponse impulsionnelle d’un système discret
Définition 4.3.2
La réponse indicielle d’un système est la sortie en réponse à une entrée en échelon. Dans le cas de systèmes linéaires et invariants, la réponse indicielle est la somme cumulée (intégrale numérique) de la réponse impulsionnelle.
4.3.2 Relation de convolution dans les systèmes linéaires invariants
4.3.2.1 Cas discret
Dans le cas des systèmes linéaires et invariants à temps discret, la sortie y peut se calculer à partir de la réponse impulsionnelle du système. En effet, le signal d’entrée u peut être vu comme une suite infinie d’impulsions décalées dans le temps :
u(k) =
+∑∞
n=−∞
u(n)δ(k − n) (4.3.1)
Comme le système est linéaire et invariant, la sortie est la somme infinie des réponses à ces impulsions. La réponse à l’impulsion u(n)δ(k − n) est égale à la suite u(n)h(k − n) (système invariant). Il vient donc :
y(k) =
+∑∞
n=−∞
u(n)h(k − n) (4.3.2)
Finalement, pour une entrée u quelconque et dans le cas d’un système linéaire et invariant, la sortie y peut donc être calculée par convolution de l’entrée par la réponse impulsionnelle :
y(k) = h ∗ u(k) =
+∑∞
n=−∞
h(n)u(k − n) (4.3.3)
Plus de détails sur la convolution sont donnés en annexe D.
4.3.2.2 Cas continu
Comme pour le cas discret, la réponse impulsionnelle d’un système est la sortie y(t) = h(t) en réponse à l’entrée u(t) = δ(t), où δ(t) est l’impulsion de Dirac (voir figure 4.2). La réponse indicielle d’un système est la sortie en réponse à une entrée en échelon. Dans le cas de systèmes linéaires et invariants, la réponse indicielle est l’intégrale de la réponse impulsionnelle.


48 Chapitre 4. Modélisation sous forme de fonction de transfert
Système Σ
u(t) = δ(t) y(t) = h(t)
t
u(t)
t
h(t)
Figure 4.2 – Réponse impulsionnelle d’un système continu
4.4 Etude des systèmes linéaires et invariants par fonction de transfert
4.4.1 Fonction de transfert
La relation entrée-sortie d’un système linéaire et invariant (SLI) de réponse impulsionnelle h(t) (en continu) ou h(k) (en discret) est une équation de convolution dans le domaine temporel (figure 4.3).
x SLI (h) y
y = h∗x
Figure 4.3 – Produit de convolution y = h ∗ x
Si l’on applique la transformée adéquate (Laplace dans le cas continu ou en z dans le cas discret), de par les propriétés des transformées de Laplace et en z, on obtient les relations suivantes :
Y (p) = H(p)X(p) ou Y (z) = H(z)X(z) (4.4.1)
où Y , H et X sont les transformées (de Laplace ou en z) des signaux y, h et x.
Définition 4.4.1
La transformée de la réponse impulsionnelle du SLI :
H(p) = Y (p)
X(p) ou H(z) = Y (z)
X (z )
est appelée fonction de transfert ou transmittance du SLI.
L’intérêt de l’utilisation des transmittances vient du fait que la plupart des systèmes étudiés sont constitués par la mise en cascade de sous-systèmes élémentaires (figure 4.4).
x SLI 1 (h1) y1 SLI 2 (h2) y2 SLI 3 (h3) y
h
Figure 4.4 – Mise en cascade de systèmes
L’étude de ce système dans le domaine temporel conduit à l’expression, en général compliquée : y = h3 ∗ h2 ∗ h1 ∗ x. L’utilisation des transmittances conduit à l’expression relativement simple : Y = H3H2H1X.
Une autre structure importante où l’utilisation des transmittances est indispensable est celle des systèmes bouclés (figure 4.5).


4.4. Etude des systèmes linéaires et invariants par fonction de transfert 49
x + ε SLI 1 (h1) y
SLI 2 (h2)
−
Figure 4.5 – Système bouclé
L’étude de ce système dans le domaine temporel donne :
ε = x − h2 ∗ y y = h1 ∗ ε
}
⇒ y = h1 ∗ x − h1 ∗ h2 ∗ y ⇔ (δ + h1 ∗ h2) ∗ y = h1 ∗ x
Cette expression ne permet pas d’expliciter y à partir de x. L’utilisation des transmittances conduit à une expression plus simple et permet d’expliciter Y à partir de X :
Y = H1 (X − H2Y ) ⇔ Y = H1
1 + H1H2
X
4.4.2 Stabilité EBSB
4.4.2.1 Définition
Définition 4.4.2
Un SLI sera dit stable EBSB (Entrée Bornée Sortie Bornée) si sa réponse à toute entrée bornée en amplitude est bornée.
Cette définition de la stabilité est la plus souvent utilisée en pratique lorsqu’on représente un système par fonction de transfert. Une condition nécessaire et suffisante de la stabilité EBSB est :
∫ +∞
−∞
|h(u)| du < ∞ ou
+∑∞
k=−∞
|h(k)| < ∞ (4.4.2)
c’est-à-dire que h(t) (en continu) ou h(k) (en discret) est absolument sommable.
Démonstration. Cette démonstration est seulement présentée dans le cas continu.
(i) Condition suffisante de stabilité : soit l’entrée bornée x(t) (|x(t)| < M ). Alors :
|y(t)| =
∣∣∣∣
∫ +∞
−∞
h(u)x(t − u)du
∣∣∣∣ ≤
∫ +∞
−∞
|h(u)| |x(t − u)| du ≤ M
∫ +∞
−∞
|h(u)| du
donc y(t) est bornée ; la condition est suffisante. (ii) Condition nécessaire de stabilité : soit l’entrée x(t) = sgn (h(−t)) :
y(0) =
∫ +∞
−∞
h(u)x(−u)du =
∫ +∞
−∞
|h(u)| du
y(0) doit être borné donc la condition est nécessaire.
Remarque 4.4.1. Cette démonstration se transpose sans difficulté dans le cas discret.


50 Chapitre 4. Modélisation sous forme de fonction de transfert
4.4.2.2 Conditions de stabilité et transmittance
On a vu ci-dessus une condition nécessaire et suffisante de stabilité EBSB sur h(t) ou h(k). On va chercher ici un critère de stabilité sur la transmittance. On va montrer que ce critère dépend des propriétés de causalité du SLI (causal ou anti-causal), ce qui n’est pas le cas de la condition de stabilité donnée dans le domaine temporel. Considérons tout d’abord le cas d’un système continu causal dont la fonction de transfert H(p) a pour abscisse de convergence σ1 :
H(p) =
∫ +∞
0
h(t)e−ptdt pour Re(p) > σ1
|H(0)| =
∣∣∣∣
∫ +∞
0
h(t)dt
∣∣∣∣ ≤
∫ +∞
0
|h(t)| dt
Si le système est stable EBSB cette dernière intégrale est bornée, donc H(0) existe, ce qui signifie que 0 est dans le domaine de convergence de H(p), c’est-à-dire que σ1 est négative et que H(p) existe pour tout p à partie réelle positive ou nulle. Dans la plupart des cas étudiés, la transmittance sera une fraction rationnelle :
H(p) = N (p)
D(p)
où N (p) et D(p) sont des polynômes. Dans ce cas les pôles de H(p) (valeurs de p rendant H(p) infinie) étant par définition à l’extérieur du domaine de convergence sont à partie réelle négative. Pour conclure :
Théorème 4.4.1
Un SLI continu causal dont la transmittance est une fraction rationnelle sera stable EBSB si et seulement si les pôles de sa transmittance sont à partie réelle strictement négative (c’està-dire situés dans le demi-plan complexe gauche).
Dans le cas discret, on montre par une démonstration analogue en calculant H(z) pour z = 1 que 1 est dans le domaine de convergence de H(z), d’où l’on déduit :
Théorème 4.4.2
Un SLI discret causal dont la transmittance est une fraction rationnelle est stable EBSB si et seulement si les pôles de sa transmittance sont de module strictement inférieur à 1 (c’est-à-dire à l’intérieur du cercle unité).
Dans le cas des systèmes anti-causaux les conclusions précédentes sont inversées ; c’est-à-dire qu’un SLI anti-causal sera stable si et seulement si les pôles sont à partie réelle positive dans le cas continu ou de module supérieur à 1 dans le cas discret.
4.4.2.3 Critères de Routh et de Jury
Ces deux critères permettent de savoir si un système continu (Routh) ou discret (Jury) est stable EBSB. Leur démonstration étant longue et de peu d’intérêt ici, seul le résultat est donné.
4.4.2.3.1 Critère de Routh Le critère de Routh donne une condition nécessaire et suffisante pour que les racines d’un polynôme à coefficient réels aient toutes une partie réelle strictement négative. Soit le polynôme D(p) = anpn + an−1pn−1 + · · · + a1p + a0. Les racines de D(p) ont toutes une partie réelle strictement négative si et seulement si :
(i) ai > 0 ; 0 ≤ i ≤ n
(ii) les coefficients de la première colonne du tableau de Routh (tableau 4.5, sont tous positifs.


4.4. Etude des systèmes linéaires et invariants par fonction de transfert 51
1 an an−2 an−4 · · ·
2 an−1 an−3 an−5 · · ·
3 c1 = an−1an−2 − anan−3
an−1
c2 = an−1an−4 − anan−5
an−1
···
4 d1 = c1an−3 − c2an−1
c1
d2 = c1an−5 − c3an−1
c1
···
... ... ... ...
n m1 m2 n + 1 n1
Tableau 4.5 – Tableau de Routh
De plus, le nombre de changements de signe dans la première colonne est égal au nombre de racines de D(p) à partie réelle positive. L’application du critère suppose évidemment qu’on puisse aller jusqu’au bout de la construction du tableau, c’est-à-dire qu’aucun des coefficients de la première colonne ne soit nul (dans le cas contraire, on conclut que le critère n’est pas vérifié).
Remarque 4.4.2. Lorsque dans les formules du tableau 4.5 un coefficient est absent (par exemple si an−5 n’existe pas), on le remplace par un 0.
4.4.2.3.2 Critère de Jury Le critère de Jury donne une condition nécessaire et suffisante pour que les racines d’un polynôme à coefficients réels aient toutes un module strictement inférieur à 1. Soit le polynôme D(z) = a0,0 + a0,1z + a0,2z2 + · · · + a0,nzn, avec a0,n > 0. On construit le tableau (n − 1) × (n + 1) suivant :


a0,0 a0,1 a0,2 a0,3 · · · a0,n−1 a0,n
a1,0 a1,1 a1,2 a1,3 · · · a1,n−1 0
... ... ... ... . . . ... ...
an−2,0 an−2,1 an−2,2 0 · · · 0 0


avec :
aj+1,k =


∣∣∣∣ aj,0 aj,n−j−k
aj,n−j aj,k
∣∣∣∣ pour 0 ≤ k ≤ n − j − 1
0 pour k > n − j − 1 D(z) n’a pas de racine de module supérieur ou égal à 1 si et seulement si :
1.
∑n
i=0
a0,i = D(1) > 0
2. (−1)n
n ∑
i=0
(−1)ia0,i = (−1)nD(−1) > 0
3. |a0,0| − a0,n < 0
4. |aj,0| − |aj,n−j| > 0, pour j = 1, 2, . . . , n − 2
4.4.3 Réponse en fréquence
4.4.3.1 Définition
La réponse en fréquence ̂h(f ) (notion qui sera approfondie dans le cours Traitement de signaux ) d’un système linéaire invariant peut être déterminée expérimentalement par une analyse harmonique du système en injectant à l’entrée un signal sinusoïdal. Les données expérimentales
∣∣∣̂h(f )
∣∣∣ et
arg
(̂h(f )
) sont reportées dans un système de coordonnées, par exemple dans le plan de Bode.
∣∣∣̂h (f0)
∣∣∣ = A′
A et arg
(̂h (f0)
)
=φ


52 Chapitre 4. Modélisation sous forme de fonction de transfert
Cas où n = 2 Cas où n = 3
D(z) = a0,2z2 + a0,1z + a0,0, a0,2 > 0 D(z) = a0,3z3 + a0,2z2 + a0,1z + a0,0, a0,3 > 0 Conditions de stabilité :
1. a0,0 + a0,1 + a0,2 > 0 1. a0,0 + a0,1 + a0,2 + a0,3 > 0 2. a0,0 − a0,1 + a0,2 > 0 2. −a0,0 + a0,1 − a0,2 + a0,3 > 0 3. |a0,0| − a0,2 < 0 3. |a0,0| − a0,3 < 0 4. ne s’applique pas puisque n − 2 = 0 4. |a1,0| − |a1,2| > 0
soit ∣∣a20,0 − a20,3
∣∣ − |a0,0a0,2 − a0,1a0,3| > 0
Tableau 4.6 – Conditions de Jury dans les cas de polynômes d’ordre 2 et 3
x(t) = A sin (2πf0t) SLI
y(t) = A′ sin (2πf0t + φ)
4.4.3.2 Fonction de transfert et réponse harmonique
Cas continu
On considère un système mono-variable continu, le cas des systèmes multi-variables s’en déduisant immédiatement. On applique à l’entrée du système linéaire invariant un signal sinusoïdal :
u(t) = u0 sin(ω0t + φ) = Im(u0ejφejω0t) (4.4.3)
La sortie est égale à la convolution de ce signal par la réponse impulsionnelle h :
y(t) = h ∗ Im(u0ejφejω0t) = Im(h ∗ u0ejφejω0t)
= u0Im
(∫ +∞
−∞
h(τ )ejφejω0(t−τ )dτ
)
= u0Im
((∫ +∞
−∞
h(τ )e−jω0τ dτ
)
ejφejω0t
) (4.4.4)
On reconnaît la transformée de Laplace de h calculée au point jω0, notée H(jω0). Finalement :
y(t) = u0 |H(jω0)| sin(ω0t + φ + arg(H(jω0))) (4.4.5)
La sortie est donc un signal sinusoïdal de même pulsation, dont l’amplitude est multipliée par le module de la fonction de transfert en jω0, i.e. H(jω0), avec un déphasage supplémentaire égal à l’argument de H(jω0). La réponse en fréquence, ou réponse harmonique peut donc se déduire de la transformée de Laplace en posant formellement p = jω. Cependant, pour que cette opération ait un sens, il est nécessaire que la transformée de Laplace soit définie sur l’axe imaginaire. C’est en particulier le cas pour les systèmes causaux stables qui ont tous leurs pôles dans le demi-plan gauche.
Cas discret
De la même façon, pour un système discret attaqué par une entrée sinusoïdale du type :
u(k) = u0 sin(2πkν + φ) (4.4.6)
la sortie se calcule à partir de la transformée en z, notée H(z), de la réponse en fréquence calculée au point e2πjν :
y(k) = u0
∣∣H(e2πjν)∣∣ sin(2πkν + φ + arg(H(e2πjν))) (4.4.7)
Comme dans le cas continu, pour que cette opération ait un sens, il est nécessaire que la transformée en z soit définie sur le cercle unité. C’est en particulier le cas pour les systèmes causaux stables, qui ont tous leurs pôles dans le cercle unité.


4.4. Etude des systèmes linéaires et invariants par fonction de transfert 53
4.4.3.3 Conditions d’existence de la réponse en fréquence
La réponse en fréquence est la transformée de Fourier de la réponse impulsionnelle. En particulier, cette transformée existe si la réponse impulsionnelle est absolument sommable. Cette condition étant également la condition de stabilité des SLI on peut en déduire que pour les systèmes stables (mais pour les systèmes stables seulement) on peut passer des transmittances à variables complexes à la réponse en fréquence par le changement de variable adéquat suivant :
p = j2πf ou z = ej2πν .
Exemple 4.4.1 (Système du premier ordre). Soit H(p) = 1
p + 1 . Le pôle de H(p) (p = −1) est à
partie réelle négative donc ce système est stable, et :
̂h(f ) = H(p)
∣∣∣p=j2πf = 1
j2πf + 1
Exemple 4.4.2 (Système intégrateur h(t) = u(t) (échelon)). Soit H(p) = 1
p . Le pôle de H(p)
(p = 0) n’est pas à partie réelle strictement négative donc ce système est instable et :
̂h(f ) = F {h(t)}(f ) = 1
2 δ(f ) + 1
2πj Pf
(1
f
)
6= H(p)
∣∣∣p=j2πf = 1
j2πf
La différence provient du fait que H(p) est définie au sens des fonctions alors que ̂h(f ) est définie au sens des distributions.
4.4.4 Passage état – transfert. Formes compagnons
Nous avons vu dans les chapitres précédents deux méthodes d’analyse des systèmes linéaires permanents : une représentation externe caractérisée par une fonction de transfert H(p) et une représentation interne caractérisée par la représentation d’état. Nous allons voir ici comment passer d’une représentation interne à une représentation externe et inversement. Dans le cas général où le système a m entrées et p sorties, la transmittance H(p) est une matrice (appelée matrice de transfert) de dimension p × m : 

Y1(p) Y2...(p)
Yi ...(p)
Yn(p)


=


H11(p) H12(p) · · · H1j(p) · · · H1m(p) H21(p) H22(p) · · · H2j(p) · · · H2m(p)
... ... . . . ... . . . ...
Hi1(p) Hi2(p) · · · Hij (p) · · · Him(p)
... ... . . . ... . . . ...
Hn1(p) Hn2(p) · · · Hnj(p) · · · Hnm(p)




U1(p) U2...(p)
Uj...(p)
Um(p)


avec Hij(p) =
( Yi
Uj
(p)
)
Uk(p)=0 pour k6=j
.
4.4.4.1 Passage état → transfert
Systèmes à temps continu Connaissant les équations d’état du système linéaire invariant, on cherche la matrice de transfert H(p). Pour cela on applique la transformée de Laplace aux deux équations d’état. En ne considérant que la partie causale des signaux on obtient :


L
{ dx(t) dt
}
(p) = L{Ax(t) + Bu(t)}(p)
L{y(t)}(p) = L{Cx(t) + Du(t)}(p)
⇔
{ pX(p) − x(t0)e−pt0 = AX(p) + BU (p)
Y (p) = CX(p) + DU (p)


54 Chapitre 4. Modélisation sous forme de fonction de transfert
d’où :
X(p) = (pI − A)−1 (x (t0) e−pt0 + BU (p))
et :
Y (p) =
(
C (pI − A)−1 B + D
)
U (p) + C (pI − A)−1 x (t0) e−pt0
Par définition, la transmittance caractérise la relation entre les variations de la (ou des) sortie(s) en fonction des variations du (ou des) signaux d’entrée(s) ; cela revient à définir H(p) comme Y (p) = H(p)U (p) pour x(t0) = 0. On a donc ici :
H(p) = C (pI − A)−1 B + D (4.4.8)
Remarque 4.4.3. Calcul de (pI − A)−1 :
Afin de pouvoir revenir dans le domaine temporel, il peut être intéressant de mettre (pI − A)−1 sous la forme :
(pI − A)−1 = B0pn−1 + B1pn−2 + · · · + Bn−1
pn + d1pn−1 + · · · + dn
où les Bi sont des matrices carrées n × n et les scalaires di sont les coefficients du polynôme caractéristique de A :
det (pI − A) = pn + d1pn−1 + · · · + dn
Il existe pour cela des méthodes systématiques et récursives comme l’algorithme de LeverrierSouriau décrit ci-dessous :
B0 = I d1 = −Tr (B0A)
B1 = B0A + d1I d2 = − 1
2 Tr (B1A)
B2 = B1A + d2I d3 = − 1
3 Tr (B2A)
... ...
Bk = Bk−1A + dkI dk+1 = − 1
k + 1 Tr (BkA)
... ...
Bn−1 = Bn−2A + dn−1I dn = − 1
n Tr (Bn−1A)
La dernière équation Bn = Bn−1A + dnI = 0 sert de vérification au calcul.
Remarque 4.4.4. Changement de base de la représentation interne : Nous avons déjà vu que la représentation d’état d’un système n’est pas unique. Si on effectue le changement de base x′(t) = M x(t) on obtient comme équations d’état :
dx′(t)
dt = A′x′(t) + B′u(t) avec A′ = M AM −1 et B′ = M B
y(t) = C′x′(t) + D′u(t) avec C′ = CM −1 et D′ = D
d’où :
H′(p) = C′ (pI − A′)−1 B′ + D′
= CM −1 (pI − M AM −1)−1 M B + D
= C (M −1 (pI − M AM −1) M )−1 B + D
= C (pI − A)−1 B + D
= H(p)
Le changement de base interne n’a bien évidemment pas modifié la matrice de transfert du système.


4.4. Etude des systèmes linéaires et invariants par fonction de transfert 55
Remarque 4.4.5. Stabilité du système : La relation liant la fonction de transfert H(p) et la matrice d’évolution A :
H(p) = C (pI − A)−1 B + D (4.4.9)
implique que les pôles de H(p) sont inclus dans l’ensemble des valeurs propres de A. On peut en déduire la relation suivante :
stabilité asymptotique ⇒ stabilité EBSB
Systèmes à temps discret Les relations entre les équations d’état et la fonction de transfert d’un SLI à temps discret se déduisent par simple transposition du cas continu. En particulier, en appliquant la transformée en z aux équations (3.6.3), on obtient la fonction de transfert :
H(z) = C (zI − F )−1 G + D (4.4.10)
soit une relation analogue à (4.4.9), en remplaçant p par z, et les matrices A et B par F et G respectivement.
4.4.4.2 Passage transfert → état
Cette section présente diverses approches pour passer d’une fonction de transfert à une représentation d’état d’un système à temps continu. Les passages transfert → état pour des systèmes à temps discret se font suivant une démarche analogue au cas continu. Nous allons voir ici comment passer d’une représentation externe caractérisée par la matrice de transfert H(p) à une représentation interne. Afin de simplifier les calculs, on se limitera ici aux systèmes à une entrée et une sortie. La généralisation au cas multi-entrées et/ou multi-sorties peut se faire sur chaque fonction de transfert Hij(p) au prix d’une complexité accrue. Nous allons voir deux représentations d’état appelées forme compagnon pour la commande et forme compagnon pour l’observation.
4.4.4.2.1 Forme compagnon pour la commande Posons :
H(p) = b0 + b1p + · · · + bmpm
a0 + a1p + · · · + pn = N (p)
D(p) = Y (p)
U (p) = Y (p)W (p)
W (p)U (p)
On se place dans un premier temps dans le cas où m est strictement inférieur à n.
En identifiant Y (p)
W (p) avec N (p) et U (p)
W (p) avec D(p) on trouve :
{ Y (p) = (b0 + b1p + · · · + bmpm) W (p)
U (p) = (a0 + a1p + · · · + pn) W (p)
soit dans le domaine temporel :


y(t) = b0w(t) + b1
dw(t)
dt + · · · + bm
dmw(t) dtm dnw(t)
dtn = −a0w(t) − a1
dw(t)
dt − · · · − an−1
dn−1w(t)
dtn−1 + u(t)
ce qui conduit à choisir comme variables d’état du système :
x1(t) = w(t)
x2(t) = dx1(t)
dt = dw(t)
dt
x3(t) = dx2(t)
dt = d2w(t)
dt2
...
xn(t) = dxn−1(t)
dt = dn−1w(t)
dtn−1


56 Chapitre 4. Modélisation sous forme de fonction de transfert
ce qui donne sous forme matricielle :
d dt


x1(t)
x2......(t)
xn(t)


=


0 1 0 ··· 0 0 0 1 ··· 0
... ... ... . . . ...
0 0 0 ··· 1
−a0 −a1 −a2 · · · −an−1




x1(t)
x2......(t)
xn(t)


+


0
......0
1


u(t)
c’est-à-dire : dx(t)
dt = Ax(t) + Bu(t) (première équation d’état)
et :
y(t) = (b0 b1 · · · bm 0 · · · 0)


x1(t) x2...(t)
xn(t)


c’est-à-dire : y(t) = Cx(t) (deuxième équation d’état avec D = 0)
Cette représentation d’état est appelée forme compagnon pour la commande. L’implantation de cette forme correspond à la figure 4.6.
u +
1 p
xn 1 p
xn−1 1
p
x1
b0
+y
an−1
+
−
bn−1
+
bn−2
++
an−2
+
+
a0
+
Figure 4.6 – Forme compagnon pour la commande
Remarque 4.4.6. Cas où m = n :
Si m = n (degré du numérateur de H(p) égal au degré du dénominateur), on peut écrire H(p) sous la forme H(p) = H1(p) + K avec H1(p) nulle à l’infini. On peut alors appliquer la méthode précédente à H1(p) ; il suffit d’ajouter au signal de sortie dans la deuxième équation du système d’équations d’état, le terme Ku(t).
4.4.4.2.2 Forme compagnon pour l’observation On pose :
H(p) = b0 + b1p + · · · + bn−1pn−1
a0 + a1p + · · · + pn = N (p)
D(p) = Y (p)
U (p)
en divisant N (p) et D(p) par pn, on obtient :
Y (p) =
(
bn−1
1
p + · · · + b1
1
pn−1 + b0
1 pn
)
U (p) −
(
an−1
1
p + · · · + a1
1
pn−1 + a0
1 pn
)
Y (p)


4.4. Etude des systèmes linéaires et invariants par fonction de transfert 57
que l’on peut écrire sous la forme :
Y (p) = 1
p
(
ζn−1 + 1
p
(
ζn−2 + 1
p
(
ζn−3 + 1
p
(
···+ 1
p ζ0
))))
avec ζj = bjU (p) − ajY (p)
en posant Xn(p) = L{xn(t)}(p) = Y (p), on obtient les relations suivantes :


Xn(p) = 1
p (bn−1U (p) − an−1Xn(p) + Xn−1(p))
Xn−1(p) = 1
p (bn−2U (p) − an−2Xn(p) + Xn−2(p))
...
X1(p) = 1
p (b0U (p) − a0Xn(p))
u
b0
+1
p x1
b1
+1
p x2
1
p xn−1
bn−1
+1
p xn
y
an−1
−
a1
−
a0
−
Figure 4.7 – Forme compagnon pour l’observation
Ces n équations donnent dans le domaine temporel :


dx1(t)
dt = b0u(t) − a0xn(t)
dx2(t)
dt = b1u(t) − a1xn(t) + x1(t)
dx3(t)
dt = b2u(t) − a2xn(t) + x2(t)
...
dxn(t)
dt = bn−1u(t) − an−1xn(t) + xn−1(t)
ce qui s’écrit sous forme matricielle :
d dt


x1(t) x2...(t)
xn−1(t) xn(t)


=


0 0 · · · 0 −a0 1 0 · · · 0 −a1
... ... . . . ... ...
0 0 · · · 0 −an−2 0 0 · · · 1 −an−1




x1(t) x2...(t)
xn−1(t) xn(t)


+


b0
b...1
bn−2
bn−1


u(t)
c’est-à-dire : dx
dt = Ax(t) + Bu(t) (première équation d’état)


58 Chapitre 4. Modélisation sous forme de fonction de transfert
et :
y(t) = (0 0 · · · 0 1)


x1(t) x2...(t)
xn−1(t) xn(t)


c’est-à-dire : y(t) = Cx(t) (deuxième équation d’état avec D = 0)
Cette représentation d’état est appelée forme compagnon pour l’observation et est implantée par le schéma bloc de la figure 4.7.


Chapitre 5
Analyse des performances des
systèmes dynamiques
5.1 Introduction
Dans ce chapitre sont étudiés les comportements temporel et fréquentiel de systèmes linéaires invariants élémentaires du 1er ou du 2ème ordre, analogiques ou numériques. Ils interviennent dans la décomposition des fonctions de transfert des systèmes d’ordre plus élevé, facilitant ainsi l’étude de celles-ci, comme le montre par exemple la représentation de Bode pour les systèmes analogiques. Des exemples d’utilisation de cette représentation sont proposés. Le diagramme de Bode d’un système numérique avec un pôle du premier ordre ainsi que le diagramme de Bode d’un système du second ordre numérique sont analysés. Puis, les diagrammes de Bode des systèmes passe-tout, des systèmes à déphasage minimal et des systèmes avec retard pur sont présentés. On peut plus généralement envisager une approche des comportements fréquentiel et temporel des systèmes analogiques ou numériques en considérant la position des pôles et des zéros de la fonction de transfert. Une analyse temporelle des systèmes du premier ordre et du second ordre est également proposée dans ce chapitre.
5.2 Diagramme de Bode des systèmes à temps continu
5.2.1 Définition
Une fonction de transfert, dite à constantes localisées, peut se décomposer sous la forme :
H(p) = Kpqe−τp
n∏k
k=1
(
1+ p
ωk
) n ∏l
l=1
(
1 + 2ζl
p
ωl
+
(p
ωl
)2)
n∏m
m=1
(
1+ p
ωm
) n∏n
n=1
(
1 + 2ζn
p
ωn
+
(p
ωn
)2) (5.2.1)
avec le gain K ∈ R, le comportement basse fréquence donné par q ∈ Z, le retard pur τ ∈ R, les pulsations de brisure pour les termes du premier ordre ωk, ωm ∈ R∗, les pulsations de brisure pour
les termes du deuxième ordre ωl, ωn ∈ R∗+ et les amortissements |ζl| , |ζn| < 1.
La représentation de Bode donne les variations de 20 log (|H (jω)|) (logarithme décimal et module exprimé en dB) et de arg (H (jω)) (phase exprimée en degrés) en fonction de la pulsation ω, l’échelle des pulsations étant logarithmique. L’étude des asymptotes de ces deux fonctions donne le tracé asymptotique de Bode, utilisé notamment en Automatique. Le module en décibel (respectivement la phase) de H (jω) est la somme des modules en décibel (respectivement des phases) des termes élémentaires (du 1er, du 2ème ordre et de la forme Kpqe−τp avec q entier relatif et τ un nombre réel) intervenant dans la décomposition de H(p). Dans la suite nous allons d’abord traiter le cas des systèmes sans retard (avec τ = 0) et ensuite le cas des systèmes à retard pur sera abordé dans la section 5.4.3.
59


60 Chapitre 5. Analyse des performances des systèmes dynamiques
Il convient donc de donner dans un premier temps le comportement fréquentiel des systèmes du 1er et du 2ème ordre afin de proposer ensuite une méthode permettant d’obtenir le tracé asymptotique de Bode de H(p).
5.2.2 Systèmes du 1er ordre
5.2.2.1 Systèmes avec un zéro
La fonction de transfert :
H(p) = 1 + p
ω0
(5.2.2)
possède la représentation de Bode tracée en figure 5.1 pour ω0 > 0. On a représenté en trait fin le tracé réel et en trait gras le tracé asymptotique. Pour ω0 < 0, le module est identique et la phase est l’opposée de celle représentée ici. Par convention, la pente de 20 dB/décade est qualifiée de pente +1.
0
5
10
15
20
25
3 dB
pente 20 dB/décade
ou pente +1
Module (dB)
10−1 100 101
0
10
20
30
40
50
60
70
80
90
100
45 ̊
ω/ω0
Phase (deg)
Figure 5.1 – Tracé de Bode d’un système avec un zéro
5.2.2.2 Système avec un pôle
La fonction de transfert :
H(p) = 1
1+ p
ω0
= ω0
p + ω0
(5.2.3)
possède la représentation de Bode tracée en figure 5.2 pour ω0 > 0. On a représenté en trait fin le tracé réel et en trait gras le tracé asymptotique. Pour ω0 < 0, le module est identique et la phase est l’opposée de celle représentée ici. Par convention, la pente de −20 dB/décade est qualifiée de pente −1.


5.2. Diagramme de Bode des systèmes à temps continu 61
0
−5
−10
−15
−20
−25
−3 dB
pente −20 dB/décade
ou pente −1
Module (dB)
10−1 100 101
−100
−90
−80
−70
−60
−50
−40
−30
−20
−10
0
−45 ̊
ω/ω0
Phase (deg)
Figure 5.2 – Tracé de Bode d’un système avec un pôle
5.2.3 Systèmes du 2ème ordre
La fonction de transfert :
H(p) = 1
1 + 2ζ p
ω0
+
(p
ω0
)2 = ω02
p2 + 2ζω0p + ω02
(5.2.4)
possède la représentation de Bode tracée en figure 5.3 pour ω0 > 0 et :
ζ ∈ {0, 1; 0, 2; 0, 3; 0, 4; 0, 5; 0, 6; 0, 7; 0, 8; 0, 9; 1; 2; 3; 5; 7; 10; 20}
Remarque 5.2.1. Le lecteur pourra remarquer que pour ζ > 1, le système du "second ordre" se factorise en deux systèmes du premier ordre.
La pulsation ω0 est appelée pulsation propre et ζ est l’amortissement. Lorsque ζ <
√2
2 , le
module présente un maximum :
|H (jω)|max = 1
2ζ√1 − ζ2 pour ω
ω0
= √1 − 2ζ2 (5.2.5)
On a représenté en trait fin le tracé réel et en trait gras le tracé asymptotique. Par convention, la pente de −40 dB/décade est qualifiée de pente −2. Pour des valeurs de ζ opposées, le module est identique et la phase est l’opposée de celle représentée ici. Pour obtenir le tracé de :
H(p) = 1 + 2ζ p
ω0
+
(p
ω0
)2
il suffit de prendre l’opposé du module en dB et de la phase de la fonction de transfert précédente.


62 Chapitre 5. Analyse des performances des systèmes dynamiques
−60
−50
−40
−30
−20
−10
0
10
20
pente
−40 dB/décade
ou pente −2
ζ = 0, 1
ζ = 20
Module (dB)
10−1 100 101
−180
−135
−90
−45
0 ζ = 0, 1
ζ = 20
ω/ω0
Phase (deg)
Figure 5.3 – Tracé de Bode d’un système du second ordre
5.2.4 Méthode pratique de tracé asymptotique
La fonction de transfert H(p) sans retard (τ = 0) présentée en 5.2.1 est décomposée en termes élémentaires décrits en 5.2.2 et 5.2.3. Plutôt que de faire la somme des tracés asymptotiques de ces termes pour obtenir le tracé de Bode associé à H(p), on prend en compte leur contribution au fur et à mesure en faisant croître la pulsation ω de zéro jusqu’à l’infini.
— Pour ω → 0, H(jω) → Kjqωq. En module, l’asymptote est donc une droite de pente q × 20
dB/décade (ou +q) coupant l’axe 0 dB à la pulsation ω =
∣∣∣∣
1 K
∣∣∣∣
1
q . En phase, l’asymptote est
une droite horizontale d’ordonnée q × 90 ̊ si K > 0 ou q × 90 ̊ + 180 ̊ si K < 0.
Ensuite on fait croître ω. Quand une des pulsations de brisure |ωk|, ωl, |ωm|, ωn est rencontrée, on fait évoluer le tracé en adoptant les règles suivantes :
— Pour ω = |ωk|, le terme à prendre en compte est 1 + p
ωk
au numérateur. En module, le
tracé asymptotique subit un changement de pente de +20 dB/décade (ou +1). En phase, l’asymptote subit un saut de 90° × sgn (ωk).
— Pour ω = |ωm|, le terme à prendre en compte est 1 + p
ωm
au dénominateur. En module, le
tracé asymptotique subit un changement de pente de −20 dB/décade (ou −1). En phase, l’asymptote subit un saut de −90° × sgn (ωm).
— Pour ω = ωl, le terme à prendre en compte est 1+2ζl
p
ωl
+
(p
ωl
)2
au numérateur. En module,
le tracé asymptotique subit un changement de pente de +40 dB/décade (ou +2). En phase, l’asymptote subit un saut de 180° × sgn (ζl).
— Pour ω = ωn, le terme à prendre en compte est 1 + 2ζn
p
ωn
+
(p
ωn
)2
au dénominateur. En
module, le tracé asymptotique subit un changement de pente de −40 dB/décade (ou −2). En phase, l’asymptote subit un saut de −180° × sgn (ζn).


5.2. Diagramme de Bode des systèmes à temps continu 63
Exemple 5.2.1 (Diagramme de Bode). On s’intéresse au tracé de Bode de la fonction de transfert :
H(p) = (1 + p) (1 + 50p) (1 + 5p)
(1 + 0, 05p) (1 + 8p + 100p2) (5.2.6)
Pour faire apparaître les pulsations où vont intervenir les évolutions du tracé (pulsations de brisure), on peut réécrire la fonction de transfert :
H(p) =
(1 + p)
(
1+ p
0, 02
)(
1+ p
0, 2
)
(
1+ p
20
)(
1 + 2 · 0, 4 · p
0, 1 +
(p
0, 1
)2) (5.2.7)
On obtient alors le tracé de la figure 5.4 après application des règles décrites en 5.2.4.
0
10
20
30
40
Module (dB)
10−2 10−1 100 101 102
−90
0
90
ω (rad/s)
Phase (deg)
Figure 5.4 – Exemple de tracé de Bode
On peut constater que le tracé réel s’éloigne d’autant plus du tracé asymptotique que les pulsations de brisure sont proches.
Exemple 5.2.2 (Exemple d’application). En Automatique, on est fréquemment amené à modéliser un système physique en le considérant comme linéaire invariant. Pour un moteur à courant continu entraînant une charge mécanique, il est possible par exemple de déterminer une relation simplifiée entre la tension d’alimentation du moteur et sa vitesse de rotation : Ωm(p)
Um(p) = Kv
1 + τp
Les paramètres de cette fonction de transfert peuvent être déterminés en procédant à une analyse harmonique (voir 10.3.1 : mesure de l’amplitude et du déphasage de la sortie pour une tension um(t) = A cos (ωt) avec plusieurs valeurs de la pulsation ω). Le modèle est aussi validé par l’analyse des équations différentielles régissant le système. On peut en déduire la relation entre la tension d’alimentation et la position angulaire :
H(p) = Θm(p)
Um(p) = Kv
p(1 + τ p)


64 Chapitre 5. Analyse des performances des systèmes dynamiques
puisque Ωm(p) = pΘm(p). Un schéma simple d’asservissement où on souhaite que la position θm(t) soit aussi proche que possible d’une commande e(t) peut être proposé en figure 5.5. Un dispositif de mesure de position angulaire (potentiomètre) délivre une tension égale à cette position. Le gain K est réglable et on se propose de lui donner une valeur convenable. La fonction de transfert de l’ensemble vaut :
Hensemble(p) = Θm(p)
E(p) = KH(p)
1 + KH(p) = 1
1+ p
K Kv
+ τ p2
K Kv
(5.2.8)
(une analyse sommaire du schéma de la figure 5.5 permet d’obtenir cette fonction de transfert).
+
e(t) ε(t) K um(t) H(p) θm(t)
mesure de position (gain 1)
−
Figure 5.5 – Schéma d’un asservissement de position
Pour se ramener à l’étude du paragraphe 5.2.3, on peut l’écrire sous la forme :
Hensemble(p) = 1
1 + 2ζ p
ω0
+
(p
ω0
)2 avec ω0 =
√ KKv
τ et ζ = 1
2√K Kv τ
Pour faire en sorte que la sortie suive au mieux la commande, il faudrait que Hensemble (jω) reste proche de 1 pour des pulsations les plus élevées possibles, soit une valeur de ω0 la plus élevée possible. En effet, le tracé asymptotique nous indique que Hensemble (jω) ≈ 1 pour ω < ω0. On pourrait pour cela augmenter arbitrairement le gain K. Cependant, si K est trop grand, l’amortissement ζ devient trop faible et on s’éloigne trop de la condition Hensemble (jω) ≈ 1 pour ω < ω0 car une résonance apparaît dans la réponse en fréquence. Une valeur convenable de l’amortissement (correspondant à un tracé réel proche du tracé asymp
totique) est par exemple ζ =
√2
2 (figure 5.11), d’où la valeur :
K= 1
2Kvτ
La bande passante du système vaut alors ω0 = 1
τ√2 .
5.3 Diagramme de Bode des systèmes numériques
5.3.1 1er ordre tout pôle
Un système du premier ordre numérique tout pôle possède une fonction de transfert :
H(z) = 1
1 − az−1 (5.3.1)
L’équation aux différences qui lui est associée est :
y(n) = u(n) + ay(n − 1)
La réponse en fréquence vaut :
H (e2πjν) = 1
1 − ae−2πjν


5.3. Diagramme de Bode des systèmes numériques 65
On peut représenter en figure 5.6 le module de cette réponse pour différentes valeurs de a (a varie de −0, 9 à 0, 9 par pas de 0, 1) et faire une interprétation géométrique de cette représentation en fonction de la position du pôle a de la fonction H(z). En effet :
H(z) = z
z − a soit ∣∣H (e2πjν)∣∣ = 1
|e2πjν − a| = 1
MP
où P est le point dans le plan complexe correspondant au pôle et M un point se déplaçant sur le cercle unité. On observe directement ainsi un comportement passe-bas pour a > 0 et passe haut pour a < 0.
0 0,1 0,2 0,3 0,4 0,5
−10
−5
0
5
10
15
20
a = 0, 9 a = −0, 9
Fréquence réduite ν
Module (dB)
Re(z)
Im(z)
M
a
P
2πν
1
Figure 5.6 – Réponse en fréquence d’un système numérique du premier ordre
5.3.2 2ème ordre tout pôle
Un système du second ordre numérique tout pôle possède une fonction de transfert :
H(z) = 1
1 + a1z−1 + a2z−2 = 1
(1 − rejθz−1) (1 − re−jθz−1) = 1
1 − 2r cos θz−1 + r2z−2 (5.3.2)
(on n’envisage pas le cas où les deux pôles sont réels, ce qui reviendrait à une décomposition en deux systèmes du premier ordre). L’équation aux différences qui lui est associée est :
y(n) = u(n) − a1y(n − 1) − a2y(n − 2)
La réponse en fréquence vaut :
H (e2πjν ) = 1
1 + a1e−2πjν + a2e−4πjν
On a représenté en figure 5.7 le module des réponses en fréquences associées à des valeurs de θ = 2πν0 avec les valeurs de ν0 et r suivantes :
ν0 ∈ {0, 1; 0, 15; 0, 2; 0, 25; 0, 3; 0, 35; 0, 4}
r ∈ {0, 65; 0, 7; 0, 75; 0, 8; 0, 85; 0, 9; 0, 95}
On constate que pour des valeurs de r proches de 1 et une valeur de θ = 2πν0, la réponse présente une résonance pour une fréquence proche de ν0.
En effet, les deux fréquences ν = 0 et ν = 1
2 correspondent à des extremums de la réponse en
fréquence et il y a une troisième fréquence extrémale lorsque :
cos θ < 2r
1 + r2


66 Chapitre 5. Analyse des performances des systèmes dynamiques
Cette fréquence νmax vérifie alors :
cos (2πνmax) = cos θ 1 + r2
2r
et le module de la réponse à cette fréquence vaut :
∣∣H (e2πjνmax
)∣∣ = 1
(1 − r2) sin θ
0 0,05 0,1 0,15 0,2 0,25 0,3 0,35 0,4 0,45 0,5
−15
−10
−5
0
5
10
15
20
25 θ = 2πν0 avec ν0 = 0, 4 r = 0, 95
r = 0, 9
r = 0, 85
Fréquence réduite ν
Module (dB)
Figure 5.7 – Réponse en fréquence d’un système numérique du second ordre
On peut par conséquent connaître le comportement fréquentiel à partir des pôles de la fonction de transfert (figure 5.8) et faire une interprétation géométrique de la réponse en fréquence que l’on peut exprimer sous la forme :
∣∣H (e2πjν )∣∣ = 1
M P1 · M P2
5.4 Diagramme de Bode des systèmes passe-tout, à déphasage minimal ou avec retard pur
5.4.1 Systèmes passe-tout
Un système passe-tout analogique vérifie :
|H (jω)| = 1 pour tout ω


5.4. Diagramme de Bode des systèmes passe-tout, à déphasage minimal ou avec retard pur 67
Re(z)
Im(z)
P1
P2
M
r
r
2πν
θ
−θ
1
Figure 5.8 – Position des pôles de la fonction de transfert 5.3.2
sans contrainte sur la phase arg (H (jω)). Cette situation survient lorsqu’un pôle P est compensé par un zéro −P . On obtient alors des filtres de la forme :
H(p) =
N ∏
k=1
(p + P k
)
N ∏
k=1
(p − Pk)
(5.4.1)
avec la contrainte de stabilité Re (Pk) < 0, appelés aussi déphaseurs analogiques purs. Un système passe-tout numérique vérifie :
∣∣H (e2πjν)∣∣ = 1 pour tout ν
sans contrainte sur la phase arg (H (e2πjν)). Cette situation survient lorsqu’un pôle P est compensé
par un zéro Z = 1
P . On obtient alors des filtres de la forme :
H(z) =
N ∏
k=1
(P k − z−1)
N ∏
k=1
(1 − Pkz−1) (5.4.2)
avec la contrainte de stabilité |Pk| < 1, appelés aussi déphaseurs numériques purs.
5.4.2 Systèmes à déphasage minimal
Considérons par exemple la fonction de transfert :
H(p) =
(1 + p)
(
1+ p
10
)
(1 + 10p)
(
1+ p
5
)
(1 + 2p) (1 + 20p)
(5.4.3)
On représente en figure 5.9 le module et la phase de H (jω) (tracé en gras pour la phase). Toutes les autres fonctions de la forme :
H(p) =
(1 ± p)
(
1± p
10
)
(1 ± 10p)
(
1+ p
5
)
(1 + 2p) (1 + 20p)
(5.4.4)


68 Chapitre 5. Analyse des performances des systèmes dynamiques
ont le même module (figure 5.9). On les obtient en effet en multipliant la fonction de transfert initiale par un déphaseur pur étudié au paragraphe 5.4.1. Les phases associées sont représentées en trait fin sur le graphe. On constate que la phase est maximale lorsque tous les zéros sont à partie réelle négative (en considérant que le déphasage est l’opposé de la phase étudiée, on a bien un déphasage minimal ).
Définition 5.4.1
Plus généralement, on appelle filtre analogique à déphasage minimal un filtre dont tous les zéros sont à partie réelle négative.
Pour un filtre quelconque, on peut toujours se ramener à un tel filtre en multipliant la fonction de transfert initiale par le déphaseur analogique pur approprié.
−20
−15
−10
−5
0
Module (dB)
10−2 10−1 100 101 102
0
−100
−200
−300
−400
−500
−600
ω/ω0
Phase (deg)
Figure 5.9 – Réponse en fréquence d’une famille de filtres ayant le même module
Dans le domaine numérique, on pourrait faire la même constatation. On appelle alors filtre numérique à déphasage minimal un filtre dont tous les zéros sont de module inférieur à 1. Pour un filtre quelconque, on peut toujours se ramener à un tel filtre en multipliant la fonction de transfert initiale par le déphaseur numérique pur approprié.
5.4.3 Systèmes avec retard pur
La sortie d’un système peut ne pas évoluer instantanément lorsque l’on fait évoluer son entrée. Il est alors nécessaire de considérer des fonctions de transfert de la forme :
G(p) = e−τpH(p) (5.4.5)
où H(p) est une fonction de transfert à constantes localisées (paragraphe 5.2.1) et où τ est un retard pur . Si y(t) est la réponse indicielle du système H(p) seul, la réponse indicielle du système G(p) est alors y(t − τ ). On peut ainsi rendre compte d’un comportement temporel, difficilement modélisable par une simple fonction de transfert à constantes localisées (voir identification par la méthode de Strejc, paragraphe 10.2.3). Pour le tracé de Bode d’un tel système, la règle est la suivante :


5.5. Analyse temporelle 69
— le module est le même que |H (jω)| car ∣∣e−jωτ ∣∣ = 1 ;
— la phase du système est arg (H (jω)) − 180 ωτ
π exprimée en degré.
En revanche, la notion de retard pur ne présente aucune difficulté pour un système numérique ; on obtiendrait une fonction de transfert z−τdH(z) où le retard τd s’exprime en nombre d’échantillons.
5.5 Analyse temporelle
5.5.1 Systèmes analogiques
5.5.1.1 1er ordre tout pôle
L’étude du comportement fréquentiel de :
H(p) = 1
1+ p
ω0
= ω0
p + ω0
(5.5.1)
a été faite au 5.2.2. On peut s’intéresser aussi à la réponse temporelle d’un tel système, en particulier la réponse à un échelon 1(t). Il s’agit donc de déterminer le signal temporel associé à une transformée de Laplace égale à :
H (p)
p = ω0
p (p + ω0)
La décomposition en éléments simples donne accès au résultat :
Y (p) = H(p)
p =1
p− 1
p + ω0
L’expression temporelle de la réponse indicielle est alors :
y(t) = (1 − e−ω0t) 1(t) (5.5.2)
On constate ainsi que le pôle P0 = −ω0 détermine directement le comportement temporel du système.
Si l’on note la constante de temps T = 1
ω0
, la fonction de transfert (5.5.1) devient :
H(p) = 1
1 + T p (5.5.3)
La réponse indicielle (5.5.2) (représentée figure 5.10) peut s’écrire en fonction de T comme suit :
T 3T
0, 63
0, 951
t
y(t)
Figure 5.10 – Réponse indicielle d’une fonction de transfert d’ordre 1 sans zéro avec gain unitaire
y(t) =
(
1 − e− t
T
)
1(t) (5.5.4)
Le temps de réponse à 5% de ce système à est de 3T (voir figure 5.10).


70 Chapitre 5. Analyse des performances des systèmes dynamiques
5.5.1.2 2ème ordre tout pôle
L’étude du comportement fréquentiel de :
H(p) = 1
1 + 2ζ p
ω0
+
(p
ω0
)2 (5.5.5)
a été faite au paragraphe 5.2.3. On peut s’intéresser aussi à la réponse temporelle d’un tel système, en particulier la réponse à un échelon unitaire 1(t). Il s’agit donc de déterminer le signal temporel associé à une transformée de Laplace égale à :
H (p)
p = ω02
p (p2 + 2ζω0p + ω02) = ω02
p (p − P1) (p − P2)
La décomposition en éléments simples donne accès au résultat :
Y (p) = H(p)
p =1
p + ω02
P1 − P2
(1
P1 (p − P1) − 1
P2 (p − P2)
)
L’expression temporelle de la réponse indicielle est alors :
y(t) =
(
1 + ω02
P1 − P2
(1
P1
eP1t − 1
P2
eP2 t
))
1(t) (5.5.6)
Cette réponse est tracée sur la figure 5.11 pour ω0 > 0 et :
ζ ∈ {0, 1; 0, 2; 0, 3; 0, 4; 0, 5; 0, 6; 0, 7; 0, 8; 0, 9; 1; 2; 3; 5; 7; 10; 20}
0 2 4 6 8 10 12 14 16 18 20
0
0,2
0,4
0,6
0,8
1
1,2
1,4
1,6
1,8
Echelon d’entrée (trait gras)
ζ = 0, 1
1, 37
D% = 37%
ζ = 20
ω0tm
ω0t
Amplitude
Figure 5.11 – Réponse indicielle d’un système du second ordre
On peut remarquer que pour des amortissements faibles (0 < ζ < 0, 5), le temps du premier maximum noté tm vérifie approximativement :
ω0tm ≈ 3


5.5. Analyse temporelle 71
la relation exacte étant en fait :
tm = π
ω0
√1 − ζ2 (5.5.7)
Pour 0 < ζ < 1, une autre caractéristique de la réponse indicielle est le dépassement, qui est l’écart (amplitude maximale de la sortie − amplitude de la sortie en régime permanent) divisé par l’amplitude de la sortie en régime permanent. On montre qu’il est égal à :
D = exp
(
− πζ
√1 − ζ2
)
(5.5.8)
Lorsque 0 < ζ < 1, les deux pôles P1 et P2 sont complexes conjugués et valent :
P1 = ω0
(
−ζ + j√1 − ζ2
) et P2 = ω0
(
−ζ − j√1 − ζ2
)
La position de ces pôles peut être représentée dans le plan complexe (figure 5.12). On peut noter que l’angle θ qui apparaît sur la figure vérifie sin θ = ζ. Ainsi, pour des amortissements inférieurs à 1, le module des pôles (ω0) détermine approximativement le temps du premier maximum tm de la réponse indicielle (donné par la relation (5.5.7)), et la partie réelle détermine le dépassement D (donné par (5.5.8)).
Re(p)
Im(p)
P1
P2
ω0
θ
−ζω0
Figure 5.12 – Position des pôles d’un système du 2ème ordre, pour ζ < 1
5.5.1.3 2ème ordre avec pôles et zéros
Sans considérer un cas général, observons l’incidence de la position des pôles et des zéros sur les comportements fréquentiel et temporel du système de fonction de transfert :
H(p) = p2 + ω02
p2 + 2ζω0p + ω02
= (p − Z1) (p − Z2)
(p − P1) (p − P2) avec 0 < ζ < 1 (5.5.9)
La position des pôles et des zéros dans le plan complexe est représentée en figure 5.13. On observe deux pôles ω0
(
−ζ ± j√1 − ζ2
) et deux zéros ±jω0. La réponse en fréquence est tracée en figure 5.14 pour :
ζ ∈ {0, 1; 0, 2; 0, 3; 0, 4; 0, 5; 0, 6; 0, 7; 0, 8; 0, 9; 1}
On obtient une famille de filtres réjecteurs d’un signal harmonique de pulsation ω0. La présence des deux zéros a pour effet d’annuler la réponse à la pulsation ω0 soit H (jω0) = 0 quel que soit l’amortissement. Ils sont tous l’approximation d’un filtre idéal de gain 1 à toutes pulsations sauf à ω0 où le gain vaut 0.


72 Chapitre 5. Analyse des performances des systèmes dynamiques
Re(p)
Im(p)
P1
P2
ω0
Z1
Z2
−ζω0
Figure 5.13 – Position des pôles et des zéros de la fonction de transfert 5.5.9
−20
−10
0 ζ = 0, 1
ζ =1
Module (dB)
10−1 100 101
−90
−45
0
45
90
ζ = 0, 1
ζ =1
ω/ω0
Phase (deg)
Figure 5.14 – Réponse d’un filtre réjecteur
On peut montrer que l’intervalle de largeur ∆ω dans lequel :
|H (jω)| <
√2
2 (soit − 3 dB)
vaut ∆ω ≈ 2ω0ζ ; l’approximation est d’autant meilleure que l’amortissement est faible. La réponse indicielle d’un tel système n’est pas la plus intéressante. En revanche, la réponse du système à une entrée u(t) = sin (ω0t) 1(t) donnera une information sur le temps que met le système à tendre vers le régime permanent qui est ici un signal nul (puisque H (jω0) = 0). On a :
U (p) = ω0
p2 + ω02
d’où Y (p) = ω0
p2 + 2ζω0p + ω02 La sortie vaut alors :
y(t) = 1
√1 − ζ2 e−ζω0t sin
(√1 − ζ2ω0t
)
1(t) (5.5.10)


5.6. Conclusion de la partie I 73
La sortie tend d’autant plus lentement vers le régime permanent que l’amortissement est faible.
On obtient une constante de temps τ = 1
ω0ζ associée au terme en exponentielle, qui traduit la
vitesse de convergence vers cet état permanent que l’on souhaite atteindre le plus rapidement possible. Globalement, on observe un compromis entre : — la précision sur la réalisation du filtre (largeur de bande atténuée ∆ω = 2ω0ζ)
— le temps de réponse du système (constante de temps τ = 1
ω0ζ )
Le produit τ ∆ω est constant et vaut 2, ce qui permet d’énoncer pour cet exemple une sorte de principe d’incertitude : ”on ne peut avoir simultanément une bonne précision sur la réponse fréquentielle et temporelle”.
5.6 Conclusion de la partie I
Ici s’achève la partie I sur la représentation et l’analyse de modèles de systèmes à états continus. En synthèse, cette partie a permis de présenter, pour des systèmes à temps continu ou discret respectivement :
— la représentation d’un système sous forme d’état, constituée d’une équation d’évolution donnant la variation des variables d’état au cours du temps et d’une équation de sortie. Même si elle est loin de couvrir tous les modèles possibles (par exemple les équations à dérivées partielles ne s’y retrouvent pas), cette représentation offre un cadre de modélisation assez général puisqu’elle peut englober des modèles non-linéaires et variants dans le temps.
— l’étude de propriétés des points d’équilibre de systèmes non linéaires sous forme de représentation d’état : au-delà de la définition formelle des différents types de stabilité, on a vu que leur étude passe généralement par une linéarisation du système non linéaire autour d’un point d’équilibre afin de se ramener au cas d’un système linéaire.
— le cas particulier des systèmes linéaires et invariants dans le temps, traité de manière approfondie car de nombreux résultats peuvent être obtenus analytiquement dans ce cas, alors que la résolution ne peut généralement être traitée que de manière numérique lorsque cette hypothèse n’est pas vérifiée. On a vu que les SLI peuvent se représenter sous forme d’une fonction de transfert dont les propriétés permettent ainsi des conclusions sur la stabilité du point d’équilibre.
— l’analyse fréquentielle (via le diagramme de Bode) ou temporelle (via la réponse indicielle) d’un système linéaire invariant dans le temps.
Ces propriétés, qui caractérisent le comportement de tels systèmes, seront exploitées en partie III lorsqu’il s’agira de traiter le problème d’identification. En effet, cela nous permettra, face à un système réel que l’on cherchera à représenter par un modèle, d’utiliser les propriétés observées sur le système réel pour en déduire une forme adéquate de modèle à proposer. Nous allons à présent passer à la description de la représentation d’une autre classe de systèmes, les systèmes à états discrets.




Deuxième partie
Modélisation des systèmes à état
discret
75




Chapitre 6
Introduction sur la modélisation des
systèmes à état discret
6.1 Problématique
Dans de nombreux systèmes complexes, l’enchaînement des tâches effectuées par le système provient d’évènements tels que l’arrivée d’un signal, la fin d’une tâche précédente, la libération d’une ressource, le changement d’un mode opératoire, etc. La survenue d’un tel évènement entraîne ainsi des phénomènes tels que la concurrence pour une même ressource, la synchronisation de tâches ou encore la saturation de certaines variables. De tels systèmes sont particulièrement présents dans les réseaux informatiques, les systèmes de production et de logistique, les réseaux de transport, les réseaux de communication, les réseaux de régulation biologiques et nous en verrons de nombreux exemples dans ce cours. De tels systèmes ne peuvent généralement pas se modéliser de façon simple à l’aide des outils abordés dans les chapitres précédents traitant de la modélisation des systèmes à état continu. Il est en particulier difficile de représenter le système par un jeu d’équations différentielles de la forme  ̇x(t) = f (x(t), u(t)) où x(t) représente l’état du système et u(t) les entrées, car l’état x(t) subit des variations instantanées en réponse aux évènements. Nous allons ainsi voir dans cette partie certaines méthodes permettant d’appréhender la modélisation des systèmes à évènements discrets
6.2 Motivation et structure de la partie II
Afin d’introduire de manière informelle les concepts et notions traités dans ce chapitre, nous considérons une marche aléatoire dans le plan sous la forme d’un jeu à 4 joueurs. Un mobile, supposé ponctuel et initialement placé à l’origine, peut ainsi se déplacer dans un espace à deux dimensions (x1(t), x2(t)) sous l’action de 4 joueurs N, E, S, O ayant pour objectif d’emmener le mobile en un point particulier de l’espace, différent pour chaque joueur et tenu secret. Chaque joueur dispose d’un bouton :
— lorsque le joueur N presse son bouton, le mobile se déplace d’une unité dans le sens des x2(t) croissants ;
— lorsque le joueur E presse son bouton, le mobile se déplace d’une unité dans le sens des x1(t) croissants ;
— lorsque le joueur S presse son bouton, le mobile se déplace d’une unité dans le sens des x2(t) décroissants ;
— lorsque le joueur O presse son bouton, le mobile se déplace d’une unité dans le sens des x1(t) décroissants.
L’état du jeu est donné par la position du mobile dans le plan (x1(t), x2(t)). L’évolution du jeu est entièrement définie par la séquence d’évènements. La figure 6.1 présente ainsi l’évolution du jeu en réponse à la séquence N → E → S → S → O → S → O.
77


78 Chapitre 6. Introduction sur la modélisation des systèmes à état discret
x1
x2
0
1
1
(N )
(E)
(S)
(O) (S)
(O) (S)
Figure 6.1 – Exemple de marche aléatoire
Nous voyons dans cet exemple que le temps n’apparaît pas de façon explicite. La date à laquelle se produit l’évènement n’a pas d’influence sur l’évolution du mobile. On parlera ici d’un système à évènement discret non temporisé. La taille de l’espace d’état est ici a priori infinie (c’est-àdire que x1(t) et x2(t) ne sont a priori pas bornés). Si l’on ajoute au jeu la règle que le mobile doit rester dans le domaine du plan défini par −1 ≤ x1(t) ≤ 1 et −1 ≤ x2(t) ≤ 1 (les joueurs n’ont pas le droit de provoquer un mouvement qui ferait sortir le mobile de ce domaine), on peut représenter l’évolution du système sous la forme d’un automate représenté sur la figure 6.2, dans laquelle, pour simplifier, on fait l’hypothèse que deux joueurs ne peuvent appuyer sur leur bouton exactement au même instant. L’automate présenté dans cette figure contient tous les mouvements possibles dans les intervalles spécifiés, et non seulement la séquence indiquée figure 6.1. Nous présenterons formellement les systèmes à évènements discrets non temporisés, et en particulier ce type de modélisation par automate fini dans le chapitre 7.
(−1, 1)
(E)
(O)
(0, 1)
(E)
(O)
(1, 1)
(N ) (S) (N ) (S) (N ) (S)
(−1, 0)
(E)
(O)
(0, 0)
(E)
(O)
(1, 0)
(N ) (S) (N ) (S) (N ) (S)
(−1, −1)
(E)
(O)
(0, −1)
(E)
(O)
(1, −1)
Figure 6.2 – Système à évènement discret non temporisé. Exemple d’automate pour modéliser la marche aléatoire
Supposons désormais que l’on rajoute une nouvelle règle au jeu, qui doit se jouer en un temps limité, avec un délai maximum de réflexion autorisé pour chaque joueur durant la partie. Dans ce cas, les dates auxquelles se produisent les évènements deviennent importantes et vont influer sur l’évolution future du jeu. On peut par exemple représenter l’évolution du jeu sous la forme d’un chronogramme comme sur la figure 6.3. Dans cette figure, à partir de l’état initial (0, 0), à l’instant t1, le mobile fait un saut d’un pas vers le Nord, arrivant ainsi en (0, 1) jusqu’au moment t2, où il fait un saut vers l’Est jusqu’à (1, 1) et ainsi de suite. Nous aborderons les systèmes à évènements discrets dits temporisés dans le chapitre 8. Les joueurs confirmés décident alors de complexifier leur jeu. La pression sur leur bouton d’action n’engendre plus alors un saut dans l’espace, mais une translation rectiligne uniforme (par exemple) dans leur direction d’action. Ainsi, si le joueur N appuie sur son bouton à l’instant t0,


6.2. Motivation et structure de la partie II 79
x1
−2
−1
0
1
2
x2
−2
−1
0
1
2
(N, t1) (E, t2) (S, t3) (S, t4) (O, t5) (S, t6) (O, t7)
Figure 6.3 – Systèmes à évenements discrets temporisés. Représentation par chronogramme de la marche aléatoire
l’évolution du mobile devient (a > 0 et fixé à l’avance) :
x ̇ 1(t) = 0 → x1(t) = x1(t0)
x ̇ 2(t) = +a → x2(t) = x2(t0) + a(t − t0) (6.2.1)
et ce jusqu’à ce qu’un autre joueur décide d’appuyer sur son bouton. Un tel système est dit système hybride. L’arrivée d’un évènement entraine une modification brusque de la dynamique continue du système. La modélisation de tels systèmes sera abordée à la section 8.5 du chapitre 8.
Enfin, le jeu présenté ici est un jeu autonome, dans le sens où aucun signal externe ne vient agir sur le mouvement du mobile. On peut tout à fait imaginer qu’un évènement extérieur (sous la forme de l’apparition d’un signal exogène par exemple) vienne modifier l’évolution du système : à une date aléatoire un mauvais génie viendra décaler la position du mobile d’une unité, modifier la valeur du paramètre a, etc. La simulation d’évènements discrets nécessite l’introduction de distributions d’évènements discrets telles que les lois de Rayleigh ou de Poisson que nous verrons au chapitre 9.
Remarque 6.2.1. Attention, il ne faut absolument pas confondre la notion de systèmes à évènements discrets avec, par exemple, les systèmes échantillonnés vus dans la partie de modélisation des systèmes à état continu, même si dans cet exemple introductif très simple il serait possible de modéliser le système de la marche aléatoire par une équation d’état discrète de la forme xk+1 = f (xk, uk) en considérant que l’indice k ne fait pas référence au temps, mais à la kième évolution du système. Pour les systèmes à évènements discrets, c’est bien la survenue d’évènements qui provoque les changements d’état.


80 Chapitre 6. Introduction sur la modélisation des systèmes à état discret
6.3 Définition des systèmes à évènements discrets
A partir de l’exemple précédent, nous pouvons définir un système à évènements discrets comme suit.
Définition 6.3.1
Un Système à Evénements Discrets (SED) est un système défini par un espace d’états discrets et des évolutions, i.e. des trajectoires, fondées sur une succession d’états et de transitions.
Plusieurs points sont ici à souligner :
— La notion d’espace d’état est la même que celle qui a été utilisée dans la modélisation des systèmes à états continus par l’intermédiaire de la représentation d’état : la connaissance de l’état du système à un instant t0 est suffisante pour en prédire le comportement futur dès lors que l’on connait les entrées qui sont appliquées au système.
— Cet espace d’état est discret, ce qui veut dire que le nombre des états possibles est dénombrable ; il peut être fini ou infini.
— Les évènements sont dits discrets s’ils apparaissent à des instants discrets du temps, c’est-àdire que leur apparition est instantanée et déclenche une transition instantanée de l’état.
— Des symboles, définis par les éléments d’un alphabet et appelés évènements, sont associés aux transitions.
Si l’on s’intéresse seulement à l’ordre de récurrence tout en ignorant le temps, des SED nontemporisés peuvent être élaborés à base d’automates à états finis, réseaux de Petri non-temporisés, Grafcet, etc. Des informations temporelles cruciales peuvent être intégrées au système afin de spécifier les trajectoires d’évènements et leurs instants. Ces systèmes peuvent être représentés par :
— Modèles temporisés non-stochastiques où le temps est connu a priori : automates temporisés, réseaux de Petri temporisés, algèbre min-max etc.
— Modèles temporisés stochastiques fondés sur des hypothèses statistiques : chaînes de Markov, réseaux de files d’attente, processus semi-markoviens généralisés, réseaux de Petri stochastiques.


Chapitre 7
Modélisation des systèmes à
évènements discrets non temporisés
Ce chapitre permet de formaliser ce qu’est un modèle non temporisé de système à évènements discrets et d’en donner les principales caractéristiques. Les éléments de base de la modélisation de ce type de systèmes par des automates ou par des réseaux de Petri non-temporisés seront abordés par la suite.
Définition 7.0.1
Un système à évènements discrets est dit non temporisé lorsque seule la séquence des évènements est considérée, les dates d’occurrences n’ayant pas d’effet.
7.1 Modélisation par automate
7.1.1 Définition et exemple d’automate
Nous formalisons ici la notion d’automate introduite dans la section 6.2 à l’aide de l’exemple de la marche aléatoire. Définition 7.1.1
Un automate à états finis, également appelé automate fini A peut être représenté par un quadruplet A = (Q, Σ, φ, Q0), avec : — Q un ensemble fini de sommets représentant des états discrets ; — Σ un ensemble de symboles (évènements) appelés alphabet ;
— φ la relation de transition définie de Q × Σ dans Q. Cette relation φ peut être également définie comme un ensemble de transitions entre les états, définie alors par un triplet (sommet source, évènement, sommet but ) ; — Q0 ⊂ Q un ensemble d’états initiaux.
Ainsi, si le système se trouve dans un état q1 et qu’un évènement représenté par le symbole σ se produit, il évoluera vers l’état q2 tel que q2 = φ(q1, σ). La fonction φ peut n’être que partielle si certaines transitions ne sont pas définies. Il peut donc être plus rigoureux de définir la transition φ non pas comme une fonction, mais comme une partie de Q × Σ × Q, c’est-à-dire φ ⊂ Q × Σ × Q, avec la convention suivante : si (q1, σ, q2) ∈ φ, alors le symbole σ fait passer l’automate de l’état q1 à l’état q2. Cette représentation est nécessaire dans le cas d’automates non déterministes (cf. définition 7.1.2). Un automate se représentera de façon très naturelle par un graphe dont les noeuds correspondront aux états et les transitions correspondront aux arcs. Les états initiaux sont généralement représentés par une flèche entrante sur le graphe. On parlera d’automate fini si l’ensemble Q est fini, d’automate infini dans le cas contraire.
81


82 Chapitre 7. Modélisation des systèmes à évènements discrets non temporisés
Exemple 7.1.1. Nous considérons ici le cas d’un (petit !) loueur de véhicules électriques. Le loueur possède 2 véhicules. Nous supposons pour simplifier qu’un véhicule loué nécessite forcément une recharge avant de pouvoir être loué à nouveau. L’état de l’ensemble de véhicules est donc caractérisé par le nombre de véhicules disponibles chargés nc et le nombre de véhicules déchargés nd. Nous noterons l’état défini par le vecteur X = (nc, nd). Les évènements pouvant faire évoluer le système sont la location d’un véhicule, notée loc ; le retour d’un véhicule, noté ret ou la recharge d’un véhicule, notée ch. Nous supposerons que : 1. initialement le loueur possède deux véhicules chargés prêt à la location ; 2. pendant la journée, les voitures sont louées une par une et non pas les deux voitures en même temps ; 3. toutes les voitures sont retournées le soir. La modélisation du système peut se faire à l’aide de l’automate représenté sur la figure 7.1.
(0, 0) (1, 0) (0, 1)
(2, 0) (1, 1) (0, 2)
loc
loc
ret
ch
ret
ch
loc
ch
ret
Figure 7.1 – Automate pour la modélisation de l’ensemble de véhicules
Pour reprendre les notations de la définition 7.1.1, nous avons donc :
— Q = {(0, 0), (0, 1), (1, 0), (1, 1), (2, 0), (0, 2)} ;
— Σ = {loc, ret, ch} ;
— φ peut être définie par simple énumération, par exemple φ((1, 1), ch) = (2, 0). Si l’on considère la définition comme ensemble de transitions, nous avons :
φ = { ((2, 0), loc, (1, 0)) , ((1, 0), loc, (0, 0)) , ((0, 0), ret, (0, 1)) , ((0, 1), ch, (1, 0)) , ((1, 0), ret, (1, 1)) , ((1, 1), ch, (2, 0)) ,
((0, 1), ret, (0, 2)) , ((0, 2), ch, (1, 1)) , ((1, 1), loc, (0, 1))}
— Q0 = {(2, 0)}.
Selon les applications, on pourra ajouter un cinquième élément Qf ⊂ Q à la définition de l’automate qui correspondra aux états finaux de l’automate. On parle d’états marqués pour ces états. Ces états seront représentés sur l’automate par un double cercle. Dans notre exemple, on peut imaginer que le loueur souhaite que ses deux véhicules soient de retour en fin de journée pour pouvoir les recharger dans la nuit. L’ensemble des états marqués est alors Qf = {(2, 0), (1, 1), (0, 2)}. Nous pouvons remarquer que la notion d’évènement est très générale, puisqu’elle peut correspondre à l’arrivée d’un signal ou d’une grandeur extérieure au système (l’utilisateur a appuyé sur un bouton par exemple) ou à une condition satisfaite par un signal interne au système ("le niveau d’eau a atteint la hauteur désirée"). Il existe différentes variantes à la définition de l’automate telle que donnée à la définition 7.1.1 lorsque l’on souhaite ajouter explicitement des entrées et des sorties. On trouve ainsi les extensions suivantes :
— Automate de Moore : dans ce cas, on trouve une fonction qui associe à chaque état une valeur pour la (ou les) sortie(s) du système. La sortie ne dépend ainsi que de l’état (l’évènement de sortie est émis lorsque l’automate rentre dans l’état). Conventionnellement, la sortie est indiquée en gras au dessus de l’état ; elle peut correspondre par exemple à une information délivrée par un capteur à l’arrivée dans cet état.
— Automate de Mealy : la sortie dépend d’un état et d’un évènement d’entrée reçu dans cet état. Ainsi, dans un état x si l’on reçoit un évènement d’entrée ei , il y aura une transition


7.1. Modélisation par automate 83
vers un état y et émission d’un évènement de sortie eo lors de la transition. Les transitions sont étiquetées avec des évènements de la forme ’évènement d’entrée ei / évènement de sortie eo’.
7.1.2 Propriétés des automates
7.1.2.1 Caractère déterministe / non déterministe
Définition 7.1.2
Un automate sera dit déterministe si les deux conditions suivantes sont remplies : — il n’y a qu’un seul état initial, c’est-à-dire Q0 = {q0} ; — à partir d’un état, un même symbole ne peut conduire que dans un seul état, c’est à dire :
∀q ∈ Q, ∀σ ∈ Σ, ((q, σ, q1) ∈ φ & (q, σ, q2) ∈ φ) ⇒ q1 = q2 (7.1.1)
Dans le cas contraire, on parlera d’automates non déterministes ou stochastiques. Ainsi, il est possible que pour certains automates un même symbole puisse potentiellement entraîner plusieurs transitions (bien sûr une seule transition sera effectuée), ou bien que certaines transitions soient spontanées (la transition a lieu sans qu’aucun évènement ne soit apparu). Du point de vue de la modélisation, ce type d’automate peut correspondre à des incertitudes de modélisation (on ne sait pas par exemple avec certitude quelle va être la conséquence exacte d’un évènement, un évènement peut ne pas être mesuré, etc.). Du point de vue de la théorie des automates, les applications des automates non déterministes sont nombreuses, mais leur étude complète dépasse le cadre de ce cours.
7.1.2.2 Accessibilité, co-accessibilité, complément
Reprenons tout d’abord la notion de fonction de transition, donnée à la définition 7.1.1. Nous pouvons étendre cette définition de la transition pour une suite de symboles reçus à partir d’un état q0. En effet, si l’automate reçoit une suite de symboles valides (au sens où toutes les transitions correspondantes sont définies) σ1σ2...σn à partir d’un état q0, le système évoluera jusqu’à l’état qn défini par φ(φ(...φ(φ(q0, σ1), σ2), ...), σn). On notera de façon abrégée la lecture de cette suite de symboles σ1σ2...σn par φ(q0, σ1σ2...σn) = qn.
Définition 7.1.3
Un état q sera dit accessible depuis un état initial q0 s’il existe une suite de symboles σ1σ2...σn valide telle que φ(q0, σ1σ2...σn) = q.
Un automate dont tous les états sont accessibles sera dit accessible. Clairement, on peut retirer de l’automate de départ la partie non accessible et obtenir un automate dont le comportement sera identique. Du point de vue de la modélisation d’un système à évènements discrets, trouver des états non accessibles est souvent le signe d’une erreur dans le processus qui a conduit à ce modèle.
Définition 7.1.4
Un état q sera dit co-accessible s’il existe une suite de symboles σ1σ2...σn valide permettant d’aller dans l’un des états marqués, c’est à dire que φ(q, σ1σ2...σn) = qm avec qm ∈ Qf .
Si l’automate obtenu en éliminant la partie non co-accessible est identique à l’automate de départ, alors l’automate est dit co-accessible.
Remarque 7.1.1. Il ne suffit pas que tous les états soient co-accessibles pour que l’automate le soit. En effet, supposons qu’un automate ait deux états marqués qf1 et qf2. Tous les états peuvent être co-accessibles, mais avoir seulement des chemins conduisant à qf1, tandis que qf2 n’est pas accessible.


84 Chapitre 7. Modélisation des systèmes à évènements discrets non temporisés
Si un automate n’est pas co-accessible, cela peut souvent être le signe d’un système mal conçu. En effet, les états marqués sont souvent ceux vers lesquels on souhaite que le système évolue. Dire qu’un état n’est pas co-accessible signifie qu’il est possible que le système soit arrivé dans un état à partir duquel il n’est pas possible de le faire évoluer vers un état marqué.
Définition 7.1.5
Un automate sera dit élagué s’il est à la fois accessible et co-accessible.
L’élaguage d’un automate consistera ainsi à prendre successivement la partie accessible et coaccessible d’un automate, ces deux opérations pouvant être faites dans un ordre quelconque.
Exemple 7.1.2. Afin d’illustrer ces notions, considérons l’automate initial représenté sur la figure 7.2.
q0
q1
q2
q3 q4
q5
q6
a
b
a
c
c
b
c
a a
b
Figure 7.2 – Automate initial
L’état 6 n’est pas accessible à partir de l’état initial q0. Pour obtenir un automate accessible (représenté sur la figure 7.3), on le supprime ainsi que les transitions sortant de cet état.
q0
q1
q2
q3 q4
q5 a
b
a
c
c
b
c
a
Figure 7.3 – Automate accessible
Si par ailleurs on repart de l’automate de la figure 7.2, la recherche de la partie co-accessible conduit à l’automate représenté sur la figure 7.4 où on trouve tous les états permettant d’aller dans l’état marqué q2. Dans cet exemple, les états q3, q4 et q5 ne permettent pas des transitions vers l’état marqué. Enfin, si on applique successivement les deux opérations, on obtient l’automate élagué de la figure 7.5.


7.1. Modélisation par automate 85
q0
q1
q2 q6
a
b
c
b
Figure 7.4 – Automate co-accessible
q0
q1
q2
a
b
c
Figure 7.5 – Automate élagué
7.1.3 Composition des automates
Nous avons vu dans les chapitres précédents qu’un système peut être vu comme une architecture de sous-systèmes en interactions. Il est donc nécessaire de pouvoir hiérarchiser un modèle (dans le sens où un automate peut être décomposé en sous-automates) ou bien de combiner plusieurs automates pour les faire évoluer ensemble.
7.1.3.1 Automates hiérarchiques
Définition 7.1.6
Un automate est dit hiérarchique lorsque certains de ses états sont eux-mêmes des automates.
Nous ne rentrerons pas ici dans une présentation détaillée des machines d’état ou statecharts, notions par ailleurs reprises dans UML et qui seront abordées dans le cours de Modélisation Systèmes de deuxième année. De manière très intuitive, nous pouvons étendre la notion des automates, en considérant la représentation d’un état donnée sur la figure 7.6. Il apparaît assez évident que ce qui est repris par les termes "actions" et "activités" à l’intérieur d’un état peuvent renvoyer à une description du comportement de cet état sous forme d’un automate.
Exemple 7.1.3. La figure 7.7 donne un exemple d’automate hiérarchique pour le fonctionnement d’une machine. Au niveau supérieur, la machine peut être dans l’un des trois états suivants Q = {a, n, d} :
— a : la machine est à l’arrêt ;
— n : la machine est dans le mode de fonctionnement normal ;
— d : la machine est en défaillance.
Entre ces états, on trouve les transitions associées aux évènements suivants Σ = {μ, α, π, ρ} :
— μ : démarrage de la machine ;
— α : demande d’arrêt de la machine ;


86 Chapitre 7. Modélisation des systèmes à évènements discrets non temporisés
Actions à faire en entrant
Activités dans l’état
Actions à faire en sortant
Depuis états précédents
e3/A3 e2/A2
e1/A1
Evénement déclenchant la transition
Actions à faire durant la transition
Figure 7.6 – Description générale d’un état
ad
n1 n2 n3
μ
ρ
f1
f2
α
f3
n
π
Figure 7.7 – Exemple d’automate hiérarchisé
— π : apparition d’un défaut ;
— ρ : réparation de la machine.
Un exemple de transition associée à un évènement dans le niveau supérieur est le suivant :
φsup(a, μ) = n.
L’état initial est q0 = {a}. Au niveau inférieur, les états n1, n2, n3 et les transitions associées aux évènements f1, f2 et f3 permettent de décrire le fonctionnement de la machine dans le mode normal (par exemple φinf (n1, f1) = n2).
7.1.3.2 Produit synchrone d’automates
Nous considérons ici deux automates (incluant des états marqués) notés :
A1 = (Q1, Σ1, φ1, Q01, Qf1) et A2 = (Q2, Σ2, φ2, Q02, Qf2).
Définition 7.1.7
Le produit synchrone des automates A1 et A2, noté A1 × A2 est défini par : A1 × A2 = Ac (Q1 × Q2, Σ1 ∩ Σ2, φprod, Q01 × Q02, Qf1 × Qf2), avec :
φprod((q1, q2), e) =
{ (φ1(q1, e), φ2(q2, e)) si les deux transitions sont définies
non définie sinon (7.1.2)


7.1. Modélisation par automate 87
La notation Ac(.) signifie que l’on ne garde que la partie accessible de l’automate résultant. Plusieurs faits sont en outre à remarquer :
— l’opération × ne prend en compte que les évènements qui appartiennent à l’intersection des ensembles considérés Σ1 ∩ Σ2.
— le produit est nécessairement synchrone dans le sens où un évènement arrive exactement au même instant au niveau des deux automates entrainant une transition simultanée.
— tous les évènements privés (c’est-à-dire n’appartenant qu’à l’un des deux automates) sont absents du produit.
Exemple 7.1.4. On considère les deux automates donnés sur la figure 7.8.
xy
z
c
a
a, c
ab
b
01
a
b
b
a
Figure 7.8 – Automates utilisés pour illustrer le produit synchrone
L’état initial du produit de ces deux automates (également appelé automate produit) est (x, 0) correspondant au seul couple possible d’états initiaux pour les deux automates. A partir de cet état, on voit que la seule transition simultanément possible pour les deux automates est a, qui conduit à l’état (x, 1). Une fois dans cet état, de nouveau une seule transition est possible simultanément sur les deux automates : l’évènement a fait ainsi rester l’automate dans l’état (x, 1). Il n’y a plus de nouvel état à analyser, le produit synchrone obtenu est représenté sur la figure 7.9. Les états x pour le premier automate et 1 pour le deuxième étant des états marqués, l’état (x, 1) est marqué dans l’automate produit.
x, 0 x, 1
a
a
Figure 7.9 – Produit synchrone des deux automates
7.1.3.3 Parallélisation d’automates
On reprend ici les deux automates A1 = (Q1, Σ1, φ1, Q01, Qf1) et A2 = (Q2, Σ2, φ2, Q02, Qf2). La parallélisation consiste à faire évoluer les deux automates de façon partiellement synchrone en considérant tous les évènements qui peuvent se produire pour l’un ou l’autre des automates.
Définition 7.1.8
La parallélisation des automates A1 et A2, notée A1||A2 est définie par :
A1||A2 = Ac (Q1 × Q2, Σ1 ∪ Σ2, φpar, Q01 × Q02, Qf1 × Qf2) ,
avec :
φpar((q1, q2), e) =


(φ1(q1, e), φ2(q2, e)) si les deux transitions sont définies (φ1(q1, e), q2) si la transition n’est définie que pour A1 (q1, φ2(q2, e)) si la transition n’est définie que pour A2 non définie sinon
(7.1.3)


88 Chapitre 7. Modélisation des systèmes à évènements discrets non temporisés
On notera que la parallélisation des deux automates est partiellement synchronisée dans le sens où un évènenement présent simultanément sur les deux automates doit se déclencher exactement au même instant pour que ce type de transition ait lieu dans l’automate résultant.
Exemple 7.1.5. La figure 7.10 présente le résultat de la parallélisation des deux automates représentés sur la figure 7.8 (avec Q1 = {x, y, z} et Q2 = {0, 1}) :
Q = {(x, 0), (x, 1), (y, 0), (y, 1), (z, 0), (z, 1)}.
Les états (x, 1) et (z, 1) correspondent aux états marqués. En parallélisant ces deux automates, on peut voir qu’à partir de l’état (x, 0) si l’on applique la transition associée à l’évènement a on arrive dans l’état (x, 1), en revanche la transition associée à l’évènement b permet de rester dans l’état (x, 0). Retrouver l’ensemble de l’automate de la figure 7.10 est laissé comme exercice au lecteur.
x, 0 z, 0 y, 0
x, 1 z, 1 y, 1
c
a
b
c
b
a
b
c
a
bb
a, c
b
a
a
Figure 7.10 – Parallélisation des deux automates
7.1.4 Analyse d’un système à évènements discrets non temporisé représenté par un automate
7.1.4.1 Simulation et bisimulation d’automates
Considérons deux automates A1 et A2 définis sur un même ensemble d’évènements Σ. De manière informelle, on dira que A1 simule A2 si toute suite d’évènements exécutée par A2 peut également être exécutée par A1. Si réciproquement A2 simule A1 (c’est-à-dire que toute suite d’évènements exécutée par A1 peut l’être également par A2), les deux automates sont dits bisimilaires. Plus formellement, on a la définition suivante de la bisimilarité, en se limitant au cas d’automates déterministes : Définition 7.1.9
Soient deux automates A1 = (Q1, Σ, φ1, Q01, Qf1) et A2 = (Q2, Σ, φ2, Q02, Qf2). Ces deux automates sont bisimilaires s’il existe une relation R binaire de Q1 ×Q2, au sens où (q1, q2) ∈ R signifie que les deux états q1 et q2 sont en relation R, ce que nous noterons q1Rq2, telle que :
— les états initiaux Q01 et Q02 sont en relation (pour un automate déterministe il n’y a qu’un seul état initial) ; — pour tout état q1 ∈ Q1, il existe q2 ∈ Q2 tel que q1Rq2 ; — pour tout état q2 ∈ Q2, il existe q1 ∈ Q1 tel que q1Rq2 ;
— si q1Rq2 et σ ∈ Σ, si q3 = φ1(q1, σ) est défini, alors q4 = φ2(q2, σ) est défini et q3Rq4 ;
— si q1Rq2 et σ ∈ Σ, si q4 = φ2(q2, σ) est défini, alors q3 = φ1(q1, σ) est défini et q3Rq4 ; — pour les états marqués, si q1Rq2, alors (q1 ∈ Qf1 ⇔ q2 ∈ Qf2).
Ces notions sont particulièrement intéressantes pour aborder des problèmes de simplification ou réduction de modèle.


7.1. Modélisation par automate 89
7.1.4.2 Deadlock et livelock
Définition 7.1.10
Le deadlock ou blocage fatal consiste en une situation où il n’y a plus d’évolution possible alors que l’automate est arrivé dans un état non marqué.
Définition 7.1.11
Le livelock ou blocage vivant caractérise une situation où un sous-ensemble d’états non marqués devient le seul accessible.
L’évolution future de l’automate reste alors confinée dans ce seul sous-ensemble. Le blocage n’est pas fatal car l’état peut encore évoluer sous l’effet des évènements, mais l’automate ne peut plus atteindre un état marqué.
Exemple 7.1.6. La figure 7.11 présente l’exemple d’un automate dans lequel :
— l’état q4 constitue un deadlock ;
— les sous-ensembles formés par les états q1 et q3 constituent un livelock.
q0
q1
q2
q3
q4
s
m
b
s
as
m
Figure 7.11 – Exemple d’automate présentant un deadlock et un livelock
La détermination de ces situations permet d’analyser le bon fonctionnement d’un système. Ces notions sont bien sûr liées aux notions d’atteignabilité ou d’accessibilité vues précédemment. Elles trouvent également un large champ d’application dans les problématiques liées au diagnostic et à la sûreté de fonctionnement.
7.1.5 Utilisation de la notion de langage par les automates
Bien qu’elle ne soit pas primordiale dans une optique de modélisation, la notion de langage est d’importance majeure dans la théorie des automates à laquelle elle est souvent associée. Nous en présentons ici quelques aspects et les liens naturels qui existent avec les automates.
Définition 7.1.12
On appelle alphabet, noté Σ dans la suite, un ensemble, fini ou infini, de lettres ou de symboles.
Définition 7.1.13
Un mot u est un ensemble fini de lettres de Σ. Sa longeur est notée |u|. On note Σ∗ l’ensemble des mots finis qui peuvent être formés à partir des lettres de Σ.
Le mot vide est très souvent noté ε. De nombreuses opérations peuvent être définies sur les mots. L’un des plus importantes est la concaténation de deux mots u et v qui permet d’obtenir un nouveau mot w = u.v, tel que :
w(i) =
( u(i), si i ≤ |u|
v(i − |u|), si |u| + 1 ≤ i ≤ |u| + |v|
)
(7.1.4)


90 Chapitre 7. Modélisation des systèmes à évènements discrets non temporisés
Définition 7.1.14
Un langage L est un ensemble fini ou infini de mots, c’est-à-dire que L ⊂ Σ∗.
Exemple 7.1.7. Si Σ = {ε, a, b, c}, L1 = {ε, a, aab, ca, bc} est un langage (fini). L2 = {combinaisons de a et b} = {ε, a, b, aa, bb, ab, ba, bba, aab, aba...} est un langage (infini).
De nombreuses opérations existent également sur les langages (union, intersection, par exemple, dès lors qu’il s’agit d’opérations d’union ou d’intersection sur des ensembles). En particulier, la concaténation de langages revêt une grande importance. La concaténation de langage L1 et L2 est ainsi donnée par :
L1 ⊂ Σ∗, L2 ⊂ Σ∗, L1L2 = {w = u.v, u ∈ L1, v ∈ L2} (7.1.5)
Définition 7.1.15
La fermeture par préfixe L d’un langage L est définie de la façon suivante :
L ⊂ Σ∗, L = {s ∈ Σ∗|∃t ∈ Σ∗, st ∈ L} (7.1.6)
Il s’agit de l’ensemble des préfixes des mots de l’alphabet L. Généralement L ⊂ L (il suffit que ε ∈ L). Si L = L, l’alphabet L est dit fermé (ou clos) par préfixe. On définit enfin la fermeture de Kleene de L (aussi nommée fermeture itérative) par :
L∗ = {ε} ∪ L ∪ LL ∪ LLL ∪ ... (7.1.7)
On remarquera que l’on a utilisé la même notation, Σ, pour l’ensemble des symboles entrant dans la définition d’un automate et l’alphabet permettant de définir un langage. En effet, si l’on considère les symboles d’un automate comme un alphabet, les suites de transitions permises par un automate vont constituer des mots reconnus par l’automate. Ainsi, la question "comment créer un automate reproduisant un langage donné ?" renverra-t-elle à la phase de modélisation d’un système, tandis que la question "quel est le langage parlé par cet automate ?" renverra à la phase d’analyse des propriétés du modèle. Considérons un automate A = (Q, Σ, φ, Q0, Qf ). Le langage reconnu par l’automate est défini par : L(A) = {s ∈ Σ∗|∃q0 ∈ Q0 pour lequel φ(q0, s) est défini} (7.1.8)
On rappelle que pour un automate déterministe l’état initial est unique. Le langage marqué par l’automate est quant à lui donné par :
Lm(A) = {s ∈ Σ∗|∃q0 ∈ Q0 pour lequel φ(q0, s) ∈ Qf } (7.1.9)
De nombreuses propriétés des automates peuvent être analysées en utilisant cette notion de langage. Ces approches sortent néanmoins du cadre de ce cours traitant des aspects de modélisation des systèmes à évènements discrets.
7.2 Modélisation par réseau de Petri non temporisés
Cette partie est très largement inspirée du polycopié (Pierre Chlique, 2000), dont elle reprend de très larges extraits. Les réseaux de Petri constituent une alternative aux automates à états finis pour la représentation des systèmes à évènements discrets. Ils sont en particulier bien adaptés à la modélisation des processus ayant des activités parallèles. Leur définition dans les années soixante répondait à un besoin d’analyse et de validation des programmes conçus pour les machines multiprocesseurs. Ils restent actuellement largement utilisés pour la modélisation des activités des systèmes temps réel. Nous définirons tout d’abord dans ce chapitre les réseaux de Petri simples autonomes. Ceux-ci permettent de modéliser le comportement de systèmes isolés et présentent surtout un ensemble de propriétés vérifiables.